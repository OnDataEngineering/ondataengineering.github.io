<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>The Week That Was - 14/04/2017</title><link>http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</link><pubDate>Fri, 14 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s the Easter holidays here in the UK, so no technology summary today, but let’s recap the last week before we forget everything we looked at.&lt;/p&gt; &lt;p&gt;This week, we’ve been looking at the Cloudera’s closed source products - &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;, their tool for creating and managing CDH hadoop clusters, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, a set of products for data management, data encryption and helping migrate SQL workloads to Hadoop, and &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, for doing CDH Hadoop in the cloud. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;The philosophical debate between Cloudera and Hortonworks on the used of closed source software is an interesting one, and lends almost a personal element to their commercial rivalry. The general view is that Cloudera have added closed source software into their offering to increase lock in, but I’m not entirely convinced by this - the cost of moving from Cloudera Manager/Navigator to an alternative doesn’t feel like it significantly impacts the fundamental costs of migrating from one distribution to another. Does it provide extra encouragement for companies to take up subscription licences - again I’m not entirely convinced, the risk with not having commercial support for critical systems is likely to be the driver here. Cloudera’s stated view is that it’s protection for their investment in Hadoop open source projects, to prevent a large company with deep pockets competing with them by distributing the open source software that they’ve put so much investment into. What’s clear is that most of the arguments are ideological in nature - I think if you look at it impartially the use of closed source software by Cloudera is unlikely to significantly impact any selection process.&lt;/p&gt; &lt;p&gt;And so on to the products themselves. I feel like I’ve probably done &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; a slight disservice in it’s technology summary - cold hard facts on how it compares to &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt; seem to be pretty scarce (perhaps we’ll try and do something about this at some point), however the general consensus seems to be that Cloudera Manager was more mature and more capable, but that Ambari has been catching up rapidly, and there’s probably not a huge amount in it any more.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; started off as Cloudera’s data (or metadata) management tool, and is probably slightly more mature and capable in this space than &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt;. Metadata management in general still feels very immature however - most tools don’t deliver on their promises, and the investment, time and effort to get value out of them is often under estimated, leading to the infamous data swamp if you’re working in the Hadoop space.&lt;/p&gt; &lt;p&gt;Today, in addition to it’s original &lt;a href=&quot;/technologies/cloudera-navigator/data-management/&quot;&gt;data management&lt;/a&gt; elements, Cloudera Navigator also includes &lt;a href=&quot;/technologies/cloudera-navigator/data-encryption/&quot;&gt;data encryption&lt;/a&gt; capabilities following Cloudera’s acquisition of Gazzang, and &lt;a href=&quot;/technologies/cloudera-navigator/optimizer/&quot;&gt;Optimizer&lt;/a&gt; following their acqusition of Xplain.io, an interesting technology I know very little about for helping to migrate SQL workloads to Hadoop and to then optimise these.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; - Cloudera’s tool for creating, scaling and managing CDH clusters in all your favourite cloud environments. I’m not sure there’s a huge amount more to say than that to be honest.&lt;/p&gt; &lt;p&gt;Right - I’m off to eat chocolate. If I’ve not exploded we’ll resume next Tuesday with our summary of Cloudera themselves, and then maybe on Wednesday we’ll do our first news post to catch up on the many technologies that have had new releases since we did their initial technology summary.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</guid> </item> <item><title>Cloudera Director</title><link>http://ondataengineering.net/technologies/cloudera-director/</link><pubDate>Thu, 13 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for deploying and managing Cloudera CDH Hadoop clusters on cloud infrastructure based on automatically provisioned infrastructure with Hadoop provisioned on top via Cloudera Manager. Includes out of the box support for Amazon Web Services, Microsoft Azure and Google Cloud Platform, with support for vSphere available from VMWare, with a Service Provider Interface (SPI) for adding support for new providers. Supports the ability to scale clusters up and down, clone clusters, run post deployment scripts, and create Kerberized and highly available clusters. Manageable through a web UI, a REST API (with Python and Java APIs) and a CLI. Released at 1.0 in October 2014 as part of Cloudera Enterprise 5.2. Free to download and use, with commercial support available as part of a Cloudera Enterprise subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v2.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-director.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-director.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/director/latest.html&quot;&gt;https://www.cloudera.com/documentation/director/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera?q=director&quot;&gt;https://github.com/cloudera?q=director&lt;/a&gt; - plugins&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&quot;&gt;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&lt;/a&gt; - VMWare plugin announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-director/</guid> </item> <item><title>Cloudera Navigator Optimizer</title><link>http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://optimizer.cloudera.com/&quot;&gt;https://optimizer.cloudera.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&lt;/a&gt; - product information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/navopt/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/navopt/topics/navopt.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</guid> </item> <item><title>Cloudera Navigator Data Encryption</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Navigator Encrypt, Navigator Key Trustee Server, Navigator Key HSM, Navigator Key Trustee KMS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&quot;&gt;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&lt;/a&gt; - intro blog post to Navigator Encrypt&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&lt;/a&gt; - Cloudera security overview, including summary of encryption options&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&lt;/a&gt; - Cloudera encryption documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</guid> </item> <item><title>Cloudera Navigator Data Management</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-management/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&lt;/a&gt; - primary documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&lt;/a&gt; - list of metadata that is automatically extracted&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/navigator/apidocs/v3/&quot;&gt;http://cloudera.github.io/navigator/apidocs/v3/&lt;/a&gt; - REST API documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/navigator-sdk&quot;&gt;https://github.com/cloudera/navigator-sdk&lt;/a&gt; - Java SDK&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-management/</guid> </item> <item><title>Cloudera Navigator</title><link>http://ondataengineering.net/technologies/cloudera-navigator/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of solutions covering Data Management (technical metadata management, lineage, cluster activity and analytics, cluster audit and automated policy actions), Data Encryption (filesystem level encryption, key management and integration with HDFS transparent encryption), and a solution for identifying SQL workloads that are candidates for migration to Hadoop and then optimising these once on Hadoop (Optimizer) build around the Cloudera CDH Hadoop distribution. All products are commercial closed source products, that are only available with an appropriate Cloudera Enterprise licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v2.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-management/&quot;&gt;Cloudera Navigator Data Management&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/&quot;&gt;Cloudera Navigator Data Encryption&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/optimizer/&quot;&gt;Cloudera Navigator Optimizer&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator.html&lt;/a&gt; - Cloudera Navigator homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&quot;&gt;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&lt;/a&gt; - Cloudera Navigator datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - Data Management and Data Encryption introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&lt;/a&gt; - Optimizer introduction&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/navigator/&quot;&gt;http://blog.cloudera.com/blog/category/navigator/&lt;/a&gt; - Cloudera blog posts&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/</guid> </item> <item><title>Cloudera Manager</title><link>http://ondataengineering.net/technologies/cloudera-manager/</link><pubDate>Mon, 10 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Platform for installing, managing and monitoring Cloudera CDH Hadoop clusters. Supports creation of clusters using step by step wizards, plus cluster templates for creating multiple clusters with the same configuration (e.g. dev, test and production), using either native OS packages or parcels (a Cloudera Manager distribution format that has a number of advantages over packages). Also supports the administration and configuration of clusters (including user and resource management, and the ability to manage multiple clusters); the automated Kerberization of clusters; monitoring of cluster, host and service statuses, health and metrics; generation of events and the use of custom triggers to take action on these; the visualisation of metrics; centralised log management; HDFS reports and automatic replication of data to a backup/DR cluster. Also integrates directly with Cloudera Support to enable proactive support. Web based, with a REST API and a full security model with auditing of all actions, and the ability to add support for custom services. Introduced in January 2012 as a replacement for the Cloudera Management Suite (CMS). Available for free without some enterprise features, or as part of a Cloudera CDH subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-manager.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-manager.html&lt;/a&gt; - Cloudera Manager homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&lt;/a&gt; - Documentation - link is to the Cloudera Manager introduction, with the rest of Cloudera documentation (e.g. Installation, Upgrade, Administration, Operation and Security documents) also referencing Cloudera Manager&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloudera.github.io/cm_api/&quot;&gt;https://cloudera.github.io/cm_api/&lt;/a&gt; - Cloudera Manager API documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-manager/</guid> </item> <item><title>The Week That Was - 31/03/2017</title><link>http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</link><pubDate>Fri, 31 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;No technology summary today for various reasons, one of which is that I’m taking a break next week and we’ve probably got to a pretty good place to pause. We’ve finished looking at the new open source technologies in the Cloudera stack this week, with their proprietary closed source technologies to come, but let’s save those for a fresh week.&lt;/p&gt; &lt;p&gt;So what exactly have we looked at this week? We started by looking at &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt;, Cloudera’s competitor to &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, Cloudera’s competitor to Hortonworks’ &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt;. We then looked at &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, a structured data store that supports both updates and deletes by primary key as well as efficient analytical table scans, and &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, a new technology that’s still in beta that provides an API for tools (such as Spark and MapReduce) to access structured data in Hadoop with fine grained access control. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;At some point, and I realise I keep saying this, I want to take a deeper look into the state of the security technologies in Hadoop, and more specifically a decent comparison of &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt;. There’s some history behind how we’ve ended up with two Apache technologies that are essentially trying to solve the same problem, each has their pros and cons but either will probably do what you need them two, with Ranger possibly looking the slightly further ahead functionality wise. Note that I’ve make some minor tweaks to the &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; technology summary this week.&lt;/p&gt; &lt;p&gt;I’m not entirely sure where the whole “wrap Solr up with some tools and utilities and give it a new name” came from, but there are some interesting differences between &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt; in the wraps that they put around Solr. Hortonworks bundle Banana (the Solr port of Kibana), they both support utilities for loading data from HDFS and moving data from HBase to Solr, but Hortonworks also bundle integrations with Solr for Hive, Pig, Storm and Spark. Note again that I’ve made some minor tweaks to the HDP Search technology summary this week.&lt;/p&gt; &lt;p&gt;Cloudera position &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; as the missing link between &lt;a href=&quot;/technologies/apache-hadoop/hdfs&quot;&gt;HDFS&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt; - able to perform updates and deletes by primary key (ala HBase), as well as analytical queries performing column and table scans (ala HDFS). It’s not going to replace either for their respective specialisms, but the ability to run analytical workloads over mutable data feels like a bit of a gap in the Hadoop ecosystem at the moment (that probably led to the rise of the &lt;a href=&quot;http://lambda-architecture.net/&quot;&gt;lambda architecture&lt;/a&gt;). Kudu only provides the storage engine, but its combination with &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt; to provide a SQL interface on top feels like yet more evidence that Cloudera is firmly targeting the established OLAP database vendors. The &lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;Kudu whitepaper&lt;/a&gt; is worth a skim if you’re interested, including the performance comparison between Kudu, Parquet on HDFS and Phoenix on HBase.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, the benefits of which seem twofold. Firstly, it provides a unified data access path for Hadoop technologies - rather than every technology (MapReduce, Spark, etc.) having to implement their own reader for each file format, they can just integrate with RecordService. This then enables the second - fine grained access control to this data. At the moment, when tools like MapReduce and Spark read data from HDFS, access can only be granted at the file level - RecordService will enable finer grained access control in this scenario, which can only be a good thing. Two thoughts however - you can achieve this today by forcing these tools to read data via Hive, however my guess is that there are some performance limitations on this at scale that RecordService will address, and that at the moment it’s very early days for RecordService, plus it’s tied to Apache Sentry, so it’s going to be interesting to see how much traction this gains into the wider Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;As mentioned above I’m taking a break next week so there’ll be no updates, but we’ll be back on Monday 10th with a look at Cloudera’s closed source commercial technologies.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</guid> </item> <item><title>RecordService</title><link>http://ondataengineering.net/technologies/recordservice/</link><pubDate>Thu, 30 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Abstraction layer for accessing structured data in Hadoop that enforces fine grained access control (via Apache Sentry). Currently supports reading data from HDFS and S3 in Parquet, Text, Sequence File, RC and Avro format via a Hive table/view definition or a file path, with support for HBase and Kudu planned. Supports direct access to data via C++ and Java APIs, plus integration with MapReduce, Spark, Impala and Pig, with support for Hive planned. Supports the Apache Sentry security model, including table, view, file (via grants on uris to create external tables) and column level security, with row level filtering and data masking planned. Started in January 2015 and announced with an initial beta release in September 2015. Still in beta, with a stated plan for RecordService to be donated to the Apache Foundation in the future. Open sourced under Apache 2.0 licence, and implemented in C++ and Java.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/&quot;&gt;http://recordservice.io/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&quot;&gt;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&lt;/a&gt; - vision for RecordService&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/betas/recordservice/latest.html&quot;&gt;https://www.cloudera.com/documentation/betas/recordservice/latest.html&lt;/a&gt; - Cloudera document home (links through to RecordService site)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/recordservice&quot;&gt;https://github.com/cloudera/recordservice&lt;/a&gt; - source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/RecordServiceClient/&quot;&gt;https://github.com/cloudera/RecordServiceClient/&lt;/a&gt; - client libraries source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/ReleaseNotes/&quot;&gt;http://recordservice.io/ReleaseNotes/&lt;/a&gt; - RecordService release details&lt;/li&gt; &lt;li&gt;Other updates through Cloudera Engineering blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/recordservice/</guid> </item> <item><title>Apache Kudu</title><link>http://ondataengineering.net/technologies/apache-kudu/</link><pubDate>Wed, 29 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Columnar storage technology for tables of structured data, supporting low latency reads, updates and deletes by primary key, as well as analytical column/table scans. Provides Java, C++ and Python APIs, is queryable via Impala and Spark SQL, and provides Spark, Flume and MapReduce connectors. Supports cluster deployments (including co-existence with Hadoop), with tables partitioned into tablets (configurable on a per table basis), with tablets then replicated and distributed across the cluster, using the Raft Consensus Algorithm for consistency. Also supports variable column encoding (including bit shuffle, run length, dictionary and prefix encoding) and compression. Includes a web UI for reporting operational information, and metrics available from the command line, via HTTP or via a log file. Started in November 2012, with a initial beta release in September 2015. Donated to the Apache Foundation in December 2015, graduating in July 2016, with a 1.0 release in September 2016. Implemented in C++.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kudu&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/&quot;&gt;https://kudu.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/docs/&quot;&gt;https://kudu.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;http://kudu.apache.org/kudu.pdf&lt;/a&gt; - whitepaper including comparison to Parquet/HDFS and Phoenix/HBase&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&lt;/a&gt; - Cloudera information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/releases/&quot;&gt;https://kudu.apache.org/releases/&lt;/a&gt; - details of new releases&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/blog/&quot;&gt;https://kudu.apache.org/blog/&lt;/a&gt; - Apache Kudu blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/kudu/&quot;&gt;http://blog.cloudera.com/blog/category/kudu/&lt;/a&gt; - Cloudera blog posts on Kudu&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kudu/</guid> </item> <item><title>Cloudera Search</title><link>http://ondataengineering.net/technologies/cloudera-search/</link><pubDate>Tue, 28 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distribution of Apache Solr that also includes a number of tools for integrating with Solr using Morphlines. Includes two utilities for loading data from HDFS, the Crunch Indexer Tool (direct Solr inserts using Crunch over Spark or MapReduce), and the MapReduce Indexer Tool (creates Solr index files using Map Reduce, optionally putting these live), plus two utilities for loading data from HBase based on the Lily HBase Indexer, the Batch Indexer (for batch loads) and the NRT (Near Real Time) Indexer (for continuous replication of HBase events). First released in June 2013, with a GA release in September 2013 as part of CDH 4.3. Included tools are open sourced under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/search/&quot;&gt;https://github.com/cloudera/search/&lt;/a&gt; - HDFS utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/hbase-indexer&quot;&gt;https://github.com/cloudera/hbase-indexer&lt;/a&gt; - HBase utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-search/</guid> </item> <item><title>Apache Sentry</title><link>http://ondataengineering.net/technologies/apache-sentry/</link><pubDate>Mon, 27 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store, and plugins for Hadoop components (including Hive, Solr, Impala and HDFS, with support for Kafka and Sqoop2 in preview) to manage authorisation of user access to data, although HDFS support is limited to Hive data only. Also supports row level filtering policies for Solr, and historical support for defining policies in files per service (Sentry Policy Files). Integrates with the Hue security app (to manage permissions) and with Cloudera Navigator (for authorisation audit events). Started in 2012 as Cloudera Access, with an initial 1.0 release in 2013 as Sentry. Donated to the Apache Foundation in August 2013, graduating in March 2016. &lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Sentry&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://sentry.apache.org/index.html&quot;&gt;https://sentry.apache.org/index.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&quot;&gt;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&lt;/a&gt; - Apache documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sentry/&quot;&gt;https://blogs.apache.org/sentry/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Other updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-sentry/</guid> </item> <item><title>The Week That Was - 24/03/2017</title><link>http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</link><pubDate>Fri, 24 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;So this week we started our journey into the Cloudera technology stack. I covered the final Hortonworks bits &lt;a href=&quot;/blog/2017/03/20/hortonworks-to-cloudera/&quot;&gt;on Monday&lt;/a&gt;, but what have we looked at since then?&lt;/p&gt; &lt;p&gt;We started off by looking at Cloudera’s Hadoop distribution &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; and the technologies it bundles. We’ve covered a lot of these already (Hadoop being Hadoop there’s plenty of overlap between the various distributions), but there’s still plenty of new stuff here to keep us busy for a couple of weeks.&lt;/p&gt; &lt;p&gt;We then moved on to look at &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt;, a small piece of open source technology created to support Impala running over YARN, &lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt;, a now retired Apache open source project for deploying a number of technologies onto cloud platforms, and &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;, Cloudera’s SQL on Hadoop engine for low latency interactive queries. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I’m not sure there’s much to say about &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; right now - it’s a great Hadoop distribution, and although it’s a significantly more commercial offering that Hortonworks, you can get most of it for free (including Cloudera Manager minus some enterprise bits). There’s pros and cons all over the stack if you’re comparing it against the other distributions, but we’ll take a deeper look at this in a couple of weeks time.&lt;/p&gt; &lt;p&gt;There’s not much to say about &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt; - it was a piece of technology created by Cloudera to allow Impala to play nicely with YARN, but it’s not be adopted outside of Cloudera, who have themselves now deprecated it and will no longer be including it in CDH from v6.0 onwards (this wasn’t originally referenced in the technology summary so I’ve since updated it).&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt; feels like a bit of history. It’s well and truly dead now (with no development since September 2012, and having been moved into the Apache Attic in March 2015), however it was the first technology (I think I’m right in saying this) that allowed you to deploy Hadoop (and a whole pile of other technologies) into a cloud environment. It feels a little clunky and anachronistic now - there’s bespoke Java code written for each technology it supported to manage the software deployment and management using jclouds - but I’m guessing at the time it was almost revolutionary, paving the way for a whole pile of later technologies.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;. At some point I want to dig into the whole Impala/Hive debate / religious war (because it’s a fascinating look into the relationship and cultural differences between Cloudera and Hortonworks as much as anything). Hive has always been a large batch data transformation engine (albeit executing SQL) - every query starting a new job (originally MapReduce but lately Spark or Tez) with all the associated overheads and latency, but with the ability to process as much data as your Hadoop cluster would hold. What it wouldn’t do is support large numbers of more targeted queries at a low latency, for example from a group of users running queries against a data mart (the so called interactive query use case) - this was the use case Impala (and Parquet - the columnar data format) were created to target. Impala was therefore never designed to replace or compete with Hive, it’s competition are the traditional OLAP database such as Greenplum, Netezza and Teradata, with Impala trying to deliver a roughly comparable capability at a much lower cost. Hortonworks of course felt that Hive should support both use cases, and its introduction of LLAP (which allows long running processes to execute multiple queries) was it’s answer to this.&lt;/p&gt; &lt;p&gt;And that’s us for this week - have a good weekend, and we’ll see you on the other side.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</guid> </item> <item><title>Apache Impala</title><link>http://ondataengineering.net/technologies/apache-impala/</link><pubDate>Fri, 24 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore. Focus is on analytical (OLAP) use cases, and more specifically on low latency interactive queries (rather than long running batch queries), with some support for batch inserts of data. Supports DDL statements for updating the Hive Metastore, uses (broadly) the same SQL syntax as Hive (including UDFs and a range of aggregate and analytical functions), as well as the same JDBC / ODBC drivers, and is therefore compatible with any Hive query tool (such as Beeline). Supports querying over data in Parquet, Text, Avro, RCFile and SequenceFile formats, with the ability to write Parquet and Text data. Support Kerberos and LDAP authentication, and integration with Apache Sentry for authorisation. Includes a shell (Impala Shell) that supports some shell only commands for tuning performance and diagnosing problems. Created by Cloudera, started in May 2011 and first announced in October 2012, with a 1.0 GA release in May 2013. Donated to the Apache Foundation in December 2015, is still incubating, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Impala&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://impala.incubator.apache.org/&quot;&gt;https://impala.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-impala/</guid> </item> <item><title>Apache Whirr</title><link>http://ondataengineering.net/technologies/apache-whirr/</link><pubDate>Thu, 23 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A set of libraries (now moved to the Apache Attic and no longer maintained) for deploying and managing a supported set of services in a cloud environment. Written in Java, with explicit support for a set of standard services (including Hadoop, Cassandra, HBase, Elasticsearch and Solr) configured through property files. Uses jclouds to provision and manage cloud infrastructure, and provides both a CLI and Java API. Originally a set of python scripts maintained as an Hadoop contrib project. Donated to the Apache Foundation in May 2010, graduating in August 2011. Development ceased in September 2012, with the project being moved to the Apache Attic in March 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Whirr&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://whirr.apache.org/&quot;&gt;https://whirr.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/WHIRR&quot;&gt;https://cwiki.apache.org/confluence/display/WHIRR&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://attic.apache.org/projects/whirr.html&quot;&gt;https://attic.apache.org/projects/whirr.html&lt;/a&gt; - Apache Attic page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-whirr/</guid> </item> <item><title>Llama</title><link>http://ondataengineering.net/technologies/llama/</link><pubDate>Wed, 22 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for long running low-latency distributed applications to request resources from YARN, built to support Apache Impala. Operates as an un-managed YARN application master (that handles resource requests over a Thrift API and delivers resource notifications) and a node manager plugin (that delivers resource availability information to co-located services). Created by Cloudera in August 2013 and hosted on GitHub under an Apache 2.0 licence. Maintained by Cloudera to support new Impala and CDH releases, but now deprecated and will no longer be included in CDH from v6.0 onwards.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/llama/&quot;&gt;http://cloudera.github.io/llama/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/llama&quot;&gt;https://github.com/cloudera/llama&lt;/a&gt; - code repository&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/llama/</guid> </item> <item><title>Cloudera CDH</title><link>http://ondataengineering.net/technologies/cloudera-cdh/</link><pubDate>Tue, 21 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;A distribution of Hadoop based on the addition of a number of closed source products, including Cloudera Manager (for installing and managing clusters) and Cloudera Navigator (for managing metadata and the encryption of data). Bundled projects tend to lag the open source versions and pull forward more patches than other distributions. Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Impala, and a number of Apache projects that aren't (yet) part of the core distribution. Available via RPMs, or can be installed using Cloudera Manager (for local installs) or Cloudera Director (for installation on cloud platforms) as Cloudera Enterprise (under an annual per node or elastic cloud licence model with commercial support) or Cloudera Express (a free version without some enterprise features), with Cloudera Enterprise coming in a range of licence options (listed on the Cloudera website under products) which each including support for different Apache products. First released in March 2009.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;CDH, Cloudera Express, Cloudera Enterprise&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-avro/&quot;&gt;Apache Avro&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Apache Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-whirr/&quot;&gt;Apache Whirr&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;, &lt;a href=&quot;/technologies/llama/&quot;&gt;Llama&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Details of the Apache project versions bundled with each version of CDH are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball.html&quot;&gt;this page&lt;/a&gt; of the CDH release notes. Deprecated items and projects are detailed on &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_deprecated.html&quot;&gt;this page&lt;/a&gt;. New features, known issues and fixed issues are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes_cdh.html&quot;&gt;this page&lt;/a&gt;. See some of the links below for details on the different Cloudera versions and options.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&lt;/a&gt; - CDH bundled projects datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&lt;/a&gt; - Cloudera Enterprise datasheet (including details of products supported under each licence option)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&lt;/a&gt; - differences between Express and Enterprise editions&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;http://blog.cloudera.com/&lt;/a&gt; - Cloudera engineering blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&quot;&gt;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&lt;/a&gt; - Release Announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-cdh/</guid> </item> <item><title>Hortonworks to Cloudera</title><link>http://ondataengineering.net/blog/2017/03/20/hortonworks-to-cloudera/</link><pubDate>Mon, 20 Mar 2017 07:40:00 +0000</pubDate> <description> &lt;p&gt;Right - I think we’re done with our trip through the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; technology stack, however there are two updates today before we move on. Apologies in advance if this screws up either the RSS feeds or e-mail newsletters - I’m not entirely sure how these will handle updates to the site, but there’s only one way to find out. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, I’ve re-worked the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; page to better describe their product offerings. The one thing I really like about Hortonworks is it’s openness. Normally when looking at commercial vendors there’s a whole pile of exaggeration and misdirection about what their product is and what it can do and how it’s so much better than any other option on the market, however because Hortonworks deal entirely in open source technologies they feel like a more open and transparent company, and actually understanding what they offer therefore feels a little more straightforward. There are some big commercial vendors coming up on my list however where I don’t have a huge amount of experience with their products, and I’m therefore holding out no hope of being able to understand the detail of what they offer, given the lack of any publicly available documentation and product websites that are little more than content-less flashy brochures. When I get to these, I’m definitely going to need some help.&lt;/p&gt; &lt;p&gt;Secondly, I’ve added a page for &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows&quot;&gt;HDP for Windows&lt;/a&gt;, which is now also included in our list of Hadoop Distributions. Hadoop itself, and a bunch of the other related Apache technologies support being built on Windows as a native Windows executable, however HDP is (as far as I’m aware) the only Hadoop distribution that supports Windows (presumably as part of Hortonworks’ deal with Microsoft for Azure HDInsight). It’s not the full HDP distribution however - missing some key technologies including Ambari, Solr and Spark.&lt;/p&gt; &lt;p&gt;Up tomorrow then - our first look into the Cloudera technology stack. We’ll start with their distributions (CDH, Cloudera Express and Cloudera Enterprise), add these to our list of Hadoop distributions, have a look at the new Apache technologies that these include that we haven’t looked at yet, and then finish up with adding Cloudera to our list of technology vendors. At least that’s the plan - managing to stick to it will probably be a first for this site.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/20/hortonworks-to-cloudera/</guid> </item> <item><title>Hortonworks Data Platform for Windows</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform-for-windows/</link><pubDate>Mon, 20 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A version of the Hortonworks Data Platform natively compiled for Windows. Generally trails the main HDP project by a minor version, doesn't use Apache Ambari for installation and management (instead being installed via a standard Windows installer), doesn't support SmartSense, and doesn't include some technologies (currently Accumulo, Atlas, Kafka, Solr, Spark and Hue). First announced in March 2013, with a GA release in May 2013.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP for Windows&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-falcon/&quot;&gt;Apache Falcon&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Apache Slider&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/index.html&lt;/a&gt; - HDP 2.4.2 for Windows documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/bk_HDP_RelNotes_Win/content/ch_relnotes_v242.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/bk_HDP_RelNotes_Win/content/ch_relnotes_v242.html&lt;/a&gt; - HDP 2.4.2 for Windows release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;See Hortonworks’ blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform-for-windows/</guid> </item> <item><title>Hortonworks</title><link>http://ondataengineering.net/tech-vendors/hortonworks/</link><pubDate>Mon, 20 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Hortonworks is a commercial company focusing on products that support the exploitation of data both at rest and in motion. Their business model is to provide support and professional services for a range of Apache open source technologies which they package and distribute for free. They are therefore extreemly active in the Apache open source space, with committers on all the technologies they distribute, and with a history of donating projects to the Apache Foundation that they have either initiated or acquired. Hortonworks was formed in June 2011 by ex-Yahoo employees.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;vendor-technologies&quot;&gt;Vendor Technologies&lt;/h2&gt; &lt;p&gt;Hortonworks have two primary offerings - &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, a fully open source distribution of Hadoop, and &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks Data Flow&lt;/a&gt;, a distribution of (primarily) Apache NiFi, Kafka and Storm for processing data in motion.&lt;/p&gt; &lt;p&gt;Both offerings are installed and managed through &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;, with Hortonworks Data Platform also including &lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt;, a technology for deploying and managing Hadoop clusters on cloud infrastructure.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows&quot;&gt;HDP for Windows&lt;/a&gt; is a version of the Hortonworks Data Platform for Windows.&lt;/p&gt; &lt;p&gt;The &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt; is also available as a number of managed cloud offerings - on Azure as HDInsight, a Microsoft branded offering, and on AWS as &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;Hortonworks Data Cloud for AWS&lt;/a&gt;, available via the AWS Marketplace.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/&quot;&gt;https://hortonworks.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/&quot;&gt;https://hortonworks.com/blog/&lt;/a&gt; - Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/hortonworks/</guid> </item> <item><title>The Week That Was - 17/03/2017</title><link>http://ondataengineering.net/blog/2017/03/17/the-week-that-was/</link><pubDate>Fri, 17 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;And another week passes…&lt;/p&gt; &lt;p&gt;This week we’ve wrapped up the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; technology stack (give or take). On Monday we’ll review what we’ve found, and look ahead to our next destination - Cloudera.&lt;/p&gt; &lt;p&gt;So what have we looked at this week? We took a spin through &lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, Hortonworks’ bundling of &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt;. We’ve looked at Kafka and Storm previously, but we paused this week to look at &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt; and it’s sub-project &lt;a href=&quot;/technologies/apache-nifi/minifi&quot;&gt;MiNiFi&lt;/a&gt; in more detail.&lt;/p&gt; &lt;p&gt;And we finished off by looking at &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;HDCloud for AWS&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;Hortonworks DataFlow&lt;/a&gt; (HDF to it’s friends) is Hortonworks’ big push into analytics on data in motion, and more specifically into analytics in the Internet of Things world (or Internet of Anything as they refer to it). It’s a compelling story - the ability to deploy key real time analytical technologies independently from your Hadoop cluster (which can now focus on the batch historical analytical use cases) - and comes with the introduction of a new technology - &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What to say about &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;? There’s a use case here that I think NiFi fills almost unapproachably well - specifically getting batch (and probably mini batch) data to your analytical cluster. Previously you’d be looking at a bunch of technologies - Sqoop for database unloads, and some combination of shell scripts, FTP transfers, custom jobs to pull data from queues etc. etc. NiFi wraps all of this up - giving you a single solution to bring data from anywhere to a place where you can exploit it. The visualisation of the data moving through your flows, the ability to view this data, to get detailed provenance of where every file came from and when, and to perform common file level transformations just make this a great fit for this use case (although I’m never entirely convinced by the develop, test, release and configuration management story of GUI based tools, but that’s a discussion for another day). Where I think it has stiffer competition, and where I’m not as wholly convinced, is in the high volume, low latency, real-time event data space. There are a lot of well established technologies in this space (Logstash, FluentD and Heka for starters), and I’m not entirely convinced that NiFi is well architected for this use case. Do I really want provenance and record level state tracking when I’m bringing in billions of records per day - that seems like a significant overhead to me. By it’s a space NiFi is targeting, both with &lt;a href=&quot;/technologies/apache-nifi/minifi&quot;&gt;MiNiFi&lt;/a&gt; (which supports collection, transformation and forwarding out at the edge), and with some bold claims about throughput. I’m happy to accept I’ve missed something here, and I’d love to hear from anyone that can talk to this with some experience and evidence…&lt;/p&gt; &lt;p&gt;I’m going to update the Hortonworks vendor page on Monday with more information about their product offerings, as their Cloud offerings are a little more complex and convoluted that I was expecting. However &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;HDCloud for AWS&lt;/a&gt; is their only Hortonworks branded cloud offering - a tool that allows you to deploy and resize HDP clusters in AWS, but with a limited set of technologies, focusing on Hive, Spark and Zeppelin. It’s brand new, only coming out at the end of 2016, and it appears to overlap with a more general capability that &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; is targeting. We’ll keep an eye on these, as it feels like next year is going to see a lot of movement in the Hadoop on Cloud space.&lt;/p&gt; &lt;p&gt;Right - back to the grindstone before the escape of the weekend. See you all next week for our first looks at Cloudera’s product offerings.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/17/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Cloud for AWS</title><link>http://ondataengineering.net/technologies/hortonworks-data-cloud-for-aws/</link><pubDate>Fri, 17 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Service that supports the creation and management of HDP clusters on Amazon Web Services (AWS). Management is done through a Cloud Controller AWS Product that provides a web interface and CLI for orchestrating the creation of AWS resources and the deployment of clusters using Ambari, and the subsequent scaling or cloning of the cluster. Supports a number of standard cluster types, including Data Science (Spark, Zeppelin), EDW-ETL (Hive, Spark) and EDW-Analytics (Hive, Zeppelin), with clusters also including Tez, Pig and Scoop, along with a number of standard node types, including worker nodes (that support HDFS and YARN) and computer nodes (that only support YARN). Clusters are designed to be ephemeral, however Amazon RDS can be used to provide persistent storage of Cloud Controller and Hive metadata, and Amazon S3 can be used to provide persistent cluster storage. Also supports Hortonworks SmartSense, cluster templates, the use of Spot Instances for compute nodes, and node recipes for executing custom scripts pre/post the Ambari cluster setup. Comes with free community support from Hortonworks. First launched in November 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDCloud for AWS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/cloud/aws/&quot;&gt;https://hortonworks.com/products/cloud/aws/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDCloudAWS/HDCloudAWS-1.11.1/bk_hdcloud-aws/content/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDCloudAWS/HDCloudAWS-1.11.1/bk_hdcloud-aws/content/index.html&lt;/a&gt; - v1.11.1 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/availability-hortonworks-data-cloud-aws/&quot;&gt;https://hortonworks.com/press-releases/availability-hortonworks-data-cloud-aws/&lt;/a&gt; - original press release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/marketplace/pp/B01LXOQBOU&quot;&gt;https://aws.amazon.com/marketplace/pp/B01LXOQBOU&lt;/a&gt; - AWS Cloud Controller product page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-cloud-for-aws/</guid> </item> <item><title>MiNiFi</title><link>http://ondataengineering.net/technologies/apache-nifi/minifi/</link><pubDate>Thu, 16 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;Lightweight headless version of NiFi used to collect and process data at it's source, before forwarding it on for centralised processing. Supports all key NiFi functionality including all NiFi processors, guaranteed delivery, data buffering (including back pressure and pressure release) and prioritised queuing, however flows are specified in configuration files, status information and statistics are only available via Reporting Tasks or via a CLI, and provenance can only be viewed by exporting events via Reporting Tasks to log files or a full NiFi instance. Supports warm re-deployments, automatically restarting to load a new configuration written to disk or pushed or pulled over HTTP. Available as a Java or Native C++ executable. Started in March 2016, with a 0.1 release in December 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/minifi/index.html&quot;&gt;http://nifi.apache.org/minifi/index.html&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/minifi/system-admin-guide.html&quot;&gt;http://nifi.apache.org/minifi/system-admin-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/nifi/#section_4&quot;&gt;https://hortonworks.com/apache/nifi/#section_4&lt;/a&gt; - Hortonworks information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - Hortonworks documentation (as part of HDF)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/MINIFI/Release+Notes&quot;&gt;https://cwiki.apache.org/confluence/display/MINIFI/Release+Notes&lt;/a&gt; - release notes&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-nifi/minifi/</guid> </item> <item><title>Apache NiFi</title><link>http://ondataengineering.net/technologies/apache-nifi/</link><pubDate>Wed, 15 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;General purpose technology for the movement of data between systems, including the ingestion of data into an analytical platform. Based on directed acyclic graph of Processors and Connections, with the unit of work being a FlowFile (a blob of data plus a set of key/value pair attributes). Supports guaranteed delivery of FlowFiles, with NiFi resiliently storing state (by default to a local write ahead log) and data blobs (by default a set of local partitions on disk), with all transformation logic executed via a thread pool within the NiFi instance (with the option to deploy multiple NiFi instances as a cluster). All flows are configured in a graphical user interface, which is also used for management and operations (starting/stopping individual Processors and viewing real time statuses, statistics and other information). Also supports data provenance (reporting on the processing events and lineage of individual FlowFiles), scheduling of Processor execution (based on periodic execution timers or cron specifications), multi-threaded Processor execution, configuration of Processor batch sizes (to enable low latency or high throughput), prioritised queues within Connections (allowing FlowFiles to be processed based on their age or a priority attribute as an alternative to FIFO), back pressure (based on counts or data volume against individual Connections) and pressure release (automatic discarding of FlowFiles based on their age), the ability to stream data to and from other NiFi instances and other streaming technologies, the ability to import and export flows as XML (flow templates), an expression language for setting Processor configuration and populating FlowFile attributes, Controller Services to provide shared services to processors (e.g. access to credentials, shared state), Reporting Tasks to output status and statistics information and a user security model. Extensible through the addition of custom Processors, Controller Services, Reporting Tasks and Prioritizers, and integrates with Apache Ranger and Apache Ambari. Originally developed at the NSA as &quot;Niagara Files&quot;, before being donated to the Apache Foundation in November 2014, graduating in July 2015. Java based, with development lead by Hortonworks after their aquisition of Onyara (which was set up by original NiFi developers to provide commercial support and services).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;NiFi&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache NiFi&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Lightweight headless version of NiFi used to collect and process data at it's source, before forwarding it on for centralised processing. Supports all key NiFi functionality including all NiFi processors, guaranteed delivery, data buffering (including back pressure and pressure release) and prioritised queuing, however flows are specified in configuration files, status information and statistics are only available via Reporting Tasks or via a CLI, and provenance can only be viewed by exporting events via Reporting Tasks to log files or a full NiFi instance. Supports warm re-deployments, automatically restarting to load a new configuration written to disk or pushed or pulled over HTTP. Available as a Java or Native C++ executable. Started in March 2016, with a 0.1 release in December 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/&quot;&gt;http://nifi.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/docs.html&quot;&gt;http://nifi.apache.org/docs.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/nifi/&quot;&gt;https://hortonworks.com/apache/nifi/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - Hortonworks documentation (as part of HDF)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes&quot;&gt;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes&lt;/a&gt; - release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-nifi/</guid> </item> <item><title>Hortonworks DataFlow</title><link>http://ondataengineering.net/technologies/hortonworks-data-flow/</link><pubDate>Tue, 14 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A distribution of a set of Apache open source technologies (primarily NiFi, Kafka and Storm) for processing data, with all products integrated with Ranger for security and Ambari for management. All bundled projects are Apache open source projects based on official Apache project releases, with any patches for bug fixes or new features pulled from official Apache project patches from later releases of the project. Available as RPMs or can be installed using Apache Ambari (via a management pack). Provided free of charge, with training, consultancy and support available from Hortonworks. First released in September 2015 as a distribution of just NiFi following the acquisition by Hortonworks of Onyara,who were setup by the creators of NiFi to provided commercial support for it.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDF&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The details of the Apache projects distributed as part of Hortonworks DataFlow are detailed in the release notes, along with the specific versions included, the unsupported features, the patches pulled forward from future project releases, and the known vulnerabilities and issues.&lt;/p&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;September 2015&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-to-acquire-onyara-to-turn-internet-of-anything-data-into-actionable-insights/&quot;&gt;https://hortonworks.com/press-releases/hortonworks-to-acquire-onyara-to-turn-internet-of-anything-data-into-actionable-insights/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Initial version consisting of just Apache NiFi&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.1&lt;/td&gt; &lt;td&gt;December 2015&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-1-1-released/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-1-1-released/&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.2&lt;/td&gt; &lt;td&gt;March 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-1-2-released/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-1-2-released/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Storm and Kafka added&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.0&lt;/td&gt; &lt;td&gt;September 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-2-0-ga/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-2-0-ga/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Ranger and Ambari support added&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.1&lt;/td&gt; &lt;td&gt;December 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/announcing-availability-hortonworks-dataflow-hdf-2-1/&quot;&gt;https://hortonworks.com/blog/announcing-availability-hortonworks-dataflow-hdf-2-1/&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/data-center/hdf/&quot;&gt;https://hortonworks.com/products/data-center/hdf/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - HDF 2.1.0 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/bk_dataflow-release-notes/content/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/bk_dataflow-release-notes/content/index.html&lt;/a&gt; - HDF 2.1.2 release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/category/hdf/&quot;&gt;https://hortonworks.com/blog/category/hdf/&lt;/a&gt; - blog posts&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-flow/</guid> </item> <item><title>Hortonworks</title><link>http://ondataengineering.net/blog/2017/03/13/hortonworks/</link><pubDate>Mon, 13 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Right - we’ve finished with our probing into the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies, it’s time to move on.&lt;/p&gt; &lt;p&gt;So today, we’re going to add &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt; to our vendor catalogue, and over the next week and a bit have a look at some of the other technology offerings they have outside of HDP. Once we’re done with that, we’ll revert to our original course of looking at all the major Hadoop distributions.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/13/hortonworks/</guid> </item> <item><title>The Week That Was - 10/03/2017</title><link>http://ondataengineering.net/blog/2017/03/10/the-week-that-was/</link><pubDate>Fri, 10 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;And so we come to the end of the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies. On Monday we’ll start looking at the remainder of the Hortonworks technology offerings (yes - I know we’re meant to be working our way through the Hadoop distributions - it’ll only be a short detour), but for now let’s summarise what we’ve looked at this week.&lt;/p&gt; &lt;p&gt;First up was the second add-on to HDP based on a partnership with another company - &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hortonworks HBD&lt;/a&gt; (aka Pivotal HDB, aka Apache Hawq). We then looked at the management components of the HDP stack - &lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Apache Ambari&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-smartsense&quot;&gt;Hortonworks SmartSense&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So - &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hortonworks HBD&lt;/a&gt;. It’s Pivotal HDB - you download it from Pivotal and the Hortonworks documentation links through to the Pivotal documentation, but with Hortonworks (according to the press release) providing customer support and professional implementation services. The press release is worth a look - as part of the deal Pivotal agreed to drop Pivotal HD (their Hadoop distribution) and resell HDP instead, and Hortonworks agreed to distribute HDB. But given their investment in Hive through the Stinger initiative, you have to wonder how interested Hortonworks are in pushing it. Which is possibly a shame, because Apache Hawq is probably the most mature SQL engine available on Hadoop today - whether that’s a good or bad thing, and how much traction it’s going to get I don’t know.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Apache Ambari&lt;/a&gt; - Hortonworks competitor to Cloudera Manager. What I found most interesting about Ambari was the list of contributors - 50 from Hortonworks, 6 from IBM, 6 from Pivotal, 4 from RedHat plus some more - 82 in total. That’s a pretty significant development capacity, and probably goes to show how valuable having an easy way to provision and manage Hadoop clusters is to its adoption. What also struck me about Ambari was how much it didn’t feel like an open source technology - it only (realistically) supports the installation of HDP, the committers are all employees of large companies and the Apache documentation is pretty poor.&lt;/p&gt; &lt;p&gt;I split &lt;a href=&quot;/technologies/apache-ambari/ambari-views&quot;&gt;Ambari Views&lt;/a&gt; out from Ambari for a couple of reasons. Firstly, I ran out of time on Tuesday to include it in the Ambari technology summary, and there was probably too much to put in a single summary anyway, but also because I think Ambari Views is targeting a slightly different use case and group of users than Ambari. It feels like Hortonworks is lining this up as a competitor to Hue (they have a Hue to Ambari migration tool for starters), however it feels lightweight (in features) and heavyweight (in terms of hardware requirements) compared to Hue, and I don’t see it gaining the same traction. Perhaps if Cloudera had donated Hue to the Apache Foundation Ambari Views wouldn’t even exist.&lt;/p&gt; &lt;p&gt;And &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; - an extremely interesting technology where cloud infrastructure meets Docker meets Hadoop. It feels like early days for Cloudbreak, however Hadoop in the Cloud (on or off premesis) is seeing massive investment from both Cloudera and Hortonworks at the moment, and it’s a really interesting area that I’d love to come back to at some point.&lt;/p&gt; &lt;p&gt;Lastly to &lt;a href=&quot;/technologies/hortonworks-smartsense&quot;&gt;Hortonworks SmartSense&lt;/a&gt;. Hortonworks’ business model is interesting - their commitment to open source means you can use their entire technology stack for free, you only pay for support and professional services, but this means their support and services offering has to deliver value and be worth the money (which also means that their stack can’t be too reliable or easy to manage without their help). SmartSense is their only technology that isn’t open source, and is the key piece in the value of their support offering. And the fact it appears to contain a bunch of cluster analytics that aren’t available through Ambari is an interesting facet of that.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/10/the-week-that-was/</guid> </item> <item><title>Hortonworks SmartSense</title><link>http://ondataengineering.net/technologies/hortonworks-smartsense/</link><pubDate>Fri, 10 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Supports the capture of diagnostic information from Hadoop clusters (including configuration, metrics and logs from both Hadoop and the Operating System) into a bundle for upload (either manually or automatically) to the Hortonworks support portal to assist in the resolution of support issues and the delivery of cluster optimisation and preventative action recommendations, with support for anonymisation (including IP addresses and host names, with support for further custom rules) and encryption of information in bundles and a SmartSense gateway to proxy uploads if direct internet access isn't available. Also includes functionality to help understand and analyse cluster activity include the Activity Analyser (aggregates data from YARN, Tez, MapReduce and HDFS into Ambari Metrics) and Activity Explorer (an embedded instance of Apache Zeppelin with pre-built notebooks for exploring and visualising cluster activity). Installable and manageable through Apache Ambari. Part of the Hortonworks support offering, introduced in June 2015 as part of HDP 2.3.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;SmartSense&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/services/support/smartsense/&quot;&gt;https://hortonworks.com/services/support/smartsense/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/SS1/SmartSense-1.3.1/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/SS1/SmartSense-1.3.1/index.html&lt;/a&gt; - current documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-smartsense/</guid> </item> <item><title>Cloudbreak</title><link>http://ondataengineering.net/technologies/cloudbreak/</link><pubDate>Thu, 09 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Solution for deploying and managing Hadoop clusters on cloud infrastructure based on automatically provisioned infrastructure running base docker images with Hadoop provisioned on top via Apache Ambari using Blueprints. Includes out of the box support for Amazon Web Services, Microsoft Azure, Google Cloud Platform and OpenStack, plus a Service Provider Interface (SPI) for adding support for new providers. Supports automated scaling of clusters based on Ambari Metrics and Alerts (Periscope), custom scripts that can be run on hosts before or after deployment (Recipes), a number of out of the box Blueprints, plus a number of technical preview features, including the use of custom docker images, data locality specifiers, Kerberized clusters, support for external AD/LDAP servers and deployment on Mesos. Manageable through a web UI, a REST API, a CLI and an interactive shell. Originally created by SequenceIQ, with an initial beta release in July 2014, with SequenceIQ then acquired by Hortonworks in April 2015, and a 1.0 release of Cloudbreak included in HDP 2.3 in July 2015. Open sourced under the Apache 2.0 licence, with a stated plan for the code to be donated to the Apache Foundation.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.6&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://sequenceiq.com/cloudbreak-docs/latest/&quot;&gt;http://sequenceiq.com/cloudbreak-docs/latest/&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/sequenceiq/cloudbreak&quot;&gt;https://github.com/sequenceiq/cloudbreak&lt;/a&gt; - Code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/cloudbreak/&quot;&gt;https://hortonworks.com/apache/cloudbreak/&lt;/a&gt; - Hortonworks information, including blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/Cloudbreak/Cloudbreak-1.6.3/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/Cloudbreak/Cloudbreak-1.6.3/index.html&lt;/a&gt; - Hortonworks documentation page, however links through to SequenceIQ docs page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-acquires-sequenceiq-to-provide-automated-deployment-of-hadoop-everywhere/&quot;&gt;https://hortonworks.com/blog/hortonworks-acquires-sequenceiq-to-provide-automated-deployment-of-hadoop-everywhere/&lt;/a&gt; - SequenceIQ acquisition announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudbreak/</guid> </item> <item><title>Ambari Views</title><link>http://ondataengineering.net/technologies/apache-ambari/ambari-views/</link><pubDate>Wed, 08 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Framework within Ambari that allows new applications or views to be added to Ambari, based on new client side code (HTML, JavaScript and CSS) supported by new backend code (Java) that exposes REST API end points for the UI to consume. Comes with support for a number of views out of the box, including YARN Queue Manager (supports the creation and configuration of YARN capacity schedule queues), Files (supports copying and moving, uploading and setting permissions on files in HDFS), Falcon (supports defining, scheduling and monitoring data management pipelines), Hive (supports browsing databases, executing queries and viewing explain plans, saving queries, viewing query history and uploading data to Hive tables), Pig (supports executing Pig scripts and viewing execution history), SmartSense (supports capture and download of bundles), Storm (supports viewing cluster status, monitoring topologies, perform topology management and access metrics and logs) and Tez (supports viewing and debugging Tez jobs), along with technical previews of Workflow Designer, Zeppelin and Hue migration views. Views can be deployed into a standalone Ambari instance to separate these from the primary Ambari management instance and to support scaling out.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ambari/ambari-views/</guid> </item> <item><title>Apache Ambari</title><link>http://ondataengineering.net/technologies/apache-ambari/</link><pubDate>Tue, 07 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Platform for installing, managing and monitoring Apache Hadoop clusters. Supports the installation of different versions of different distributions of Hadoop through Stack definitions (with support for HDP out of the box, and further stacks and add ons available through management packs), and the specification of Blueprints (cluster layouts and configuration for a given Stack) that can be used to programmatically create multiple clusters (e.g. dev, test and production). Also supports both rolling (no downtime) and express (faster but with downtime) upgrades; cluster administration (including adding and removing nodes/services, viewing the status of nodes/services, and configuring services with the versioning of configuration and the ability to rollback changes); the automated Kerberization of clusters; the collection, storage (in HBase) and visualisation (via Grafana or through dashboards in Ambari) of system and Hadoop component metrics via the Ambari Metrics System (AMS); alerting on statuses and metrics; the collection, storage (in Solr) and searching/viewing of log entries from across the Hadoop cluster (currently in technical preview); and a framework for UI components within Ambari (Ambari Views, treated here as a sub-project). Web based, with a REST API, and backed by a backend database (Oracle, MySQL or Postgres). Donated to the Apache Foundation by Hortonworks, IBM and Yahoo in August 2011 as the Hadoop Management System (HMS), graduating in December 2013 after changing it's name to Ambari. Still under active development with a large number of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ambari&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache Ambari&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-ambari/ambari-views/&quot;&gt;Ambari Views&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Framework within Ambari that allows new applications or views to be added to Ambari, based on new client side code (HTML, JavaScript and CSS) supported by new backend code (Java) that exposes REST API end points for the UI to consume. Comes with support for a number of views out of the box, including YARN Queue Manager (supports the creation and configuration of YARN capacity schedule queues), Files (supports copying and moving, uploading and setting permissions on files in HDFS), Falcon (supports defining, scheduling and monitoring data management pipelines), Hive (supports browsing databases, executing queries and viewing explain plans, saving queries, viewing query history and uploading data to Hive tables), Pig (supports executing Pig scripts and viewing execution history), SmartSense (supports capture and download of bundles), Storm (supports viewing cluster status, monitoring topologies, perform topology management and access metrics and logs) and Tez (supports viewing and debugging Tez jobs), along with technical previews of Workflow Designer, Zeppelin and Hue migration views. Views can be deployed into a standalone Ambari instance to separate these from the primary Ambari management instance and to support scaling out.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://ambari.incubator.apache.org/&quot;&gt;http://ambari.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/ambari/&quot;&gt;http://hortonworks.com/apache/ambari/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/Ambari/Ambari-2.4.2.0/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/Ambari/Ambari-2.4.2.0/index.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/AMBARI/Ambari&quot;&gt;https://cwiki.apache.org/confluence/display/AMBARI/Ambari&lt;/a&gt; - Apache developer level documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ambari/</guid> </item> <item><title>Apache Hawq</title><link>http://ondataengineering.net/technologies/apache-hawq/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A port of the Greenplum MPP database (which itself is based on PostgreSQL) to run over YARN and HDFS. Supports all the features of Greenplum (ACID transactions, broad SQL support and in database language and analytics support, including support for Apache MADLib), integrated with Apache Ambari, an Input Format for MapReduce to read Hawq tables, and both row and Parquet (column) based storage of data managed by Hawq. Also supports queries over data not managed by Hawq via external tables, with a Java based framework (PXF) for accessing external data, and out of the box support for accessing data in HDFS (text, Avro, JSON), Hive and HBase, with a number of open source connectors also available. Fault tolerant and horizontally scalable, with the ability to scale up or down on the fly. Originally created as Pivotal Hawq based on a fork of Greenplum in 2011, with an initial 1.0 release as part of Pivotal HD in July 2013. Open sourced and donated to the Apache Foundation in September 2015, becoming Apache Hawq, with the first open source release (2.0) in October 2016. Development led by Pivotal, who also distribute binaries as Pivotal HDB and provide training, consultancy and support. Pivotal HDB is also available as Hortonworks HDB.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Pivotal HDB, Hortonworks HDB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Pivotal, &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hawq.incubator.apache.org/&quot;&gt;http://hawq.incubator.apache.org/&lt;/a&gt; - Apache Hawq homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hawq.incubator.apache.org/docs/userguide/latest/index.html&quot;&gt;http://hawq.incubator.apache.org/docs/userguide/latest/index.html&lt;/a&gt; - Apache Hawq documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/HAWQ/&quot;&gt;https://cwiki.apache.org/confluence/display/HAWQ/&lt;/a&gt; - Apache Hawq Wiki&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/hawk/&quot;&gt;http://hortonworks.com/apache/hawk/&lt;/a&gt; - Hortonworks information on Apache Hawq&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_hdb-quick-guide/content/ch_hdb_summary.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_hdb-quick-guide/content/ch_hdb_summary.html&lt;/a&gt; - Hortonworks HDB documentation (links through to Pivotal HDB docs)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://pivotal.io/pivotal-hdb&quot;&gt;https://pivotal.io/pivotal-hdb&lt;/a&gt; - Pivotal HDB homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hdb.docs.pivotal.io/&quot;&gt;http://hdb.docs.pivotal.io/&lt;/a&gt; - Pivotal HDB documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://content.pivotal.io/blog/the-way-to-hadoop-native-sql&quot;&gt;https://content.pivotal.io/blog/the-way-to-hadoop-native-sql&lt;/a&gt; - Hawq open source announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&quot;&gt;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&lt;/a&gt; - Hortonworks and Pivotal HDB announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via Hortonworks and Pivotal blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-hawq/</guid> </item> <item><title>The Week That Was - 03/03/2017</title><link>http://ondataengineering.net/blog/2017/03/03/the-week-that-was/</link><pubDate>Fri, 03 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;Right - we’re nearly at the end of the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies. Let’s summarise what we’ve looked at this week.&lt;/p&gt; &lt;p&gt;We started off with &lt;a href=&quot;/technologies/apache-slider&quot;&gt;Apache Slider&lt;/a&gt;, then looked at &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Apache Accumulo&lt;/a&gt;, before finishing off with &lt;a href=&quot;/technologies/livy&quot;&gt;Livy&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-slider&quot;&gt;Apache Slider&lt;/a&gt; is interesting. It feels like a technology that allows you to run any long running app on YARN and have it play nicely with other YARN apps should be something people care about, because isn’t the whole selling point of Hadoop that you can have on analytical cluster that supports multiple workloads that all play nicely together, but it looks like outside of Hortonworks there’s very take up. It’s been in incubation since April 2014, and it seems like the biggest barrier to graduation is that there simply aren’t any committers outside of Hortonworks.&lt;/p&gt; &lt;p&gt;If there’s any one technology that kick-started the rise of the streaming data engines is has to be &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt; - the granddaddy of streaming technologies and still the 900 pound gorilla in the room. It’s not perfect, people have taken a lot of potshots at it over the years, and Twitter have now moved on (to Heron), however it’s been successful for a reason, and it looks like it’s been given a new lease of life after joining the Apache foundation, so if you’re looking at streaming use cases I don’t think you can afford not to look at it. Brush up on your micro batch vs record at a time considerations first however.&lt;/p&gt; &lt;p&gt;It want to look at &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;Apache HBase&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Apache Accumulo&lt;/a&gt; in more detail in the future, however Accumulo is gaining good adoption, is bundled with most Hadoop distributions, and has some interesting differentiations from HBase.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/livy&quot;&gt;Livy&lt;/a&gt; - a little piece of technology that’s come out of Cloudera that underpins the ability for analytical notebooks to run Spark code on remote clusters. I wonder how much it rankles Hortonworks to distribute Livy and Hue - both (open source Apache licenced) technologies that currently sit in a Cloudera repository in GitHub.&lt;/p&gt; &lt;p&gt;And last up for this week is &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt; - a custom bundling of Solr (along with a bunch of other technologies), built and maintained by Lucidworks and distributed as an add on to the Hortonworks Data Platform. It means that Solr doesn’t come out of the box with HDP (you have to download an extra Ambari management pack manually to install it), but it looks like a great partnership for Hortonworks - you get support from arguably the leading experts in Solr, and get Solr bundled with a bunch of other useful stuff that you don’t get with the other distributions.&lt;/p&gt; &lt;p&gt;Next week - the final HDP technologies. Have a great weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/03/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Platform Search</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform-search/</link><pubDate>Fri, 03 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An add on package to HDP that bundles up Solr, Banana, and a suite of libraries and tools for integrating with Solr from Hadoop (utilities for loading data from HDFS), Hive (a SerDe to allow Solr data to be read and written as a Hive table), Pig (store and load functions), HBase (replication of HBase events to Solr based on the Lily HBase indexer), Storm and Spark (both SDKs for integrating with Solr). Available as an add on Ambari management pack or as a set of RPMs. Built, maintained and supported by Lucidworks on behalf of Hortonworks, first announced in April 2014 as part of the introduction of Solr with HDP 2.1.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP Search&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;, Lucidworks&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;, Banana&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://doc.lucidworks.com/lucidworks-hdpsearch/2.5/index.html&quot;&gt;https://doc.lucidworks.com/lucidworks-hdpsearch/2.5/index.html&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_solr-search-installation/content/ch_hdp-search.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_solr-search-installation/content/ch_hdp-search.html&lt;/a&gt; - Hortonworks installation documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/bringing-enterprise-search-enterprise-hadoop/&quot;&gt;https://hortonworks.com/blog/bringing-enterprise-search-enterprise-hadoop/&lt;/a&gt; - Partnership announcement blog post&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform-search/</guid> </item> <item><title>Livy</title><link>http://ondataengineering.net/technologies/livy/</link><pubDate>Thu, 02 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A service that allows Spark jobs (pre-compiled JARs) or code snippets (Scala or Python) to be executed by remote systems over a REST API or via clients for Java, Scala and Python. Supports re-use of Spark Contexts (and caching and sharing of RDDs across jobs and clients), multiple concurrent clients, secure authenticated communications and batch job submissions. Started in November 2015 based on code from Hue, with a formal announcement and first release in June 2016. Open source under the Apache 2.0 licence, hosted on GitHub with development led by Cloudera and Microsoft. Still considered to be in alpha, but under active development, and used by tools such as Hue and Zeppelin.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://livy.io/&quot;&gt;http://livy.io/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/livy&quot;&gt;https://github.com/cloudera/livy&lt;/a&gt; - code repository&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/more/news-and-events/press-releases/2016-06-06-cloudera-microsoft-lead-development-open-source-project-livy-for-easy-use-spark-end-user-applications.html&quot;&gt;https://www.cloudera.com/more/news-and-events/press-releases/2016-06-06-cloudera-microsoft-lead-development-open-source-project-livy-for-easy-use-spark-end-user-applications.html&lt;/a&gt; - original announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/livy/releases&quot;&gt;https://github.com/cloudera/livy/releases&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/livy/</guid> </item> <item><title>Apache Accumulo</title><link>http://ondataengineering.net/technologies/apache-accumulo/</link><pubDate>Wed, 01 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;NoSQL wide-column datastore based on BigTable. Supports horizontal scalability, cell based access control (based on arbitrary boolean expressions of user security labels), high availability, atomic read-modify-write operations, map reduce support (both as a source and sink), table constraints, LDAP and Kerberos integration, and replication between instances. Comes with a web based monitoring interface (Accumulo Monitor) and a CLI. Written in Java, with thrift based API allowing access from other languages including C++, Python, Ruby. Originally developed at the NSA, donated to the Apache Foundation in September 2011, before graduating in March 2012, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Accumulo&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/&quot;&gt;http://accumulo.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/docs-archive/&quot;&gt;http://accumulo.apache.org/docs-archive/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/accumulo/&quot;&gt;https://hortonworks.com/apache/accumulo/&lt;/a&gt; - Hortonworks information&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/news/&quot;&gt;http://accumulo.apache.org/news/&lt;/a&gt; - news page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-accumulo/</guid> </item> <item><title>Apache Storm</title><link>http://ondataengineering.net/technologies/apache-storm/</link><pubDate>Tue, 28 Feb 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Specialised distributed stream processing technology based on a single record (not micro batch) model with at least once processing semantics. Processing flows are called topologies based on a directed acyclic graph of spouts (which produce unbounded streams of tuples) and bolts (which process streams and optionally produce output streams). Supports high throughput and low latency use cases, horizontal scalability, fault tolerance (failed workers are automatically restarted and failed over to new nodes if required), back pressure, windowing (with support for sliding and tumbling windows based on time or event counts), stateful bolts and a shared bolt storage cache (that's updatable from the command line). Also includes a higher level micro batch API (Trident) that supports exactly-once processing semantics, fault-tolerant state management and higher level operations including joins, aggregations and groupings, support for SQL (StormSQL) and frameworks and utilities to make defining and deploying topologies easier (Flux). Has both a graphical web based and command line interface, plus a REST API. Primarily written in Clojure, JVM based, but supports multiple languages through the use of Thrift for defining and submitting topologies, and the use of spouts that can interface to other languages using JSON over stdin/stdout. Originally created at BackType, before being open sourced in September 2011 after the acquisition of BackType by Twitter. Donated to the Apache Foundation in September 2013, graduating in September 2014, with a 1.0 release in April 2016. Has multiple reference cases for being deployed at scale, including Twitter, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Storm&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v1.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/&quot;&gt;http://storm.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/storm/&quot;&gt;https://hortonworks.com/apache/storm/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/releases/1.0.3/index.html&quot;&gt;http://storm.apache.org/releases/1.0.3/index.html&lt;/a&gt; - documentation for current release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_storm-component-guide/content/ch_storm-overview.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_storm-component-guide/content/ch_storm-overview.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nathanmarz.com/blog/history-of-apache-storm-and-lessons-learned.html&quot;&gt;http://nathanmarz.com/blog/history-of-apache-storm-and-lessons-learned.html&lt;/a&gt; - history of storm&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;http://accumulo.apache.org/news/&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/index.html&quot;&gt;http://storm.apache.org/index.html&lt;/a&gt; - Storm new announced on Apache homepage&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-storm/</guid> </item> <item><title>Apache Slider</title><link>http://ondataengineering.net/technologies/apache-slider/</link><pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for hosting long running distributed applications on YARN, allowing YARN to manage the resources these applications use. Can handle any application that supports a base set of requirements (including being able to install and run from a tarball), with experimental support for docker packaged applications. Operates as a YARN application master (the Slider AM), an associated command line interface and lightweight agents to manage running components. Supports manual scaling, automatic recovery, rolling upgrades and component placement controls, and includes out of the box configuration for a number of applications including Accumulo, HBase, Kafka, Memcached, Solr, Storm and Tomcat. An incubating Apache project, originally donated in April 2014. Hasn't yet reached a v1.0 milestone, however still under development led by Hortonworks.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Slider&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.91&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://slider.incubator.apache.org&quot;&gt;http://slider.incubator.apache.org&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/deploying-long-running-services-on-apache-hadoop-yarn-cluster/&quot;&gt;https://hortonworks.com/blog/deploying-long-running-services-on-apache-hadoop-yarn-cluster/&lt;/a&gt; - introduction blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/slider/&quot;&gt;https://hortonworks.com/apache/slider/&lt;/a&gt; - Hortonworks information on slider, including links to blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_yarn-resource-management/content/ch_slider.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_yarn-resource-management/content/ch_slider.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://slider.incubator.apache.org/docs/&quot;&gt;http://slider.incubator.apache.org/docs/&lt;/a&gt; - Slider documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-slider/</guid> </item> <item><title>The Week That Was - 24/02/2017</title><link>http://ondataengineering.net/blog/2017/02/24/the-week-that-was/</link><pubDate>Fri, 24 Feb 2017 08:20:00 +0000</pubDate> <description> &lt;p&gt;And so we’ve started our foray into the technologies bundled with &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. We’ve already looked at a large number of these technologies, but there’s a few here that are new.&lt;/p&gt; &lt;p&gt;First up this week were the Hortonworks candidates in the metadata management and security space - &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-knox&quot;&gt;Apache Knox&lt;/a&gt;. We’ve then finished the week with &lt;a href=&quot;/technologies/apache-falcon&quot;&gt;Apache Falcon&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Everyone says they want metadata management, data catalogues and business glossaries, very few people actually build them, and they’re desperately un-sexy. Which is why you don’t often see open source technologies in this space. &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt; is trying to buck that trend, with some significant commercial backers. It’s going to be interesting to see how far this gets and what level of adoptions it gets. At the moment it feels like it’s trailing Cloudera Navigator, but that’s a commercial product which perhaps gives Cloudera greater impetus to invest in it. One to come back to at some point I think.&lt;/p&gt; &lt;p&gt;We’ll also be coming back to look at the state of security in the Hadoop Ecosystem - Cloudera and MapR are supporting Apache Sentry, whereas Hortonworks are supporting &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-knox&quot;&gt;Apache Knox&lt;/a&gt;. Competition and survival of the fittest in open source is one of it’s greatest strengths, however in this case it seems like the Cloudera Hortonworks rivalry (for want of a better word) is perhaps not helping to overall Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;I really want to like &lt;a href=&quot;/technologies/apache-falcon&quot;&gt;Apache Falcon&lt;/a&gt;, however I think I need to get to know it better before I start professing any love. It’s trying to solve a real problem - managing and orchestrating your data pipelines and the data that moves between and through these - however it’s a difficult problem, and creating a reductive solution can create real limitations and constraints. Another one I’d like to return to in due course.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;, here to claim the crown (from &lt;a href=&quot;/technologies/apache-zookeeper&quot;&gt;Apache ZooKeeper&lt;/a&gt;) of the best, most widely used technology you’ve probably never heard of. If you use an open source technology that has a SQL interface, you’re more than likely to be using Calcite - it provides SQL parsing, cost based optimisation and JDBC frameworks that are used in Hive, Drill, Storm, Apex, Druid, Kylin, Phoenix, Solr, Flink, Cascading and Samza amongst others. Creators of open source software often don’t get the acknowledgement they deserve, but Julian Hyde deserves our thanks and appreciation for creating what would become Apache Calcite.&lt;/p&gt; &lt;p&gt;Right - I’m done with this week. See you on the other side of the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/24/the-week-that-was/</guid> </item> <item><title>Apache Calcite</title><link>http://ondataengineering.net/technologies/apache-calcite/</link><pubDate>Fri, 24 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A framework for building SQL based data access capabilities. Supports a SQL parser and validator, tools for the transformation and (cost based) optimisation of SQL expression trees, and an adapter framework for accessing metadata and executing queries (including out of the box adapters for a number of database technologies as well as CSV files and POJO objects), along with specific support for streaming SQL queries and optimising data cube queries to use materialised views. Also includes (as a sub-project named Avatica), a framework for building database drivers with support for a standard JDBC driver, server and wire protocols, plus a local embeddable JDBC driver. Used in a range of other projects including Drill, Flink, Hive, Kylin, Phoenix, Samza, Storm and Cascading. An Apache project, originally created by Julian Hyde in May 2012 as Optiq, donated to the Apache Foundation in May 2014, graduating in October 2015 following a v1.0 release in January 2015. Under active development with a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Calcite, Avatica&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v1.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/&quot;&gt;https://calcite.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/docs/&quot;&gt;https://calcite.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/docs/avatica_overview.html&quot;&gt;https://calcite.apache.org/docs/avatica_overview.html&lt;/a&gt; - Avatica overview&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/news/&quot;&gt;https://calcite.apache.org/news/&lt;/a&gt; - Calcite news&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/avatica/news/&quot;&gt;https://calcite.apache.org/avatica/news/&lt;/a&gt; - Avatica news&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-calcite/</guid> </item> <item><title>Apache Falcon</title><link>http://ondataengineering.net/technologies/apache-falcon/</link><pubDate>Thu, 23 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data feed management system for Hadoop. Supports the definition, scheduling and orchestration (including support for late data and retry policies) of data processing pipelines (referred to as processes, with support for Ozzie, Spark, Hive and Pig jobs), the management of the data produced and consumed by these pipelines (referred to as feeds, with support for data in HDFS and Hive) and the generation and visualisation of pipeline lineage information, all across multiple Hadoop clusters. Also includes the ability to mirror or replicate HDFS and Hive data between clusters, to failover processing between clusters and to import and export data using Sqoop. Supports both a web and command line interface and a REST API. An Apache project, graduating in December 2014, having been originally donated by inMobi in April 2013. Hasn't yet reached a v1.0 milestone, however still under development led by inMobi and Hortonworks with a range of other contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Falcon&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://falcon.apache.org/&quot;&gt;http://falcon.apache.org/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/falcon/&quot;&gt;http://hortonworks.com/apache/falcon/&lt;/a&gt; - Hortonworks information on Falcon, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-movement-and-integration/content/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-movement-and-integration/content/index.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-falcon/</guid> </item> <item><title>Apache Knox</title><link>http://ondataengineering.net/technologies/apache-knox/</link><pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A stateless gateway for the Apache Hadoop ecosystem that provides perimeter security. Includes support for user authentication (via LDAP, Active Directory and a number of single sign on solutions), access authorisation on a per service basis, transitions to Kerberos authentication, reverse proxying and auditing, extension points for supporting new services, audit capabilities, and out of the box support for a number of Hadoop technology end points. An Apache project, started by Hortonworks in February 2013, donated to the Apache Foundation two months later in April, before graduating in February 2014. Hasn't yet reached a v1.0 milestone, however still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Knox&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/&quot;&gt;http://knox.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/books/knox-0-11-0/user-guide.html&quot;&gt;http://knox.apache.org/books/knox-0-11-0/user-guide.html&lt;/a&gt; - extreemly comprehensive documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/knox-gateway/&quot;&gt;http://hortonworks.com/apache/knox-gateway/&lt;/a&gt; - Hortonworks information on Knox&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&lt;/a&gt; - Hortonworks documentation on Knox&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KNOX/News&quot;&gt;https://cwiki.apache.org/confluence/display/KNOX/News&lt;/a&gt; - news updates&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-knox/</guid> </item> <item><title>Apache Ranger</title><link>http://ondataengineering.net/technologies/apache-ranger/</link><pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store (with a web based administration interface and REST API), and plugins for Hadoop components (including HDFS, Hive, HBase, Storm, Knox, Solr, Kafka, YARN, Atlas and NiFi) to manage authorisation of user access to data. Supports data masking and row level access policies (currently only supported by Hive), the ability to define policies against tags as well as directly against resources (with tags assigned to resources externally, e.g. in Apache Atlas), and the ability to use more complex conditions (e.g. denying access after an expiration date or based on a users location). Extendable with the ability to add support for new services (Ranger Stacks) and to add custom decision rules (via content enrichers and condition evaluators). Also supports a full audit capability of access requests and decisions, and a key management service for HDFS encryption keys. An incubating Apache project, donated in July 2014 by the Hortonworks following their acquisition of XA Secure. Has not yet reached a v1.0 milestone, but is still under active development with a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ranger&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.6&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.incubator.apache.org/&quot;&gt;http://ranger.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.apache.org/faq.html&quot;&gt;http://ranger.apache.org/faq.html&lt;/a&gt; - FAQs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/ranger/&quot;&gt;http://hortonworks.com/apache/ranger/&lt;/a&gt; - Hortonworks information on Ranger, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&lt;/a&gt; - Hortonworks documentation on Ranger&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/RANGER&quot;&gt;https://cwiki.apache.org/confluence/display/RANGER&lt;/a&gt; - Apache Ranger Wiki, with most information detailed by release under the Release Folders page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ranger/</guid> </item> <item><title>Apache Atlas</title><link>http://ondataengineering.net/technologies/apache-atlas/</link><pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A metadata and data governance solution for Hadoop. Supports an extensible metadata model with out of the box support for Hive datasets and data lineage from Hive queries and Sqoop imports, with limited support for Falcon, Storm and Kafka. Allows datasets and data items to be tagged (and for these tags to be used for access control by Apache Ranger), and includes support for business taxonomies as a technical preview. Implemented as a graph based database using Titan (which by default uses HBase and Solr), with a web based user interface and a REST API for searching and visualising/retrieving metadata, and Kafka topics for the ingest of metadata (primarily from hooks in metadata sources such as Hive or Sqoop) and the publishing of metadata change events. An incubating Apache project, donated to the Apache Foundation in May 2015 by the Hortonworks Data Governance Initiative in partnership with Aetna, Merck, Target, Schlumberger and SAS. Has not yet reached a v1.0 milestone or graduated as a top level Apache project, but is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Atlas&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/&quot;&gt;http://atlas.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/atlas&quot;&gt;http://hortonworks.com/apache/atlas&lt;/a&gt; - Hortonworks background information, including links to relevant blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/Architecture.html&quot;&gt;http://atlas.incubator.apache.org/Architecture.html&lt;/a&gt; - Architecture overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&lt;/a&gt; - Hortonworks documentation from 2.5.3 HDP release&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs*&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-atlas/</guid> </item> <item><title>The Week That Was - 17/02/2017</title><link>http://ondataengineering.net/blog/2017/02/17/the-week-that-was/</link><pubDate>Fri, 17 Feb 2017 16:50:00 +0000</pubDate> <description> &lt;p&gt;So let’s review the technologies we’ve looked at this week as we come to the end of our journey through the technologies bundled with Apache Bigtop.&lt;/p&gt; &lt;p&gt;The last Bigtop technologies we looked at where a couple of web based end user tools (&lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-zeppelin&quot;&gt;Apache Zeppelin&lt;/a&gt;), an HDFS compatible filesystem (&lt;a href=&quot;/technologies/quantcast-file-system&quot;&gt;Quantcast File System&lt;/a&gt;) and an MPP database (&lt;a href=&quot;/technologies/greenplum&quot;&gt;Greenplum&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;And today, we’ve started our look the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Of all the technologies we’ve looked at this week, &lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; was the biggest surprise. It’s an open source project licensed under the Apache 2.0 licence, but is not an Apache Foundation project (it actually sits in a Cloudera github repository). It’s pitched as a general purpose user interface for Hadoop, and the range of functionality it includes was surprising - everything from managing data in HDFS to creating Ozzie workflows to monitoring YARN logs to running SQL and Solr queries. It’s not an analysis notebook ala Jupyter or Zeppelin (although it now has some basic functionality in this area), but a web front end onto all the common Hadoop components, and if you’re using Hadoop, I would strongly suggest it’s worth your time to take a look at it. Even Hortonworks bundle it (despite the fact it’s not an Apache project), although they obviously don’t advertise this.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-zeppelin&quot;&gt;Apache Zeppelin&lt;/a&gt; is however an analytical notebook, with support for a wide range of languages and analytical tools. If you’re doing interactive or exploratory analytics it’s probably well worth a look.&lt;/p&gt; &lt;p&gt;The promise and potential of open source software is often overstated, but if you have a strong development team that are comfortable in opening and extending open source software then you can create fantastic capabilities specifically tuned to your business. &lt;a href=&quot;/technologies/quantcast-file-system&quot;&gt;Quantcast File System&lt;/a&gt; is a great example of this - an HDFS compatible filesystem based on an open source project (KFS) that allows Quantcast to operate at a scale that isn’t supported by other technologies. Companies that operate at extreme scale are fantastic breeding grounds for innovation, and we’ll definitely look at some of the technologies coming out of companies like Netflix, Facebook, eBay and LinkedIn in the future.&lt;/p&gt; &lt;p&gt;There are many reasons why companies open source projects - to pay back to the community, to accelerate development, and because a technology is no longer of significant commercial value. &lt;a href=&quot;/technologies/greenplum&quot;&gt;Greenplum&lt;/a&gt; feels like it falls into the final category - it’s been a commercial product since 2003 and has failed to gain any significant traction. It does however still seem to be under development (although primarily by Pivotal rather than by outside competitors), so maybe I’m misjudging this. I wouldn’t be &lt;a href=&quot;http://www.ness.com/big-data-101-the-rise-and-fall-of-greenplum-2/&quot;&gt;the only one&lt;/a&gt; however.&lt;/p&gt; &lt;p&gt;And today we looked at our second Hadoop distribution - the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. There’s a lot to like about HDP, especially it’s commitment to open source - I just hope that Hortonworks can work out a commercial model that makes them a sustainable business.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/17/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Platform</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform/</link><pubDate>Fri, 17 Feb 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A distribution of Hadoop based on a commitment to the Apache open source ecosystem. All bundled projects are Apache open source projects based on official Apache project releases, with any patches for bug fixes or new features official Apache project patches pulled from later releases of the project. Available as RPMs or can be installed using Apache Ambari (for local installs) or Cloudbreak (for installation on cloud platforms). Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Spark SQL, HDP Search and Hortonworks HDB. Provided free of charge, with training, consultancy and support available from Hortonworks, along with their proprietary SmartSense support tool. First released in June 2012.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 2.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-falcon/&quot;&gt;Apache Falcon&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Apache Slider&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Apache Zeppelin&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/livy/&quot;&gt;Livy&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;Apache Hawq&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;Hortonworks Data Platform Search&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-smartsense/&quot;&gt;Hortonworks SmartSense&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The base Apache project versions bundled with each version of HDP are shown on the HDP home page, as well as on the first page of the release notes. Details of the features in these releases that Hortonworks don’t support, and the patches that have been applied to these releases are also available in the release notes, along with known vulnerabilities, fixes from previous versions and known issues.&lt;/p&gt; &lt;p&gt;Note that:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Apache Calcite, Apache DataFu, Apache Mahout and Hue are not referenced on the HDP home page, but are part of HDP (they are referenced in the release notes)&lt;/li&gt; &lt;li&gt;Livy is not mentioned on the HDP home page or the release notes, but is part of HDP (it’s in the HDP rpm repo and included Zeppelin installation steps)&lt;/li&gt; &lt;li&gt;Although Solr is referenced on the HDP home page and in the release note, it is only available via the HDP Search add-on to HDP&lt;/li&gt; &lt;li&gt;Hortonworks HDB is Pivotal HDB, with support and consultancy provided by Hortonworks, and is distributed as an add-on to HDP&lt;/li&gt; &lt;li&gt;Cascading is referenced in the release notes, but isn’t part of HDP (it’s not in the HDP repo and isn’t covered by the installation guide)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/products/data-center/hdp/&quot;&gt;http://hortonworks.com/products/data-center/hdp/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/index.html&lt;/a&gt; - HDP 2.5.0 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/bk_release-notes/content/ch_relnotes_v250.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/bk_release-notes/content/ch_relnotes_v250.html&lt;/a&gt; - HDP 2.5.0 release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/blog/&quot;&gt;http://hortonworks.com/blog/&lt;/a&gt; - Hortonworks Blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform/</guid> </item> <item><title>Apache Bigtop to HDP</title><link>http://ondataengineering.net/blog/2017/02/17/apache-bigtop-to-hdp/</link><pubDate>Fri, 17 Feb 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;And so we’ve come to the end of the technologies included in Apache Bigtop - it’s been a bit of a meandering trip, taking in some well known sights, some up and coming stuff, and some slightly odd and obscure pieces.&lt;/p&gt; &lt;p&gt;But time and tide wait for no man, so on we march, continuing our trip into the world of Hadoop Distributions. Up next, it’s the Hortonworks Data Platform (HDP) - we’ll start by looking at HDP itself, and then move on to the technologies it includes that we haven’t looked at yet.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/17/apache-bigtop-to-hdp/</guid> </item> <item><title>Greenplum</title><link>http://ondataengineering.net/technologies/greenplum/</link><pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A shared nothing, massively parallel processing (MPP) database optimised for analytical / OLAP workloads. Based on a fork PostgreSQL, it is essentially multiple PostgreSQL databases working together as a single logical database. Supports a cost-based query optimiser optimised for large analytical workloads, multiple storage models (including append only, columnar and heap), full ACID compliance and concurrent transactions, multiple index types, broad SQL support, a range of client connectors (including ODBC and JDBC), high capacity bulk load and unload tools, in database query language support (including Python, R, Perl, Java and C), and in database analytics support (including machine learning via Apache MADLib, geographic analytics via PostGIS and encryption via PGCrypto). Originally created by Greenplum (the company) which was founded in September 2003 before being brought by EMC in 2010, with Greenplum (the database) then spun out as part of Pivotal Software in 2013 before being open sourced in in October 2015 under the Apache 2.0 licence with the source code hosted on GitHub. Development is still led by Pivotal (with little evidence of outside contributions), who also distribute binaries as Pivotal Greenplum and provide training, consultancy and support.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Pivotal Greenplum, GPDB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Pivotal&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 4.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://greenplum.org/&quot;&gt;http://greenplum.org/&lt;/a&gt; - open source project homepage &lt;a href=&quot;https://github.com/greenplum-db/gpdb&quot;&gt;https://github.com/greenplum-db/gpdb&lt;/a&gt; - code repository &lt;a href=&quot;https://pivotal.io/pivotal-greenplum&quot;&gt;https://pivotal.io/pivotal-greenplum&lt;/a&gt; - Pivotal Greenplum homepage &lt;a href=&quot;https://github.com/greenplum-db/greenplum-db.github.io/wiki/Greenplum-Architecture&quot;&gt;https://github.com/greenplum-db/greenplum-db.github.io/wiki/Greenplum-Architecture&lt;/a&gt; - architecture overview &lt;a href=&quot;https://content.pivotal.io/datasheets/pivotal-greenplum&quot;&gt;https://content.pivotal.io/datasheets/pivotal-greenplum&lt;/a&gt; - Pivotal Greenplum datasheet &lt;a href=&quot;http://gpdb.docs.pivotal.io/&quot;&gt;http://gpdb.docs.pivotal.io/&lt;/a&gt; - documentation &lt;a href=&quot;https://network.pivotal.io/products/pivotal-gpdb&quot;&gt;https://network.pivotal.io/products/pivotal-gpdb&lt;/a&gt; - download site&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://greenplum.org/&quot;&gt;http://greenplum.org/&lt;/a&gt; - link to Greenplum announcement mailing list&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/greenplum/</guid> </item> <item><title>Quantcast File System</title><link>http://ondataengineering.net/technologies/quantcast-file-system/</link><pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Open source HDFS compatible distributed file system, which focuses on improving performance and scalability over HDFS. Uses erase coding (specifically Reed-Solomon error correction) allowing each data block to be stored with a 50% overhead over 9 nodes with data able to be read from any 6 (half the space required by HDFS with 3 way replication). Also supports online addition of new data (chunk) nodes, automatic re-balancing and re-replication of data, Unix style permissions support and C++ and Java client libraries. Published benchmarks suggest a 50/75% read/write performance increase over HDFS, and significantly faster metadata operations. Now also runs over Amazon S3. Built and maintained by Quantcast, who open sourced it in August 2012. An evolution of the Kosmos File System (KFS), an open source project started by Kosmix in 2005, which Quantcast first adopted in 2007. Built in C++ and released under the Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;QFS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Quantcast&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Quiet&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 1.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://quantcast.github.io/qfs/&quot;&gt;https://quantcast.github.io/qfs/&lt;/a&gt; - homepage &lt;a href=&quot;https://github.com/quantcast/qfs/&quot;&gt;https://github.com/quantcast/qfs/&lt;/a&gt; - code &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/&quot;&gt;https://github.com/quantcast/qfs/wiki/&lt;/a&gt; - documentation &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/Introduction-To-QFS&quot;&gt;https://github.com/quantcast/qfs/wiki/Introduction-To-QFS&lt;/a&gt; - introduction and summary of benefits &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/Performance-Comparison-to-HDFS&quot;&gt;https://github.com/quantcast/qfs/wiki/Performance-Comparison-to-HDFS&lt;/a&gt; - performance comparison to HDFS &lt;a href=&quot;https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/&quot;&gt;https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/&lt;/a&gt; - information on running over S3 &lt;a href=&quot;https://gigaom.com/2012/09/27/quantcast-releases-bigger-faster-stronger-hadoop-file-system/&quot;&gt;https://gigaom.com/2012/09/27/quantcast-releases-bigger-faster-stronger-hadoop-file-system/&lt;/a&gt; - background information &lt;a href=&quot;http://www.odbms.org/blog/2013/03/big-data-improving-hadoop-for-petascale-processing-at-quantcast/&quot;&gt;http://www.odbms.org/blog/2013/03/big-data-improving-hadoop-for-petascale-processing-at-quantcast/&lt;/a&gt; - interview with creators&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://www.quantcast.com/feed/&quot;&gt;http://www.quantcast.com/feed/&lt;/a&gt; - occasional updates on the Quantcast blog&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/quantcast-file-system/</guid> </item> <item><title>Apache Zeppelin</title><link>http://ondataengineering.net/technologies/apache-zeppelin/</link><pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A web based notebook for interactive data analytics. Supports a wide range of interpreters (including Spark, JDBC SQL, Pig, Elasticsearch, Beam, Flink, Shell, Python amongst many others), a range of output formats (plain text, HTML, mathematical expressions using MathJax and tabular data), a range of visualisations for tabular data (including the ability to add more via a JavaScript NPM based plugin system called Helium), forms for user entry of parameters, and an Angular API to enable dynamic and interactive functionality within notebooks. Has a plugable storage for notebooks (with out of the box support for git, S3, Azure and ZeppelinHub), support for multi-user environments and a security model. Open sourced by NFLabs (now called ZEPL) in 2013 before being donated to the Apache Foundation in December 2014, graduating in May 2016. Under active development with a wide range of contributors, led by ZEPL, who sell Zeppelin as a managed service (ZepplinHub).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Zeppelin&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, ZEPL&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://zeppelin.apache.org/&quot;&gt;http://zeppelin.apache.org/&lt;/a&gt; - homepage &lt;a href=&quot;https://zeppelin.apache.org/docs/&quot;&gt;https://zeppelin.apache.org/docs/&lt;/a&gt; - documentation by version &lt;a href=&quot;https://www.zepl.com/&quot;&gt;https://www.zepl.com/&lt;/a&gt; - ZEPL homepage &lt;a href=&quot;https://www.zeppelinhub.com/&quot;&gt;https://www.zeppelinhub.com/&lt;/a&gt; - ZepplinHub home page&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://zeppelin.apache.org/&quot;&gt;https://zeppelin.apache.org/&lt;/a&gt; - release announcements via the homepage&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-zeppelin/</guid> </item> </channel> </rss>
