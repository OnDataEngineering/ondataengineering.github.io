<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>OnDataEngineering</title>
		<description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description>
		<link>http://ondataengineering.net/</link>
		<atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Big Data</title>
				<link>http://ondataengineering.net/blog/2016/12/09/big-data/</link>
				<pubDate>Fri, 09 Dec 2016 00:00:00 +0000</pubDate>
				<description>&lt;p&gt;Before we get stuck in, a short digression to talk about Big Data.
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;There are many different definitions of Big Data, but for arguments sake let’s say this refers to the exploitation of data that would have previously been uneconomical due to the volume of data, the structure or format of the data (e.g. unstructured, semi-structured, or complex file formats such as video and audio) and the types of analytics required (e.g. path, graph or time series analysis)&lt;/p&gt;

&lt;p&gt;I’ve a couple of comments to make on this topic.&lt;/p&gt;

&lt;p&gt;Firstly, in my (humble) option Big Data is a marketing term (supported by new technologies - primarily Hadoop) that’s been exploited to sell these technologies and to give the industry something to talk about.  However, I think this has been a broadly positive thing, in that it’s brought data analytics to the mainstream, spurred uptake of new technologies and encouraged companies to invest in analytics and data processing that they may not have done previously. In any case it’s probably just about run its course now (as demonstrated as it’s fall down the far side of the hype curve), and has definitely resulted in the devaluation of other (perhaps more traditional) analytical capabilities which still have a role to play and in many cases deliver capabilities that Big Data technologies can’t yet match.&lt;/p&gt;

&lt;p&gt;Secondly, I think there’s been a lot of misinformation about Big Data and Big Data technologies. It’s not a replacement for existing BI/MI and analytical capabilities, and in fact needs to coexist and integrate with these in order to deliver on its promises. It’s not always cheaper or more performant than existing technologies, and won’t always reduce the timescales and costs for analytics or data exploration. And it’s not a new or innovative technology -  I know of companies that were analysing multi-petabyte data stores and doing real time analytics over ten years ago, parallel distributed file systems have been around for a lot longer than that, and there are many established technologies that have data processing capabilities that the new technologies are only just starting to catch up to.&lt;/p&gt;

&lt;p&gt;In terms of this site the plan is to look at the wider picture and take an holistic view of data transformation and exploitation.  I’ve therefore no plans to talk explicitly about Big Data, but in looking at the wider picture we will absolutely cover everything relating to it (the technologies and the new use cases these enable) alongside coverage of other new technologies, more established technologies and capabilities, and the interesting intersection between them all.&lt;/p&gt;
</description>
				<guid isPermaLink="true">http://ondataengineering.net/blog/2016/12/09/big-data/</guid>
			</item>
		
			<item>
				<title>Welcome</title>
				<link>http://ondataengineering.net/blog/2016/12/07/welcome/</link>
				<pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
				<description>&lt;p&gt;For me, one of the biggest challenges in exploiting data (be that through reporting, big data analytics, machine learning or any one of a dozen similar capabilities) is making sure you have the right data in the right place at the right time to allow you to do this efficiently.
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;For example, &lt;a href=&quot;http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html&quot;&gt;this&lt;/a&gt; article from the New York Times and &lt;a href=&quot;http://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/&quot;&gt;this&lt;/a&gt; more recent one from Forbes talks about how the analysis of big data promises unique business insights, but for big-data scientists there is significant manual ‘janitor work’ (up to 80% of their time) required to prepare data, and although the research is sponsored by Data Wrangling tool vendors, the conclusions will resonate with many data scientists.  Combine this with the historical cost, delivery speed and agility issues typically associated with delivery data warehouse or reporting solutions, and for me it’s never been clearer that we need to get smarter at how we prepare and manage data.&lt;/p&gt;

&lt;p&gt;Part of the solution to this is better Data Engineering, ensuring the processes, tools, technologies, data platforms, regular data feeds and their data preparation jobs are in place to allow the data to be exploited in an efficient, reliable and repeatable way.  The aim of this site is therefore to try to offer independent, critical and technical thinking on the technologies, architectural patterns and delivery capabilities that can help address this.&lt;/p&gt;

&lt;p&gt;My hope is that this becomes a community owned and authored site of trusted reference material on these topics.  To that end, all the content on this site is licensed under the Creative Commons Attribution 4.0 International License and hosted in a public GitHub repository, and there are a set of Discourse forums for discussions. Details of how to contribute and get involved can be found on every page.&lt;/p&gt;
</description>
				<guid isPermaLink="true">http://ondataengineering.net/blog/2016/12/07/welcome/</guid>
			</item>
		
	</channel>
</rss>
