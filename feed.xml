<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>Apache Myriad</title><link>http://ondataengineering.net/technologies/apache-myriad/</link><pubDate>Mon, 24 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Tool that allows YARN applications to run over Apache Mesos, allowing them to co-exist and share cluster resources. Consists of Myriad Executor, a Mesos managed task that in turns manages a YARN Node Manager, and Myriad Scheduler, a plugin for the YARN Resource Manager that delegates resource negotiation to Mesos (and launches Myriad Executor processes on required nodes via Mesos). Supports fixed resource allocation to YARN Node Managers, as well as fine-grained scaling where resources are dynamically requested from Mesos. Includes a web based user interface and REST API that includes support for scaling YARN resources when using fixed resource allocation. Originally created by eBay, MapR and Mesosphere and dondated to the Apache Foundation in March 2015. Has not yet graduated or reached a 1.0 release, with development activity seeming very quiet since October 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Myriad&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commerical Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v0.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/&quot;&gt;http://myriad.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/docs/&quot;&gt;http://myriad.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/product-overview/apache-myriad/&quot;&gt;https://mapr.com/products/product-overview/apache-myriad/&lt;/a&gt; - MapR information&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/news/&quot;&gt;http://myriad.apache.org/news/&lt;/a&gt; - news&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-myriad/</guid> </item> <item><title>The Week That Was - 21/04/2017</title><link>http://ondataengineering.net/blog/2017/04/21/the-week-that-was/</link><pubDate>Fri, 21 Apr 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;We’ve been a little bit all over the shop this week, but let’s try and summarise what we’ve looked at.&lt;/p&gt; &lt;p&gt;We started late having taken Monday off for Easter, with a look at &lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt; on Tuesday, closing out our review of them and their technologies. We then took another break on Wednesday to catchup on everything that’s changed in the technologies we’ve looked at to date, returning on Thursday with the start of our journey into MapR, the final Hadoop distribution we’re going to look at in detail. We’ve started by looking at their open source components, looking at the &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt; &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I think we’ve probably covered most of what there is to say on Cloudera in previous posts. At the moment they’re the biggest player in the Hadoop space, with a significant investment from Intel (an order of magnitude greater than any investment Hortonworks or MapR have secured), plus a recently announced IPO. What’s going to be interesting is how they transition from the “Hadoop’s the hot new thing come and get it from us” business model to one focused on specific business challenges and direct competition to more established BI and analytics vendors - you can see the start of that in the way they’ve recently re-organised their product offerings.&lt;/p&gt; &lt;p&gt;I don’t know a huge amount about MapR, so am looking forward to learning more. What I’ve looked at so far looks interesting - a commercial data repository that supports multiple interfaces (file orientated, database and messaging), addresses some of Hadoop’s limitations, and provides Hadoop compatible APIs (specifically HDFS, HBase and Kafka APIs), that’s blended with YARN to provide an Hadoop compatible analytics platform. It’s going to be interesting to dig into the detail and understand how this differentiates itself from vanilla Hadoop.&lt;/p&gt; &lt;p&gt;We’ve started off our look at MapR by looking at the &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt; - a bundle of open source Apache Hadoop components that are certified to work together and to run on the MapR platform. All your favourite Hadoop technologies are in there (bar Solr), and MapR seem to have given themselves licence to pick and choose from technolgies backed by both Cloudera and Hortonworks - an enviable position to be in.&lt;/p&gt; &lt;p&gt;There aren’t many technologies in the MapR Ecosystem Pack we’ve not looked at previously, the main one being &lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt;. It’s another interactive (low latency high throughput) SQL query engine, with the big differentiator being that it can query and join across data in multiple datastores (including all your favourite filesystems, NoSQL and RDBMS databases) without first having to define a schema. There’s a lot of power here - being able to query data where it is without having to first bring it all together first or do lots of preparation delivers a huge range of benefits. Drill’s facing off against &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Impala&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; in the emerging interactive SQL on Hadoop space - there’s much more to dig into here in the future, however if you’re looking to get started there’s an interesting write up of Impala vs Drill from Rittman Mead &lt;a href=&quot;https://www.rittmanmead.com/blog/2017/04/sql-on-hadoop-impala-vs-drill/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;That’ll do for this week - have a lovely weekend and we’ll see you on the other side.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/21/the-week-that-was/</guid> </item> <item><title>Apache Drill</title><link>http://ondataengineering.net/technologies/apache-drill/</link><pubDate>Fri, 21 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;An MPP query engine that supports queries over one or more underlying databases or datasets without first defining a schema and with the ability to join data from multiple datastores together. Supports a range of underlying technologies including HDFS, NAS, HBase, MongoDB, MapR-DB, MapR-FS, Amazon S3, Azure Blob Storage, Google Cloud Storage, JDBC, Avro, JSON and Parquet. Pushes queries down to underlying datastores where possible, and supports an in-memory columnar datastore based on a schema free JSON document model for performing cross datastore query operations. Supports dynamic schema discovery, with support for complex and nested types, including a number of SQL extensions. Supports standard SQL, UDFs (including Hive UDFs) and comes with JDBC and ODBC drivers, a REST API, plus a shell, web console and C++ API. Designed to be horizontally scalable and to support high throughput and low latency use cases. Supports Kerberos and username/password authentication, plus a full authorisation model. Created by MapR Based on Google's Dremel paper, donated to the Apache Foundation in September 2012, graduating in November 2014, with a 1.0 release in May 2015, and is still under active development&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Drill&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commerical Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v1.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/&quot;&gt;http://drill.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/docs/&quot;&gt;http://drill.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/blog/&quot;&gt;http://drill.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-drill/</guid> </item> <item><title>MapR Ecosystem Pack</title><link>http://ondataengineering.net/technologies/mapr-ecosystem-pack/</link><pubDate>Thu, 20 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A package of components certified to work together against one or more versions of the MapR Converged Data Platform. Has new major releases roughtly once a quarter, with most components kept resonably up to date with the open source version, with any patching done publically in GitHub. Available as RPMs, and installable via the MapR Installer. Also includes a plugin for OpenStack Sahara to allow OpenStack to create and manage MapR clusters. These components were originally bundled as part of the MapR Converged Data Platform, but were broken out as the MapR Ecosystem Pack in September 2016 to allow them to be released independantly.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;MEP&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;MapR&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v3.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-myriad/&quot;&gt;Apache Myriad&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Apache Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, MapR Monitoring, MapR Streams Tools&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Details of the component versions can be found in the release notes, along with detailed release nodes for each of the components and details of the packages for each component.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/c_ecosystem_intro.html&quot;&gt;http://maprdocs.mapr.com/home/c_ecosystem_intro.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/EcosystemRN/EcoPackRN.html&quot;&gt;http://maprdocs.mapr.com/home/EcosystemRN/EcoPackRN.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/InteropMatrix/r_release_mep_dates.html&quot;&gt;http://maprdocs.mapr.com/home/InteropMatrix/r_release_mep_dates.html&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/AdvancedInstallation/InstallingEcoWithoutInstaller.html&quot;&gt;http://maprdocs.mapr.com/home/AdvancedInstallation/InstallingEcoWithoutInstaller.html&lt;/a&gt; - installation docs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mapr&quot;&gt;https://github.com/mapr&lt;/a&gt; - component source ode&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://package.mapr.com/releases/MEP/&quot;&gt;http://package.mapr.com/releases/MEP/&lt;/a&gt; - package repository&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Announcements via the MapR product announcements blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-ecosystem-pack/</guid> </item> <item><title>The Mid Week News - 19/04/2017</title><link>http://ondataengineering.net/blog/2017/04/19/the-mid-week-news/</link><pubDate>Wed, 19 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, I’ve been slack in getting this out there, which means we’ve built up a nasty backlog, but it’s time to talk about what’s changed since we originally wrote some of our technology summaries. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, there are new releases of the &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;. &lt;a href=&quot;https://hortonworks.com/blog/announcing-the-general-availability-of-hortonworks-data-platform-2-6/&quot;&gt;Version 2.6 of HDP&lt;/a&gt; brings two main features - &lt;a href=&quot;https://hortonworks.com/blog/top-5-performance-boosters-with-apache-hive-llap/&quot;&gt;Hive LLAP&lt;/a&gt;, the ability for Hive to target the real time interactive query space, and &lt;a href=&quot;https://hortonworks.com/blog/apache-hive-moving-beyond-analytics-offload-with-sql-merge/&quot;&gt;Hive ACID Merges&lt;/a&gt;, allowing data to be transactionally loaded into Hive. &lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/Announce-Cloudera-Enterprise-5-11-is-Now-Available/m-p/53808#M170&quot;&gt;Version 5.11 of CDH&lt;/a&gt; brings Navigator lineage support for Spark, the integration of Kudu with Kerberos, improvements to S3 support and support for Azure Data Lake Store.&lt;/p&gt; &lt;p&gt;There have also been a mass of projects that have seen new releases. Ordinarily I’d like to provide some sort of commentary on these, however given I’ve built up such a backlog we’ll just list them off this week. Each technology page includes a link to the relevent release announcement or details if you’re interested however. So, in no particular order the technologies that have seen new releases are: &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet C++&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In terms of other technologies news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sqoop2 has been deprecated by Cloudera as of CDH 5.9, and will be removed from CDH in version 6. Suggests that all is not well in Sqoop2 land.&lt;/li&gt; &lt;li&gt;Hadoop 3.0 is now into it’s second alpha release. Summary is &lt;a href=&quot;http://hadoop.apache.org/docs/r3.0.0-alpha2/index.html&quot;&gt;here&lt;/a&gt;, with some thoughts form &lt;a href=&quot;https://hortonworks.com/blog/data-lake-3-0-part-4-cutting-storage-overhead-in-half-with-hdfs-erasure-coding/&quot;&gt;Hortonworks&lt;/a&gt; and &lt;a href=&quot;http://blog.cloudera.com/blog/2017/02/apache-hadoop-3-0-0-alpha2-released/&quot;&gt;Cloudera&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt; has graduated to a top level Apache project. There’s an &lt;a href=&quot;https://www.infoq.com/news/2017/03/apache-ranger-top-level-project&quot;&gt;InfoQ write-up&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/linkedin/gobblin&quot;&gt;Gobblin&lt;/a&gt; has been donated to the Apache Foundation by LinkedIn&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We’ll try and do this weekly going forward - let’s just hope keeping up to date with everything doesn’t prove to be unsustainable! And next week we’ll have a look at some of the interesting blog posts I’ve been accumulating.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/19/the-mid-week-news/</guid> </item> <item><title>Cloudera</title><link>http://ondataengineering.net/tech-vendors/cloudera/</link><pubDate>Tue, 18 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Cloudera is a commercial company focusing on offerings based around an Apache Hadoop distribution that's supplemented with a number of commercial components, distributed as a free express version (with cut down versions of some of the commercial components), and as an enterprise version with an annual subscription fee. They are extreemly active in the Apache open source space, with committers on all the technologies they distribute, and with a history of donating projects to the Apache Foundation that they have either initiated or acquired. Formed in 2008 by ex-employees from Google, Yahoo, Facebook and Oracle, with Doug Cutting, the original author of Hadoop, joining in 2009 as Chief Architect.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;vendor-technologies&quot;&gt;Vendor Technologies&lt;/h2&gt; &lt;p&gt;Cloudera’s offerings are based around &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;, their distribution of Apache Hadoop, which includes a number of commercial components, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; (for creating and managing clusters), &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; (a data management and encryption solution) and &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; (for installing CDH on cloud based platforms), and comes in a number of editions, includng a free version as “Cloudera Express”.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; is also available on AWS as a &lt;a href=&quot;https://aws.amazon.com/quickstart/architecture/cloudera/&quot;&gt;Cloudera EDH AWS Quick Start&lt;/a&gt;, and via &lt;a href=&quot;https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.director-on-azure?tab=Overview&quot;&gt;Cloudera Director on the Azure Marketplace&lt;/a&gt;. Their best practice and guidence for running CDH in hte Cloud is available at &lt;a href=&quot;https://www.cloudera.com/documentation/director/cloud.html&quot;&gt;https://www.cloudera.com/documentation/director/cloud.html&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/&quot;&gt;https://www.cloudera.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://vision.cloudera.com/&quot;&gt;https://vision.cloudera.com/&lt;/a&gt; - Leadership blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;http://blog.cloudera.com/&lt;/a&gt; - Engineering blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&quot;&gt;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&lt;/a&gt; - Release Announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/cloudera/</guid> </item> <item><title>The Week That Was - 14/04/2017</title><link>http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</link><pubDate>Fri, 14 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s the Easter holidays here in the UK, so no technology summary today, but let’s recap the last week before we forget everything we looked at.&lt;/p&gt; &lt;p&gt;This week, we’ve been looking at the Cloudera’s closed source products - &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;, their tool for creating and managing CDH hadoop clusters, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, a set of products for data management, data encryption and helping migrate SQL workloads to Hadoop, and &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, for doing CDH Hadoop in the cloud. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;The philosophical debate between Cloudera and Hortonworks on the used of closed source software is an interesting one, and lends almost a personal element to their commercial rivalry. The general view is that Cloudera have added closed source software into their offering to increase lock in, but I’m not entirely convinced by this - the cost of moving from Cloudera Manager/Navigator to an alternative doesn’t feel like it significantly impacts the fundamental costs of migrating from one distribution to another. Does it provide extra encouragement for companies to take up subscription licences - again I’m not entirely convinced, the risk with not having commercial support for critical systems is likely to be the driver here. Cloudera’s stated view is that it’s protection for their investment in Hadoop open source projects, to prevent a large company with deep pockets competing with them by distributing the open source software that they’ve put so much investment into. What’s clear is that most of the arguments are ideological in nature - I think if you look at it impartially the use of closed source software by Cloudera is unlikely to significantly impact any selection process.&lt;/p&gt; &lt;p&gt;And so on to the products themselves. I feel like I’ve probably done &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; a slight disservice in it’s technology summary - cold hard facts on how it compares to &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt; seem to be pretty scarce (perhaps we’ll try and do something about this at some point), however the general consensus seems to be that Cloudera Manager was more mature and more capable, but that Ambari has been catching up rapidly, and there’s probably not a huge amount in it any more.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; started off as Cloudera’s data (or metadata) management tool, and is probably slightly more mature and capable in this space than &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt;. Metadata management in general still feels very immature however - most tools don’t deliver on their promises, and the investment, time and effort to get value out of them is often under estimated, leading to the infamous data swamp if you’re working in the Hadoop space.&lt;/p&gt; &lt;p&gt;Today, in addition to it’s original &lt;a href=&quot;/technologies/cloudera-navigator/data-management/&quot;&gt;data management&lt;/a&gt; elements, Cloudera Navigator also includes &lt;a href=&quot;/technologies/cloudera-navigator/data-encryption/&quot;&gt;data encryption&lt;/a&gt; capabilities following Cloudera’s acquisition of Gazzang, and &lt;a href=&quot;/technologies/cloudera-navigator/optimizer/&quot;&gt;Optimizer&lt;/a&gt; following their acqusition of Xplain.io, an interesting technology I know very little about for helping to migrate SQL workloads to Hadoop and to then optimise these.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; - Cloudera’s tool for creating, scaling and managing CDH clusters in all your favourite cloud environments. I’m not sure there’s a huge amount more to say than that to be honest.&lt;/p&gt; &lt;p&gt;Right - I’m off to eat chocolate. If I’ve not exploded we’ll resume next Tuesday with our summary of Cloudera themselves, and then maybe on Wednesday we’ll do our first news post to catch up on the many technologies that have had new releases since we did their initial technology summary.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</guid> </item> <item><title>Cloudera Director</title><link>http://ondataengineering.net/technologies/cloudera-director/</link><pubDate>Thu, 13 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for deploying and managing Cloudera CDH Hadoop clusters on cloud infrastructure based on automatically provisioned infrastructure with Hadoop provisioned on top via Cloudera Manager. Includes out of the box support for Amazon Web Services, Microsoft Azure and Google Cloud Platform, with support for vSphere available from VMWare, with a Service Provider Interface (SPI) for adding support for new providers. Supports the ability to scale clusters up and down, clone clusters, run post deployment scripts, and create Kerberized and highly available clusters. Manageable through a web UI, a REST API (with Python and Java APIs) and a CLI. Released at 1.0 in October 2014 as part of Cloudera Enterprise 5.2. Free to download and use, with commercial support available as part of a Cloudera Enterprise subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v2.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-director.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-director.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/director/latest.html&quot;&gt;https://www.cloudera.com/documentation/director/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera?q=director&quot;&gt;https://github.com/cloudera?q=director&lt;/a&gt; - plugins&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&quot;&gt;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&lt;/a&gt; - VMWare plugin announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-director/</guid> </item> <item><title>Cloudera Navigator Optimizer</title><link>http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://optimizer.cloudera.com/&quot;&gt;https://optimizer.cloudera.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&lt;/a&gt; - product information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/navopt/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/navopt/topics/navopt.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</guid> </item> <item><title>Cloudera Navigator Data Encryption</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Navigator Encrypt, Navigator Key Trustee Server, Navigator Key HSM, Navigator Key Trustee KMS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&quot;&gt;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&lt;/a&gt; - intro blog post to Navigator Encrypt&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&lt;/a&gt; - Cloudera security overview, including summary of encryption options&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&lt;/a&gt; - Cloudera encryption documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</guid> </item> <item><title>Cloudera Navigator Data Management</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-management/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&lt;/a&gt; - primary documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&lt;/a&gt; - list of metadata that is automatically extracted&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/navigator/apidocs/v3/&quot;&gt;http://cloudera.github.io/navigator/apidocs/v3/&lt;/a&gt; - REST API documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/navigator-sdk&quot;&gt;https://github.com/cloudera/navigator-sdk&lt;/a&gt; - Java SDK&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-management/</guid> </item> <item><title>Cloudera Navigator</title><link>http://ondataengineering.net/technologies/cloudera-navigator/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of solutions covering Data Management (technical metadata management, lineage, cluster activity and analytics, cluster audit and automated policy actions), Data Encryption (filesystem level encryption, key management and integration with HDFS transparent encryption), and a solution for identifying SQL workloads that are candidates for migration to Hadoop and then optimising these once on Hadoop (Optimizer) build around the Cloudera CDH Hadoop distribution. All products are commercial closed source products, that are only available with an appropriate Cloudera Enterprise licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v2.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-management/&quot;&gt;Cloudera Navigator Data Management&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/&quot;&gt;Cloudera Navigator Data Encryption&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/optimizer/&quot;&gt;Cloudera Navigator Optimizer&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator.html&lt;/a&gt; - Cloudera Navigator homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&quot;&gt;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&lt;/a&gt; - Cloudera Navigator datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - Data Management and Data Encryption introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&lt;/a&gt; - Optimizer introduction&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/navigator/&quot;&gt;http://blog.cloudera.com/blog/category/navigator/&lt;/a&gt; - Cloudera blog posts&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/</guid> </item> <item><title>Cloudera Manager</title><link>http://ondataengineering.net/technologies/cloudera-manager/</link><pubDate>Mon, 10 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Platform for installing, managing and monitoring Cloudera CDH Hadoop clusters. Supports creation of clusters using step by step wizards, plus cluster templates for creating multiple clusters with the same configuration (e.g. dev, test and production), using either native OS packages or parcels (a Cloudera Manager distribution format that has a number of advantages over packages). Also supports the administration and configuration of clusters (including user and resource management, and the ability to manage multiple clusters); the automated Kerberization of clusters; monitoring of cluster, host and service statuses, health and metrics; generation of events and the use of custom triggers to take action on these; the visualisation of metrics; centralised log management; HDFS reports and automatic replication of data to a backup/DR cluster. Also integrates directly with Cloudera Support to enable proactive support. Web based, with a REST API and a full security model with auditing of all actions, and the ability to add support for custom services. Introduced in January 2012 as a replacement for the Cloudera Management Suite (CMS). Available for free without some enterprise features, or as part of a Cloudera CDH subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-manager.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-manager.html&lt;/a&gt; - Cloudera Manager homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&lt;/a&gt; - Documentation - link is to the Cloudera Manager introduction, with the rest of Cloudera documentation (e.g. Installation, Upgrade, Administration, Operation and Security documents) also referencing Cloudera Manager&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloudera.github.io/cm_api/&quot;&gt;https://cloudera.github.io/cm_api/&lt;/a&gt; - Cloudera Manager API documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-manager/</guid> </item> <item><title>The Week That Was - 31/03/2017</title><link>http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</link><pubDate>Fri, 31 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;No technology summary today for various reasons, one of which is that I’m taking a break next week and we’ve probably got to a pretty good place to pause. We’ve finished looking at the new open source technologies in the Cloudera stack this week, with their proprietary closed source technologies to come, but let’s save those for a fresh week.&lt;/p&gt; &lt;p&gt;So what exactly have we looked at this week? We started by looking at &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt;, Cloudera’s competitor to &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, Cloudera’s competitor to Hortonworks’ &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt;. We then looked at &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, a structured data store that supports both updates and deletes by primary key as well as efficient analytical table scans, and &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, a new technology that’s still in beta that provides an API for tools (such as Spark and MapReduce) to access structured data in Hadoop with fine grained access control. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;At some point, and I realise I keep saying this, I want to take a deeper look into the state of the security technologies in Hadoop, and more specifically a decent comparison of &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt;. There’s some history behind how we’ve ended up with two Apache technologies that are essentially trying to solve the same problem, each has their pros and cons but either will probably do what you need them two, with Ranger possibly looking the slightly further ahead functionality wise. Note that I’ve make some minor tweaks to the &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; technology summary this week.&lt;/p&gt; &lt;p&gt;I’m not entirely sure where the whole “wrap Solr up with some tools and utilities and give it a new name” came from, but there are some interesting differences between &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt; in the wraps that they put around Solr. Hortonworks bundle Banana (the Solr port of Kibana), they both support utilities for loading data from HDFS and moving data from HBase to Solr, but Hortonworks also bundle integrations with Solr for Hive, Pig, Storm and Spark. Note again that I’ve made some minor tweaks to the HDP Search technology summary this week.&lt;/p&gt; &lt;p&gt;Cloudera position &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; as the missing link between &lt;a href=&quot;/technologies/apache-hadoop/hdfs&quot;&gt;HDFS&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt; - able to perform updates and deletes by primary key (ala HBase), as well as analytical queries performing column and table scans (ala HDFS). It’s not going to replace either for their respective specialisms, but the ability to run analytical workloads over mutable data feels like a bit of a gap in the Hadoop ecosystem at the moment (that probably led to the rise of the &lt;a href=&quot;http://lambda-architecture.net/&quot;&gt;lambda architecture&lt;/a&gt;). Kudu only provides the storage engine, but its combination with &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt; to provide a SQL interface on top feels like yet more evidence that Cloudera is firmly targeting the established OLAP database vendors. The &lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;Kudu whitepaper&lt;/a&gt; is worth a skim if you’re interested, including the performance comparison between Kudu, Parquet on HDFS and Phoenix on HBase.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, the benefits of which seem twofold. Firstly, it provides a unified data access path for Hadoop technologies - rather than every technology (MapReduce, Spark, etc.) having to implement their own reader for each file format, they can just integrate with RecordService. This then enables the second - fine grained access control to this data. At the moment, when tools like MapReduce and Spark read data from HDFS, access can only be granted at the file level - RecordService will enable finer grained access control in this scenario, which can only be a good thing. Two thoughts however - you can achieve this today by forcing these tools to read data via Hive, however my guess is that there are some performance limitations on this at scale that RecordService will address, and that at the moment it’s very early days for RecordService, plus it’s tied to Apache Sentry, so it’s going to be interesting to see how much traction this gains into the wider Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;As mentioned above I’m taking a break next week so there’ll be no updates, but we’ll be back on Monday 10th with a look at Cloudera’s closed source commercial technologies.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</guid> </item> <item><title>RecordService</title><link>http://ondataengineering.net/technologies/recordservice/</link><pubDate>Thu, 30 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Abstraction layer for accessing structured data in Hadoop that enforces fine grained access control (via Apache Sentry). Currently supports reading data from HDFS and S3 in Parquet, Text, Sequence File, RC and Avro format via a Hive table/view definition or a file path, with support for HBase and Kudu planned. Supports direct access to data via C++ and Java APIs, plus integration with MapReduce, Spark, Impala and Pig, with support for Hive planned. Supports the Apache Sentry security model, including table, view, file (via grants on uris to create external tables) and column level security, with row level filtering and data masking planned. Started in January 2015 and announced with an initial beta release in September 2015. Still in beta, with a stated plan for RecordService to be donated to the Apache Foundation in the future. Open sourced under Apache 2.0 licence, and implemented in C++ and Java.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/&quot;&gt;http://recordservice.io/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&quot;&gt;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&lt;/a&gt; - vision for RecordService&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/betas/recordservice/latest.html&quot;&gt;https://www.cloudera.com/documentation/betas/recordservice/latest.html&lt;/a&gt; - Cloudera document home (links through to RecordService site)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/recordservice&quot;&gt;https://github.com/cloudera/recordservice&lt;/a&gt; - source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/RecordServiceClient/&quot;&gt;https://github.com/cloudera/RecordServiceClient/&lt;/a&gt; - client libraries source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/ReleaseNotes/&quot;&gt;http://recordservice.io/ReleaseNotes/&lt;/a&gt; - RecordService release details&lt;/li&gt; &lt;li&gt;Other updates through Cloudera Engineering blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/recordservice/</guid> </item> <item><title>Apache Kudu</title><link>http://ondataengineering.net/technologies/apache-kudu/</link><pubDate>Wed, 29 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Columnar storage technology for tables of structured data, supporting low latency reads, updates and deletes by primary key, as well as analytical column/table scans. Provides Java, C++ and Python APIs, is queryable via Impala and Spark SQL, and provides Spark, Flume and MapReduce connectors. Supports cluster deployments (including co-existence with Hadoop), with tables partitioned into tablets (configurable on a per table basis), with tablets then replicated and distributed across the cluster, using the Raft Consensus Algorithm for consistency. Also supports variable column encoding (including bit shuffle, run length, dictionary and prefix encoding) and compression. Includes a web UI for reporting operational information, and metrics available from the command line, via HTTP or via a log file. Started in November 2012, with a initial beta release in September 2015. Donated to the Apache Foundation in December 2015, graduating in July 2016, with a 1.0 release in September 2016. Implemented in C++.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kudu&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/&quot;&gt;https://kudu.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/docs/&quot;&gt;https://kudu.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;http://kudu.apache.org/kudu.pdf&lt;/a&gt; - whitepaper including comparison to Parquet/HDFS and Phoenix/HBase&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&lt;/a&gt; - Cloudera information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/releases/&quot;&gt;https://kudu.apache.org/releases/&lt;/a&gt; - details of new releases&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/blog/&quot;&gt;https://kudu.apache.org/blog/&lt;/a&gt; - Apache Kudu blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/kudu/&quot;&gt;http://blog.cloudera.com/blog/category/kudu/&lt;/a&gt; - Cloudera blog posts on Kudu&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kudu/</guid> </item> <item><title>Cloudera Search</title><link>http://ondataengineering.net/technologies/cloudera-search/</link><pubDate>Tue, 28 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distribution of Apache Solr that also includes a number of tools for integrating with Solr using Morphlines. Includes two utilities for loading data from HDFS, the Crunch Indexer Tool (direct Solr inserts using Crunch over Spark or MapReduce), and the MapReduce Indexer Tool (creates Solr index files using Map Reduce, optionally putting these live), plus two utilities for loading data from HBase based on the Lily HBase Indexer, the Batch Indexer (for batch loads) and the NRT (Near Real Time) Indexer (for continuous replication of HBase events). First released in June 2013, with a GA release in September 2013 as part of CDH 4.3. Included tools are open sourced under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/search/&quot;&gt;https://github.com/cloudera/search/&lt;/a&gt; - HDFS utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/hbase-indexer&quot;&gt;https://github.com/cloudera/hbase-indexer&lt;/a&gt; - HBase utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-search/</guid> </item> <item><title>Apache Sentry</title><link>http://ondataengineering.net/technologies/apache-sentry/</link><pubDate>Mon, 27 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store, and plugins for Hadoop components (including Hive, Solr, Impala and HDFS, with support for Kafka and Sqoop2 in preview) to manage authorisation of user access to data, although HDFS support is limited to Hive data only. Also supports row level filtering policies for Solr, and historical support for defining policies in files per service (Sentry Policy Files). Integrates with the Hue security app (to manage permissions) and with Cloudera Navigator (for authorisation audit events). Started in 2012 as Cloudera Access, with an initial 1.0 release in 2013 as Sentry. Donated to the Apache Foundation in August 2013, graduating in March 2016. &lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Sentry&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://sentry.apache.org/index.html&quot;&gt;https://sentry.apache.org/index.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&quot;&gt;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&lt;/a&gt; - Apache documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sentry/&quot;&gt;https://blogs.apache.org/sentry/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Other updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-sentry/</guid> </item> <item><title>The Week That Was - 24/03/2017</title><link>http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</link><pubDate>Fri, 24 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;So this week we started our journey into the Cloudera technology stack. I covered the final Hortonworks bits &lt;a href=&quot;/blog/2017/03/20/hortonworks-to-cloudera/&quot;&gt;on Monday&lt;/a&gt;, but what have we looked at since then?&lt;/p&gt; &lt;p&gt;We started off by looking at Cloudera’s Hadoop distribution &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; and the technologies it bundles. We’ve covered a lot of these already (Hadoop being Hadoop there’s plenty of overlap between the various distributions), but there’s still plenty of new stuff here to keep us busy for a couple of weeks.&lt;/p&gt; &lt;p&gt;We then moved on to look at &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt;, a small piece of open source technology created to support Impala running over YARN, &lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt;, a now retired Apache open source project for deploying a number of technologies onto cloud platforms, and &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;, Cloudera’s SQL on Hadoop engine for low latency interactive queries. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I’m not sure there’s much to say about &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; right now - it’s a great Hadoop distribution, and although it’s a significantly more commercial offering that Hortonworks, you can get most of it for free (including Cloudera Manager minus some enterprise bits). There’s pros and cons all over the stack if you’re comparing it against the other distributions, but we’ll take a deeper look at this in a couple of weeks time.&lt;/p&gt; &lt;p&gt;There’s not much to say about &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt; - it was a piece of technology created by Cloudera to allow Impala to play nicely with YARN, but it’s not be adopted outside of Cloudera, who have themselves now deprecated it and will no longer be including it in CDH from v6.0 onwards (this wasn’t originally referenced in the technology summary so I’ve since updated it).&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt; feels like a bit of history. It’s well and truly dead now (with no development since September 2012, and having been moved into the Apache Attic in March 2015), however it was the first technology (I think I’m right in saying this) that allowed you to deploy Hadoop (and a whole pile of other technologies) into a cloud environment. It feels a little clunky and anachronistic now - there’s bespoke Java code written for each technology it supported to manage the software deployment and management using jclouds - but I’m guessing at the time it was almost revolutionary, paving the way for a whole pile of later technologies.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;. At some point I want to dig into the whole Impala/Hive debate / religious war (because it’s a fascinating look into the relationship and cultural differences between Cloudera and Hortonworks as much as anything). Hive has always been a large batch data transformation engine (albeit executing SQL) - every query starting a new job (originally MapReduce but lately Spark or Tez) with all the associated overheads and latency, but with the ability to process as much data as your Hadoop cluster would hold. What it wouldn’t do is support large numbers of more targeted queries at a low latency, for example from a group of users running queries against a data mart (the so called interactive query use case) - this was the use case Impala (and Parquet - the columnar data format) were created to target. Impala was therefore never designed to replace or compete with Hive, it’s competition are the traditional OLAP database such as Greenplum, Netezza and Teradata, with Impala trying to deliver a roughly comparable capability at a much lower cost. Hortonworks of course felt that Hive should support both use cases, and its introduction of LLAP (which allows long running processes to execute multiple queries) was it’s answer to this.&lt;/p&gt; &lt;p&gt;And that’s us for this week - have a good weekend, and we’ll see you on the other side.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</guid> </item> <item><title>Apache Impala</title><link>http://ondataengineering.net/technologies/apache-impala/</link><pubDate>Fri, 24 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore. Focus is on analytical (OLAP) use cases, and more specifically on low latency interactive queries (rather than long running batch queries), with some support for batch inserts of data. Supports DDL statements for updating the Hive Metastore, uses (broadly) the same SQL syntax as Hive (including UDFs and a range of aggregate and analytical functions), as well as the same JDBC / ODBC drivers, and is therefore compatible with any Hive query tool (such as Beeline). Supports querying over data in Parquet, Text, Avro, RCFile and SequenceFile formats, with the ability to write Parquet and Text data. Support Kerberos and LDAP authentication, and integration with Apache Sentry for authorisation. Includes a shell (Impala Shell) that supports some shell only commands for tuning performance and diagnosing problems. Created by Cloudera, started in May 2011 and first announced in October 2012, with a 1.0 GA release in May 2013. Donated to the Apache Foundation in December 2015, is still incubating, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Impala&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://impala.incubator.apache.org/&quot;&gt;https://impala.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-impala/</guid> </item> <item><title>Apache Whirr</title><link>http://ondataengineering.net/technologies/apache-whirr/</link><pubDate>Thu, 23 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A set of libraries (now moved to the Apache Attic and no longer maintained) for deploying and managing a supported set of services in a cloud environment. Written in Java, with explicit support for a set of standard services (including Hadoop, Cassandra, HBase, Elasticsearch and Solr) configured through property files. Uses jclouds to provision and manage cloud infrastructure, and provides both a CLI and Java API. Originally a set of python scripts maintained as an Hadoop contrib project. Donated to the Apache Foundation in May 2010, graduating in August 2011. Development ceased in September 2012, with the project being moved to the Apache Attic in March 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Whirr&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://whirr.apache.org/&quot;&gt;https://whirr.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/WHIRR&quot;&gt;https://cwiki.apache.org/confluence/display/WHIRR&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://attic.apache.org/projects/whirr.html&quot;&gt;https://attic.apache.org/projects/whirr.html&lt;/a&gt; - Apache Attic page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-whirr/</guid> </item> <item><title>Llama</title><link>http://ondataengineering.net/technologies/llama/</link><pubDate>Wed, 22 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for long running low-latency distributed applications to request resources from YARN, built to support Apache Impala. Operates as an un-managed YARN application master (that handles resource requests over a Thrift API and delivers resource notifications) and a node manager plugin (that delivers resource availability information to co-located services). Created by Cloudera in August 2013 and hosted on GitHub under an Apache 2.0 licence. Maintained by Cloudera to support new Impala and CDH releases, but now deprecated and will no longer be included in CDH from v6.0 onwards.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/llama/&quot;&gt;http://cloudera.github.io/llama/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/llama&quot;&gt;https://github.com/cloudera/llama&lt;/a&gt; - code repository&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/llama/</guid> </item> <item><title>Cloudera CDH</title><link>http://ondataengineering.net/technologies/cloudera-cdh/</link><pubDate>Tue, 21 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;A distribution of Hadoop based on the addition of a number of closed source products, including Cloudera Manager (for installing and managing clusters) and Cloudera Navigator (for managing metadata and the encryption of data). Bundled projects tend to lag the open source versions and pull forward more patches than other distributions. Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Impala, and a number of Apache projects that aren't (yet) part of the core distribution. Available via RPMs, or can be installed using Cloudera Manager (for local installs) or Cloudera Director (for installation on cloud platforms) as Cloudera Enterprise (under an annual per node or elastic cloud licence model with commercial support) or Cloudera Express (a free version without some enterprise features), with Cloudera Enterprise coming in a range of licence options (listed on the Cloudera website under products) which each including support for different Apache products. First released in March 2009.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;CDH, Cloudera Express, Cloudera Enterprise&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v5.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-avro/&quot;&gt;Apache Avro&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Apache Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-whirr/&quot;&gt;Apache Whirr&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;, &lt;a href=&quot;/technologies/llama/&quot;&gt;Llama&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Details of the Apache project versions bundled with each version of CDH are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball.html&quot;&gt;this page&lt;/a&gt; of the CDH release notes. Deprecated items and projects are detailed on &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_deprecated.html&quot;&gt;this page&lt;/a&gt;. New features, known issues and fixed issues are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes_cdh.html&quot;&gt;this page&lt;/a&gt;. See some of the links below for details on the different Cloudera versions and options.&lt;/p&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.11&lt;/td&gt; &lt;td&gt;2017-04-18&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/Announce-Cloudera-Enterprise-5-11-is-Now-Available/m-p/53808#M170&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&lt;/a&gt; - CDH bundled projects datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&lt;/a&gt; - Cloudera Enterprise datasheet (including details of products supported under each licence option)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&lt;/a&gt; - differences between Express and Enterprise editions&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;http://blog.cloudera.com/&lt;/a&gt; - Cloudera engineering blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&quot;&gt;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&lt;/a&gt; - Release Announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-cdh/</guid> </item> <item><title>Hortonworks to Cloudera</title><link>http://ondataengineering.net/blog/2017/03/20/hortonworks-to-cloudera/</link><pubDate>Mon, 20 Mar 2017 07:40:00 +0000</pubDate> <description> &lt;p&gt;Right - I think we’re done with our trip through the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; technology stack, however there are two updates today before we move on. Apologies in advance if this screws up either the RSS feeds or e-mail newsletters - I’m not entirely sure how these will handle updates to the site, but there’s only one way to find out. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, I’ve re-worked the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; page to better describe their product offerings. The one thing I really like about Hortonworks is it’s openness. Normally when looking at commercial vendors there’s a whole pile of exaggeration and misdirection about what their product is and what it can do and how it’s so much better than any other option on the market, however because Hortonworks deal entirely in open source technologies they feel like a more open and transparent company, and actually understanding what they offer therefore feels a little more straightforward. There are some big commercial vendors coming up on my list however where I don’t have a huge amount of experience with their products, and I’m therefore holding out no hope of being able to understand the detail of what they offer, given the lack of any publicly available documentation and product websites that are little more than content-less flashy brochures. When I get to these, I’m definitely going to need some help.&lt;/p&gt; &lt;p&gt;Secondly, I’ve added a page for &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows&quot;&gt;HDP for Windows&lt;/a&gt;, which is now also included in our list of Hadoop Distributions. Hadoop itself, and a bunch of the other related Apache technologies support being built on Windows as a native Windows executable, however HDP is (as far as I’m aware) the only Hadoop distribution that supports Windows (presumably as part of Hortonworks’ deal with Microsoft for Azure HDInsight). It’s not the full HDP distribution however - missing some key technologies including Ambari, Solr and Spark.&lt;/p&gt; &lt;p&gt;Up tomorrow then - our first look into the Cloudera technology stack. We’ll start with their distributions (CDH, Cloudera Express and Cloudera Enterprise), add these to our list of Hadoop distributions, have a look at the new Apache technologies that these include that we haven’t looked at yet, and then finish up with adding Cloudera to our list of technology vendors. At least that’s the plan - managing to stick to it will probably be a first for this site.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/20/hortonworks-to-cloudera/</guid> </item> <item><title>Hortonworks Data Platform for Windows</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform-for-windows/</link><pubDate>Mon, 20 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A version of the Hortonworks Data Platform natively compiled for Windows. Generally trails the main HDP project by a minor version, doesn't use Apache Ambari for installation and management (instead being installed via a standard Windows installer), doesn't support SmartSense, and doesn't include some technologies (currently Accumulo, Atlas, Kafka, Solr, Spark and Hue). First announced in March 2013, with a GA release in May 2013.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP for Windows&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-falcon/&quot;&gt;Apache Falcon&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Apache Slider&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/index.html&lt;/a&gt; - HDP 2.4.2 for Windows documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/bk_HDP_RelNotes_Win/content/ch_relnotes_v242.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.4.2-Win/bk_HDP_RelNotes_Win/content/ch_relnotes_v242.html&lt;/a&gt; - HDP 2.4.2 for Windows release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;See Hortonworks’ blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform-for-windows/</guid> </item> <item><title>Hortonworks</title><link>http://ondataengineering.net/tech-vendors/hortonworks/</link><pubDate>Mon, 20 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Hortonworks is a commercial company focusing on products that support the exploitation of data both at rest and in motion. Their business model is to provide support and professional services for a range of Apache open source technologies which they package and distribute for free. They are therefore extreemly active in the Apache open source space, with committers on all the technologies they distribute, and with a history of donating projects to the Apache Foundation that they have either initiated or acquired. Hortonworks was formed in June 2011 by ex-Yahoo employees.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;vendor-technologies&quot;&gt;Vendor Technologies&lt;/h2&gt; &lt;p&gt;Hortonworks have two primary offerings - &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, a fully open source distribution of Hadoop, and &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks Data Flow&lt;/a&gt;, a distribution of (primarily) Apache NiFi, Kafka and Storm for processing data in motion.&lt;/p&gt; &lt;p&gt;Both offerings are installed and managed through &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;, with Hortonworks Data Platform also including &lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt;, a technology for deploying and managing Hadoop clusters on cloud infrastructure.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows&quot;&gt;HDP for Windows&lt;/a&gt; is a version of the Hortonworks Data Platform for Windows.&lt;/p&gt; &lt;p&gt;The &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt; is also available as a number of managed cloud offerings - on Azure as HDInsight, a Microsoft branded offering, and on AWS as &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;Hortonworks Data Cloud for AWS&lt;/a&gt;, available via the AWS Marketplace.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/&quot;&gt;https://hortonworks.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/&quot;&gt;https://hortonworks.com/blog/&lt;/a&gt; - Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/hortonworks/</guid> </item> <item><title>The Week That Was - 17/03/2017</title><link>http://ondataengineering.net/blog/2017/03/17/the-week-that-was/</link><pubDate>Fri, 17 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;And another week passes…&lt;/p&gt; &lt;p&gt;This week we’ve wrapped up the &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; technology stack (give or take). On Monday we’ll review what we’ve found, and look ahead to our next destination - Cloudera.&lt;/p&gt; &lt;p&gt;So what have we looked at this week? We took a spin through &lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, Hortonworks’ bundling of &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt;. We’ve looked at Kafka and Storm previously, but we paused this week to look at &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt; and it’s sub-project &lt;a href=&quot;/technologies/apache-nifi/minifi&quot;&gt;MiNiFi&lt;/a&gt; in more detail.&lt;/p&gt; &lt;p&gt;And we finished off by looking at &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;HDCloud for AWS&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;Hortonworks DataFlow&lt;/a&gt; (HDF to it’s friends) is Hortonworks’ big push into analytics on data in motion, and more specifically into analytics in the Internet of Things world (or Internet of Anything as they refer to it). It’s a compelling story - the ability to deploy key real time analytical technologies independently from your Hadoop cluster (which can now focus on the batch historical analytical use cases) - and comes with the introduction of a new technology - &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What to say about &lt;a href=&quot;/technologies/apache-nifi&quot;&gt;Apache NiFi&lt;/a&gt;? There’s a use case here that I think NiFi fills almost unapproachably well - specifically getting batch (and probably mini batch) data to your analytical cluster. Previously you’d be looking at a bunch of technologies - Sqoop for database unloads, and some combination of shell scripts, FTP transfers, custom jobs to pull data from queues etc. etc. NiFi wraps all of this up - giving you a single solution to bring data from anywhere to a place where you can exploit it. The visualisation of the data moving through your flows, the ability to view this data, to get detailed provenance of where every file came from and when, and to perform common file level transformations just make this a great fit for this use case (although I’m never entirely convinced by the develop, test, release and configuration management story of GUI based tools, but that’s a discussion for another day). Where I think it has stiffer competition, and where I’m not as wholly convinced, is in the high volume, low latency, real-time event data space. There are a lot of well established technologies in this space (Logstash, FluentD and Heka for starters), and I’m not entirely convinced that NiFi is well architected for this use case. Do I really want provenance and record level state tracking when I’m bringing in billions of records per day - that seems like a significant overhead to me. By it’s a space NiFi is targeting, both with &lt;a href=&quot;/technologies/apache-nifi/minifi&quot;&gt;MiNiFi&lt;/a&gt; (which supports collection, transformation and forwarding out at the edge), and with some bold claims about throughput. I’m happy to accept I’ve missed something here, and I’d love to hear from anyone that can talk to this with some experience and evidence…&lt;/p&gt; &lt;p&gt;I’m going to update the Hortonworks vendor page on Monday with more information about their product offerings, as their Cloud offerings are a little more complex and convoluted that I was expecting. However &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws/&quot;&gt;HDCloud for AWS&lt;/a&gt; is their only Hortonworks branded cloud offering - a tool that allows you to deploy and resize HDP clusters in AWS, but with a limited set of technologies, focusing on Hive, Spark and Zeppelin. It’s brand new, only coming out at the end of 2016, and it appears to overlap with a more general capability that &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; is targeting. We’ll keep an eye on these, as it feels like next year is going to see a lot of movement in the Hadoop on Cloud space.&lt;/p&gt; &lt;p&gt;Right - back to the grindstone before the escape of the weekend. See you all next week for our first looks at Cloudera’s product offerings.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/17/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Cloud for AWS</title><link>http://ondataengineering.net/technologies/hortonworks-data-cloud-for-aws/</link><pubDate>Fri, 17 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Service that supports the creation and management of HDP clusters on Amazon Web Services (AWS). Management is done through a Cloud Controller AWS Product that provides a web interface and CLI for orchestrating the creation of AWS resources and the deployment of clusters using Ambari, and the subsequent scaling or cloning of the cluster. Supports a number of standard cluster types, including Data Science (Spark, Zeppelin), EDW-ETL (Hive, Spark) and EDW-Analytics (Hive, Zeppelin), with clusters also including Tez, Pig and Scoop, along with a number of standard node types, including worker nodes (that support HDFS and YARN) and computer nodes (that only support YARN). Clusters are designed to be ephemeral, however Amazon RDS can be used to provide persistent storage of Cloud Controller and Hive metadata, and Amazon S3 can be used to provide persistent cluster storage. Also supports Hortonworks SmartSense, cluster templates, the use of Spot Instances for compute nodes, and node recipes for executing custom scripts pre/post the Ambari cluster setup. Comes with free community support from Hortonworks. First launched in November 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDCloud for AWS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/cloud/aws/&quot;&gt;https://hortonworks.com/products/cloud/aws/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDCloudAWS/HDCloudAWS-1.11.1/bk_hdcloud-aws/content/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDCloudAWS/HDCloudAWS-1.11.1/bk_hdcloud-aws/content/index.html&lt;/a&gt; - v1.11.1 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/availability-hortonworks-data-cloud-aws/&quot;&gt;https://hortonworks.com/press-releases/availability-hortonworks-data-cloud-aws/&lt;/a&gt; - original press release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/marketplace/pp/B01LXOQBOU&quot;&gt;https://aws.amazon.com/marketplace/pp/B01LXOQBOU&lt;/a&gt; - AWS Cloud Controller product page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-cloud-for-aws/</guid> </item> <item><title>MiNiFi</title><link>http://ondataengineering.net/technologies/apache-nifi/minifi/</link><pubDate>Thu, 16 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;Lightweight headless version of NiFi used to collect and process data at it's source, before forwarding it on for centralised processing. Supports all key NiFi functionality including all NiFi processors, guaranteed delivery, data buffering (including back pressure and pressure release) and prioritised queuing, however flows are specified in configuration files, status information and statistics are only available via Reporting Tasks or via a CLI, and provenance can only be viewed by exporting events via Reporting Tasks to log files or a full NiFi instance. Supports warm re-deployments, automatically restarting to load a new configuration written to disk or pushed or pulled over HTTP. Available as a Java or Native C++ executable. Started in March 2016, with a 0.1 release in December 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/minifi/index.html&quot;&gt;http://nifi.apache.org/minifi/index.html&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/minifi/system-admin-guide.html&quot;&gt;http://nifi.apache.org/minifi/system-admin-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/nifi/#section_4&quot;&gt;https://hortonworks.com/apache/nifi/#section_4&lt;/a&gt; - Hortonworks information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - Hortonworks documentation (as part of HDF)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/MINIFI/Release+Notes&quot;&gt;https://cwiki.apache.org/confluence/display/MINIFI/Release+Notes&lt;/a&gt; - release notes&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-nifi/minifi/</guid> </item> <item><title>Apache NiFi</title><link>http://ondataengineering.net/technologies/apache-nifi/</link><pubDate>Wed, 15 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;General purpose technology for the movement of data between systems, including the ingestion of data into an analytical platform. Based on directed acyclic graph of Processors and Connections, with the unit of work being a FlowFile (a blob of data plus a set of key/value pair attributes). Supports guaranteed delivery of FlowFiles, with NiFi resiliently storing state (by default to a local write ahead log) and data blobs (by default a set of local partitions on disk), with all transformation logic executed via a thread pool within the NiFi instance (with the option to deploy multiple NiFi instances as a cluster). All flows are configured in a graphical user interface, which is also used for management and operations (starting/stopping individual Processors and viewing real time statuses, statistics and other information). Also supports data provenance (reporting on the processing events and lineage of individual FlowFiles), scheduling of Processor execution (based on periodic execution timers or cron specifications), multi-threaded Processor execution, configuration of Processor batch sizes (to enable low latency or high throughput), prioritised queues within Connections (allowing FlowFiles to be processed based on their age or a priority attribute as an alternative to FIFO), back pressure (based on counts or data volume against individual Connections) and pressure release (automatic discarding of FlowFiles based on their age), the ability to stream data to and from other NiFi instances and other streaming technologies, the ability to import and export flows as XML (flow templates), an expression language for setting Processor configuration and populating FlowFile attributes, Controller Services to provide shared services to processors (e.g. access to credentials, shared state), Reporting Tasks to output status and statistics information and a user security model. Extensible through the addition of custom Processors, Controller Services, Reporting Tasks and Prioritizers, and integrates with Apache Ranger and Apache Ambari. Originally developed at the NSA as &quot;Niagara Files&quot;, before being donated to the Apache Foundation in November 2014, graduating in July 2015. Java based, with development lead by Hortonworks after their aquisition of Onyara (which was set up by original NiFi developers to provide commercial support and services).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;NiFi&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache NiFi&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Lightweight headless version of NiFi used to collect and process data at it's source, before forwarding it on for centralised processing. Supports all key NiFi functionality including all NiFi processors, guaranteed delivery, data buffering (including back pressure and pressure release) and prioritised queuing, however flows are specified in configuration files, status information and statistics are only available via Reporting Tasks or via a CLI, and provenance can only be viewed by exporting events via Reporting Tasks to log files or a full NiFi instance. Supports warm re-deployments, automatically restarting to load a new configuration written to disk or pushed or pulled over HTTP. Available as a Java or Native C++ executable. Started in March 2016, with a 0.1 release in December 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/&quot;&gt;http://nifi.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nifi.apache.org/docs.html&quot;&gt;http://nifi.apache.org/docs.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/nifi/&quot;&gt;https://hortonworks.com/apache/nifi/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - Hortonworks documentation (as part of HDF)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes&quot;&gt;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes&lt;/a&gt; - release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-nifi/</guid> </item> <item><title>Hortonworks DataFlow</title><link>http://ondataengineering.net/technologies/hortonworks-data-flow/</link><pubDate>Tue, 14 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A distribution of a set of Apache open source technologies (primarily NiFi, Kafka and Storm) for processing data, with all products integrated with Ranger for security and Ambari for management. All bundled projects are Apache open source projects based on official Apache project releases, with any patches for bug fixes or new features pulled from official Apache project patches from later releases of the project. Available as RPMs or can be installed using Apache Ambari (via a management pack). Provided free of charge, with training, consultancy and support available from Hortonworks. First released in September 2015 as a distribution of just NiFi following the acquisition by Hortonworks of Onyara,who were setup by the creators of NiFi to provided commercial support for it.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDF&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The details of the Apache projects distributed as part of Hortonworks DataFlow are detailed in the release notes, along with the specific versions included, the unsupported features, the patches pulled forward from future project releases, and the known vulnerabilities and issues.&lt;/p&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;September 2015&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-to-acquire-onyara-to-turn-internet-of-anything-data-into-actionable-insights/&quot;&gt;https://hortonworks.com/press-releases/hortonworks-to-acquire-onyara-to-turn-internet-of-anything-data-into-actionable-insights/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Initial version consisting of just Apache NiFi&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.1&lt;/td&gt; &lt;td&gt;December 2015&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-1-1-released/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-1-1-released/&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.2&lt;/td&gt; &lt;td&gt;March 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-1-2-released/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-1-2-released/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Storm and Kafka added&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.0&lt;/td&gt; &lt;td&gt;September 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-2-0-ga/&quot;&gt;https://hortonworks.com/blog/hortonworks-dataflow-2-0-ga/&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Ranger and Ambari support added&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.1&lt;/td&gt; &lt;td&gt;December 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/announcing-availability-hortonworks-dataflow-hdf-2-1/&quot;&gt;https://hortonworks.com/blog/announcing-availability-hortonworks-dataflow-hdf-2-1/&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/data-center/hdf/&quot;&gt;https://hortonworks.com/products/data-center/hdf/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/index.html&lt;/a&gt; - HDF 2.1.0 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/bk_dataflow-release-notes/content/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDF2/HDF-2.1.0/bk_dataflow-release-notes/content/index.html&lt;/a&gt; - HDF 2.1.2 release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/category/hdf/&quot;&gt;https://hortonworks.com/blog/category/hdf/&lt;/a&gt; - blog posts&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-flow/</guid> </item> <item><title>Hortonworks</title><link>http://ondataengineering.net/blog/2017/03/13/hortonworks/</link><pubDate>Mon, 13 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Right - we’ve finished with our probing into the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies, it’s time to move on.&lt;/p&gt; &lt;p&gt;So today, we’re going to add &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt; to our vendor catalogue, and over the next week and a bit have a look at some of the other technology offerings they have outside of HDP. Once we’re done with that, we’ll revert to our original course of looking at all the major Hadoop distributions.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/13/hortonworks/</guid> </item> <item><title>The Week That Was - 10/03/2017</title><link>http://ondataengineering.net/blog/2017/03/10/the-week-that-was/</link><pubDate>Fri, 10 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;And so we come to the end of the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies. On Monday we’ll start looking at the remainder of the Hortonworks technology offerings (yes - I know we’re meant to be working our way through the Hadoop distributions - it’ll only be a short detour), but for now let’s summarise what we’ve looked at this week.&lt;/p&gt; &lt;p&gt;First up was the second add-on to HDP based on a partnership with another company - &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hortonworks HBD&lt;/a&gt; (aka Pivotal HDB, aka Apache Hawq). We then looked at the management components of the HDP stack - &lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Apache Ambari&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-smartsense&quot;&gt;Hortonworks SmartSense&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So - &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hortonworks HBD&lt;/a&gt;. It’s Pivotal HDB - you download it from Pivotal and the Hortonworks documentation links through to the Pivotal documentation, but with Hortonworks (according to the press release) providing customer support and professional implementation services. The press release is worth a look - as part of the deal Pivotal agreed to drop Pivotal HD (their Hadoop distribution) and resell HDP instead, and Hortonworks agreed to distribute HDB. But given their investment in Hive through the Stinger initiative, you have to wonder how interested Hortonworks are in pushing it. Which is possibly a shame, because Apache Hawq is probably the most mature SQL engine available on Hadoop today - whether that’s a good or bad thing, and how much traction it’s going to get I don’t know.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Apache Ambari&lt;/a&gt; - Hortonworks competitor to Cloudera Manager. What I found most interesting about Ambari was the list of contributors - 50 from Hortonworks, 6 from IBM, 6 from Pivotal, 4 from RedHat plus some more - 82 in total. That’s a pretty significant development capacity, and probably goes to show how valuable having an easy way to provision and manage Hadoop clusters is to its adoption. What also struck me about Ambari was how much it didn’t feel like an open source technology - it only (realistically) supports the installation of HDP, the committers are all employees of large companies and the Apache documentation is pretty poor.&lt;/p&gt; &lt;p&gt;I split &lt;a href=&quot;/technologies/apache-ambari/ambari-views&quot;&gt;Ambari Views&lt;/a&gt; out from Ambari for a couple of reasons. Firstly, I ran out of time on Tuesday to include it in the Ambari technology summary, and there was probably too much to put in a single summary anyway, but also because I think Ambari Views is targeting a slightly different use case and group of users than Ambari. It feels like Hortonworks is lining this up as a competitor to Hue (they have a Hue to Ambari migration tool for starters), however it feels lightweight (in features) and heavyweight (in terms of hardware requirements) compared to Hue, and I don’t see it gaining the same traction. Perhaps if Cloudera had donated Hue to the Apache Foundation Ambari Views wouldn’t even exist.&lt;/p&gt; &lt;p&gt;And &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; - an extremely interesting technology where cloud infrastructure meets Docker meets Hadoop. It feels like early days for Cloudbreak, however Hadoop in the Cloud (on or off premesis) is seeing massive investment from both Cloudera and Hortonworks at the moment, and it’s a really interesting area that I’d love to come back to at some point.&lt;/p&gt; &lt;p&gt;Lastly to &lt;a href=&quot;/technologies/hortonworks-smartsense&quot;&gt;Hortonworks SmartSense&lt;/a&gt;. Hortonworks’ business model is interesting - their commitment to open source means you can use their entire technology stack for free, you only pay for support and professional services, but this means their support and services offering has to deliver value and be worth the money (which also means that their stack can’t be too reliable or easy to manage without their help). SmartSense is their only technology that isn’t open source, and is the key piece in the value of their support offering. And the fact it appears to contain a bunch of cluster analytics that aren’t available through Ambari is an interesting facet of that.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/10/the-week-that-was/</guid> </item> <item><title>Hortonworks SmartSense</title><link>http://ondataengineering.net/technologies/hortonworks-smartsense/</link><pubDate>Fri, 10 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Supports the capture of diagnostic information from Hadoop clusters (including configuration, metrics and logs from both Hadoop and the Operating System) into a bundle for upload (either manually or automatically) to the Hortonworks support portal to assist in the resolution of support issues and the delivery of cluster optimisation and preventative action recommendations, with support for anonymisation (including IP addresses and host names, with support for further custom rules) and encryption of information in bundles and a SmartSense gateway to proxy uploads if direct internet access isn't available. Also includes functionality to help understand and analyse cluster activity include the Activity Analyser (aggregates data from YARN, Tez, MapReduce and HDFS into Ambari Metrics) and Activity Explorer (an embedded instance of Apache Zeppelin with pre-built notebooks for exploring and visualising cluster activity). Installable and manageable through Apache Ambari. Part of the Hortonworks support offering, introduced in June 2015 as part of HDP 2.3.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;SmartSense&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/services/support/smartsense/&quot;&gt;https://hortonworks.com/services/support/smartsense/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/SS1/SmartSense-1.3.1/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/SS1/SmartSense-1.3.1/index.html&lt;/a&gt; - current documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-smartsense/</guid> </item> <item><title>Cloudbreak</title><link>http://ondataengineering.net/technologies/cloudbreak/</link><pubDate>Thu, 09 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Solution for deploying and managing Hadoop clusters on cloud infrastructure based on automatically provisioned infrastructure running base docker images with Hadoop provisioned on top via Apache Ambari using Blueprints. Includes out of the box support for Amazon Web Services, Microsoft Azure, Google Cloud Platform and OpenStack, plus a Service Provider Interface (SPI) for adding support for new providers. Supports automated scaling of clusters based on Ambari Metrics and Alerts (Periscope), custom scripts that can be run on hosts before or after deployment (Recipes), a number of out of the box Blueprints, plus a number of technical preview features, including the use of custom docker images, data locality specifiers, Kerberized clusters, support for external AD/LDAP servers and deployment on Mesos. Manageable through a web UI, a REST API, a CLI and an interactive shell. Originally created by SequenceIQ, with an initial beta release in July 2014, with SequenceIQ then acquired by Hortonworks in April 2015, and a 1.0 release of Cloudbreak included in HDP 2.3 in July 2015. Open sourced under the Apache 2.0 licence, with a stated plan for the code to be donated to the Apache Foundation.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.6&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://sequenceiq.com/cloudbreak-docs/latest/&quot;&gt;http://sequenceiq.com/cloudbreak-docs/latest/&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/sequenceiq/cloudbreak&quot;&gt;https://github.com/sequenceiq/cloudbreak&lt;/a&gt; - Code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/cloudbreak/&quot;&gt;https://hortonworks.com/apache/cloudbreak/&lt;/a&gt; - Hortonworks information, including blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/Cloudbreak/Cloudbreak-1.6.3/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/Cloudbreak/Cloudbreak-1.6.3/index.html&lt;/a&gt; - Hortonworks documentation page, however links through to SequenceIQ docs page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/hortonworks-acquires-sequenceiq-to-provide-automated-deployment-of-hadoop-everywhere/&quot;&gt;https://hortonworks.com/blog/hortonworks-acquires-sequenceiq-to-provide-automated-deployment-of-hadoop-everywhere/&lt;/a&gt; - SequenceIQ acquisition announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudbreak/</guid> </item> <item><title>Ambari Views</title><link>http://ondataengineering.net/technologies/apache-ambari/ambari-views/</link><pubDate>Wed, 08 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Framework within Ambari that allows new applications or views to be added to Ambari, based on new client side code (HTML, JavaScript and CSS) supported by new backend code (Java) that exposes REST API end points for the UI to consume. Comes with support for a number of views out of the box, including YARN Queue Manager (supports the creation and configuration of YARN capacity schedule queues), Files (supports copying and moving, uploading and setting permissions on files in HDFS), Falcon (supports defining, scheduling and monitoring data management pipelines), Hive (supports browsing databases, executing queries and viewing explain plans, saving queries, viewing query history and uploading data to Hive tables), Pig (supports executing Pig scripts and viewing execution history), SmartSense (supports capture and download of bundles), Storm (supports viewing cluster status, monitoring topologies, perform topology management and access metrics and logs) and Tez (supports viewing and debugging Tez jobs), along with technical previews of Workflow Designer, Zeppelin and Hue migration views. Views can be deployed into a standalone Ambari instance to separate these from the primary Ambari management instance and to support scaling out.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ambari/ambari-views/</guid> </item> <item><title>Apache Ambari</title><link>http://ondataengineering.net/technologies/apache-ambari/</link><pubDate>Tue, 07 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Platform for installing, managing and monitoring Apache Hadoop clusters. Supports the installation of different versions of different distributions of Hadoop through Stack definitions (with support for HDP out of the box, and further stacks and add ons available through management packs), and the specification of Blueprints (cluster layouts and configuration for a given Stack) that can be used to programmatically create multiple clusters (e.g. dev, test and production). Also supports both rolling (no downtime) and express (faster but with downtime) upgrades; cluster administration (including adding and removing nodes/services, viewing the status of nodes/services, and configuring services with the versioning of configuration and the ability to rollback changes); the automated Kerberization of clusters; the collection, storage (in HBase) and visualisation (via Grafana or through dashboards in Ambari) of system and Hadoop component metrics via the Ambari Metrics System (AMS); alerting on statuses and metrics; the collection, storage (in Solr) and searching/viewing of log entries from across the Hadoop cluster (currently in technical preview); and a framework for UI components within Ambari (Ambari Views, treated here as a sub-project). Web based, with a REST API, and backed by a backend database (Oracle, MySQL or Postgres). Donated to the Apache Foundation by Hortonworks, IBM and Yahoo in August 2011 as the Hadoop Management System (HMS), graduating in December 2013 after changing it's name to Ambari. Still under active development with a large number of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ambari&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v2.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache Ambari&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-ambari/ambari-views/&quot;&gt;Ambari Views&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Framework within Ambari that allows new applications or views to be added to Ambari, based on new client side code (HTML, JavaScript and CSS) supported by new backend code (Java) that exposes REST API end points for the UI to consume. Comes with support for a number of views out of the box, including YARN Queue Manager (supports the creation and configuration of YARN capacity schedule queues), Files (supports copying and moving, uploading and setting permissions on files in HDFS), Falcon (supports defining, scheduling and monitoring data management pipelines), Hive (supports browsing databases, executing queries and viewing explain plans, saving queries, viewing query history and uploading data to Hive tables), Pig (supports executing Pig scripts and viewing execution history), SmartSense (supports capture and download of bundles), Storm (supports viewing cluster status, monitoring topologies, perform topology management and access metrics and logs) and Tez (supports viewing and debugging Tez jobs), along with technical previews of Workflow Designer, Zeppelin and Hue migration views. Views can be deployed into a standalone Ambari instance to separate these from the primary Ambari management instance and to support scaling out.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.5&lt;/td&gt; &lt;td&gt;2017-03-24&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/Ambari-2.5.0.3/bk_ambari-release-notes/content/ch_relnotes-ambari-2.5.0.3.html&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://ambari.incubator.apache.org/&quot;&gt;http://ambari.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/ambari/&quot;&gt;http://hortonworks.com/apache/ambari/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/Ambari/Ambari-2.4.2.0/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/Ambari/Ambari-2.4.2.0/index.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/AMBARI/Ambari&quot;&gt;https://cwiki.apache.org/confluence/display/AMBARI/Ambari&lt;/a&gt; - Apache developer level documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ambari/</guid> </item> <item><title>Apache Hawq</title><link>http://ondataengineering.net/technologies/apache-hawq/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A port of the Greenplum MPP database (which itself is based on PostgreSQL) to run over YARN and HDFS. Supports all the features of Greenplum (ACID transactions, broad SQL support and in database language and analytics support, including support for Apache MADLib), integrated with Apache Ambari, an Input Format for MapReduce to read Hawq tables, and both row and Parquet (column) based storage of data managed by Hawq. Also supports queries over data not managed by Hawq via external tables, with a Java based framework (PXF) for accessing external data, and out of the box support for accessing data in HDFS (text, Avro, JSON), Hive and HBase, with a number of open source connectors also available. Fault tolerant and horizontally scalable, with the ability to scale up or down on the fly. Originally created as Pivotal Hawq based on a fork of Greenplum in 2011, with an initial 1.0 release as part of Pivotal HD in July 2013. Open sourced and donated to the Apache Foundation in September 2015, becoming Apache Hawq, with the first open source release (2.0) in October 2016. Development led by Pivotal, who also distribute binaries as Pivotal HDB and provide training, consultancy and support. Pivotal HDB is also available as Hortonworks HDB.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Pivotal HDB, Hortonworks HDB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Pivotal, &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - 2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hawq.incubator.apache.org/&quot;&gt;http://hawq.incubator.apache.org/&lt;/a&gt; - Apache Hawq homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hawq.incubator.apache.org/docs/userguide/latest/index.html&quot;&gt;http://hawq.incubator.apache.org/docs/userguide/latest/index.html&lt;/a&gt; - Apache Hawq documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/HAWQ/&quot;&gt;https://cwiki.apache.org/confluence/display/HAWQ/&lt;/a&gt; - Apache Hawq Wiki&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/hawk/&quot;&gt;http://hortonworks.com/apache/hawk/&lt;/a&gt; - Hortonworks information on Apache Hawq&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_hdb-quick-guide/content/ch_hdb_summary.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_hdb-quick-guide/content/ch_hdb_summary.html&lt;/a&gt; - Hortonworks HDB documentation (links through to Pivotal HDB docs)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://pivotal.io/pivotal-hdb&quot;&gt;https://pivotal.io/pivotal-hdb&lt;/a&gt; - Pivotal HDB homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hdb.docs.pivotal.io/&quot;&gt;http://hdb.docs.pivotal.io/&lt;/a&gt; - Pivotal HDB documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://content.pivotal.io/blog/the-way-to-hadoop-native-sql&quot;&gt;https://content.pivotal.io/blog/the-way-to-hadoop-native-sql&lt;/a&gt; - Hawq open source announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&quot;&gt;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&lt;/a&gt; - Hortonworks and Pivotal HDB announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via Hortonworks and Pivotal blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-hawq/</guid> </item> <item><title>The Week That Was - 03/03/2017</title><link>http://ondataengineering.net/blog/2017/03/03/the-week-that-was/</link><pubDate>Fri, 03 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;Right - we’re nearly at the end of the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt; technologies. Let’s summarise what we’ve looked at this week.&lt;/p&gt; &lt;p&gt;We started off with &lt;a href=&quot;/technologies/apache-slider&quot;&gt;Apache Slider&lt;/a&gt;, then looked at &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Apache Accumulo&lt;/a&gt;, before finishing off with &lt;a href=&quot;/technologies/livy&quot;&gt;Livy&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-slider&quot;&gt;Apache Slider&lt;/a&gt; is interesting. It feels like a technology that allows you to run any long running app on YARN and have it play nicely with other YARN apps should be something people care about, because isn’t the whole selling point of Hadoop that you can have on analytical cluster that supports multiple workloads that all play nicely together, but it looks like outside of Hortonworks there’s very take up. It’s been in incubation since April 2014, and it seems like the biggest barrier to graduation is that there simply aren’t any committers outside of Hortonworks.&lt;/p&gt; &lt;p&gt;If there’s any one technology that kick-started the rise of the streaming data engines is has to be &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Apache Storm&lt;/a&gt; - the granddaddy of streaming technologies and still the 900 pound gorilla in the room. It’s not perfect, people have taken a lot of potshots at it over the years, and Twitter have now moved on (to Heron), however it’s been successful for a reason, and it looks like it’s been given a new lease of life after joining the Apache foundation, so if you’re looking at streaming use cases I don’t think you can afford not to look at it. Brush up on your micro batch vs record at a time considerations first however.&lt;/p&gt; &lt;p&gt;It want to look at &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;Apache HBase&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Apache Accumulo&lt;/a&gt; in more detail in the future, however Accumulo is gaining good adoption, is bundled with most Hadoop distributions, and has some interesting differentiations from HBase.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/livy&quot;&gt;Livy&lt;/a&gt; - a little piece of technology that’s come out of Cloudera that underpins the ability for analytical notebooks to run Spark code on remote clusters. I wonder how much it rankles Hortonworks to distribute Livy and Hue - both (open source Apache licenced) technologies that currently sit in a Cloudera repository in GitHub.&lt;/p&gt; &lt;p&gt;And last up for this week is &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt; - a custom bundling of Solr (along with a bunch of other technologies), built and maintained by Lucidworks and distributed as an add on to the Hortonworks Data Platform. It means that Solr doesn’t come out of the box with HDP (you have to download an extra Ambari management pack manually to install it), but it looks like a great partnership for Hortonworks - you get support from arguably the leading experts in Solr, and get Solr bundled with a bunch of other useful stuff that you don’t get with the other distributions.&lt;/p&gt; &lt;p&gt;Next week - the final HDP technologies. Have a great weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/03/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Platform Search</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform-search/</link><pubDate>Fri, 03 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An add on package to HDP that bundles up Solr, Banana, and a suite of libraries and tools for integrating with Solr from Hadoop (utilities for loading data from HDFS), Hive (a SerDe to allow Solr data to be read and written as a Hive table), Pig (store and load functions), HBase (replication of HBase events to Solr based on the Lily HBase indexer), Storm and Spark (both SDKs for integrating with Solr). Available as an add on Ambari management pack or as a set of RPMs. Built, maintained and supported by Lucidworks on behalf of Hortonworks, first announced in April 2014 as part of the introduction of Solr with HDP 2.1.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP Search&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;, Lucidworks&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;, Banana&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://doc.lucidworks.com/lucidworks-hdpsearch/2.5/index.html&quot;&gt;https://doc.lucidworks.com/lucidworks-hdpsearch/2.5/index.html&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_solr-search-installation/content/ch_hdp-search.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_solr-search-installation/content/ch_hdp-search.html&lt;/a&gt; - Hortonworks installation documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/bringing-enterprise-search-enterprise-hadoop/&quot;&gt;https://hortonworks.com/blog/bringing-enterprise-search-enterprise-hadoop/&lt;/a&gt; - Partnership announcement blog post&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via the Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform-search/</guid> </item> <item><title>Livy</title><link>http://ondataengineering.net/technologies/livy/</link><pubDate>Thu, 02 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A service that allows Spark jobs (pre-compiled JARs) or code snippets (Scala or Python) to be executed by remote systems over a REST API or via clients for Java, Scala and Python. Supports re-use of Spark Contexts (and caching and sharing of RDDs across jobs and clients), multiple concurrent clients, secure authenticated communications and batch job submissions. Started in November 2015 based on code from Hue, with a formal announcement and first release in June 2016. Open source under the Apache 2.0 licence, hosted on GitHub with development led by Cloudera and Microsoft. Still considered to be in alpha, but under active development, and used by tools such as Hue and Zeppelin.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://livy.io/&quot;&gt;http://livy.io/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/livy&quot;&gt;https://github.com/cloudera/livy&lt;/a&gt; - code repository&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/more/news-and-events/press-releases/2016-06-06-cloudera-microsoft-lead-development-open-source-project-livy-for-easy-use-spark-end-user-applications.html&quot;&gt;https://www.cloudera.com/more/news-and-events/press-releases/2016-06-06-cloudera-microsoft-lead-development-open-source-project-livy-for-easy-use-spark-end-user-applications.html&lt;/a&gt; - original announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/livy/releases&quot;&gt;https://github.com/cloudera/livy/releases&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/livy/</guid> </item> <item><title>Apache Accumulo</title><link>http://ondataengineering.net/technologies/apache-accumulo/</link><pubDate>Wed, 01 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;NoSQL wide-column datastore based on BigTable. Supports horizontal scalability, cell based access control (based on arbitrary boolean expressions of user security labels), high availability, atomic read-modify-write operations, map reduce support (both as a source and sink), table constraints, LDAP and Kerberos integration, and replication between instances. Comes with a web based monitoring interface (Accumulo Monitor) and a CLI. Written in Java, with thrift based API allowing access from other languages including C++, Python, Ruby. Originally developed at the NSA, donated to the Apache Foundation in September 2011, before graduating in March 2012, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Accumulo&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/&quot;&gt;http://accumulo.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/docs-archive/&quot;&gt;http://accumulo.apache.org/docs-archive/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/accumulo/&quot;&gt;https://hortonworks.com/apache/accumulo/&lt;/a&gt; - Hortonworks information&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://accumulo.apache.org/news/&quot;&gt;http://accumulo.apache.org/news/&lt;/a&gt; - news page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-accumulo/</guid> </item> <item><title>Apache Storm</title><link>http://ondataengineering.net/technologies/apache-storm/</link><pubDate>Tue, 28 Feb 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Specialised distributed stream processing technology based on a single record (not micro batch) model with at least once processing semantics. Processing flows are called topologies based on a directed acyclic graph of spouts (which produce unbounded streams of tuples) and bolts (which process streams and optionally produce output streams). Supports high throughput and low latency use cases, horizontal scalability, fault tolerance (failed workers are automatically restarted and failed over to new nodes if required), back pressure, windowing (with support for sliding and tumbling windows based on time or event counts), stateful bolts and a shared bolt storage cache (that's updatable from the command line). Also includes a higher level micro batch API (Trident) that supports exactly-once processing semantics, fault-tolerant state management and higher level operations including joins, aggregations and groupings, support for SQL (StormSQL) and frameworks and utilities to make defining and deploying topologies easier (Flux). Has both a graphical web based and command line interface, plus a REST API. Primarily written in Clojure, JVM based, but supports multiple languages through the use of Thrift for defining and submitting topologies, and the use of spouts that can interface to other languages using JSON over stdin/stdout. Originally created at BackType, before being open sourced in September 2011 after the acquisition of BackType by Twitter. Donated to the Apache Foundation in September 2013, graduating in September 2014, with a 1.0 release in April 2016. Has multiple reference cases for being deployed at scale, including Twitter, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Storm&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.1&lt;/td&gt; &lt;td&gt;2017-03-29&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://storm.apache.org/2017/03/29/storm110-released.html&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/&quot;&gt;http://storm.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/storm/&quot;&gt;https://hortonworks.com/apache/storm/&lt;/a&gt; - Hortonworks information, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/releases/1.0.3/index.html&quot;&gt;http://storm.apache.org/releases/1.0.3/index.html&lt;/a&gt; - documentation for current release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_storm-component-guide/content/ch_storm-overview.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_storm-component-guide/content/ch_storm-overview.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://nathanmarz.com/blog/history-of-apache-storm-and-lessons-learned.html&quot;&gt;http://nathanmarz.com/blog/history-of-apache-storm-and-lessons-learned.html&lt;/a&gt; - history of storm&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;http://accumulo.apache.org/news/&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://storm.apache.org/index.html&quot;&gt;http://storm.apache.org/index.html&lt;/a&gt; - Storm new announced on Apache homepage&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-storm/</guid> </item> <item><title>Apache Slider</title><link>http://ondataengineering.net/technologies/apache-slider/</link><pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for hosting long running distributed applications on YARN, allowing YARN to manage the resources these applications use. Can handle any application that supports a base set of requirements (including being able to install and run from a tarball), with experimental support for docker packaged applications. Operates as a YARN application master (the Slider AM), an associated command line interface and lightweight agents to manage running components. Supports manual scaling, automatic recovery, rolling upgrades and component placement controls, and includes out of the box configuration for a number of applications including Accumulo, HBase, Kafka, Memcached, Solr, Storm and Tomcat. An incubating Apache project, originally donated in April 2014. Hasn't yet reached a v1.0 milestone, however still under development led by Hortonworks.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Slider&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.91&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://slider.incubator.apache.org&quot;&gt;http://slider.incubator.apache.org&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/deploying-long-running-services-on-apache-hadoop-yarn-cluster/&quot;&gt;https://hortonworks.com/blog/deploying-long-running-services-on-apache-hadoop-yarn-cluster/&lt;/a&gt; - introduction blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/apache/slider/&quot;&gt;https://hortonworks.com/apache/slider/&lt;/a&gt; - Hortonworks information on slider, including links to blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_yarn-resource-management/content/ch_slider.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_yarn-resource-management/content/ch_slider.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://slider.incubator.apache.org/docs/&quot;&gt;http://slider.incubator.apache.org/docs/&lt;/a&gt; - Slider documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-slider/</guid> </item> <item><title>The Week That Was - 24/02/2017</title><link>http://ondataengineering.net/blog/2017/02/24/the-week-that-was/</link><pubDate>Fri, 24 Feb 2017 08:20:00 +0000</pubDate> <description> &lt;p&gt;And so we’ve started our foray into the technologies bundled with &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. We’ve already looked at a large number of these technologies, but there’s a few here that are new.&lt;/p&gt; &lt;p&gt;First up this week were the Hortonworks candidates in the metadata management and security space - &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-knox&quot;&gt;Apache Knox&lt;/a&gt;. We’ve then finished the week with &lt;a href=&quot;/technologies/apache-falcon&quot;&gt;Apache Falcon&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Everyone says they want metadata management, data catalogues and business glossaries, very few people actually build them, and they’re desperately un-sexy. Which is why you don’t often see open source technologies in this space. &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt; is trying to buck that trend, with some significant commercial backers. It’s going to be interesting to see how far this gets and what level of adoptions it gets. At the moment it feels like it’s trailing Cloudera Navigator, but that’s a commercial product which perhaps gives Cloudera greater impetus to invest in it. One to come back to at some point I think.&lt;/p&gt; &lt;p&gt;We’ll also be coming back to look at the state of security in the Hadoop Ecosystem - Cloudera and MapR are supporting Apache Sentry, whereas Hortonworks are supporting &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-knox&quot;&gt;Apache Knox&lt;/a&gt;. Competition and survival of the fittest in open source is one of it’s greatest strengths, however in this case it seems like the Cloudera Hortonworks rivalry (for want of a better word) is perhaps not helping to overall Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;I really want to like &lt;a href=&quot;/technologies/apache-falcon&quot;&gt;Apache Falcon&lt;/a&gt;, however I think I need to get to know it better before I start professing any love. It’s trying to solve a real problem - managing and orchestrating your data pipelines and the data that moves between and through these - however it’s a difficult problem, and creating a reductive solution can create real limitations and constraints. Another one I’d like to return to in due course.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;, here to claim the crown (from &lt;a href=&quot;/technologies/apache-zookeeper&quot;&gt;Apache ZooKeeper&lt;/a&gt;) of the best, most widely used technology you’ve probably never heard of. If you use an open source technology that has a SQL interface, you’re more than likely to be using Calcite - it provides SQL parsing, cost based optimisation and JDBC frameworks that are used in Hive, Drill, Storm, Apex, Druid, Kylin, Phoenix, Solr, Flink, Cascading and Samza amongst others. Creators of open source software often don’t get the acknowledgement they deserve, but Julian Hyde deserves our thanks and appreciation for creating what would become Apache Calcite.&lt;/p&gt; &lt;p&gt;Right - I’m done with this week. See you on the other side of the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/24/the-week-that-was/</guid> </item> <item><title>Apache Calcite</title><link>http://ondataengineering.net/technologies/apache-calcite/</link><pubDate>Fri, 24 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A framework for building SQL based data access capabilities. Supports a SQL parser and validator, tools for the transformation and (cost based) optimisation of SQL expression trees, and an adapter framework for accessing metadata and executing queries (including out of the box adapters for a number of database technologies as well as CSV files and POJO objects), along with specific support for streaming SQL queries and optimising data cube queries to use materialised views. Also includes (as a sub-project named Avatica), a framework for building database drivers with support for a standard JDBC driver, server and wire protocols, plus a local embeddable JDBC driver. Used in a range of other projects including Drill, Flink, Hive, Kylin, Phoenix, Samza, Storm and Cascading. An Apache project, originally created by Julian Hyde in May 2012 as Optiq, donated to the Apache Foundation in May 2014, graduating in October 2015 following a v1.0 release in January 2015. Under active development with a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Calcite, Avatica&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v1.12&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.12&lt;/td&gt; &lt;td&gt;2017-03-24&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://calcite.apache.org/news/2017/03/24/release-1.12.0/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/&quot;&gt;https://calcite.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/docs/&quot;&gt;https://calcite.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/docs/avatica_overview.html&quot;&gt;https://calcite.apache.org/docs/avatica_overview.html&lt;/a&gt; - Avatica overview&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/news/&quot;&gt;https://calcite.apache.org/news/&lt;/a&gt; - Calcite news&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://calcite.apache.org/avatica/news/&quot;&gt;https://calcite.apache.org/avatica/news/&lt;/a&gt; - Avatica news&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-calcite/</guid> </item> <item><title>Apache Falcon</title><link>http://ondataengineering.net/technologies/apache-falcon/</link><pubDate>Thu, 23 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data feed management system for Hadoop. Supports the definition, scheduling and orchestration (including support for late data and retry policies) of data processing pipelines (referred to as processes, with support for Ozzie, Spark, Hive and Pig jobs), the management of the data produced and consumed by these pipelines (referred to as feeds, with support for data in HDFS and Hive) and the generation and visualisation of pipeline lineage information, all across multiple Hadoop clusters. Also includes the ability to mirror or replicate HDFS and Hive data between clusters, to failover processing between clusters and to import and export data using Sqoop. Supports both a web and command line interface and a REST API. An Apache project, graduating in December 2014, having been originally donated by inMobi in April 2013. Hasn't yet reached a v1.0 milestone, however still under development led by inMobi and Hortonworks with a range of other contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Falcon&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://falcon.apache.org/&quot;&gt;http://falcon.apache.org/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/falcon/&quot;&gt;http://hortonworks.com/apache/falcon/&lt;/a&gt; - Hortonworks information on Falcon, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-movement-and-integration/content/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-movement-and-integration/content/index.html&lt;/a&gt; - Hortonworks documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-falcon/</guid> </item> <item><title>Apache Knox</title><link>http://ondataengineering.net/technologies/apache-knox/</link><pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A stateless gateway for the Apache Hadoop ecosystem that provides perimeter security. Includes support for user authentication (via LDAP, Active Directory and a number of single sign on solutions), access authorisation on a per service basis, transitions to Kerberos authentication, reverse proxying and auditing, extension points for supporting new services, audit capabilities, and out of the box support for a number of Hadoop technology end points. An Apache project, started by Hortonworks in February 2013, donated to the Apache Foundation two months later in April, before graduating in February 2014. Hasn't yet reached a v1.0 milestone, however still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Knox&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v0.12&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.12&lt;/td&gt; &lt;td&gt;2017-03-20&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/www-announce/201703.mbox/%3CCA%2BTBRctuHBLB%3DC4gHggQJaGjzPaMUMprcXx-P_mmSnLvf-55OQ%40mail.gmail.com%3E&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/&quot;&gt;http://knox.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/books/knox-0-11-0/user-guide.html&quot;&gt;http://knox.apache.org/books/knox-0-11-0/user-guide.html&lt;/a&gt; - extreemly comprehensive documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/knox-gateway/&quot;&gt;http://hortonworks.com/apache/knox-gateway/&lt;/a&gt; - Hortonworks information on Knox&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&lt;/a&gt; - Hortonworks documentation on Knox&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KNOX/News&quot;&gt;https://cwiki.apache.org/confluence/display/KNOX/News&lt;/a&gt; - news updates&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-knox/</guid> </item> <item><title>Apache Ranger</title><link>http://ondataengineering.net/technologies/apache-ranger/</link><pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store (with a web based administration interface and REST API), and plugins for Hadoop components (including HDFS, Hive, HBase, Storm, Knox, Solr, Kafka, YARN, Atlas and NiFi) to manage authorisation of user access to data. Supports data masking and row level access policies (currently only supported by Hive), the ability to define policies against tags as well as directly against resources (with tags assigned to resources externally, e.g. in Apache Atlas), and the ability to use more complex conditions (e.g. denying access after an expiration date or based on a users location). Extendable with the ability to add support for new services (Ranger Stacks) and to add custom decision rules (via content enrichers and condition evaluators). Also supports a full audit capability of access requests and decisions, and a key management service for HDFS encryption keys. An Apache project, donated in July 2014 as Argus by the Hortonworks following their acquisition of XA Secure, graaduating in February 2017. Has not yet reached a v1.0 milestone, but is still under active development with a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ranger&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;Hortonworks Data Platform for Windows&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;2017-02-28&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/RANGER/0.7.0+Release+-+Apache+Ranger&quot;&gt;wiki page&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.incubator.apache.org/&quot;&gt;http://ranger.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.apache.org/faq.html&quot;&gt;http://ranger.apache.org/faq.html&lt;/a&gt; - FAQs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/ranger/&quot;&gt;http://hortonworks.com/apache/ranger/&lt;/a&gt; - Hortonworks information on Ranger, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&lt;/a&gt; - Hortonworks documentation on Ranger&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/RANGER&quot;&gt;https://cwiki.apache.org/confluence/display/RANGER&lt;/a&gt; - Apache Ranger Wiki, with most information detailed by release under the Release Folders page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ranger/</guid> </item> <item><title>Apache Atlas</title><link>http://ondataengineering.net/technologies/apache-atlas/</link><pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A metadata and data governance solution for Hadoop. Supports an extensible metadata model with out of the box support for Hive datasets and data lineage from Hive queries and Sqoop imports, with limited support for Falcon, Storm and Kafka. Allows datasets and data items to be tagged (and for these tags to be used for access control by Apache Ranger), and includes support for business taxonomies as a technical preview. Implemented as a graph based database using Titan (which by default uses HBase and Solr), with a web based user interface and a REST API for searching and visualising/retrieving metadata, and Kafka topics for the ingest of metadata (primarily from hooks in metadata sources such as Hive or Sqoop) and the publishing of metadata change events. An incubating Apache project, donated to the Apache Foundation in May 2015 by the Hortonworks Data Governance Initiative in partnership with Aetna, Merck, Target, Schlumberger and SAS. Has not yet reached a v1.0 milestone or graduated as a top level Apache project, but is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Atlas&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v0.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.8&lt;/td&gt; &lt;td&gt;2017-03-31&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/www-announce/201703.mbox/%3C8634D8C3-56D3-4E13-B292-B6C51F6AD5CC%40apache.org%3E&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/&quot;&gt;http://atlas.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/atlas&quot;&gt;http://hortonworks.com/apache/atlas&lt;/a&gt; - Hortonworks background information, including links to relevant blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/Architecture.html&quot;&gt;http://atlas.incubator.apache.org/Architecture.html&lt;/a&gt; - Architecture overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&lt;/a&gt; - Hortonworks documentation from 2.5.3 HDP release&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs*&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-atlas/</guid> </item> </channel> </rss>
