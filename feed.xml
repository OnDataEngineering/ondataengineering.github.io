<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>Apache Knox</title><link>http://ondataengineering.net/technologies/apache-knox/</link><pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A stateless gateway for the Apache Hadoop ecosystem that provides perimeter security. Includes support for user authentication (via LDAP, Active Directory and a number of single sign on solutions), access authorisation on a per service basis, transitions to Kerberos authentication, reverse proxying and auditing, extension points for supporting new services, audit capabilities, and out of the box support for a number of Hadoop technology end points. An Apache project, started by Hortonworks in February 2013, donated to the Apache Foundation two months later in April, before graduating in February 2014. Hasn't yet reached a v1.0 milestone, however still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Knox&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/&quot;&gt;http://knox.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://knox.apache.org/books/knox-0-11-0/user-guide.html&quot;&gt;http://knox.apache.org/books/knox-0-11-0/user-guide.html&lt;/a&gt; - extreemly comprehensive documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/knox-gateway/&quot;&gt;http://hortonworks.com/apache/knox-gateway/&lt;/a&gt; - Hortonworks information on Knox&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/perimeter_security_with_apache_knox.html&lt;/a&gt; - Hortonworks documentation on Knox&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KNOX/News&quot;&gt;https://cwiki.apache.org/confluence/display/KNOX/News&lt;/a&gt; - news updates&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-knox/</guid> </item> <item><title>Apache Ranger</title><link>http://ondataengineering.net/technologies/apache-ranger/</link><pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a web based administration interface, a REST API, and a central policy engine used by plugins within individual Hadoop components (including HDFS, Hive, HBase, Storm, Knox, Solr, Kafka, YARN, Atlas and NiFi). Supports data access, data masking, and row level filtering policies (with masking and row level filtering currently only supported by Hive), the ability to define policies against tags as well as directly against resources (with tags assigned to resources externally, e.g. in Apache Atlas), and the ability to use more complex conditions (e.g. denying access after an expiration date or based on a users location). Extendable with the ability to add support for new services (Ranger Stacks) and to add custom decision rules (via content enrichers and condition evaluators). Also supports a full audit capability of access requests and decisions, and a key management service for HDFS encryption keys. An incubating Apache project, donated in July 2014 by the Hortonworks following their acquisition of XA Secure. Has not yet reached a v1.0 milestone, but is still under active development with a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ranger&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.6&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.incubator.apache.org/&quot;&gt;http://ranger.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://ranger.apache.org/faq.html&quot;&gt;http://ranger.apache.org/faq.html&lt;/a&gt; - FAQs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/ranger/&quot;&gt;http://hortonworks.com/apache/ranger/&lt;/a&gt; - Hortonworks information on Ranger, including tutorials and blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_security/content/ch_hdp-security-guide-authorization.html&lt;/a&gt; - Hortonworks documentation on Ranger&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/RANGER&quot;&gt;https://cwiki.apache.org/confluence/display/RANGER&lt;/a&gt; - Apache Ranger Wiki, with most information detailed by release under the Release Folders page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ranger/</guid> </item> <item><title>Apache Atlas</title><link>http://ondataengineering.net/technologies/apache-atlas/</link><pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A metadata and data governance solution for Hadoop. Supports an extensible metadata model with out of the box support for Hive datasets and data lineage from Hive queries and Sqoop imports, with limited support for Falcon, Storm and Kafka. Allows datasets and data items to be tagged (and for these tags to be used for access control by Apache Ranger), and includes support for business taxonomies as a technical preview. Implemented as a graph based database using Titan (which by default uses HBase and Solr), with a web based user interface and a REST API for searching and visualising/retrieving metadata, and Kafka topics for the ingest of metadata (primarily from hooks in metadata sources such as Hive or Sqoop) and the publishing of metadata change events. An incubating Apache project, donated to the Apache Foundation in May 2015 by the Hortonworks Data Governance Initiative in partnership with Aetna, Merck, Target, Schlumberger and SAS. Has not yet reached a v1.0 milestone or graduated as a top level Apache project, but is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Atlas&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/&quot;&gt;http://atlas.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/apache/atlas&quot;&gt;http://hortonworks.com/apache/atlas&lt;/a&gt; - Hortonworks background information, including links to relevant blog posts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://atlas.incubator.apache.org/Architecture.html&quot;&gt;http://atlas.incubator.apache.org/Architecture.html&lt;/a&gt; - Architecture overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.3/bk_data-governance/content/ch_hdp_data_governance_overview.html&lt;/a&gt; - Hortonworks documentation from 2.5.3 HDP release&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Hortonworks and Apache blogs*&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-atlas/</guid> </item> <item><title>The Week That Was - 17/02/2017</title><link>http://ondataengineering.net/blog/2017/02/17/the-week-that-was/</link><pubDate>Fri, 17 Feb 2017 16:50:00 +0000</pubDate> <description> &lt;p&gt;So let’s review the technologies we’ve looked at this week as we come to the end of our journey through the technologies bundled with Apache Bigtop.&lt;/p&gt; &lt;p&gt;The last Bigtop technologies we looked at where a couple of web based end user tools (&lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-zeppelin&quot;&gt;Apache Zeppelin&lt;/a&gt;), an HDFS compatible filesystem (&lt;a href=&quot;/technologies/quantcast-file-system&quot;&gt;Quantcast File System&lt;/a&gt;) and an MPP database (&lt;a href=&quot;/technologies/greenplum&quot;&gt;Greenplum&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;And today, we’ve started our look the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Of all the technologies we’ve looked at this week, &lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; was the biggest surprise. It’s an open source project licensed under the Apache 2.0 licence, but is not an Apache Foundation project (it actually sits in a Cloudera github repository). It’s pitched as a general purpose user interface for Hadoop, and the range of functionality it includes was surprising - everything from managing data in HDFS to creating Ozzie workflows to monitoring YARN logs to running SQL and Solr queries. It’s not an analysis notebook ala Jupyter or Zeppelin (although it now has some basic functionality in this area), but a web front end onto all the common Hadoop components, and if you’re using Hadoop, I would strongly suggest it’s worth your time to take a look at it. Even Hortonworks bundle it (despite the fact it’s not an Apache project), although they obviously don’t advertise this.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-zeppelin&quot;&gt;Apache Zeppelin&lt;/a&gt; is however an analytical notebook, with support for a wide range of languages and analytical tools. If you’re doing interactive or exploratory analytics it’s probably well worth a look.&lt;/p&gt; &lt;p&gt;The promise and potential of open source software is often overstated, but if you have a strong development team that are comfortable in opening and extending open source software then you can create fantastic capabilities specifically tuned to your business. &lt;a href=&quot;/technologies/quantcast-file-system&quot;&gt;Quantcast File System&lt;/a&gt; is a great example of this - an HDFS compatible filesystem based on an open source project (KFS) that allows Quantcast to operate at a scale that isn’t supported by other technologies. Companies that operate at extreme scale are fantastic breeding grounds for innovation, and we’ll definitely look at some of the technologies coming out of companies like Netflix, Facebook, eBay and LinkedIn in the future.&lt;/p&gt; &lt;p&gt;There are many reasons why companies open source projects - to pay back to the community, to accelerate development, and because a technology is no longer of significant commercial value. &lt;a href=&quot;/technologies/greenplum&quot;&gt;Greenplum&lt;/a&gt; feels like it falls into the final category - it’s been a commercial product since 2003 and has failed to gain any significant traction. It does however still seem to be under development (although primarily by Pivotal rather than by outside competitors), so maybe I’m misjudging this. I wouldn’t be &lt;a href=&quot;http://www.ness.com/big-data-101-the-rise-and-fall-of-greenplum-2/&quot;&gt;the only one&lt;/a&gt; however.&lt;/p&gt; &lt;p&gt;And today we looked at our second Hadoop distribution - the &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;Hortonworks Data Platform&lt;/a&gt;. There’s a lot to like about HDP, especially it’s commitment to open source - I just hope that Hortonworks can work out a commercial model that makes them a sustainable business.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/17/the-week-that-was/</guid> </item> <item><title>Hortonworks Data Platform</title><link>http://ondataengineering.net/technologies/hortonworks-data-platform/</link><pubDate>Fri, 17 Feb 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A distribution of Hadoop based on a commitment to the Apache open source ecosystem. All bundled projects are Apache open source projects based on official Apache project releases, with any patches for bug fixes or new features official Apache project patches pulled from later releases of the project. Available as RPMs or can be installed using Apache Ambari (for local installs) or Cloudbreak (for installation on cloud platforms). Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Spark SQL, HDP Search and Hortonworks HDB. Provided free of charge, with training, consultancy and support available from Hortonworks, along with their proprietary SmartSense support tool. First released in June 2012.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;HDP&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Hortonworks&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 2.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Apache Zeppelin&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, Accumulo, Calcite, Falcon, Livy, Slider, Storm&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;HDP Search, Hortonworks HDB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;Ambari, Cloudbreak&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The base Apache project versions bundled with each version of HDP are shown on the HDP home page, as well as on the first page of the release notes. Details of the features in these releases that Hortonworks don’t support, and the patches that have been applied to these releases are also available in the release notes, along with known vulnerabilities, fixes from previous versions and known issues.&lt;/p&gt; &lt;p&gt;Note that:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Apache Calcite, Apache DataFu, Apache Mahout and Hue are not referenced on the HDP home page, but are part of HDP (they are referenced in the release notes)&lt;/li&gt; &lt;li&gt;Livy is not mentioned on the HDP home page or the release notes, but is part of HDP (it’s in the HDP rpm repo and included Zeppelin installation steps)&lt;/li&gt; &lt;li&gt;Although Solr is referenced on the HDP home page and in the release note, it is only available via the HDP Search add-on to HDP&lt;/li&gt; &lt;li&gt;Hortonworks HDB is Pivotal HDB, with support and consultancy provided by Hortonworks, and is distributed as an add-on to HDP&lt;/li&gt; &lt;li&gt;Cascading is referenced in the release notes, but isn’t part of HDP (it’s not in the HDP repo and isn’t covered by the installation guide)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/products/data-center/hdp/&quot;&gt;http://hortonworks.com/products/data-center/hdp/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/index.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/index.html&lt;/a&gt; - HDP 2.5.0 documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/bk_release-notes/content/ch_relnotes_v250.html&quot;&gt;http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.5.0/bk_release-notes/content/ch_relnotes_v250.html&lt;/a&gt; - HDP 2.5.0 release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/blog/&quot;&gt;http://hortonworks.com/blog/&lt;/a&gt; - Hortonworks Blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-data-platform/</guid> </item> <item><title>Apache Bigtop to HDP</title><link>http://ondataengineering.net/blog/2017/02/17/apache-bigtop-to-hdp/</link><pubDate>Fri, 17 Feb 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;And so we’ve come to the end of the technologies included in Apache Bigtop - it’s been a bit of a meandering trip, taking in some well known sights, some up and coming stuff, and some slightly odd and obscure pieces.&lt;/p&gt; &lt;p&gt;But time and tide wait for no man, so on we march, continuing our trip into the world of Hadoop Distributions. Up next, it’s the Hortonworks Data Platform (HDP) - we’ll start by looking at HDP itself, and then move on to the technologies it includes that we haven’t looked at yet.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/17/apache-bigtop-to-hdp/</guid> </item> <item><title>Greenplum</title><link>http://ondataengineering.net/technologies/greenplum/</link><pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A shared nothing, massively parallel processing (MPP) database optimised for analytical / OLAP workloads. Based on a fork PostgreSQL, it is essentially multiple PostgreSQL databases working together as a single logical database. Supports a cost-based query optimiser optimised for large analytical workloads, multiple storage models (including append only, columnar and heap), full ACID compliance and concurrent transactions, multiple index types, broad SQL support, a range of client connectors (including ODBC and JDBC), high capacity bulk load and unload tools, in database query language support (including Python, R, Perl, Java and C), and in database analytics support (including machine learning via Apache MADLib, geographic analytics via PostGIS and encryption via PGCrypto). Originally created by Greenplum (the company) which was founded in September 2003 before being brought by EMC in 2010, with Greenplum (the database) then spun out as part of Pivotal Software in 2013 before being open sourced in in October 2015 under the Apache 2.0 licence with the source code hosted on GitHub. Development is still led by Pivotal (with little evidence of outside contributions), who also distribute binaries as Pivotal Greenplum and provide training, consultancy and support.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Pivotal Greenplum, GPDB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Pivotal&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 4.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://greenplum.org/&quot;&gt;http://greenplum.org/&lt;/a&gt; - open source project homepage &lt;a href=&quot;https://github.com/greenplum-db/gpdb&quot;&gt;https://github.com/greenplum-db/gpdb&lt;/a&gt; - code repository &lt;a href=&quot;https://pivotal.io/pivotal-greenplum&quot;&gt;https://pivotal.io/pivotal-greenplum&lt;/a&gt; - Pivotal Greenplum homepage &lt;a href=&quot;https://github.com/greenplum-db/greenplum-db.github.io/wiki/Greenplum-Architecture&quot;&gt;https://github.com/greenplum-db/greenplum-db.github.io/wiki/Greenplum-Architecture&lt;/a&gt; - architecture overview &lt;a href=&quot;https://content.pivotal.io/datasheets/pivotal-greenplum&quot;&gt;https://content.pivotal.io/datasheets/pivotal-greenplum&lt;/a&gt; - Pivotal Greenplum datasheet &lt;a href=&quot;http://gpdb.docs.pivotal.io/&quot;&gt;http://gpdb.docs.pivotal.io/&lt;/a&gt; - documentation &lt;a href=&quot;https://network.pivotal.io/products/pivotal-gpdb&quot;&gt;https://network.pivotal.io/products/pivotal-gpdb&lt;/a&gt; - download site&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://greenplum.org/&quot;&gt;http://greenplum.org/&lt;/a&gt; - link to Greenplum announcement mailing list&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/greenplum/</guid> </item> <item><title>Quantcast File System</title><link>http://ondataengineering.net/technologies/quantcast-file-system/</link><pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Open source HDFS compatible distributed file system, which focuses on improving performance and scalability over HDFS. Uses erase coding (specifically Reed-Solomon error correction) allowing each data block to be stored with a 50% overhead over 9 nodes with data able to be read from any 6 (half the space required by HDFS with 3 way replication). Also supports online addition of new data (chunk) nodes, automatic re-balancing and re-replication of data, Unix style permissions support and C++ and Java client libraries. Published benchmarks suggest a 50/75% read/write performance increase over HDFS, and significantly faster metadata operations. Now also runs over Amazon S3. Built and maintained by Quantcast, who open sourced it in August 2012. An evolution of the Kosmos File System (KFS), an open source project started by Kosmix in 2005, which Quantcast first adopted in 2007. Built in C++ and released under the Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;QFS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Quantcast&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Quiet&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 1.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://quantcast.github.io/qfs/&quot;&gt;https://quantcast.github.io/qfs/&lt;/a&gt; - homepage &lt;a href=&quot;https://github.com/quantcast/qfs/&quot;&gt;https://github.com/quantcast/qfs/&lt;/a&gt; - code &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/&quot;&gt;https://github.com/quantcast/qfs/wiki/&lt;/a&gt; - documentation &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/Introduction-To-QFS&quot;&gt;https://github.com/quantcast/qfs/wiki/Introduction-To-QFS&lt;/a&gt; - introduction and summary of benefits &lt;a href=&quot;https://github.com/quantcast/qfs/wiki/Performance-Comparison-to-HDFS&quot;&gt;https://github.com/quantcast/qfs/wiki/Performance-Comparison-to-HDFS&lt;/a&gt; - performance comparison to HDFS &lt;a href=&quot;https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/&quot;&gt;https://www.quantcast.com/blog/quantcast-file-system-on-amazon-s3/&lt;/a&gt; - information on running over S3 &lt;a href=&quot;https://gigaom.com/2012/09/27/quantcast-releases-bigger-faster-stronger-hadoop-file-system/&quot;&gt;https://gigaom.com/2012/09/27/quantcast-releases-bigger-faster-stronger-hadoop-file-system/&lt;/a&gt; - background information &lt;a href=&quot;http://www.odbms.org/blog/2013/03/big-data-improving-hadoop-for-petascale-processing-at-quantcast/&quot;&gt;http://www.odbms.org/blog/2013/03/big-data-improving-hadoop-for-petascale-processing-at-quantcast/&lt;/a&gt; - interview with creators&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://www.quantcast.com/feed/&quot;&gt;http://www.quantcast.com/feed/&lt;/a&gt; - occasional updates on the Quantcast blog&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/quantcast-file-system/</guid> </item> <item><title>Apache Zeppelin</title><link>http://ondataengineering.net/technologies/apache-zeppelin/</link><pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A web based notebook for interactive data analytics. Supports a wide range of interpreters (including Spark, JDBC SQL, Pig, Elasticsearch, Beam, Flink, Shell, Python amongst many others), a range of output formats (plain text, HTML, mathematical expressions using MathJax and tabular data), a range of visualisations for tabular data (including the ability to add more via a JavaScript NPM based plugin system called Helium), forms for user entry of parameters, and an Angular API to enable dynamic and interactive functionality within notebooks. Has a plugable storage for notebooks (with out of the box support for git, S3, Azure and ZeppelinHub), support for multi-user environments and a security model. Open sourced by NFLabs (now called ZEPL) in 2013 before being donated to the Apache Foundation in December 2014, graduating in May 2016. Under active development with a wide range of contributors, led by ZEPL, who sell Zeppelin as a managed service (ZepplinHub).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Zeppelin&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, ZEPL&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://zeppelin.apache.org/&quot;&gt;http://zeppelin.apache.org/&lt;/a&gt; - homepage &lt;a href=&quot;https://zeppelin.apache.org/docs/&quot;&gt;https://zeppelin.apache.org/docs/&lt;/a&gt; - documentation by version &lt;a href=&quot;https://www.zepl.com/&quot;&gt;https://www.zepl.com/&lt;/a&gt; - ZEPL homepage &lt;a href=&quot;https://www.zeppelinhub.com/&quot;&gt;https://www.zeppelinhub.com/&lt;/a&gt; - ZepplinHub home page&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://zeppelin.apache.org/&quot;&gt;https://zeppelin.apache.org/&lt;/a&gt; - release announcements via the homepage&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-zeppelin/</guid> </item> <item><title>Hue</title><link>http://ondataengineering.net/technologies/hue/</link><pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Web application to allow users and administrators to work with a Hadoop cluster. Features include a SQL query tool (with auto-complete, a SQL expression builder, plotting results as a graph or on a map, and the ability to refine results) over any JDBC compatible database, a Pig query tool (with auto-complete and parameterised queries), a Solr search tool (drag a drop creation of Solr dashboards with grid, timeline, graph, map and filter widgets, a tool for indexing data into Solr and a Solr index browser), a query notebook (Spark, PySpark, Scala, Hive, Impala, Pig and R queries along with visualisation of results as graphs and maps), an Oozie management tool (graphical Oozie workflow, coordinator and bundle editors and an Oozie monitoring and management dashboard), an Apache Sentry configuration tool (for managing permissions to Hive tables and Solr collections), an HDFS and S3 file browser and manager (including the ability to upload and edit data), a YARN job browser (viewing logs and statistics), a Hive Metastore manager (browse, view sample data, create and manage databases and tables), an HBase table manager (browse, view, edit, create and manage tables), a Sqoop2 manager (create, manage and execute Sqoop2 jobs), a ZooKeeper manager (list, view and edit) and a user workspace for saving work done in Hue, organising this in folders and sharing it with other users. Originally released by Cloudera as Cloudera Desktop in October 2009, before being open sourced as Hue in June 2010. Python/Django based, under active development with a wide range of contributors, and available for all major Hadoop distributions.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Hue&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 3.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://gethue.com/&quot;&gt;http://gethue.com/&lt;/a&gt; - homepage &lt;a href=&quot;https://github.com/cloudera/hue&quot;&gt;https://github.com/cloudera/hue&lt;/a&gt; - code repository&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;http://gethue.com/blog/&quot;&gt;http://gethue.com/blog/&lt;/a&gt; - Hue blog&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hue/</guid> </item> <item><title>The Week That Was - 10/02/2017</title><link>http://ondataengineering.net/blog/2017/02/10/the-week-that-was/</link><pubDate>Fri, 10 Feb 2017 16:50:00 +0000</pubDate> <description> &lt;p&gt;Wow, doesn’t time fly when you’re having fun.&lt;/p&gt; &lt;p&gt;We’re nearly at the end of our Apache Bigtop journey - this week we’ve had a look at a bunch of data processing tools (&lt;a href=&quot;/technologies/apache-apex&quot;&gt;Apache Apex&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flink&quot;&gt;Apache Flink&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-tez&quot;&gt;Apache Tez&lt;/a&gt;), and to round the week out &lt;a href=&quot;/technologies/apache-zookeeper&quot;&gt;Apache ZooKeeper&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;There are some interesting ideas in &lt;a href=&quot;/technologies/apache-apex&quot;&gt;Apache Apex&lt;/a&gt; - building low level flexible DAGs with custom operators is powerful, and their messages about minimising the amount of ceremony and focusing on business logic are great. However it feels very much like a commercial product in open source clothing (its absolutely not alone in this regard), and I’m not sure I see it making much headway. There could be potential in the graphical tools and extra stuff that comes as part of the DataTorrent commercial product however - something I’d like to take a deeper look at in the future.&lt;/p&gt; &lt;p&gt;I’m not fully informed on the history of &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, however I’m assuming that it was created to make working with MapReduce easier, and based on how many companies seem to have adopted it appears to have been pretty successful, with support for running over Spark presumably allowing these companies to migrate their Crunch works to Spark to gain the benefits. I’m also going to make a wild assumption that Crunch’s time has been and gone, and now that there are alternatives to MapReduce there’s little value in Crunch unless you’re already a heavy user.&lt;/p&gt; &lt;p&gt;To to &lt;a href=&quot;/technologies/apache-flink&quot;&gt;Apache Flink&lt;/a&gt;. There’s a lot to like about Flink, and it feels like it could be a serious contender as a leading stream processing platform if it can continue its growth, contributions and adoption. I’d love to hear from anyone that’s had experience with using Flink.&lt;/p&gt; &lt;p&gt;I have to say I’m conflicted about &lt;a href=&quot;/technologies/apache-tez&quot;&gt;Apache Tez&lt;/a&gt;. There’s part of me that sees it as an indulgence on Hortonworks part - the creation of new technology for Hive and Pig to use for executing queries when (maybe) other technologies existed already (not looking anywhere in particular Spark) that’s destined to become a footnote to history. However there’s another (perhaps larger) part of me that thinks there’s something here that I (and many people) don’t quite appreciate yet. I absolutely don’t see it as a competitor to Spark in the iterative analytics space, however I have a feeling that it might be a better and more scalable general purpose data processing engine that supports large Hive and Pig queries that Spark might struggle with. It’s great that Spark has set terabyte scale sorting benchmarks, but I’m not sure I’d want to use it to join terabyte sized datasets together. What’s going to be interesting is not the Spark vs Tez question, but more about how it holds up against new combined batch and streaming engines such as Flink.&lt;/p&gt; &lt;p&gt;And last but not least &lt;a href=&quot;/technologies/apache-zookeeper&quot;&gt;Apache ZooKeeper&lt;/a&gt;. You may not be aware you’re using it, but if you’re running almost any clustered Apache technology you probably are!&lt;/p&gt; &lt;p&gt;And with that we’re up to 28 technologies - only a couple of thousand to go!&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/10/the-week-that-was/</guid> </item> <item><title>Apache ZooKeeper</title><link>http://ondataengineering.net/technologies/apache-zookeeper/</link><pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Service for managing coordination (e.g. configuration information and synchronisation) of distributed and clustered systems. Based on a hierarchical key-value store, with support for things such as sequential nodes (whose names are automatically assigned a sequence number suffix), ephemeral nodes (which only exist whilst their owners session exists) and the ability to watch nodes. Guarantees that all writes are serial and ordered (i.e. all clients will see them in the same order), meaning it's more appropriate for low write high read scenarios. Can run in a high available cluster called an ensemble. Originally an Hadoop sub-project, but graduated to a top level Apache project in January 2011. Java based, still under active development, and used by a range of technologies including Hadoop, Mesos, HBase, Kafka and Solr.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;ZooKeeper&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 3.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;https://zookeeper.apache.org/&lt;/a&gt; - homepage &lt;a href=&quot;https://zookeeper.apache.org/doc/current/&quot;&gt;https://zookeeper.apache.org/doc/current/&lt;/a&gt; - current documentation &lt;a href=&quot;https://zookeeper.apache.org/doc/current/zookeeperOver.html&quot;&gt;https://zookeeper.apache.org/doc/current/zookeeperOver.html&lt;/a&gt; - excellent introduction&lt;/p&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://zookeeper.apache.org/releases.html&quot;&gt;https://zookeeper.apache.org/releases.html&lt;/a&gt; - release history&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-zookeeper/</guid> </item> <item><title>Apache Tez</title><link>http://ondataengineering.net/technologies/apache-tez/</link><pubDate>Thu, 09 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data processing framework based on Directed Acyclic Graphs (DAGs), that runs natively on YARN and was designed to be a replacement for the use of MapReduce within Hadoop analytical tools (primarily Hive and Pig), and therefore offer better performance with similar scalability. Targeted more at application developers rather than data engineers, includes a number of performance optimisations (including dynamic DAG re-configuration during execution and re-use of sessions and containers), and comes with a UI for viewing live and historic Tez job executions based on information in the YARN Application Timeline Server. Created by Hortonworks and donated to the Apache Foundation in February 2013 before graduating in July 2014. Still under active development, and now used by Cascading and Flink in addition to Hive and Pig.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Tez&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 0.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://tez.apache.org/&quot;&gt;https://tez.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/&quot;&gt;http://hortonworks.com/blog/apache-tez-a-new-chapter-in-hadoop-data-processing/&lt;/a&gt; - introduction to Tez, and links to further documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/blog/introducing-apache-tez-0-5/&quot;&gt;http://hortonworks.com/blog/introducing-apache-tez-0-5/&lt;/a&gt; - developer documentation introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/HadoopSummit/yahoos-experience-running-pig-on-tez-at-scale&quot;&gt;http://www.slideshare.net/HadoopSummit/yahoos-experience-running-pig-on-tez-at-scale&lt;/a&gt; - case study of Tez at scale&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://tez.apache.org/releases/index.html&quot;&gt;https://tez.apache.org/releases/index.html&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;Other news available via Hortonworks blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-tez/</guid> </item> <item><title>Apache Flink</title><link>http://ondataengineering.net/technologies/apache-flink/</link><pubDate>Wed, 08 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Specialised stream processing technology inspired by the Google Data Flow model. Based on a single record (not micro batch) model, with exactly once processing semantics (for supported sources and sinks) via light weight checkpointing, and focusing on high throughput, low latency use cases. Supports both a Java and Scala API, with a fluent DataStream API for working with continuous data flows (including a flexible windowing API that supports both event time and processing time windows and support for out of order or late data), and a DataSet API for working with batch data sets (that uses the same streaming execution engine). Also supports a number of connectors and extra libraries, including experimental support for SQL expressions, a CEP library (FlinkCEP) that can be used to detect complex event patterns, a beta package for running Storm apps on Flink, a graph processing library (Gelly) and a machine learning library (FlinkML). Clustered, with support for YARN and Mesos as well as standalone clusters. Open sourced by Data Artisans in April 2013, donated to the Apache Foundation in April 2014 before graduating in August 2014. Under active development with a large number of contributors and a range of user case studies. Sold as a hosted managed service (dA Platform) by Data Artisans who also supply training.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Flink&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Data Artisans&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 1.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://flink.apache.org/&quot;&gt;http://flink.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://ci.apache.org/projects/flink/flink-docs-release-1.2&quot;&gt;http://ci.apache.org/projects/flink/flink-docs-release-1.2&lt;/a&gt; - 1.2 release documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/KostasTzoumas/apache-flink-at-strata-san-jose-2016&quot;&gt;http://www.slideshare.net/KostasTzoumas/apache-flink-at-strata-san-jose-2016&lt;/a&gt; - good intro slides, including comparison to other technologies&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://data-artisans.com/&quot;&gt;http://data-artisans.com/&lt;/a&gt; - Data Artisans homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://flink.apache.org/blog/&quot;&gt;https://flink.apache.org/blog/&lt;/a&gt; - flink blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://data-artisans.com/blog/&quot;&gt;http://data-artisans.com/blog/&lt;/a&gt; - Data Artisans blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-flink/</guid> </item> <item><title>Apache Crunch</title><link>http://ondataengineering.net/technologies/apache-crunch/</link><pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;An abstraction layer over MapReduce (and now Spark) that provides a high level Java API for creating data transformation pipelines, originally designed to make working with MapReduce easier based on the Google FlumeJava paper. Also includes connectors for HBase, Hive and Kafka, Java 8 lambda support, an experimental Scala wrapper for the API (Scrunch), and support for in memory pipelines and helper classes to support testing. Open sourced by Cloudera in October 2011, donated to the Apache Foundation in May 2012, before graduating in February 2013. Support for Spark was added as part of v0.10 in June 2014. Still being maintained, and appears to have had been adopted at a number of large companies, but with limited new development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Crunch&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 0.14&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://crunch.apache.org/&quot;&gt;https://crunch.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://crunch.apache.org/user-guide.html&quot;&gt;https://crunch.apache.org/user-guide.html&lt;/a&gt; - user guide&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2011/10/introducing-crunch/&quot;&gt;http://blog.cloudera.com/blog/2011/10/introducing-crunch/&lt;/a&gt; - initial intro blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://crunch.apache.org/user-guide.html#motivation&quot;&gt;https://crunch.apache.org/user-guide.html#motivation&lt;/a&gt; - the motivation behind Crunch&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://crunch.apache.org/scrunch.html&quot;&gt;http://crunch.apache.org/scrunch.html&lt;/a&gt; - Scrunch page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://crunch.apache.org/download.html&quot;&gt;https://crunch.apache.org/download.html&lt;/a&gt; - new releases only appear to be announced on download page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-crunch/</guid> </item> <item><title>Apache Apex</title><link>http://ondataengineering.net/technologies/apache-apex/</link><pubDate>Mon, 06 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data transformation engine based on Directed Acyclic Graph (DAG) flows configured through a Java API or via JSON, with a stated focus on performance, code re-use, testability and ease of operations. Runs over YARN and HDFS with native support for both micro-batch streaming and batch uses cases, and includes a range of standard operators and connectors (called Apex Malhar). An Apache project, graduating in April 2016, having been originally donated in August 2015 by DataTorrent from their DataTorrent RTS product which launched in June 2014. Java based, with development lead by DataTorrent who distribute it as DataTorrent RTS in two editions - a Community Edition (which also includes a basic management GUI and a tool for configuring Apex for data ingestion), and an Enterprise Edition (which further includes a graphical transformation editor, a self service dashboard, security integration and commercial support, and is also available as a cloud offering).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Apex, DataTorrent RTS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, DataTorrent&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v3.5 (Apex Core), v3.6 (Apex Malhar), v3.7 (DataTorrent RTS)&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://apex.apache.org/&quot;&gt;https://apex.apache.org/&lt;/a&gt; - Apex homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://apex.apache.org/docs.html&quot;&gt;https://apex.apache.org/docs.html&lt;/a&gt; -Apex documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datatorrent.com/products-services/datatorrent-rts/&quot;&gt;https://www.datatorrent.com/products-services/datatorrent-rts/&lt;/a&gt; - DataTorrent RTS home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.datatorrent.com/&quot;&gt;http://docs.datatorrent.com/&lt;/a&gt; - DataTorrent documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datatorrent.com/blog/introducing-apache-apex-incubating/&quot;&gt;https://www.datatorrent.com/blog/introducing-apache-apex-incubating/&lt;/a&gt; - introductory blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datatorrent.com/products-services/edition-comparison/&quot;&gt;https://www.datatorrent.com/products-services/edition-comparison/&lt;/a&gt; - DataTorrent editions comparison&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://apex.apache.org/&quot;&gt;https://apex.apache.org/&lt;/a&gt; - release announcements&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datatorrent.com/blog/&quot;&gt;https://www.datatorrent.com/blog/&lt;/a&gt; - DataTorrent blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-apex/</guid> </item> <item><title>The Week That Was - 03/02/2017</title><link>http://ondataengineering.net/blog/2017/02/03/the-week-that-was/</link><pubDate>Fri, 03 Feb 2017 16:50:00 +0000</pubDate> <description> &lt;p&gt;And another week goes by - let’s have a look back over the technologies we’ve looked at this week.&lt;/p&gt; &lt;p&gt;We kicked off the week by looking at &lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, a couple of utilities designed to make working in the Hadoop ecosystem a little easier, before moving on to &lt;a href=&quot;/technologies/apache-phoenix&quot;&gt;Apache Phoenix&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-tajo&quot;&gt;Apache Tajo&lt;/a&gt;. a couple of query engines (also over the Hadoop ecosystem), and then finishing with &lt;a href=&quot;/technologies/apache-mahout&quot;&gt;Apache Mahout&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt; is a solid concept and feels like it fills a bit of a void - how can I easily create Hive tables and load data in from a variety of sources without writing code - however it doesn’t ever seem to have gained much traction, and it looks like even Cloudera aren’t developing and maintaining it any more. It’s also the first non Apache technology we’re looked at on this site! I’m definitely planning to revisit Kite and some of it’s concepts when we talk about Data Lakes in the future however.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt; is actually two things - a set of user defined functions for Pig, and a MapReduce framework for calculating aggregations over regular ingestions of data into Hadoop based on only processing the new data called Hourglass. The first of these sounds well worth a look if you any sort of significant work in Pig. The second I’m less sure about - you’ll have to be using MapReduce, and you’d have to want to follow their pattern, however as a concept or an exemplar it could well be worth a look.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-phoenix&quot;&gt;Apache Phoenix&lt;/a&gt; surprised me - it appears to be an extremely active project, with excellent documentation and a great range of companies that are using it in production, and in providing a SQL query later over HBase, fills an interesting niche within the Hadoop ecosystem. Hive and Impala are great if you have batch updates (and ideally just appends), but they don’t support low latency random updates and queries (along with the full table scans) that HBase (and therefore Phoenix) does. It’s going to be interesting to see how this stacks up against Kudu as this matures and gains adoption, and how the major Hadoop distributions look to support this use case.&lt;/p&gt; &lt;p&gt;I’m not quite sure what to make of &lt;a href=&quot;/technologies/apache-tajo&quot;&gt;Apache Tajo&lt;/a&gt;. It seems like a great technology, with significant commercial backing from Gruter, however I’m not sure it’s getting much traction, and I’m not sure what niche it’s trying to target - it feels uncomfortably close to Hive and Impala. Maybe prior to Hive on Tez/Spark Tajo had some differentiation in terms of low latency queries.&lt;/p&gt; &lt;p&gt;And last (but not least) &lt;a href=&quot;/technologies/apache-mahout&quot;&gt;Apache Mahout&lt;/a&gt;. Mahout has been a staple of most Hadoop distributions for a while (probably as a result of it being one of the first machine learning technologies in the Hadoop space), but what’s interesting is that it completely reinvented itself in April 2015 to become a general purpose distributed linear algebra engine that can run over Spark (with H2O and Flink support coming), and (if running on Spark) is fully compatible with other Spark libraries such as MLlib.&lt;/p&gt; &lt;p&gt;That’s it for this week - have a great weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/02/03/the-week-that-was/</guid> </item> <item><title>Apache Mahout</title><link>http://ondataengineering.net/technologies/apache-mahout/</link><pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Machine learning technology comprising of a Scala based linear algebra engine (codenamed Samsara) with an R-like DSL/API that runs over Spark (with experimental support for H2O and Flink), an optimiser, a wide variety of pre-made algorithms, and a Scala REPL (based on Spark Shell) for interactive execution. Can be embedded and integrated within larger applications, for example MLlib when running over Spark. Also includes some original, now deprecated, algorithms implemented over MapReduce. Created in January 2008 as a Lucene sub-project, becoming a top level Apache project in April 2010. The original MapReduce algorithms were deprecated and Samsara introduced as part of v0.10 in April 2015. Supported by most major Hadoop distributions, and still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Mahout&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - 0.12&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mahout.apache.org/&quot;&gt;https://mahout.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.weatheringthroughtechdays.com/2015/04/mahout-010x-first-mahout-release-as.html&quot;&gt;http://www.weatheringthroughtechdays.com/2015/04/mahout-010x-first-mahout-release-as.html&lt;/a&gt; - introduction to new architecture introduced in v0.10&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mahout.apache.org/general/release-notes.html&quot;&gt;https://mahout.apache.org/general/release-notes.html&lt;/a&gt; - new releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-mahout/</guid> </item> <item><title>Apache Tajo</title><link>http://ondataengineering.net/technologies/apache-tajo/</link><pubDate>Thu, 02 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Distributed analytical database engine. Supports HDFS, Amazon S3, Google Cloud Storage, OpenStack Swift and local storage, and querying over Postgres, HBase and Hive tables. Provides a standard SQL interface, JDBC driver, and supports partitioning, compression and indexing (currently experimental). An Apache project, donated by Gruter in March 2013, and graduated in April 2014. Java based, with development lead by Gruter who also supply commercial support, a Tajo managed service, a data analytics hub (Qrytica) built on Tajo, and a Tajo Data Warehouse appliance.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Tajo&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Gruter&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v0.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://tajo.apache.org/&quot;&gt;http://tajo.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://tajo.apache.org/docs/current/&quot;&gt;http://tajo.apache.org/docs/current/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://gruter.com/technology/tajo/&quot;&gt;http://gruter.com/technology/tajo/&lt;/a&gt; - Gruter product page&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://tajo.apache.org/&quot;&gt;http://tajo.apache.org/&lt;/a&gt; - news and releases&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.gruter.com/blog/&quot;&gt;http://www.gruter.com/blog/&lt;/a&gt; - Gruter blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-tajo/</guid> </item> <item><title>Apache Phoenix</title><link>http://ondataengineering.net/technologies/apache-phoenix/</link><pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A SQL query engine over Apache HBase tables that supports a subset of SQL 92 (including joins), and comes with a JDBC driver. Supports a range of features including ACID transactions (via Apache Tephra), user defined functions, secondary indexes, atomic upserts, views, multi tenancy tables (where each user or tenant can only see their data) and dynamic columns (which are only specified at query time). Supports a range of SQL DDL commands, creating and modifying underlying HBase tables as required, or can run over existing HBase tables in a read only mode. Comes with connectors to allow Spark, Hive, Pig, Flume and MapReduce to read and write Phoenix tables, and a number of utilities, including a bulk loader and a command line SQL tool. Open sourced by SalesForce in January 2013 at v1.0, donated to the Apache foundation in December 2013, before graduating in May 2014. Commercial support available through Hortonworks as part of HDP, with Cloudera making it available via Cloudera Labs without support. Active project with a range of contributors, including many from SalesForce and Hortonworks.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Phoenix&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;February 2017 - v4.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://phoenix.apache.org/&quot;&gt;http://phoenix.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/phoenix/entry/announcing_phoenix_4_9_released&quot;&gt;https://blogs.apache.org/phoenix/entry/announcing_phoenix_4_9_released&lt;/a&gt; - 4.9 announcement (homepage doesn’t appear to have been updated)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/phoenix/entry/apache_phoenix_released_next_major&quot;&gt;https://blogs.apache.org/phoenix/entry/apache_phoenix_released_next_major&lt;/a&gt; - 3.0/4.0 announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.cloudera.com/blog/2015/05/apache-phoenix-joins-cloudera-labs&quot;&gt;https://blog.cloudera.com/blog/2015/05/apache-phoenix-joins-cloudera-labs&lt;/a&gt; - Cloudera labs announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://phoenix-hbase.blogspot.co.uk/&quot;&gt;http://phoenix-hbase.blogspot.co.uk/&lt;/a&gt; - original blog, now superseded by the Apache blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/phoenix/&quot;&gt;https://blogs.apache.org/phoenix/&lt;/a&gt; - project blog including release announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-phoenix/</guid> </item> <item><title>DataFu Pig</title><link>http://ondataengineering.net/technologies/apache-datafu/datafu-pig/</link><pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A set of user defined functions for Apache Pig, including support for statistical calculations, bag and set operations, sessionisation of streams of data, cardinality estimation, sampling, hashing, PageRank and others.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Uses&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org/docs/datafu/getting-started.html&quot;&gt;https://datafu.incubator.apache.org/docs/datafu/getting-started.html&lt;/a&gt; - homepage (see linked blog posts for further information and examples)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org/docs/datafu/guide.html&quot;&gt;https://datafu.incubator.apache.org/docs/datafu/guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-datafu/datafu-pig/</guid> </item> <item><title>DataFu Hourglass</title><link>http://ondataengineering.net/technologies/apache-datafu/datafu-hourglass/</link><pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A framework over MapReduce that supports the efficient generation of statistics of dated data by incrementally updating the previous days output. Supports both fixed length and fixed start point windows, and the generation of statistics by input partition or as a total over all input data.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org/docs/hourglass/getting-started.html&quot;&gt;https://datafu.incubator.apache.org/docs/hourglass/getting-started.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org/blog/2013/10/03/datafus-hourglass-incremental-data-processing-in-hadoop.html&quot;&gt;https://datafu.incubator.apache.org/blog/2013/10/03/datafus-hourglass-incremental-data-processing-in-hadoop.html&lt;/a&gt; - introduction (contains examples and information not available in the documentation)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://datafu.incubator.apache.org/docs/hourglass/1.3.1/&quot;&gt;http://datafu.incubator.apache.org/docs/hourglass/1.3.1/&lt;/a&gt; - Javadoc (note link from &lt;a href=&quot;https://datafu.incubator.apache.org/docs/hourglass/javadoc.html&quot;&gt;here&lt;/a&gt; is wrong)&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-datafu/datafu-hourglass/</guid> </item> <item><title>Apache DataFu</title><link>http://ondataengineering.net/technologies/apache-datafu/</link><pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A set of libraries for working with data in Hadoop. Consists of two sub-projects - DataFu Pig (a set of Pig User Defined Functions) and DataFu Hourglass (a framework for incremental processing using MapReduce). Originally created at LinkedIn, with the Pig UDFs being open sourced in January 2012 as DataFu, with a v1.0 release in September 2013. Split into sub-projects in October 2013 when LinkedIn open sourced DataFu Hourglass and added it to the project. Donated to the Apache Foundation in January 2014, however is still incubating and has not yet graduated. Last release was v1.3 in November 2015 (albeit with a very minor v1.3.1 release in August 2016), with little development activity since this time.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;DataFu&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache DataFu&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-datafu/datafu-hourglass/&quot;&gt;DataFu Hourglass&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A framework over MapReduce that supports the efficient generation of statistics of dated data by incrementally updating the previous days output. Supports both fixed length and fixed start point windows, and the generation of statistics by input partition or as a total over all input data.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Apache DataFu&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-datafu/datafu-pig/&quot;&gt;DataFu Pig&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A set of user defined functions for Apache Pig, including support for statistical calculations, bag and set operations, sessionisation of streams of data, cardinality estimation, sampling, hashing, PageRank and others.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org&quot;&gt;https://datafu.incubator.apache.org&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://datafu.incubator.apache.org/blog/&quot;&gt;https://datafu.incubator.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-datafu/</guid> </item> <item><title>Morphlines</title><link>http://ondataengineering.net/technologies/kite/morphlines/</link><pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A configuration driven in-memory transformation pipeline that can be embedded into any Java code base, with specific support for Flume, MapReduce, HBase, Spark and Solr. Supports multiple different file types including CSV, Avro, JSON, Parquet, RCFile, SequenceFile, ProtoBuf and XML plus gzip, bzip2, tar zip and jar files. Also supports a number of transformation steps out of the box, including integration with Apache Tika for reading common file formats.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kitesdk.org/docs/current/morphlines/&quot;&gt;http://kitesdk.org/docs/current/morphlines/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kitesdk.org/docs/current/morphlines/morphlines-reference-guide.html&quot;&gt;http://kitesdk.org/docs/current/morphlines/morphlines-reference-guide.html&lt;/a&gt; - reference guide&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2013/07/morphlines-the-easy-way-to-build-and-integrate-etl-apps-for-apache-hadoop/&quot;&gt;http://blog.cloudera.com/blog/2013/07/morphlines-the-easy-way-to-build-and-integrate-etl-apps-for-apache-hadoop/&lt;/a&gt; - intro&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/kite/morphlines/</guid> </item> <item><title>Kite Maven Plugin</title><link>http://ondataengineering.net/technologies/kite/kite-maven-plugin/</link><pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A Maven plugin that supports the packaging, deployment and execution of applications onto Hadoop.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kitesdk.org/docs/current/maven/plugin-info.html&quot;&gt;http://kitesdk.org/docs/current/maven/plugin-info.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/kite/kite-maven-plugin/</guid> </item> <item><title>Kite Data</title><link>http://ondataengineering.net/technologies/kite/kite-data/</link><pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Library that provides a logical dataset and record abstraction over HDFS, S3, local filesystems and HBase, including support for partitioning and views (which allow datasets to be filtered and supports automatic partition pruning). Provides a command line interface and Maven plugin for managing and viewing datasets. Supports Crunch, Flume, Spark and MapReduce, and can integrate with a Hive Metastore to make datasets available through Hive and Impala. Stores data using Avro (utilising Avro schema evolution / resolution) or Parquet.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kitesdk.org/docs/current/Kite-SDK-Guide.html&quot;&gt;http://kitesdk.org/docs/current/Kite-SDK-Guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/kite/kite-data/</guid> </item> <item><title>Kite</title><link>http://ondataengineering.net/technologies/kite/</link><pubDate>Mon, 30 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A set of libraries, tools, examples, and documentation focused on making it easier to build systems on top of the Hadoop ecosystem. Consists of three sub-projects - Kite Data (a logical dataset abstraction over Hadoop), Morphlines (embeddable configuration driven transformation pipelines) and Kite Maven Plugin (a Maven plugin for deploying Hadoop applications). Java based, Open Source under the Apache 2.0 licence and hosted on GitHub. First released in May 2013 by Cloudera as the Cloudera Development Kit (CDK), renamed to Kite in December 2013, and reached a v1.0 release in February 2015 with a number of external contributors. Last release was v1.1 in June 2015, with very little development activity since this time.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Cloudera Development Kit, CDK&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Cloudera&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Kite&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/kite/kite-data/&quot;&gt;Kite Data&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Library that provides a logical dataset and record abstraction over HDFS, S3, local filesystems and HBase, including support for partitioning and views (which allow datasets to be filtered and supports automatic partition pruning). Provides a command line interface and Maven plugin for managing and viewing datasets. Supports Crunch, Flume, Spark and MapReduce, and can integrate with a Hive Metastore to make datasets available through Hive and Impala. Stores data using Avro (utilising Avro schema evolution / resolution) or Parquet.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Kite&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/kite/kite-maven-plugin/&quot;&gt;Kite Maven Plugin&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A Maven plugin that supports the packaging, deployment and execution of applications onto Hadoop.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Kite&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/kite/morphlines/&quot;&gt;Morphlines&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A configuration driven in-memory transformation pipeline that can be embedded into any Java code base, with specific support for Flume, MapReduce, HBase, Spark and Solr. Supports multiple different file types including CSV, Avro, JSON, Parquet, RCFile, SequenceFile, ProtoBuf and XML plus gzip, bzip2, tar zip and jar files. Also supports a number of transformation steps out of the box, including integration with Apache Tika for reading common file formats.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kitesdk.org/docs/current/&quot;&gt;http://kitesdk.org/docs/current/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/kite-sdk/kite&quot;&gt;https://github.com/kite-sdk/kite&lt;/a&gt; - source code&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Any updates to Kite are likely to be published on the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/kite/</guid> </item> <item><title>Alluxio</title><link>http://ondataengineering.net/technologies/alluxio/</link><pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A distributed virtual storage layer, supporting key-value and filesystem interfaces (including HDFS compatibility and a FUSE driver) with support for a range of computation and storage frameworks (including Spark, MapReduce, HBase and Hive) over multiple storage layers (including in-memory, local, network, cloud and cluster file systems) with the ability to create unified and tiered storage, for example to create an in memory filesystem backed by disk to accelerate analytics jobs. Supports a POSIX like access control model, and a CLI and web interface for browsing the storage layer. Java based, Open Source under the Apache 2.0 licence, hosted on GitHub, with development led by Alluxio (with significant external contributions), although they don't appear to yet provide commercial support (but do provide training). Started in December 2012, open sourced in April 2013, with a v1.0 release in February 2016. Formally known as Tachyon.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Alluxio, Tachyon&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Alluxio&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://alluxio.org/&quot;&gt;http://alluxio.org/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/Alluxio/alluxio&quot;&gt;https://github.com/Alluxio/alluxio&lt;/a&gt; - source code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.alluxio.org/docs/master/en/&quot;&gt;http://www.alluxio.org/docs/master/en/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.alluxio.com/2016/02/alluxio-formerly-tachyon-is-entering-a-new-era-with-1-0-release/&quot;&gt;http://www.alluxio.com/2016/02/alluxio-formerly-tachyon-is-entering-a-new-era-with-1-0-release/&lt;/a&gt; - history&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.alluxio.com/blog&quot;&gt;https://www.alluxio.com/blog&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.alluxio.org/download&quot;&gt;http://www.alluxio.org/download&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/alluxio/</guid> </item> <item><title>The Week That Was - 27/01/2017</title><link>http://ondataengineering.net/blog/2017/01/27/the-week-that-was/</link><pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;So rather than waiting until we’ve finished looking at all the technologies included in Apache Bigtop before talking about them, let’s try wrapping up each week with a blog post summarising what we’ve looked at, and maybe at some point summarising some of the news of the week. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So what have we looked at this week?&lt;/p&gt; &lt;p&gt;Firstly, a couple of graph computation frameworks - &lt;a href=&quot;/technologies/apache-hama/&quot;&gt;Apache Hama&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-giraph&quot;&gt;Apache Giraph&lt;/a&gt;. Along with &lt;a href=&quot;/technologies/apache-spark/graphx/&quot;&gt;Spark GraphX&lt;/a&gt;, these are probably the big three graph computation frameworks on Hadoop. What’s interesting is that both GraphX and Hama seem to have seen very little development recently - either meaning they’re done and meet most people’s use cases, or there just isn’t the demand for them. Giraph still seems to be going strong, however this is mainly being used at extreme scale by Facebook and LinkedIn. My guess is that graph technologies (both computation frameworks and graph databases) are being pushed as hot technologies at the moment, however most organisations aren’t quite sure what to do with them.&lt;/p&gt; &lt;p&gt;We’re also looked at a couple of Hadoop in-memory storage accelerators - &lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Apache Ignite&lt;/a&gt; and &lt;a href=&quot;/technologies/alluxio&quot;&gt;Alluxio&lt;/a&gt; (formally known as Tachyon). These are both interesting, promising performance boosts for Hadoop computation jobs by providing an in memory HDFS compatible filesystem, as well a bunch of other features - both support an in memory key-value store, Alluxio supports tiered storage over multiple storage layers (in-memory, local and remote disk), and Ignite provides a more general purpose compute layer that supports streaming computation and arbitrary compute. If you’ve used either of these and can talk to their benefits I’d be very interested to chat in the forums.&lt;/p&gt; &lt;p&gt;And we started the week by talking about &lt;a href=&quot;/technologies/apache-bigtop&quot;&gt;Apache Bigtop&lt;/a&gt;, which I’ve already &lt;a href=&quot;/blog/2017/01/23/hadoop-distros-apache-bigtop/&quot;&gt;talked about&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Finally - you’ll now see that we’re proudly displaying our options for &lt;a href=&quot;/site/subscribe/&quot;&gt;subscribing&lt;/a&gt; to our content on the front page. Pick your poison - we support e-mail (daily and weekly), Twitter updates plus RSS and Atom feeds.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/01/27/the-week-that-was/</guid> </item> <item><title>Apache Hama</title><link>http://ondataengineering.net/technologies/apache-hama/</link><pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A general purpose BSP (Bulk Synchronous Parallel) processing engine inspired by Pregel and DistBelief that runs over Mesos or YARN. Supports BSP, graph computing and machine learning programming models, as well as Apache MRQL. An Apache project, donated in 2008, and graduated in 2012. Java based, with no commercial support available, limited case studies for it's use and limited active developers, with the last release being in June 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Hama&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Quiet&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://hama.apache.org/&quot;&gt;http://hama.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://wiki.apache.org/hama/&quot;&gt;https://wiki.apache.org/hama/&lt;/a&gt; - Wiki / documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://wiki.apache.org/incubator/HamaProposal&quot;&gt;https://wiki.apache.org/incubator/HamaProposal&lt;/a&gt; - details of Apache incubation proposal&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/hama/&quot;&gt;https://blogs.apache.org/hama/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-hama/</guid> </item> <item><title>Apache Giraph</title><link>http://ondataengineering.net/technologies/apache-giraph/</link><pubDate>Wed, 25 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;An iterative, highly scalable graph processing system built on top of MapReduce and based on Pregel, with a number of features added including a framework for creating re-usable code (called blocks). An Apache project, graduating in May 2012, having been originally donated by Yahoo in August 2011. Java based, no commercial support available, but is mature and has been adopted by a number of companies (including LinkedIn and most famously Facebook who scaled it to process a trillion edges), and has a number of active developers.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Giraph&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://giraph.apache.org/&quot;&gt;http://giraph.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://giraph.apache.org/intro.html&quot;&gt;http://giraph.apache.org/intro.html&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://engineering.linkedin.com/open-source/apache-giraph-framework-large-scale-graph-processing-hadoop-reaches-01-milestone&quot;&gt;https://engineering.linkedin.com/open-source/apache-giraph-framework-large-scale-graph-processing-hadoop-reaches-01-milestone&lt;/a&gt; - v0.1 release announcement from LinkedIn&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920/&quot;&gt;https://www.facebook.com/notes/facebook-engineering/scaling-apache-giraph-to-a-trillion-edges/10151617006153920/&lt;/a&gt; - Facebook’s story on scaling Giraph to a trillion edges&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://giraph.apache.org/&quot;&gt;http://giraph.apache.org/&lt;/a&gt; - news via homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/giraph&quot;&gt;https://blogs.apache.org/giraph&lt;/a&gt; - blog, with first entry being v1.2 announcement&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-giraph/</guid> </item> <item><title>Apache Ignite</title><link>http://ondataengineering.net/technologies/apache-ignite/</link><pubDate>Tue, 24 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A distributed in-memory data fabric/grid, supporting a number of use cases including a key value store (with SQL support), real time stream/event processing engine, arbitrary compute, long running service management, an in-memory HDFS compatible file system for acceleration of Hadoop jobs, and in-memory shared Spark RDDs. An Apache project, graduating in September 2015, having been originally donated by GridGain from their In-Memory Data Fabric product launched in 2007. Java based, with development lead by GridGain who also supply commercial support (as GridGain Professional with ongoing Q&amp;A and bug fixes before they're included in Ignite) along with GridGain Enterprise (which includes extra features such as a management GUI, enterprise security and rolling upgrades).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Ignite, GridGain&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, GridGain&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.8.0 (Ignite), v7.7 (GridGain)&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://ignite.apache.org/&quot;&gt;https://ignite.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.gridgain.com/&quot;&gt;http://www.gridgain.com/&lt;/a&gt; - Grid Gain home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.gridgain.com/products/pricing/&quot;&gt;http://www.gridgain.com/products/pricing/&lt;/a&gt; - details of GridGain editions&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://apacheignite.readme.io/docs&quot;&gt;https://apacheignite.readme.io/docs&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/apache-ignite&quot;&gt;https://www.infoq.com/presentations/apache-ignite&lt;/a&gt; - intro presentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://ignite.apache.org/blogs.html&quot;&gt;https://ignite.apache.org/blogs.html&lt;/a&gt; - Ingite blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.gridgain.com/resources/blog&quot;&gt;https://www.gridgain.com/resources/blog&lt;/a&gt; - GridGain blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-ignite/</guid> </item> <item><title>Hadoop Distros: Apache Bigtop</title><link>http://ondataengineering.net/blog/2017/01/23/hadoop-distros-apache-bigtop/</link><pubDate>Mon, 23 Jan 2017 18:00:00 +0000</pubDate> <description> &lt;p&gt;And so to our first (hopefully of many) daily technology summary.&lt;/p&gt; &lt;p&gt;I want to continue our wander through the Apache Hadoop ecosystem by looking at the common Hadoop Distributions, starting with &lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, and with this introducing our first technology category - the &lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distribution&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Apache Bigtop is interesting for a couple of reasons - firstly because it’s the only true open source Hadoop distribution (meaning that it includes many components that the commercial distributions don’t, and the components it includes are often more up to date, assuming you’re happy to use the latest snapshot builds), and secondly because of it’s history as Cloudera’s attempt to create a common base Hadoop distribution with all the associated integration testing and packaging (there are links in the &lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Bigtop page&lt;/a&gt; that provide further reading on this).&lt;/p&gt; &lt;p&gt;You’ll see that the &lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Bigtop page&lt;/a&gt; links to the Hadoop technologies we’re already covered that it packages (and vice-versa), and the aim is that over the coming days we’ll complete this list as we add technology summaries for the rest of the technologies it packages.&lt;/p&gt; &lt;p&gt;And I shouldn’t let our first technology category go uncommented - as we’re going to be looking at the common Hadoop Distributions we’ll start collecting these together under an &lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distribution&lt;/a&gt; page and try and round these out over the coming weeks.&lt;/p&gt; &lt;p&gt;That’s it for now - we’ll speak again when we’ve worked our way through the remaining technologies bundled with Apache Bigtop.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/01/23/hadoop-distros-apache-bigtop/</guid> </item> <item><title>Apache Bigtop</title><link>http://ondataengineering.net/technologies/apache-bigtop/</link><pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;An Apache open source distribution of Hadoop. Packages up a number of Apache Hadoop components, certifies their interoperability using an automated integration test suite, and packages them up as RPMs/DEBs packages for most flavours of Linux. Also includes virtual machine images and vagrant, docker and puppet recipes for deploying and working with Hadoop. Does not patch projects for distribution, but requires any fixes to be made upstream. An Apache Open Source project, started by Cloudera, donated to the Apache foundation in June 2011, graduating in September 2012, with a 1.0 release in August 2015 based on Hadoop 2.6. Since donating the project, Cloudera have backed away from it, with the project lead moving to Pivotal in December 2013. Now has a broad range of contributors, however usage by the major distributors is not clear.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Bigtop&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/alluxio/&quot;&gt;Alluxio&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-giraph/&quot;&gt;Apache Giraph&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hama/&quot;&gt;Apache Hama&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tajo/&quot;&gt;Apache Tajo&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Apache Zeppelin&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;, &lt;a href=&quot;/technologies/quantcast-file-system/&quot;&gt;Quantcast File System&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;1.2.0&lt;/td&gt; &lt;td&gt;pending&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;to date has added Flink, Tajo, Apex, QFS and GPDB&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.1.0&lt;/td&gt; &lt;td&gt;17th Feb 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/release_1_1_0_is&quot;&gt;https://blogs.apache.org/bigtop/entry/release_1_1_0_is&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0.0&lt;/td&gt; &lt;td&gt;17th Aug 2015&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/not_just_yet_another_release&quot;&gt;https://blogs.apache.org/bigtop/entry/not_just_yet_another_release&lt;/a&gt;&lt;/td&gt; &lt;td&gt;based on Hadoop 2.6&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.8.0&lt;/td&gt; &lt;td&gt;6th Oct 2014&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/release_of_apache_bigtop_01&quot;&gt;https://blogs.apache.org/bigtop/entry/release_of_apache_bigtop_01&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.7.0&lt;/td&gt; &lt;td&gt;6th Nov 2013&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/release_of_apache_bigtop_0&quot;&gt;https://blogs.apache.org/bigtop/entry/release_of_apache_bigtop_0&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.6.0&lt;/td&gt; &lt;td&gt;22nd June 2013&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/apache_bigtop_0_6_0&quot;&gt;https://blogs.apache.org/bigtop/entry/apache_bigtop_0_6_0&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.5.0&lt;/td&gt; &lt;td&gt;27th Dec 2012&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/apache_bigtop_0_5_0&quot;&gt;https://blogs.apache.org/bigtop/entry/apache_bigtop_0_5_0&lt;/a&gt;&lt;/td&gt; &lt;td&gt;first release as TLP&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://bigtop.apache.org&quot;&gt;http://bigtop.apache.org&lt;/a&gt; - Homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/BIGTOP/Index&quot;&gt;https://cwiki.apache.org/confluence/display/BIGTOP/Index&lt;/a&gt; - The Apache Bigtop Wiki&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/apache/bigtop/blob/master/bigtop.bom&quot;&gt;https://github.com/apache/bigtop/blob/master/bigtop.bom&lt;/a&gt; - details of all included packages and their versions (as of current development snapshot)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2012/07/update-on-apache-bigtop-incubating/&quot;&gt;http://blog.cloudera.com/blog/2012/07/update-on-apache-bigtop-incubating/&lt;/a&gt; - Cloudera introduction to Bigtop&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/entry/bigtop_and_why_should_you&quot;&gt;https://blogs.apache.org/bigtop/entry/bigtop_and_why_should_you&lt;/a&gt; - Early introduction to Bigtop&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.pivotal.io/pivotal/pivotal-people/pivotal-people-roman-shaposhnik-founder-of-apache-bigtop-joins-pivotal&quot;&gt;https://blog.pivotal.io/pivotal/pivotal-people/pivotal-people-roman-shaposhnik-founder-of-apache-bigtop-joins-pivotal&lt;/a&gt; - Interview with Roman Shoposhnik on the aims of Bigtop&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/BIGTOP/?selectedTab=com.atlassian.jira.jira-projects-plugin:versions-panel&quot;&gt;https://issues.apache.org/jira/browse/BIGTOP/?selectedTab=com.atlassian.jira.jira-projects-plugin:versions-panel&lt;/a&gt; - Release list and link to release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/bigtop/&quot;&gt;https://blogs.apache.org/bigtop/&lt;/a&gt; - The Apache Bigtop Blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://bigtop.apache.org/&quot;&gt;http://bigtop.apache.org/&lt;/a&gt; - details of latest release&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-bigtop/</guid> </item> <item><title>Hadoop Distributions</title><link>http://ondataengineering.net/tech-categories/hadoop_distributions/</link><pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Projects that bundle together specific versions of multiple components around the Hadoop ecosystem, certify that these work together, and deliver packages and other installation mechanisms for installing and managing these.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt; &lt;/td&gt; &lt;td&gt;An Apache open source distribution of Hadoop. Packages up a number of Apache Hadoop components, certifies their interoperability using an automated integration test suite, and packages them up as RPMs/DEBs packages for most flavours of Linux. Also includes virtual machine images and vagrant, docker and puppet recipes for deploying and working with Hadoop. Does not patch projects for distribution, but requires any fixes to be made upstream. An Apache Open Source project, started by Cloudera, donated to the Apache foundation in June 2011, graduating in September 2012, with a 1.0 release in August 2015 based on Hadoop 2.6. Since donating the project, Cloudera have backed away from it, with the project lead moving to Pivotal in December 2013. Now has a broad range of contributors, however usage by the major distributors is not clear.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A distribution of Hadoop based on a commitment to the Apache open source ecosystem. All bundled projects are Apache open source projects based on official Apache project releases, with any patches for bug fixes or new features official Apache project patches pulled from later releases of the project. Available as RPMs or can be installed using Apache Ambari (for local installs) or Cloudbreak (for installation on cloud platforms). Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Spark SQL, HDP Search and Hortonworks HDB. Provided free of charge, with training, consultancy and support available from Hortonworks, along with their proprietary SmartSense support tool. First released in June 2012.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Tech Vendor metadata --&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop_distributions/</guid> </item> <item><title>The Daily Technology Summary</title><link>http://ondataengineering.net/blog/2017/01/23/the-daily-technology-summary/</link><pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Up until today, I’ve been publishing new technology summaries in bulk every Friday. However I want to change up the pace a little, and so going forward I’m going to try to publish a new technology summary every week day.&lt;/p&gt; &lt;!--more--&gt; &lt;p&gt;Blog posts will be less frequent, and will usually be used to introduce and conclude a specific set of technologies we’re looking it. Because of this, you’ll notice that the site home page now supports a snazzy new summary of recent changes to content on the right hand side next to the summary of recent blog posts. In addition, the RSS and Atom feeds now include content updates as well as blog posts.&lt;/p&gt; &lt;p&gt;Also, in the coming days there will be new options to get the daily technology summary (and blog posts) delivered to your inbox via e-mail, and we’ll also start publishing these on Twitter (@OnDataEng) as well - just as soon as it’s all setup.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/01/23/the-daily-technology-summary/</guid> </item> <item><title>Apache Pig</title><link>http://ondataengineering.net/technologies/apache-pig/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Technology for running analytical and data processing jobs against data in Hadoop. Jobs are written in Pig Latin (a custom procedural language that can be extended using user defined functions in a range of languages), which is then translated into Map Reduce or Tez (with Spark in development) for execution. Supports both a batch mode for running pre-defined scripts and an interactive mode, and connectors for reading and writing to HBase and Accumulo as well as HDFS. Originally developed at Yahoo in 2006 before being donated to the Apache Foundation in October 2007. Graduated as an Hadoop sub-project in October 2008, before becoming a top level project in September 2010. Although has not had a v1.0 release, has been production quality for many years. Commercial support available as part of most Hadoop distributions&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Pig&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v0.16&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is used by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-datafu/datafu-pig/&quot;&gt;DataFu Pig&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://pig.apache.org/&quot;&gt;https://pig.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://pig.apache.org/releases.html&quot;&gt;https://pig.apache.org/releases.html&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://hortonworks.com/blog/announcing-apache-pig-0-14-0/&quot;&gt;http://hortonworks.com/blog/announcing-apache-pig-0-14-0/&lt;/a&gt; - Pig on Tez release announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2014/09/pig-is-flying-apache-pig-on-apache-spark/&quot;&gt;http://blog.cloudera.com/blog/2014/09/pig-is-flying-apache-pig-on-apache-spark/&lt;/a&gt; - first details of Pig on Spark&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://pig.apache.org/&quot;&gt;https://pig.apache.org/&lt;/a&gt; - news and updates&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-pig/</guid> </item> <item><title>Apache Parquet</title><link>http://ondataengineering.net/technologies/apache-parquet/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data serialisation framework that supports a columnar storage format to enable efficient querying of data. Built using Apache Thrift, and supports complex nested data structures, using techniques from the Google Dremel paper. Consists of three sub-projects, the specification and Thrift definitions (Parquet Format), the Java and Hadoop libraries (Parquet MR) and the C++ implementation (Parquet CPP). Created as a joint effort between Twitter and Cloudera based on work started as part of Avro Trevni, with an initial v1.0 release in July 2013. Donated to the Apache Foundation in May 2014, graduating in April 2015. Has seen significant adoption in the Hadoop ecosystem.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Avro&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://parquet.apache.org/&quot;&gt;http://parquet.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://parquet.apache.org/documentation/latest/&quot;&gt;http://parquet.apache.org/documentation/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2013/03/introducing-parquet-columnar-storage-for-apache-hadoop/&quot;&gt;http://blog.cloudera.com/blog/2013/03/introducing-parquet-columnar-storage-for-apache-hadoop/&lt;/a&gt; - initial announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/2013/dremel-made-simple-with-parquet&quot;&gt;https://blog.twitter.com/2013/dremel-made-simple-with-parquet&lt;/a&gt; - good introduction to Parquet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.twitter.com/2013/announcing-parquet-10-columnar-storage-for-hadoop&quot;&gt;https://blog.twitter.com/2013/announcing-parquet-10-columnar-storage-for-hadoop&lt;/a&gt; - 1.0 release announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces75&quot;&gt;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces75&lt;/a&gt; - top level project announcement, including summary of technology that support it&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/apache/parquet-mr/blob/master/CHANGES.md&quot;&gt;https://github.com/apache/parquet-mr/blob/master/CHANGES.md&lt;/a&gt; - release and change summary&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-parquet/</guid> </item> <item><title>Apache Oozie</title><link>http://ondataengineering.net/technologies/apache-oozie/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Technology for managing workflows of jobs on Hadoop clusters. Primary concepts include workflows (a sequence of jobs modelled as a directed acyclic graph), coordinators (schedule the execution of workflows based on the time or the presence of data) and bundles (collections of coordinators), with all configuration specified in XML. Supports a range of technologies, including MapReduce, Pig, Hive, Sqoop, Spark, Java executables and shell scripts. Includes a server component, a metadata database for holding definitions and state (with support for a range of database technologies), a command line interface and a read only web interface for viewing the status of jobs. Also supports the parameterisation of workflows, the modelling of datasets (and the use of these to manage dependencies between workflows within coordinators), automatic retry and failure handling, and the ability to send job status notifications via HTTP or JMS. Open sourced by Yahoo in June 2010. Donated to the Apache Foundation in July 2011, graduating in August 2012. Commercial support available as part of most Hadoop distributions&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Oozie&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v4.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://oozie.apache.org/&quot;&gt;http://oozie.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://oozie.apache.org/docs/4.3.0/index.html&quot;&gt;http://oozie.apache.org/docs/4.3.0/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://jaxenter.com/yahoos-hadoop-based-project-proposed-for-apache-incubator-103651.html&quot;&gt;https://jaxenter.com/yahoos-hadoop-based-project-proposed-for-apache-incubator-103651.html&lt;/a&gt; - intro interview&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Oozie release announcements only appear to be available via the Apache announcements mailing list&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-oozie/</guid> </item> <item><title>Kafka Streams</title><link>http://ondataengineering.net/technologies/apache-kafka/kafka-streams/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Technology that allows stream processing to be added to a Kafka cluster, consuming and publishing events from and to Kafka topics (and potentially writing output to external systems). Based on an event-at-a-time model (i.e. not micro batch), with support for stateful processing, windowing, joining and re-processing data. Supports a low level DSL API, as well as a high level API that provides both stream and table abstractions (where tables present the latest record for each key). Introduced in Kafka 0.10.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/documentation/streams&quot;&gt;http://kafka.apache.org/documentation/streams&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/kafka-streams/&quot;&gt;https://www.confluent.io/product/kafka-streams/&lt;/a&gt; - Confluent information page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/&quot;&gt;https://www.confluent.io/blog/introducing-kafka-streams-stream-processing-made-simple/&lt;/a&gt; - introduction blog post&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kafka/kafka-streams/</guid> </item> <item><title>Kafka Connect</title><link>http://ondataengineering.net/technologies/apache-kafka/kafka-connect/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for building scalable and reliable integrations between Kafka and other technologies, either for importing or exporting data. Part of the core Apache Kafka open source technology, connectors are available for a wide range of systems, including Hadoop, relational, NoSQL and analytical databases, search technologies and message queues amongst others. Runs separately to Kafka, in either a stand-alone or distributed cluster mode, with a REST API for managing connectors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/documentation/#connect&quot;&gt;http://kafka.apache.org/documentation/#connect&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/connectors/&quot;&gt;https://www.confluent.io/product/connectors/&lt;/a&gt; - Confluent information, including list of available connectors&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/how-to-build-a-scalable-etl-pipeline-with-kafka-connect/&quot;&gt;https://www.confluent.io/blog/how-to-build-a-scalable-etl-pipeline-with-kafka-connect/&lt;/a&gt; - introduction blog post&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kafka/kafka-connect/</guid> </item> <item><title>Apache Kafka</title><link>http://ondataengineering.net/technologies/apache-kafka/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Technology for buffering and storing real-time streams of data between publishers to subscribers, with a focus on high throughput at low latency. Based on a distributed, horizontally scalable architecture, with messages organised into topics which are partitioned and replicated across nodes to provide resilience and written to disk to provide persistence. Topics may have multiple publishers and subscribers, with ability to do fault tolerant reads and to load balance across subscribers. Records consist of a key, value and timestamp, with the ability to compact topics to remove updates and deletes by key. Supports a full security model, and the ability to set quotas. Comes with a Java client, but clients for a wide range of languages are also available. Has two sub-projects (Kafka Connect and Kafka Streams) that are bundled with the main product. Originally developed at LinkedIn, being open sourced in January 2011, before being donated to the Apache Foundation in July 2011. Graduated in October 2012, and although it has not had a v1.0 release is considered production quality and stable. Development is primarily led by Confluent (which was founded by the team that built Kafka at LinkedIn), who distribute a Confluent Open Source product (which includes further clients and connectors) and a subscription based Confluent Enterprise product (which includes management, replication and data balancing features and commercial support under a subscription licence). Commercial support is also available from most Hadoop vendors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kafka, Confluent&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Confluent&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v0.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache Kafka&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-kafka/kafka-connect/&quot;&gt;Kafka Connect&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Framework for building scalable and reliable integrations between Kafka and other technologies, either for importing or exporting data. Part of the core Apache Kafka open source technology, connectors are available for a wide range of systems, including Hadoop, relational, NoSQL and analytical databases, search technologies and message queues amongst others. Runs separately to Kafka, in either a stand-alone or distributed cluster mode, with a REST API for managing connectors.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Apache Kafka&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-kafka/kafka-streams/&quot;&gt;Kafka Streams&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Technology that allows stream processing to be added to a Kafka cluster, consuming and publishing events from and to Kafka topics (and potentially writing output to external systems). Based on an event-at-a-time model (i.e. not micro batch), with support for stateful processing, windowing, joining and re-processing data. Supports a low level DSL API, as well as a high level API that provides both stream and table abstractions (where tables present the latest record for each key). Introduced in Kafka 0.10.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org&quot;&gt;http://kafka.apache.org&lt;/a&gt; - project home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/intro&quot;&gt;http://kafka.apache.org/intro&lt;/a&gt; - great introduction to Kafka&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.linkedin.com/2011/01/11/open-source-linkedin-kafka&quot;&gt;https://blog.linkedin.com/2011/01/11/open-source-linkedin-kafka&lt;/a&gt; - open source announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Clients&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Clients&lt;/a&gt; - list of clients&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem&quot;&gt;https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem&lt;/a&gt; - associated technologies&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/&quot;&gt;https://www.confluent.io/product/&lt;/a&gt; - Confluent product homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/downloads&quot;&gt;http://kafka.apache.org/downloads&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/&quot;&gt;https://www.confluent.io/blog/&lt;/a&gt; - Confluent blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kafka/</guid> </item> <item><title>Apache Avro</title><link>http://ondataengineering.net/technologies/apache-avro/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Data serialisation framework that supports both messaging and data storage. Primarily uses a compact binary format but also supports a JSON format. Supports a range of data structures (including records, enumerations, arrays and maps) with APIs for a wide range of both static and dynamically typed languages. Schema based, with schemas primarily specified in JSON, and support for both code generation from schema definitions as well as dynamic runtime usage. Schemas are serialised alongside data, with support for automatic schema resolution if the schema used to read the data differs from that used to write it. Started as an Hadoop sub-project by Cloudera in April 2009, with an initial v1.0 release in July 2009, before becoming a top level Apache project in May 2010. Has seen significant adoption in the Hadoop ecosystem.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Avro&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://avro.apache.org/&quot;&gt;http://avro.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://avro.apache.org/docs/current/&quot;&gt;https://avro.apache.org/docs/current/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2009/11/avro-a-new-format-for-data-interchange/&quot;&gt;http://blog.cloudera.com/blog/2009/11/avro-a-new-format-for-data-interchange/&lt;/a&gt; - original introduction to Avro&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces4&quot;&gt;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces4&lt;/a&gt; - Avro top level project announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://avro.apache.org/releases.html&quot;&gt;http://avro.apache.org/releases.html&lt;/a&gt; - project releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-avro/</guid> </item> <item><title>Core Hadoop Technologies (pt3)</title><link>http://ondataengineering.net/blog/2017/01/20/core-hadoop-technologies-pt3/</link><pubDate>Fri, 20 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Up today, our final look at the core technologies within the Hadoop ecosystem. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;First up are &lt;a href=&quot;/technologies/apache-avro&quot;&gt;Avro&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-parquet&quot;&gt;Parquet&lt;/a&gt;, both of which are key data formats used within the Hadoop ecosystem, but with different and contrasting focuses.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt;’s a hot technology at the moment - deliverying high bandwidth low latency storage and processing of data streams, with reference cases handling millions of events per second. If you’re looking at doing anything with streaming data it’s probably well worth a look. Note that I’ve broken out &lt;a href=&quot;/technologies/apache-kafka/kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-kafka/kafka-streams&quot;&gt;Kafka Streams&lt;/a&gt; as sub-projects.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-pig&quot;&gt;Pig&lt;/a&gt; was one of the first technologies to provide a ore user friendly abstraction over MapReduce for developing Hadoop jobs. It’s starting to show it’s age however, and although Hortonworks and Yahoo (who are heavy Pig users) seem to be investing heavily in Pig on Tez, and Cloudera seems to be supporting Pig on Spark (mirroring their Hive strategies), it’s difficult to see newcomers to Hadoop who don’t have an existing investment in Pig using it over Spark and other newer tools.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/apache-oozie&quot;&gt;Oozie&lt;/a&gt; - a job scheduling an orchestration engine. It’s been a staple of most Hadoop distributions for a while now, however it’s difficult to find many big references cases for it’s use, and it’s not the most user friendly tool. Orchestration and management of data transformation pipelines feels like a huge technology gap at the moment - if anyone knows of any great technologies in this space please shout.&lt;/p&gt; &lt;p&gt;As before - click on the links to see the technology information added to the site.&lt;/p&gt; &lt;p&gt;That’s it for this week, and for the core Hadoop technologies - it’s been fun. We’ll be back on Monday to start looking at Apache Bigtop, along with a change of pace…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/01/20/core-hadoop-technologies-pt3/</guid> </item> <item><title>Apache Sqoop</title><link>http://ondataengineering.net/technologies/apache-sqoop/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Specialist technology for moving bulk data between Hadoop and structured (relational) databases. Command line based, with the ability to import and export data between a range of databases (including mainframe partitioned datasets) and HDFS, Hive, HBase and Accumulo. Supports parallel partitioned unloads, writing to Avro, Sequence File, Parquet and text files, incremental imports and saved jobs that can be shared via a simple metadata store. An Apache project, started in May 2009 as an Hadoop contrib module, migrating to a Cloudera GitHub project in April 2010 (with a v1.0 release shortly after), before being donated to the Apache foundation in June 2011, graduating in March 2012. The last major release (v1.4) was in November 2011, with only minor releases since then. However in January 2012 a significant re-write was announced as part of a proposed v2.0 release to address a number of usability, security and architectural issues. This will introduce a new Sqoop Server and Metadata Repository, supporting both a CLI and web UI, centralising job definitions, database connections and credentials, as well as enabling support for a wider range of connectors including NoSQL databases, Kafka and (S)FTP folders. Java based, with commercial support available as part of most Hadoop distributions.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Sqoop&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v1.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org&quot;&gt;http://sqoop.apache.org&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/&quot;&gt;http://sqoop.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sqoop/entry/apache_sqoop_highlights_of_sqoop&quot;&gt;https://blogs.apache.org/sqoop/entry/apache_sqoop_highlights_of_sqoop&lt;/a&gt; - introduction to Sqoop 2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sqoop/entry/apache_sqoop_graduates_from_incubator&quot;&gt;https://blogs.apache.org/sqoop/entry/apache_sqoop_graduates_from_incubator&lt;/a&gt; - early history of Sqoop&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/&quot;&gt;http://sqoop.apache.org/&lt;/a&gt; - details latest release, and hosts release notes for v1.4.0 onwards&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sqoop/&quot;&gt;https://blogs.apache.org/sqoop/&lt;/a&gt; - project blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-sqoop/</guid> </item> <item><title>Spark Streaming</title><link>http://ondataengineering.net/technologies/apache-spark/spark-streaming/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Spark library for continuous stream processing, that allows stream and batch processing (including Spark SQL and MLlib operations) to be combined. Uses a micro-batch execution model, leveraging core Spark to process each micro-batch, and provides fault tolerance through exactly-once processing semantics. Supports a number of data sources (including HDFS, sockets, Flume, Kafka, Kinesis and messaging buses), as well as functions to maintain state and to execute windowed operations. First introduced in Spark 0.7, with a production release as part of Spark 0.9.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/sql/&quot;&gt;http://spark.apache.org/sql/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html&quot;&gt;http://spark.apache.org/docs/latest/sql-programming-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/spark-streaming/</guid> </item> <item><title>Spark SQL</title><link>http://ondataengineering.net/technologies/apache-spark/spark-sql/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Spark library for processing structured data, using either SQL statements or a DataFrame API. Supports querying and writing to local datasets (including JSON, Parquet, Avro, Orc and CSV) as well as external data sources (including Hive and JDBC), including the ability to query across data sources. Includes Catalyst, a cost based optimiser that turns high level operations into low level Spark DAGs for execution. Also includes a Hive compatible Thrift JDBC/ODBC server that's compatible with Beeline and the Hive JDBC and ODBC drivers, and a REPL CLI for interactive queries. First introduced in Spark 1.0, with a production release as part of Spark 1.3.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/sql/&quot;&gt;http://spark.apache.org/sql/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/sql-programming-guide.html&quot;&gt;http://spark.apache.org/docs/latest/sql-programming-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/spark-sql/</guid> </item> <item><title>MLlib</title><link>http://ondataengineering.net/technologies/apache-spark/mllib/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Spark library for running Machine Learning algorithms. Supports a range of algorithms (including classifications, regressions, decision trees, recommendations, clustering and topic modelling), including iterative algorithms. First introduced in Spark 0.8 after being collaboratively developed with the UC Berkeley MLbase project.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/mllib//&quot;&gt;http://spark.apache.org/mllib//&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/ml-guide.html&quot;&gt;http://spark.apache.org/docs/latest/ml-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.mlbase.org/&quot;&gt;http://www.mlbase.org/&lt;/a&gt; - the UC Berkeley MLbase project&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/mllib/</guid> </item> <item><title>GraphX</title><link>http://ondataengineering.net/technologies/apache-spark/graphx/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;Spark library for processing graphs and running graph algorithms, based on graph model that supports directional edges with properties on both vertices and edges. Graphs are constructed from a pair of collections representing the edges and vertex, either directly from data on disk using builders, or prepared using other Spark functionality, with the ability to also view the graph as a set of triples. Supports a range of graph operations, as well as an optimised variant of the Pregel API, and a set of out of the box algorithms (including PageRank, connected components and triangle count). First introduced in Spark 0.9, with a production release as part of Spark 1.2, however has seen almost no new functionality since then.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/graphx/&quot;&gt;http://spark.apache.org/graphx/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/graphx-programming-guide.html&quot;&gt;http://spark.apache.org/docs/latest/graphx-programming-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/graphx/</guid> </item> <item><title>Apache Spark</title><link>http://ondataengineering.net/technologies/apache-spark/</link><pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;A high performance general purpose distributed data processing engine based on directed acyclic graphs that primarily runs in memory, but can spill to disk if required, and which supports processing applications written in Java, Scala, Python and R. Includes a number of sub-projects that support more specialised analytics including Spark SQL, Spark Streaming, MLlib (machine learning) and GraphX (graph analytics). Requires a cluster manager (YARN, EC2 and Mesos are supported as well as standalone clusters) and can access data in a wide range of technologies (including HDFS, other Hadoop data sources, relational databases and NoSQL databases). An Apache project, originally started at UC Berkley in 2009, open sourced in 2010, and donated to the Apache foundation in June 2013, graduating in February 2014. v1.0 was released in May 2014, with a v2.0 release in July 2016. Java based, with development led by Databricks (who sell a Spark hosted service), and with commercial support available as part of most Hadoop distributions.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Spark&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;January 2017 - v2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Apache Spark&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-spark/graphx/&quot;&gt;GraphX&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Spark library for processing graphs and running graph algorithms, based on graph model that supports directional edges with properties on both vertices and edges. Graphs are constructed from a pair of collections representing the edges and vertex, either directly from data on disk using builders, or prepared using other Spark functionality, with the ability to also view the graph as a set of triples. Supports a range of graph operations, as well as an optimised variant of the Pregel API, and a set of out of the box algorithms (including PageRank, connected components and triangle count). First introduced in Spark 0.9, with a production release as part of Spark 1.2, however has seen almost no new functionality since then.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Apache Spark&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-spark/mllib/&quot;&gt;MLlib&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Spark library for running Machine Learning algorithms. Supports a range of algorithms (including classifications, regressions, decision trees, recommendations, clustering and topic modelling), including iterative algorithms. First introduced in Spark 0.8 after being collaboratively developed with the UC Berkeley MLbase project.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Apache Spark&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-spark/spark-sql/&quot;&gt;Spark SQL&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Spark library for processing structured data, using either SQL statements or a DataFrame API. Supports querying and writing to local datasets (including JSON, Parquet, Avro, Orc and CSV) as well as external data sources (including Hive and JDBC), including the ability to query across data sources. Includes Catalyst, a cost based optimiser that turns high level operations into low level Spark DAGs for execution. Also includes a Hive compatible Thrift JDBC/ODBC server that's compatible with Beeline and the Hive JDBC and ODBC drivers, and a REPL CLI for interactive queries. First introduced in Spark 1.0, with a production release as part of Spark 1.3.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Apache Spark&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-spark/spark-streaming/&quot;&gt;Spark Streaming&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Spark library for continuous stream processing, that allows stream and batch processing (including Spark SQL and MLlib operations) to be combined. Uses a micro-batch execution model, leveraging core Spark to process each micro-batch, and provides fault tolerance through exactly-once processing semantics. Supports a number of data sources (including HDFS, sockets, Flume, Kafka, Kinesis and messaging buses), as well as functions to maintain state and to execute windowed operations. First introduced in Spark 0.7, with a production release as part of Spark 0.9.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/&quot;&gt;http://spark.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/&quot;&gt;http://spark.apache.org/docs/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/news/index.html&quot;&gt;http://spark.apache.org/news/index.html&lt;/a&gt; - project news&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/category/engineering&quot;&gt;https://databricks.com/blog/category/engineering&lt;/a&gt; - Databricks engineering blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/</guid> </item> </channel> </rss>
