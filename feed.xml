<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>The Week That Was - 02/06/2017</title><link>http://ondataengineering.net/blog/2017/06/02/the-week-that-was/</link><pubDate>Fri, 02 Jun 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Just a very quick update this week.&lt;/p&gt; &lt;p&gt;It’s been a much shorter week that usual due to me being elsewhere at the beginning of the week and only starting our look into object stores on Wednesday. Because of that we’ll continue into next week, and I’m therefore not going to summarise any of the technologies we’ve looked at this week today. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I’m starting to settle on a new rhythm for these technology category pages. I think I’m looking for broad coverage rather than depth - so although I would love to work through all the major technologies in each category I think my priority has to be getting good coverage of the various categories I want to cover so that there’s a framework that hopefully other people can help me build out. However, I don’t want to provide technology category pages that provide no value and don’t contain any useful or valuable information, but I don’t want to stop or reduce the number of technology summaries I’m doing - and that’s the balance I’m trying to strike. I’m not quite there yet, but I’m going to try and do technology summaries Monday to Thursday and a technology category page and some thoughts on a Friday, with the technology category page focusing on providing valuable links and very brief lists of potential technologies that fit in the category that require further analysis - a valuable starting point for understanding the potential technology options.&lt;/p&gt; &lt;p&gt;I’ve no idea if it’ll work, or if it’s achievable, but let’s find out. Next week we’ll finish of our last technology summaries for object stores, catch-up on the news, and maybe have a look at Cloudera Altus or Azure Data Lake Store if we have time.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/02/the-week-that-was/</guid> </item> <item><title>Microsoft Azure Blob Storage</title><link>http://ondataengineering.net/technologies/microsoft-azure-blob-storage/</link><pubDate>Fri, 02 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;An object store service with strong consistency, with support for multiple blob types (block, page and append), multiple storage tiers (hot and cold) and deep integration to the Azure ecosystem. Block blobs are comprised of one or more blocks with operations done at the block level with changes made visible via a final commit; page blobs are collections of 512-byte pages optimised for random read and write operations against one or more pages; and append blobs only support modification via the addition of new data to the end of the blob. Objects are organised into containers and indexed by string, with the option to list objects by prefix and to summarise results based on a delimiter allowing a filesystem to be approximated. Supports name-value pair metadata against containers and objects, both optimistic and pessimistic (lock based) concurrency, snapshots (providing read only access to objects as they were when the snapshot was taken), access control via access tokens (shared access signatures), public access to containers, configurable geo redundancy, encryption of objects (Azure Storage Service Encryption - SSE) and support for SSL connections, multi-part uploads, the use of custom domains, and logging and metrics (Azure Storage Analytics). Provides a REST API, web app (Azure Storage Explorer), a range of SDKs, a CLI and PowerShell integration.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Azure Blob Storage&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Microsoft&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;June 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/blobs/&quot;&gt;https://azure.microsoft.com/en-us/services/storage/blobs/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/storage/storage-introduction&quot;&gt;https://docs.microsoft.com/en-us/azure/storage/storage-introduction&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/rest/api/storageservices/&quot;&gt;https://docs.microsoft.com/en-us/rest/api/storageservices/&lt;/a&gt; - REST API documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/microsoft-azure-blob-storage/</guid> </item> <item><title>Amazon S3</title><link>http://ondataengineering.net/technologies/amazon-s3/</link><pubDate>Thu, 01 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;An object store service with eventual consistency, focusing on massive durability and scalability, with support for multiple storage tiers (including Amazon Glacier) and deep integration to the AWS ecosystem. Objects are organised into buckets and indexed by string, with the option to list objects by prefix and to summarise results based on a delimiter allowing a filesystem to be approximated. Metadata against objects is managed via S3 Object Tags, key-value pairs applied to objects that can be added, modified or deleted at any time. Lifecycle management policies can be assigned to name prefixes or object tags to automatically delete objects or move them between storage tiers. Supports versioning of objects, access control (at the bucket or object level), replication of objects and metadata to a bucket in a different AWS region (cross-region replication), encryption of objects and support for SSL connections, full auditing of all object operations, analytics on object operations, multi-part uploads, multi-object deletions, a flat-file output of object names and metadata (S3 Inventory), downloads via the bittorrent protocol, static website hosting and time limited object download URLs. Quotes a 99.999999999% guarentee that data won't be lost, with data stored redundantly across multiple devices and facilities within the chosen region, and scalability past trillions of objects. Provides a web based management console, mobile management app, a REST API and SDKs for a wide range of languages. First launched in March 2006.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Simple Storage Service&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Amazon&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;June 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/s3&quot;&gt;https://aws.amazon.com/s3&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/s3/details/&quot;&gt;https://aws.amazon.com/s3/details/&lt;/a&gt; - details&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/documentation/s3/&quot;&gt;https://aws.amazon.com/documentation/s3/&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/amazon-s3/</guid> </item> <item><title>Object Stores</title><link>http://ondataengineering.net/tech-categories/object-stores/</link><pubDate>Wed, 31 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Storage solutions whereby data is stored without any concept of folders or organisational structure, instead being referenced by a unique identifier and accessed via a REST API rather than a traditional filesystem API. Generally designed to be massively parallel and scalable, and often supports a range of features including support for storage of custom metadata against data, replication of data for redundancy, tiered storage and object versioning. Often most associated with cloud services, but increasing available as on-site deployable software.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/object-stores/</guid> </item> <item><title>Hadoop Compatible Filesystems</title><link>http://ondataengineering.net/blog/2017/05/26/hadoop-compatible-filesystems/</link><pubDate>Fri, 26 May 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;So how did we do with our look at &lt;a href=&quot;/tech-categories/hadoop-compatible-filesystems/&quot;&gt;Hadoop Compatible Filesystems&lt;/a&gt; this week? Spoiler - not as well as I’d hoped!&lt;/p&gt; &lt;p&gt;In hindsight, picking this as the first technology category to do was a daft idea. Not only have I been trying to work out what I want to achieve with these technology category pages, and the level and information I want to capture, but my journey into Hadoop compatible storage has involved a myriad of rabbit holes from object stores to enterprise scale out storage to in-memory to every technology and its dog having an Hadoop compatible API. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So I’m going to do my best to summarise, but this journey will probably continue next week - there’s some further detail I want to dig into, I’m not entirely happy with the technology category page, I’ve got a big pile of information that probably means I’m probably doing object stores and scale out storage as the next technology categories to close the circle.&lt;/p&gt; &lt;p&gt;Firstly, there are two use cases for an Hadoop Compatible Filesystem. The first is as a drop in replacement for HDFS - you run your filesystem and compute on the same nodes and utilise data locality to do local filesystem reads wherever possible. The second is as a way of reading and writing data from a remote data store using the standard Hadoop Filesystem API - great if you want to access and write data back to external storage, but not a replacement for your local HDFS filesystem that you’ll still be using for temporary and intermediate data.&lt;/p&gt; &lt;p&gt;If you want to swap out HDFS in your Hadoop cluster for something else, there are some technologies you can look at that are HDFS but better. The obvious one being &lt;a href=&quot;/technologies/mapr-file-system/&quot;&gt;MapR-FS&lt;/a&gt;, but the &lt;a href=&quot;/technologies/quantcast-file-system/&quot;&gt;Quantcast File System&lt;/a&gt; and Hops-HDFS are both interesting examples of open source projects that have taken HDFS and tried to improve it.&lt;/p&gt; &lt;p&gt;If you want to read and write data from Hadoop to an external system via the Hadoop Filesystem API, then the world’s your oyster, as pretty much every file or object based storage technology now allows you to do this, and generally in a (reasonably) high performance parallel way. This is the area I want to dig into in more detail next week however - what are you options if you want to store large volumes of data for analytics outside of an Hadoop cluster.&lt;/p&gt; &lt;p&gt;And as it feels like I’ve only scratched the surface of this area, I’m going to reserve the right to come and revise this information in the future. I wasn’t planning to dig so far into file and object storage at this time, but here we are so let’s see where it leads us.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/26/hadoop-compatible-filesystems/</guid> </item> <item><title>Hadoop Compatible Filesystems</title><link>http://ondataengineering.net/tech-categories/hadoop-compatible-filesystems/</link><pubDate>Fri, 26 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A parallel distributed filesystem that implements the Hadoop FileSystem API and conforms to the Hadoop Compatible Filesystem specification, allowing it to be used in place of HDFS. The use of the FileSystem API (over native filesystem access) allows for parallel reads and location aware block placement, with the HCFS specification covering runtime behaviour. Note that Hadoop Compatible Filesystems (as per HDFS) are not fully POSIX compliant, there is no formal compatibility test suite (although a test suite that will highlight potential issues is available), and that some implementations (for example object stores) do not (and cannot) fully conform to the specification.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The specification for Hadoop compatible filesystems is included in the Hadoop documentation &lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/filesystem/introduction.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;specialist-hadoop-compatible-filesystems&quot;&gt;Specialist Hadoop Compatible Filesystems&lt;/h2&gt; &lt;p&gt;The following technologies are all designed specifically to be Hadoop compatible and to be drop in replacements for HDFS within an Hadoop cluster, meaning that they can co-exist with YARN and other analytical compute workloads on the same nodes:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/hdfs/&quot;&gt;HDFS&lt;/a&gt;&lt;/td&gt; &lt;td&gt;The Hadoop Distributed Filesystem, bundled with Hadoop&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/&quot;&gt;MapR-FS&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Hadoop compatible, highly resilient and scalable distributed filesystem that also supports NoSQL table and streaming data native storage&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/quantcast-file-system/&quot;&gt;Quantcast File System&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Open source HDFS replacement, which focuses on improving performance and scalability over HDFS&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hops-HDFS&lt;/td&gt; &lt;td&gt;Experimental solution based on HDFS but using a distributed MySQL cluster for metadata to increase performance and scalability - &lt;a href=&quot;http://www.hops.io/?q=content/hdfs&quot;&gt;http://www.hops.io/?q=content/hdfs&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;See our &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page for options on deploying Hadoop clusters utilising these technologies.&lt;/p&gt; &lt;h2 id=&quot;in-memory-hadoop-compatible-filesystems&quot;&gt;In Memory Hadoop Compatible Filesystems&lt;/h2&gt; &lt;p&gt;There are also a number of in memory data grids / storage layers that provide Hadoop compatibility and the option to run Hadoop jobs entirely in memory or across tiered storage:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-alluxio&quot;&gt;Apache Alluxio&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Distributed virtual storage layer over memory and tiered storage with support for a range of interfaces. Previously known as Tachyon&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;GridGain/Apache Ignite&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Distributed in-memory data fabric/grid, including support for an in-memory Hadoop compatible filesystem&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;cloud-hadoop-compatible-filesystems&quot;&gt;Cloud Hadoop Compatible Filesystems&lt;/h2&gt; &lt;p&gt;Azure has an Hadoop compatible filesystem as a service:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Data Lake Store&lt;/td&gt; &lt;td&gt;Cloud based massively scalable HDFS compatible filesystem - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/data-lake-store/&quot;&gt;https://azure.microsoft.com/en-us/services/data-lake-store/&lt;/a&gt;; &lt;a href=&quot;https://hadoop.apache.org/docs/current/hadoop-azure-datalake/index.html&quot;&gt;https://hadoop.apache.org/docs/current/hadoop-azure-datalake/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;other-technologies&quot;&gt;Other Technologies&lt;/h2&gt; &lt;p&gt;DataStax Enterprise has an HDFS compatible file system API:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;DataStax Enterprise file system&lt;/td&gt; &lt;td&gt;Distributed Hadoop compatible filesystem that runs on DataStax Enterprise, replacing the now deprecated Cassandra File System (CFS) - &lt;a href=&quot;http://docs.datastax.com/en/dse/5.1/dse-admin/datastax_enterprise/analytics/dsefsTOC.html&quot;&gt;http://docs.datastax.com/en/dse/5.1/dse-admin/datastax_enterprise/analytics/dsefsTOC.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;parallel-distributed-filesystems&quot;&gt;Parallel Distributed Filesystems&lt;/h2&gt; &lt;p&gt;Parallel distributed filesystems provide similar capabilities to HDFS, including the ability to scale horizontally and to read a file in parallel from multiple nodes. Their general focus is on providing direct filesystem access plus NFS and object store APIs, and although most offer an Hadoop compatible API this is generally just to allow data to be exploited by Hadoop compatible workloads as a remote filesystem. Some may support installation on an Hadoop cluster as a drop in replacement for HDFS, however there are often compatibility issues and performance is often not as good as HDFS.&lt;/p&gt; &lt;h2 id=&quot;object-stores&quot;&gt;Object Stores&lt;/h2&gt; &lt;p&gt;Most object stores also provide Hadoop compatible APIs, and although this means that Hadoop can natively read and write from them using the Hadoop Filesystem API, they are not considered Hadoop Compatible Filesystems due to their lack of compliance to the compliance specification. More details can be found in the “Object Stores vs. Filesystems” section of the &lt;a href=&quot;https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/filesystem/introduction.html&quot;&gt;specification page&lt;/a&gt;.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop-compatible-filesystems/</guid> </item> <item><title>Chapter 2</title><link>http://ondataengineering.net/blog/2017/05/22/chapter-2/</link><pubDate>Mon, 22 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Given that I’m going a little short-sighted staring at Hadoop, I think it’s time to widen our gaze a little and to start chapter 2 of this site. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;In the recently added &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;Hadoop distributions comparison&lt;/a&gt; page, I introduced some categories by which I grouped and compared the technologies in the Cloudera, Hortonworks and MapR technology stacks, however at no point did I try and accurately define was I mean by each of these categories.&lt;/p&gt; &lt;p&gt;So that’s what I’m planning to do now - work through these categories (and some that aren’t on there) to create a technology category page for each that summarises the range of technologies available in that space. I’ll continue doing technology summaries for popular technologies (or anything that catches my eye), with a focus on open source and cloud technologies (with a smattering of commercial ones as and where there’s enough public information to do so).&lt;/p&gt; &lt;p&gt;We’ll kick off tomorrow with our first category, once I’ve rolled the dice and picked one!&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/22/chapter-2/</guid> </item> <item><title>Hadoop Wrap-Up</title><link>http://ondataengineering.net/blog/2017/05/19/hadoop-wrap-up/</link><pubDate>Fri, 19 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;And so I think our current look into Hadoop is probably drawing to a close. That’s not because we’re run out of technologies to look at and thing to talk about, but because it’s time to move on. We’ll double back to this in the future - I’d like to dig into the major cloud technologies, and into the commercial world of Data Engineering in the future. I’m also hoping we’ll get contributions to help flesh out this information now we have a starting point.&lt;/p&gt; &lt;p&gt;But, let’s summarise where we’ve got to with Hadoop, and pass some comment on ODPi which we looked at yesterday. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Hadoop, it’s ecosystem, and the myriad of options for using it are a complex whirling maelstrom of sound and fury. Understanding it is like trying to catch a paper bag in a strong wind - no matter how close you might get, something is always changing, meaning you’re never going to get there. Fun hyperbole aside, my hope is that the content I’ve added to this site over the last few months becomes the starting point for a set of signposts to get you started - be that the &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page which provides a summary of the options for deploying or using Hadoop capabilities, the &lt;a href=&quot;/tech-categories/hadoop-distributions/ecosystem/&quot;&gt;Hadoop ecosystem&lt;/a&gt; page which tries to summarise the technologies that run over HDFS and YARN, the &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;Hadoop distributions comparison&lt;/a&gt; page which tries to summarise the different technologies bundled with different Hadoop distributions, or the myriad of technology summaries that might give you a starting point for understanding the different options and capabilities in the wider Hadoop ecosystem. A lot of this content isn’t finished or polished, so at this time this is very much a starting point, and some pages have big banners to clearly show they’re draft and not complete.&lt;/p&gt; &lt;p&gt;There’s been a lot written and said about ODPi, and for a long time I wasn’t sure I was ever going to understand what it was or what it was trying to do. Time however tends to make stuff clearer, and whereas originally ODP talked a lot about a common core for Hadoop, it seems to have settled down on defining some specifications for Hadoop compatibility to ensure that a single piece of software will run on any Hadoop distribution. That’s a noble goal, however I think there chances of achieving it are slim to none - they’re lacking platform vendor support (no Cloudera, MapR, Microsoft, Oracle), the specifications seem extreemly lightweight (meaning compliance to the spec is unlikely to mean compatibility with all certified platforms), there’s very little software vendor buy in (less than 10 software vendors at the time of writing have certified compliance) and it just doesn’t have the breadth (covering only HDFS, YARN, MapReduce and Hive at the moment). It feels like an extreemly expensive and challenging problem to solve, which which there appears to be little demand at the moment.&lt;/p&gt; &lt;p&gt;And just before we move on, I’m doing some minor tidying up as part of the last two weeks thinking, which I’ll now try to summarise:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Each distributions technology page now includes a link to the list of certified software that runs on it&lt;/li&gt; &lt;li&gt;I’ve update the Hadoop ecosystem page to remove Flume running over YARN (because it doesn’t)&lt;/li&gt; &lt;li&gt;Where technologies run over HDFS or YARN, I’ve make sure their technology summaries include this&lt;/li&gt; &lt;li&gt;I’ve moved some of the information on the technology vendor pages into the distribution pages, for example which cloud providers they run on&lt;/li&gt; &lt;li&gt;For technologies that are compatible with HDFS I’ve added a new technology relationship to show this&lt;/li&gt; &lt;li&gt;I’ve added links to the Hadoop ecosystem page to the YARN and HDFS pages&lt;/li&gt; &lt;li&gt;I’ve tweaked some of the descriptions on the Hadoop distributions page, for example to detail where there are free versions of a distribution&lt;/li&gt; &lt;li&gt;I’ve updated the Slider technology summary to reference Hoya and Koya&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So what’s next. I think it’s time to broaden out a little, and to start looking at some of the different types of technologies that might be of interest to us, and for each one look at the technology options available to us. So we’ll try that.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/19/hadoop-wrap-up/</guid> </item> <item><title>ODPi</title><link>http://ondataengineering.net/tech-vendors/opdi/</link><pubDate>Thu, 18 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;ODPi is a non profit organisation and member of the Linux Foundation that distributes reference specifications for key Hadoop components and APIs to help drive compatibility between Hadoop distributions, sponsoring Apache Bigtop as a reference implementation. Compliance against the spec for platform vendors (to ensure any certified app will run on their platform) and software vendors (to ensure their app will run on any certified platform) is achieved through self-certification against a test suite that's bundled with Apache Bigtop. Current technologies covered by the specifications are HDFS, YARN, MapReduce, HCFS and Hive. Current certified distributions include Altiscale, ArenaData, Hortonworks, IBM and Infosys but notably does not include either Cloudera or MapR who have both publicly stated their objections to the organisation. Currently certified applications are limited to DataTorrent, Apache Hawq, SAS, Syncsort, WANDisco and a range of IBM technologies. Originally founded in February 2005 as the Open Data Platform with language that suggested it was looking to build a standard Hadoop core (the ODP core) based on HDFS, Ambari, YARN and MapReduce. Moved under the Linux Foundation in September 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Vendor Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Open Data Platform Initiative&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;specifications&quot;&gt;Specifications&lt;/h2&gt; &lt;p&gt;ODPi manages and issues two specifications:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href=&quot;https://github.com/odpi/specs/blob/master/ODPi-Runtime.md&quot;&gt;Runtime Specification&lt;/a&gt;, which provides compatibility and interoperability for a range of key Hadoop components and APIs, including HDFS, YARN, MapReduce, HCFS (Hadoop Compatible Filesystems) and Hive (specifically SQL, JDBC and beeline). Requires the use of Hadoop 2.7, Java 7 or 8, a standard set of environment variables, no modification of the public API and any addition features functions to be committed to the ASF. Uses Apache Bigtop as a reference implementation, with Bigtop also providing the certification test suite.&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;https://github.com/odpi/specs/blob/master/ODPi-Operations.md&quot;&gt;Operations Specification&lt;/a&gt;, which provides the same for managing and monitoring Apache Hadoop clusters with Ambari as reference implementation, including a contrib management pack that allows any product based on Ambari to deploy the ODPi reference implementation.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;March 2016&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;MVP for ODPi runtime spec, validation test suite and reference implementation covering HDFS, YARN and MapReduce&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.0&lt;/td&gt; &lt;td&gt;November 2016&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www.theregister.co.uk/2016/11/14/odpi_20/&quot;&gt;viewpoint from TheRegister&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Added Operations Specification, and support for HCFS and Hive to the Runtime Specification&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.1&lt;/td&gt; &lt;td&gt;April 2017&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.odpi.org/blog/2017/04/05/odpi-2-1-a-tick-for-the-future-tock&quot;&gt;summary&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Moved to using Apache Bigtop for validation testsuite and reference implementation - ODPi release now only includes specifications&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;criticisms&quot;&gt;Criticisms&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/the-open-data-platform-alliance/&quot;&gt;Cloudera’s statement&lt;/a&gt; was that there was no demand for a compliance standard from any of their partners, that the organisation was a pay-to-join vendor driven consortium that was contrary to the open source nature of Hadoop, and that open source trumps vendor driven standardisation with reference to Linux’s success and the subsequent Linux ecosystem over the attend to standardise *NIX distributions.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/our-view-open-data-platform/&quot;&gt;MapR’s statement&lt;/a&gt; largely echoed Cloudera’s with the primary argument being that there wasn’t a requirement, citing a Gartner survey in which less than 1% of companies thought vendor lock in was an issue, and that there was a significant lack of breadth in the compliance technologies&lt;/li&gt; &lt;li&gt;TheRegister has a good summary of Cloudera and MapR’s positions &lt;a href=&quot;http://www.theregister.co.uk/2015/04/24/mapr_odp_cloudera/&quot;&gt;here&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A &lt;a href=&quot;http://www.theregister.co.uk/2016/11/14/odpi_20/&quot;&gt;subsequent article from TheRegister&lt;/a&gt; to coincide with the release of ODPi 2.0 includes an interview with Charaka Goonatilake, the CTO of Panaseer, that covers their two main issues as a software vendor, specifically that it doesn’t cover enough technologies or go deep enough, meaning it doesn’t actually help them test their product once and have confidence it’s going to work across all Hadoop distributions.&lt;/li&gt; &lt;li&gt;ZDNet have also a &lt;a href=&quot;http://www.zdnet.com/article/odpi-runtime-spec-aims-to-defrag-hadoop/&quot;&gt;useful write-up&lt;/a&gt; of the challenges ODPi is experiencing&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.odpi.org/&quot;&gt;https://www.odpi.org/&lt;/a&gt; - ODPi homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/odpi&quot;&gt;https://github.com/odpi&lt;/a&gt; - ODPi repository&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/odpi/specs/wiki&quot;&gt;https://github.com/odpi/specs/wiki&lt;/a&gt; - ODPi specifications Wiki&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://pivotal.io/big-data/press-release/technology-leaders-unite-around-open-data-platform-to-increase-enterprise-adoption-of-hadoop-and-big-data&quot;&gt;Pivotal launch press release&lt;/a&gt;, including links to the press releases from Altiscale, SAS and Verizon&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://content.pivotal.io/blog/open-data-platform-initiative-putting-an-end-to-faux-pen-source-apache-hadoop-distributions&quot;&gt;Summary of the original ODP plans&lt;/a&gt; from Roman Shaposhnik&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.odpi.org/blog&quot;&gt;https://www.odpi.org/blog&lt;/a&gt; - ODPi blog&lt;/li&gt; &lt;li&gt;ODPi also have a subscription newsletter&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/opdi/</guid> </item> <item><title>The Mid Week News - 17/05/2017</title><link>http://ondataengineering.net/blog/2017/05/17/the-mid-week-news/</link><pubDate>Wed, 17 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Time for a short diversion from wrapping up our look at Hadoop to catch up on the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;New technology releases:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Version 1.2 of &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; is out. See the &lt;a href=&quot;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes#ReleaseNotes-Version1.2.0&quot;&gt;summary of new changes&lt;/a&gt; for details.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Apache Ignite&lt;/a&gt; and it’s commercial edition GridGain Professional have seen a big 2.0 releases with a complete redesign of the off-heap memory architecture which should allow the extension of in-memory data structures to SSD disks. See the &lt;a href=&quot;https://blogs.apache.org/ignite/entry/apache-ignite-2-0-redesigned&quot;&gt;Ignite announcement&lt;/a&gt; and the &lt;a href=&quot;https://www.gridgain.com/resources/blog/gridgain-professional-edition-20-released-today&quot;&gt;GridGain Professional announcement&lt;/a&gt; for more details.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Interesting blog posts:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.ebaytechblog.com/2017/05/12/enhancing-the-user-experience-of-the-hadoop-ecosystem/&quot;&gt;eBay on their use of Hue, Zeppelin and Knox&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://dzone.com/articles/how-to-become-a-data-engineer&quot;&gt;Some thoughts on being a Data Engineer&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/watermarks-tables-event-time-dataflow-model/&quot;&gt;A post from Confluent&lt;/a&gt; (who are therefore slightly biased) on why Kafka Tables provide a better solution that windowing and watermarks (with specific reference to the Beam API) for calculating rolling aggregates of revisions or updates&lt;/li&gt; &lt;li&gt;Hortonworks have been on a bit of a roll with multi-part blog posts: &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/part-1-hortonworks-building-successful-streaming-analytics-platforms/&quot;&gt;Building streaming analytics platforms&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/part-5-of-data-lake-3-0-yarn-and-containerization-supporting-docker-and-beyond/&quot;&gt;Thoughts on Data Lake 3.0&lt;/a&gt;, including docker support in YARN&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/apache-hive-druid-part-1-3/&quot;&gt;OLAP analytics with Druid and Hive&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/enterprise-security-governance-part-1/&quot;&gt;Update on governance and security in HDP 2.6&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2017/05/how-to-backup-and-disaster-recovery-for-apache-solr-part-i/&quot;&gt;How to backup and recover Solr&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://data-artisans.com/blog/official-docker-images-apache-flink&quot;&gt;An official docker image for Flink&lt;/a&gt; is now available from Data Artisans&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/how-get-started-spark-streaming-and-mapr-streams-using-kafka-api/&quot;&gt;Using Spark Streaming and MapR-Streams&lt;/a&gt; from the MapR blog&lt;/li&gt; &lt;li&gt;And a couple of interesting posts from Adrian Colyer’s The Morning Paper &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/05/04/cherrypick-adaptively-unearthing-the-best-cloud-configurations-for-big-data-analytics/&quot;&gt;CherryPick - a system for determining the best cloud configurations for big data analytics&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/05/15/trajectory-recovery-from-ash-user-privacy-is-not-preserved-in-aggregated-mobility-data/&quot;&gt;Reconstructing individual user data from aggregated mobility data&lt;/a&gt; - well worth a quick look&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/17/the-mid-week-news/</guid> </item> <item><title>Hadoop Technology Options</title><link>http://ondataengineering.net/blog/2017/05/16/hadoop-technology-options/</link><pubDate>Tue, 16 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;In the last post we looking at why you might want to use Hadoop - today I want to dig into the options for deploying or using Hadoop capabilities. Consider this a companion piece to the list of these options that’s now available on our &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Broadly speaking, if you’re looking at deploying Hadoop the options you have fall into three categories.&lt;/p&gt; &lt;p&gt;Firstly, you can use an Hadoop managed service. This automates the provisioning and management of Hadoop, allowing you to easily create, scale and destroy clusters. You’ll obviously need to either have or get your data into the cloud, however this can be a great option for dipping your toe in the waters and exploring what Hadoop can do in a very cost effective way. However, if you want a persistent cluster, or if you’re doing anything at a significant scale, then this can get expensive very quickly, so it’s worth doing your sums first. Hadoop as a service does open up another use case however - if you already have you data in the cloud then you can use an Hadoop managed service to analyse that data in place using transient processing clusters - just spin up a cluster for a specific workload and then terminate it, meaning that you’re only paying whilst your workload is running. Note however that cloud object stores are significantly slower than HDFS running on local storage in a cloud based cluster.&lt;/p&gt; &lt;p&gt;Secondly, you can deploy and manage Hadoop yourself, either on your own infrastructure or on cloud infrastructure. The choice of your own vs cloud infrastructure is subject to all the usual considerations around TCO, manageability and having your data into the cloud, however both Cloudera and Hortonworks include tools (Cloudera Directory and Cloudbreak respectively) for managing cloud based deployments (including the provisioning of cloud infrastructure and the ability to scale up and down) that are also probably your prime options if you’re running an internal cloud such as OpenStack. Whatever infrastructure you use, you’re responsible for your Hadoop installation, which means you’ll need to make a decision about which Hadoop distribution to use, and whether you use a free open source version or purchase commercial support. You’ll also need to make sure you have access to all the specialist skills required to deploy, secure and manage your cluster - although the various management tools have improved significantly over the last few years, there are still significant decisions and configuration work to be done.&lt;/p&gt; &lt;p&gt;Lastly, you can use an Hadoop appliance - a prepackaged bundle of dedicated infrastructure and Hadoop software. There’s generally price premium for these, however they’re generally well architected for performance and can massively accelerate an onsite deployment, although they may or may not be easier to manage that a custom Hadoop deployment.&lt;/p&gt; &lt;p&gt;Selecting an Hadoop technology is never going to be a quick or easy process - the range of different options, the different ways it can be deployed, the range of different capabilities, the different cost models and level of support, the skills required and the management and maintenance costs make it a complex decision. However I’m hoping that the material on this site will give you a starting point for understanding the different options to help inform this decision making process. The &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page that lists the various options should be your first call, and I’ve started a comparison of the technologies bundled in the major distributions that we’ve looked at to date on an &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;Hadoop Distributions Comparison&lt;/a&gt; page. Neither of these are complete by a long stretch, however let me know of any obvious gaps, or even better send through a pull request with any new information.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/16/hadoop-technology-options/</guid> </item> <item><title>Why Choose Hadoop?</title><link>http://ondataengineering.net/blog/2017/05/12/why-choose-hadoop/</link><pubDate>Fri, 12 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;So our Hadoop Distros week is going to be a bit longer than a week, but hey, we’re all flexible and adaptable right?&lt;/p&gt; &lt;p&gt;Today I’d like to spout some thoughts about why you might consider Hadoop, and I’d like to start but looking at it’s history. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Hadoop was originally designed for the single specific use case of doing aggregations over enormous volumes of data, and the combination of HDFS and MapReduce delivered this capability in a way that (at least at the very large scale) was not possible before and hasn’t really been superseded since. Pig and Hive were introduced as nicer ways to write MapReduce code, but didn’t fundamentally change anything. Hadoop, being open sourced, was then picked up a number of companies (both vendors and users) and taken in a couple of (largely complementary) directions.&lt;/p&gt; &lt;p&gt;First, HDFS was positioned as a great place to put all your data so that you could run a range of analytics over the top - the mythical Data Lake (although we’ll definitely talk about the challenges of building a Data Lake with Hadoop at some point). This required new technologies to bring data in (Flume and Sqoop for example), new technologies to exploit this data (Spark and Mahout for example), and a way to make all these technologies play nicely together (YARN). However there’s only so far that data in a filesystem will get you in terms of analytics - if you’re looking to do anything outside of batch appends and scanning workloads you’re going to struggle.&lt;/p&gt; &lt;p&gt;And so other technologies were introduced that used HDFS as an underlying storage technology to enable new data storage capabilities - HBase as a NoSQL database and Solr for search indexing for example. And what that created was not a single place to put all your data, but a range of complementary technologies that support different use cases, but that can share underlying infrastructure. All of which is good.&lt;/p&gt; &lt;p&gt;But there were always going to be challenges trying to move Hadoop from where it started to a more general purpose capability - you’re always going to be pushing against it’s original architectural and design decisions. HDFS is not a general purpose cluster filesystem - it was designed for a specific use case (for example it can only do file appends rather than random updates and has a hard limit on the number of files it can hold based on the memory capacity of the Name Node for), which can cause limitations when trying to use it for more general purpose analytics or to underpin other technologies (Kudu has chosen not run over HDFS for example). And YARN was a relatively late addition to Hadoop, meaning many Hadoop technologies don’t support it (including Flume, Solr and HBase, although Hortonworks is trying to address this through Slider). Which means we’re now in a position whereby you potentially have multiple technologies competing rather than co-existing on our Hadoop cluster, which feels like it’s starting to dilute some of the potential value. If you’re interested in which technologies do or don’t run over HDFS / YARN, I’ve tried to summarise it in diagrammatic form &lt;a href=&quot;/tech-categories/hadoop-distributions/ecosystem/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So what are your options around Hadoop? Firstly, as an ecosystem it contains a good set of technologies. HDFS plus Hive/Spark/etc. is a great platform for doing batch scanning analytical workloads. HBase and Solr are great technologies that stand up well to their competition, and Hive and Impala are starting to provide some serious competition for the established MPP database vendors. Deploying any one of these technologies to fulfil a role in your wider analytical ecosystem will do you well, but if you’re going to use a commercial service you’ll need to find a cost effective way of doing this - you don’t want to be buying the entire ecosystem if you’re not going to use it all. This is where Cloudera are going - starting to offer tailor packages that include sub-sets of the components focusing on specific use cases, and most of the Cloud or Hadoop as a Service offerings allow you to only pay for what you use.&lt;/p&gt; &lt;p&gt;Or you can deploy Hadoop as a common analytical platform - a single set of infrastructure and a single purchase to give you a single platform that can deliver you a range of capabilities and fulfil a range of roles in a cost effective way. Note that this generally only works if you’re deploying on site rather than using the Cloud however. This is where Hortonworks and MapR are focusing - Hortonworks is investing in technologies such as Slider to allow everything to integrate with YARN, and MapR have built their entire offering around their own shared multi-tenancy storage capability (MapR-FS) that is designed and built for exactly this use case (and fulfils it better than HDFS).&lt;/p&gt; &lt;p&gt;In summary, Hadoop like any technology has it’s strengths and weaknesses. It’s not the be all and end all, it’s certainly not going to solve all your problems and magically make you a data driven organisation, it’s not going to dramatically decrease your costs, and deploying it is going to be as much hard work than deploying any other technology. However I’m hoping that the material I’ve added to this site over the last few months will help you start to understand what Hadoop is and how it might mean one or more of your use cases, whether that’s helping you start an evaluation of how one of it’s technologies stacks up against it’s competition, or to understand the ecosystem and how a specific distribution or offering can meet your range of use cases.&lt;/p&gt; &lt;p&gt;So that’s some thoughts on why Hadoop - on Monday we’ll summarise the options for how you can get it…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/12/why-choose-hadoop/</guid> </item> <item><title>Hadoop Ecosystem</title><link>http://ondataengineering.net/tech-categories/hadoop-distributions/ecosystem/</link><pubDate>Thu, 11 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A view of the ecosystem around HDFS and YARN - the two major Hadoop components. Note that many technologies are not exclusive, and may run over other cluster filesystems or over other cluster management frameworks. Some technologies may be excluded for brevity and clarity.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;hdfs-ecosystem&quot;&gt;HDFS Ecosystem&lt;/h2&gt; &lt;p&gt;&lt;img src=&quot;/images/hdfs-ecosystem.png&quot; alt=&quot;HDFS Ecosystem&quot; /&gt;&lt;/p&gt; &lt;h2 id=&quot;yarn-ecosystem&quot;&gt;YARN Ecosystem&lt;/h2&gt; &lt;p&gt;&lt;img src=&quot;/images/yarn-ecosystem.png&quot; alt=&quot;YARN Ecosystem&quot; /&gt;&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop-distributions/ecosystem/</guid> </item> <item><title>Hadoop Distributions Comparison</title><link>http://ondataengineering.net/tech-categories/hadoop-distributions/distribution-comparison/</link><pubDate>Wed, 10 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A comparison of different Hadoop distributions, focusing on the different software packages available in each to enable an understanding of whether a distribution contains the appropriate software to meet a requirement or business case.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Component&lt;/th&gt; &lt;th&gt;Cloudera&lt;/th&gt; &lt;th&gt;HW&lt;/th&gt; &lt;th&gt;MapR&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Cluster Management&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn&quot;&gt;YARN&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn&quot;&gt;YARN&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-slider&quot;&gt;Slider&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn&quot;&gt;YARN&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-myriad&quot;&gt;Myriad&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Cluster Filesystem&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/hdfs&quot;&gt;HDFS&lt;/a&gt;; &lt;a href=&quot;/technologies/recordservice&quot;&gt;RecordService&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/hdfs&quot;&gt;HDFS&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system&quot;&gt;MapR-FS&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;NoSQL Datastore&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Accumulo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-accumulo&quot;&gt;Accumulo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/mapr-db&quot;&gt;MapR-DB&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt;;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SQL Datastore&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kudu&quot;&gt;Kudu&lt;/a&gt; + &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Impala&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-phoenix&quot;&gt;Phoenix&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hawq&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Streaming Datastore&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Batch Analytics&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive&quot;&gt;Hive&lt;/a&gt; (on Spark); &lt;a href=&quot;/technologies/apache-hadoop/map-reduce&quot;&gt;MapReduce&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-pig&quot;&gt;Pig&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark&quot;&gt;Spark&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive&quot;&gt;Hive&lt;/a&gt; (on Tez); &lt;a href=&quot;/technologies/apache-hadoop/map-reduce&quot;&gt;MapReduce&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-pig&quot;&gt;Pig&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark&quot;&gt;Spark&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-hawq&quot;&gt;Hawq&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive&quot;&gt;Hive&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-hadoop/map-reduce&quot;&gt;MapReduce&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-pig&quot;&gt;Pig&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark&quot;&gt;Spark&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Streaming Analytics&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/spark-streaming&quot;&gt;Spark Streaming&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/spark-streaming&quot;&gt;Spark Streaming&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Storm&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/spark-streaming&quot;&gt;Spark Streaming&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-storm&quot;&gt;Storm&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Graph Analytics&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/graphx&quot;&gt;Spark GraphX&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/graphx&quot;&gt;Spark GraphX&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/graphx&quot;&gt;Spark GraphX&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Interactive SQL&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-impala&quot;&gt;Impala&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive&quot;&gt;Hive&lt;/a&gt; (LLAP)&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-drill&quot;&gt;Drill&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Impala&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Machine Learning&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mahout&quot;&gt;Mahout&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark/mllib&quot;&gt;Spark MLlib&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mahout&quot;&gt;Mahout&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark/mllib&quot;&gt;Spark MLlib&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mahout&quot;&gt;Mahout&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-spark/mllib&quot;&gt;Spark MLlib&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Search&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-solr&quot;&gt;Solr&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-solr&quot;&gt;Solr&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-solr&quot;&gt;Solr&lt;/a&gt; (available as an add on pack)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Data Ingestion&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sqoop&quot;&gt;Sqoop&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-flume&quot;&gt;Flume&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sqoop&quot;&gt;Sqoop&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-flume&quot;&gt;Flume&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sqoop&quot;&gt;Sqoop&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-flume&quot;&gt;Flume&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Data Flow Management&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-falcon&quot;&gt;Falcon&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Workflow Management&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-oozie&quot;&gt;Oozie&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-oozie&quot;&gt;Oozie&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-oozie&quot;&gt;Oozie&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Security&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Sentry&lt;/a&gt;; &lt;a href=&quot;/technologies/recordservice&quot;&gt;RecordService&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-knox&quot;&gt;Knox&lt;/a&gt;; &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Ranger&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Sentry&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Management&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-manager&quot;&gt;Cloudera Manager&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Ambari&lt;/a&gt;&lt;/td&gt; &lt;td&gt;MapR Installer; MapR Control System; &lt;a href=&quot;/technologies/mapr-monitoring&quot;&gt;MapR Monitoring&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Metadata&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-navigator&quot;&gt;Cloudera Navigator&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Atlas&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Cloud Management&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-director&quot;&gt;Cloudera Director&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;User Interfaces&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-zeppelin&quot;&gt;Zeppelin&lt;/a&gt;; &lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop-distributions/distribution-comparison/</guid> </item> <item><title>Hadoop Distributions</title><link>http://ondataengineering.net/tech-categories/hadoop-distributions/</link><pubDate>Tue, 09 May 2017 00:00:00 +0100</pubDate> <description> &lt;p&gt;A software bundle built around Hadoop or an Hadoop compatible core that's often delivered as a managed service and that provides a single solution to support a range of analytical capabilities in a single deployment or service. Hadoop compatibility covers the use of YARN (for resource management of multiple jobs running on the same infrastructure), HDFS (for local storage of data with support for co-locating processing with the relevant data) and a range of cloud based storage APIs (including S3, Azure Blob Storage and OpenStack Swift), with the use of a cloud based storage API de-coupling storage from processing, allowing transient processing clusters to run against persistent storage at the cost of reduced performance.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;See also our &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;comparison of Hadoop distributions&lt;/a&gt;, our Hadoop (HDFS and YARN) &lt;a href=&quot;/tech-categories/hadoop-distributions/ecosystem/&quot;&gt;ecosystem diagrams&lt;/a&gt;, and our summary of the &lt;a href=&quot;/tech-vendors/odpi/&quot;&gt;ODPi&lt;/a&gt; organisation.&lt;/p&gt; &lt;h2 id=&quot;technologies&quot;&gt;Technologies&lt;/h2&gt; &lt;p&gt;Distributions from major commercial vendors that are available for installation on-premises or on most major clouds:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distribution of Hadoop based on the addition of a number of closed source products, including Cloudera Manager (for installing and managing clusters) and Cloudera Navigator (for managing metadata and the encryption of data). Available in free and commercial editions.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distribution of Hadoop based on a commitment to the Apache open source ecosystem, utilising only open source products with minimal extra patching. Free to use with commercial support available.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A data platform built around MapR-FS (along with MapR-DB and MapR-Streams) that provides Hadoop compatibility (via YARN and the MapR-FS HDFS compatible API) and is bundled with a package of Hadoop projects via the MapR Ecosystem Pack. Available in free and commercial editions.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM InfoSphere BigInsights&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.ibm.com/us-en/marketplace/biginsights&quot;&gt;https://www.ibm.com/us-en/marketplace/biginsights&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Distributions from major commercial vendors as a cloud / service offering:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Amazon EMR&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://aws.amazon.com/emr/&quot;&gt;https://aws.amazon.com/emr/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Microsoft Azure HD Insight&lt;/td&gt; &lt;td&gt;Based on Hortonworks HDP - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/hdinsight/&quot;&gt;https://azure.microsoft.com/en-us/services/hdinsight/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Dataproc&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://cloud.google.com/dataproc/&quot;&gt;https://cloud.google.com/dataproc/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Rackspace&lt;/td&gt; &lt;td&gt;Based on Hortonworks HDP - &lt;a href=&quot;https://www.rackspace.com/big-data&quot;&gt;https://www.rackspace.com/big-data&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Altiscale (SAP)&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.altiscale.com/big-data-as-a-service/altiscale-data-cloud/product/&quot;&gt;https://www.altiscale.com/big-data-as-a-service/altiscale-data-cloud/product/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Distributions available as a hardware appliance:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Teradata Appliance for Hadoop&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www.teradata.com/products-and-services/appliance-for-hadoop&quot;&gt;http://www.teradata.com/products-and-services/appliance-for-hadoop&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle Big Data Appliance&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.oracle.com/engineered-systems/big-data-appliance/index.html&quot;&gt;https://www.oracle.com/engineered-systems/big-data-appliance/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;On-premise or cloud based solutions offered by smaller commercial vendors that may provide a more cost effective or personal service for smaller organisations:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Xplenty&lt;/td&gt; &lt;td&gt;Includes as part of a Data Integration platform service - &lt;a href=&quot;https://www.xplenty.com&quot;&gt;https://www.xplenty.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Qubole Data Service&lt;/td&gt; &lt;td&gt;Runs on the major clouds - &lt;a href=&quot;https://www.qubole.com/&quot;&gt;https://www.qubole.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Syncfusion Big Data Platform&lt;/td&gt; &lt;td&gt;Distribution for Windows - &lt;a href=&quot;https://www.syncfusion.com/products/big-data&quot;&gt;https://www.syncfusion.com/products/big-data&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Other distributions, either more experimental or without commercial backing:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An Apache open source distribution of Hadoop. Packages up a number of Apache Hadoop components, certifies their interoperability using an automated integration test suite, and packages them up as RPMs/DEBs packages for most flavours of Linux.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OpenStack Sahara&lt;/td&gt; &lt;td&gt;Allows provisioning of Hadoop on OpenStack - &lt;a href=&quot;https://docs.openstack.org/developer/sahara/&quot;&gt;https://docs.openstack.org/developer/sahara/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hops&lt;/td&gt; &lt;td&gt;A distribution based on Hops HDFS and Hops YARN which use a distributed MySQL database for metadata to increase performance and scalability, available as a cloud or on premises offering - &lt;a href=&quot;http://www.hops.io&quot;&gt;http://www.hops.io&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Historical or legacy distributions that are no longer available, or are now simply re-badged versions of other distributions:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Intel Distribution for Apache Hadoop&lt;/td&gt; &lt;td&gt;Focused on optimisations for Intel processors, SSD disks and networking kit; ceased when Intel invested into Cloudera - see &lt;a href=&quot;https://newsroom.intel.com/news-releases/cloudera-intel-commit-to-accelerate-and-transform-how-enterprises-use-big-data-intel-makes-significant-equity-investment-in-cloudera/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Pivotal HD&lt;/td&gt; &lt;td&gt;Pivotal has now partnered with Hortonworks - see &lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop-distributions/</guid> </item> <item><title>Hadoop Distros Week</title><link>http://ondataengineering.net/blog/2017/05/08/hadoop-distros-week/</link><pubDate>Mon, 08 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;We’ve now finished looking at the major players in the Hadoop distributions space, so I’d like to take this week to look at Hadoop and Hadoop distributions in a bit more detail, and flesh out our &lt;a href=&quot;tech-categories/hadoop_distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;There’s obviously a whole pile of technologies that sit in this space we’ve not looked at, so first steps will be to refresh our definition of an Hadoop distribution, and try and get a slightly more complete list in place, including the Cloud Hadoop-as-a-service offerings, the smaller more boutique vendors, the appliances and maybe a footnote on the distributions that are no longer with us.&lt;/p&gt; &lt;p&gt;I’d then like to look at the Hadoop ecosystem in a bit more detail, and try and map out which components sit where. I’d also like to try and do a comparison between the major offerings, focusing on the different technologies they include. And finally, assuming I’ve not run out of time, a quick look at ODPI (The Open Data Platform Initiative).&lt;/p&gt; &lt;p&gt;Right, time to crack on - see you shortly.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/08/hadoop-distros-week/</guid> </item> <item><title>The Week That Was - 05/05/2017</title><link>http://ondataengineering.net/blog/2017/05/05/the-week-that-was/</link><pubDate>Fri, 05 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s nearly the weekend, which means it’s time to summarise the week.&lt;/p&gt; &lt;p&gt;We started late this week (let’s hear it for public holidays), finishing off our look at MapR, before taking a quick look at Cloudera’s &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Data Science Workbench&lt;/a&gt;. No technology summary today, but we’ll take a look at Apache Metron as part of this post. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;What I’ve really liked about MapR is their strategy around their common data platform to underpin a bunch of different data storage capabilities. I talked a little bit about their data platform &lt;a href=&quot;/blog/2017/04/28/the-week-that-was/&quot;&gt;last time&lt;/a&gt;, but this week as part of looking at &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; and &lt;a href=&quot;/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt; I’ve been thinking about how this compares and contrasts to Hadoop. Firstly, they’re both aiming to provide a common data platform that provides the ability to have a single cluster than can provide flexibility and value for money by allowing you to exploit the same infrastructure for multiple use cases. MapR appears to have fully embraced this, ensuring they support the ability to scale, partition and manage the platform in ways that Hadoop can’t yet, and by providing capabilities that Hadoop (and more specifically HDFS) doesn’t that actually make it work as a general purpose data platform - full random read and write access for starters. I’m also taken by MapR’s ability to provide access to the common data platform at different layers - rather than just build capabilities on top of their file system API, they’ve integrated (for example) MapR-DB at a much lower level, providing a range of benefits over HBase running over HDFS. It’s clear that Hadoop still has a long way to go to fulfil it’s potential, and without addressing some of it’s limitations we’re going to continue to see new technologies opting to implement their own storage systems from scratch (Kudu being a great example), leading to Hadoop clusters running multiple independent storage stacks on the same data nodes, which feels like it’s defeating the point.&lt;/p&gt; &lt;p&gt;I’ve also started wondering why there aren’t more common storage sub-system’s that multiple technologies leverage - not necessarily so that they could all co-exist on the same cluster (along this would be a side benefit), but just because storage systems are hard and complex, and it feels like there should be huge wins by having a strong and robust solution that can be leveraged for multiple capabilities. There are very few data platforms that don’t have some limitation or constraint, and that a world class storage system with a range of APIs implemented on top could be instantly competitive against a wide range of technologies. MapR are starting to demonstrate this - there’s certainly some evidence that MapR-Streams leverages their data platform and a Kafka compatible API to provide a solution that addresses a number of Kafka’s limitations.&lt;/p&gt; &lt;p&gt;Moving on, Cloudera’s &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Data Science Workbench&lt;/a&gt; is now generally available. Their use of docker seems inspired - the flexibility this gives you to use different versions of different libraries in different notebooks, and to have this execution environment follow the notebook around feels like a huge win. It’s still early days for the product however - the number of interpreters seems light (not being able to run SQL or Solr searches directly in the notebook feels like a gap), and it remains to be seen how it will fair as a commercial product against the open source &lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Apache Zeppelin&lt;/a&gt; and Jupyer.&lt;/p&gt; &lt;p&gt;I said on Wednesday I’d do a technology summary of &lt;a href=&quot;http://metron.apache.org/&quot;&gt;Apache Metron&lt;/a&gt;, however I’ve decided as a packaged analytical application it’s probably slightly outside the conceptual remit of this site. It’s definitely worth digging into if you have time however, as it’s an interesting use case for what can be done with the Hadoop ecosystem, and an interesting capability in it’s own right. If you’re looking for reading material, there’s the &lt;a href=&quot;http://metron.apache.org/&quot;&gt;Apache Metron homepage&lt;/a&gt;, &lt;a href=&quot;https://hortonworks.com/apache/metron/&quot;&gt;Hortonwork’s overview of Metron&lt;/a&gt;, and their &lt;a href=&quot;http://docs.hortonworks.com/HDPDocuments/HCP1/HCP-1.1.0/index.html&quot;&gt;user documentation&lt;/a&gt;, but a good a place to start as any is the &lt;a href=&quot;https://cwiki.apache.org/confluence/display/METRON/Metron+Architecture&quot;&gt;architecture overview&lt;/a&gt; in the Apache Metron Wiki. In summary, the architectures probably fairly standard - Apache Kafka as an input point, fed by custom probes and Apache NiFi, with data then processed using Apache Storm supporting a level of data transformation and enrichment, real time alerting and built in scoring using machine learning models, with persistence of storage into HDFS and HBase, and then a range of dashboards and visualisation capabilities over the top. Apache Spark is in there somewhere as well.&lt;/p&gt; &lt;p&gt;That’s all (for this week) folks - see you on Monday.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/05/the-week-that-was/</guid> </item> <item><title>Cloudera Data Science Workbench</title><link>http://ondataengineering.net/technologies/cloudera-data-science-workbench/</link><pubDate>Thu, 04 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A web based notebook for interactive data analytics that uses docker to provide custom execution environments for each notebook. Supports Python, R and Scala interpreters, plus remote execution of Spark with out of the box support for Hadoop security. Notebook code is run within a docker container in a managed Kubernetes instance, allowing different libraries to be installed and used by different notebooks, and other dependancies to be installed via terminal access to the container or via custom Docker images. Also includes support for version control (via git), collaboration via shared projects, sharing of notebooks via HTTP URLs, publishing of notebooks as HTML and scheduled execution of notebooks via workflows (including dependancies on other jobs). Originally created by Sense.io, which was acquired by Cloudera in March 2016. Initial GA release was 1.0 in April 2017.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017 - v1.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;2017-04-26&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/Announce-Cloudera-Data-Science-Workbench-is-now-available/m-p/54177#M173&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Initial release&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html&quot;&gt;https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/cloudera-data-science-workbench-self-service-data-science-for-the-enterprise/&quot;&gt;http://vision.cloudera.com/cloudera-data-science-workbench-self-service-data-science-for-the-enterprise/&lt;/a&gt; - introductory blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/data-science-workbench/latest.html&quot;&gt;https://www.cloudera.com/documentation/data-science-workbench/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-data-science-workbench/</guid> </item> <item><title>The Mid Week News - 03/05/2017</title><link>http://ondataengineering.net/blog/2017/05/03/the-mid-week-news/</link><pubDate>Wed, 03 May 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;So, I failed at the first hurdle in trying to do this weekly, however let’s carry on regardless.&lt;/p&gt; &lt;p&gt;This week - new products from Cloudera and Hortonworks, a bunch of Hortonworks and Cloudera releases that got missed last time, plus a collection of blog posts I’ve been collecting for a while. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;In terms of the new products from Cloudera and Hortonworks, we’ve seen &lt;a href=&quot;https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; and &lt;a href=&quot;https://hortonworks.com/apache/metron/&quot;&gt;Apache Metron&lt;/a&gt; formally released recently. I’m aiming to do tech summaries for both this week and we’ll look at these a bit closer.&lt;/p&gt; &lt;p&gt;Some Hortonworks updates that we missed last time - &lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws&quot;&gt;Hortonworks Data Cloud for AWS&lt;/a&gt; has seen a new release to 1.14, &lt;a href=&quot;/technologies/hortonworks-smartsense/&quot;&gt;Hortonworks SmartSense&lt;/a&gt; got a bump to 1.4, and it looks like &lt;a href=&quot;/technologies/hortonworks-data-platform-for-windows/&quot;&gt;HDP for Windows&lt;/a&gt; got discontinued whilst I wasn’t looking - 2.4 was the final version!&lt;/p&gt; &lt;p&gt;And on the Cloudera front, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-director&quot;&gt;Cloudera Director&lt;/a&gt; have all seen version bumps as part of the CDH 5.11 release&lt;/p&gt; &lt;p&gt;And finally, some assorted blog posts that have caught my attention recently:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Cloudera have released &lt;a href=&quot;http://blog.cloudera.com/blog/2017/04/apache-impala-leads-traditional-analytic-database/&quot;&gt;their last blog post&lt;/a&gt; on how much faster Impala is than anything else. Expect one from Hortonworks shortly that shows that Hive LLAP is actually the fastest.&lt;/li&gt; &lt;li&gt;From the ever excellent “The Morning Paper”, &lt;a href=&quot;https://blog.acolyer.org/2017/03/06/hopfs-scaling-hierarchical-file-system-metadata-using-newsql-databases/amp/&quot;&gt;a summary of a research paper on HopFS&lt;/a&gt;, a version of HDFS where the in-memory metadata database in the Name Node is replaced with a distributed database, allowing it to scale to much larger numbers of files and dramatically increase throughput.&lt;/li&gt; &lt;li&gt;An interesting &lt;a href=&quot;http://www.odbms.org/blog/2017/03/on-the-new-developments-in-apache-spark-and-hadoop-interview-with-amr-awadallah/&quot;&gt;interview with the CTO of Cloudera&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Merv Adrian’s latest &lt;a href=&quot;http://blogs.gartner.com/merv-adrian/2017/03/16/hadoop-tracker-march-2017/&quot;&gt;Hadoop tracker&lt;/a&gt; is out. I’m not sure you can directly compare the component versions in Hadoop distributions given how much each vendor pulls patches forward, but it’s an interesting analysis never-the-less.&lt;/li&gt; &lt;li&gt;The Flink blog has been busy with a &lt;a href=&quot;http://data-flair.training/blogs/apache-flink-ecosystem-components-tutorial/&quot;&gt;summary of the Flink ecosystem&lt;/a&gt; and a &lt;a href=&quot;http://data-flair.training/blogs/spark-vs-flink-vs-hadoop-comparison/&quot;&gt;comparison of Flink to Spark and MapReduce&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datanami.com/2017/03/13/hadoop-failed-us-tech-experts-say/&quot;&gt;Hadoop has failed us&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Some &lt;a href=&quot;http://www.zdnet.com/article/at-analyst-conference-cloudera-focuses-message-pleads-the-fifth-on-ipo-rumors/&quot;&gt;analysis on Cloudera’s strategy&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Tech deep dives into &lt;a href=&quot;https://blogs.apache.org/hbase/entry/accordion-hbase-breathes-with-in&quot;&gt;HBase In-Memory Compaction&lt;/a&gt; and &lt;a href=&quot;http://blog.cloudera.com/blog/2017/04/apache-kudu-read-write-paths/&quot;&gt;Kudu read write paths&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And &lt;a href=&quot;https://www.theregister.co.uk/2017/04/07/google_cloud_platform_partners_with_elastic_in_new_analytics_stretch/&quot;&gt;Elasticsearch is coming to Google’s Cloud Platform&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And last but not least - Matt Turck’s monster &lt;a href=&quot;http://mattturck.com/bigdata2017/&quot;&gt;2017 Big Data Landscape&lt;/a&gt; - essential reading&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/05/03/the-mid-week-news/</guid> </item> <item><title>MapR Converged Data Platform</title><link>http://ondataengineering.net/technologies/mapr-converged-data-platform/</link><pubDate>Wed, 03 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A data platform built around MapR-FS (along with MapR-DB and MapR-Streams) that provides Hadoop compatibility (via YARN and the MapR-FS HDFS compatible API) and is bundled with a package of Hadoop projects via the MapR Ecosystem Pack. Comes with an installer (MapR Installer) and a web based user interface for management (MapR Control System). Available as a single node version (for development and testing), as MapR Edge (a small footprint edition that can run on low power and embedded hardware close to data sources to perform initial data filtering and processing before forwarding data on to a central cluster via MapR replication), and as MapR Converged Data Platform for Docker (a marketing name for using the Converged Data Platform as persistent storage for docker containers, which is supported by the availability of PACC, the Persistent Application Client Container, a docker image containing the client libraries required for connecting to a MapR Converged Data Platform). Distributed as a free community edition (which excludes some enterprise features such as snapshots, high availability, disaster recovery and replication), and as a number of commercial editions. First released as MapR v1.0 in 2010&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;MapR Edge, MapR Converged Data Platform for Docker&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017 - 5.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/map-reduce/&quot;&gt;MapReduce&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-file-system/&quot;&gt;MapR File System&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-converged-data-platform/&quot;&gt;https://mapr.com/products/mapr-converged-data-platform/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapROverview/c_overview_intro.html&quot;&gt;http://maprdocs.mapr.com/home/MapROverview/c_overview_intro.html&lt;/a&gt; - overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/ReleaseNotes/c_relnotes_intro.html&quot;&gt;http://maprdocs.mapr.com/home/ReleaseNotes/c_relnotes_intro.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/InteropMatrix/r_release_dates.html&quot;&gt;http://maprdocs.mapr.com/home/InteropMatrix/r_release_dates.html&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://doc.mapr.com/&quot;&gt;http://doc.mapr.com/&lt;/a&gt; - documentation for previous releases (prior to 5.0)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/edge&quot;&gt;https://mapr.com/products/edge&lt;/a&gt; - MapR Edge home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://community.mapr.com/community/products/blog/2017/03/14/introducing-mapr-edge&quot;&gt;https://community.mapr.com/community/products/blog/2017/03/14/introducing-mapr-edge&lt;/a&gt; - introduction to MapR Edge&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/persistent-application-client-container/&quot;&gt;https://mapr.com/products/persistent-application-client-container/&lt;/a&gt; - PACC homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://community.mapr.com/community/products/blog/2017/02/07/persistence-in-the-age-of-microservices-introducing-mapr-converged-data-platform-for-docker&quot;&gt;https://community.mapr.com/community/products/blog/2017/02/07/persistence-in-the-age-of-microservices-introducing-mapr-converged-data-platform-for-docker&lt;/a&gt; - introduction to MapR Converged Data Platform for Docker&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Announcements via the MapR product announcements blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-converged-data-platform/</guid> </item> <item><title>MapR</title><link>http://ondataengineering.net/tech-vendors/mapr/</link><pubDate>Wed, 03 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;MapR is a commercial company focusing on products built around it's enterprise data platform. Their strategy is based on their enterprise data platform providing a range of different capabilities including filesystem, NoSQL and streaming data, plus NFS, HDFS, HBase and Kafka API compatibility, and Hadoop support with an associated package of Hadoop components. They have started and are active in a number of open source components, including Apache Drill and Apache Myriad. MapR was founded in 2009.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;vendor-technologies&quot;&gt;Vendor Technologies&lt;/h2&gt; &lt;p&gt;MapR’s primary offering is their &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;Converged Data Platform&lt;/a&gt; - a product built around their enterprise data platform that provides Hadoop compatibility and comes with an add on package of Hadoop components, and which is supported by &lt;a href=&quot;https://mapr.com/products/hadoop-as-a-service/&quot;&gt;most major cloud platform vendors&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/&quot;&gt;https://mapr.com/&lt;/a&gt; - company homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/&quot;&gt;https://mapr.com/products/&lt;/a&gt; - products homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/&quot;&gt;http://maprdocs.mapr.com/home/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/hadoop-as-a-service/&quot;&gt;https://mapr.com/products/hadoop-as-a-service/&lt;/a&gt; - MapR cloud vendor support&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/&quot;&gt;https://mapr.com/blog/&lt;/a&gt; - MapR blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://community.mapr.com/docs/DOC-1426-how-to-get-notified-of-release-product-and-patch-announcements&quot;&gt;https://community.mapr.com/docs/DOC-1426-how-to-get-notified-of-release-product-and-patch-announcements&lt;/a&gt; - product and patch announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/mapr/</guid> </item> <item><title>MapR-Streams</title><link>http://ondataengineering.net/technologies/mapr-file-system/mapr-streams/</link><pubDate>Tue, 02 May 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Extension to MapR-FS to provide streaming data storage capabilities and a Kafka compatible API. Messages (key/value pairs where the key is optional) are organised into topics, which are partitioned and stored as first class objects within MapR-FS volumes, with topics then grouped into streams. Supports encryption of streams, automatic deletion of messages (via a time to live), consumer groups, authorisation using ACEs (access control expressions), plus replication of topics to one or more remote MapR-Streams instances either synchronously or asynchronously, including support for Kafka's MirrorMaker. Comes with Java, C and Python libraries and includes a Kafka compatible API. Introduced in MapR 5.1 in Feb 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/&quot;&gt;MapR File System&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-streams-clients-and-tools/&quot;&gt;MapR Streams Clients and Tools&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-streams/&quot;&gt;https://mapr.com/products/mapr-streams/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapROverview/c_mapr_streams.html&quot;&gt;http://maprdocs.mapr.com/home/MapROverview/c_mapr_streams.html&lt;/a&gt; - overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapR_Streams/mapr_streams.html&quot;&gt;http://maprdocs.mapr.com/home/MapR_Streams/mapr_streams.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/kafka-vs-mapr-streams-why-mapr/&quot;&gt;https://mapr.com/blog/kafka-vs-mapr-streams-why-mapr/&lt;/a&gt; - comparison to Kafka&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-file-system/mapr-streams/</guid> </item> <item><title>The Week That Was - 28/04/2017</title><link>http://ondataengineering.net/blog/2017/04/28/the-week-that-was/</link><pubDate>Fri, 28 Apr 2017 08:15:00 +0100</pubDate> <description> &lt;p&gt;Time for our weekly round up of the week again.&lt;/p&gt; &lt;p&gt;We finished off the new open source technologies in the MapR Ecosystem Pack at the beginning of the week, looking at &lt;a href=&quot;/technologies/apache-myriad&quot;&gt;Apache Myriad&lt;/a&gt;, which support running YARN over Mesos.&lt;/p&gt; &lt;p&gt;We then looked at the two MapR specific packages in the MapR Ecosystem Pack - &lt;a href=&quot;/technologies/mapr-monitoring/&quot;&gt;MapR Monitoring&lt;/a&gt;, a collection of open source components for collecting and visualising metrics and log files across the MapR ecosystem, and &lt;a href=&quot;/technologies/mapr-streams-clients-and-tools/&quot;&gt;MapR Streams Clients and Tools&lt;/a&gt;, a package of Kafka components that run over the top of MapR Streams.&lt;/p&gt; &lt;p&gt;And we finished the week with a look at the meat of MapR’s offering - &lt;a href=&quot;/technologies/mapr-file-system&quot;&gt;MapR-FS&lt;/a&gt;, and the fist of it’s sub-projects &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-myriad&quot;&gt;Apache Myriad&lt;/a&gt; provides connectivity between YARN and Mesos, effectively allowing YARN to run on a Mesos cluster, either dynamically or statically being assigned resources from Mesos that it then assigns to YARN jobs. It’s had some significant backing from eBay, MapR and Mesosphere, however the project seems to have gone very quiet with no commits since October 2016, so it’s either done, hit a brick wall or it’s going nowhere. If anyone knows, I’d like to hear.&lt;/p&gt; &lt;p&gt;I’d like to talk more about monitoring analytical systems and data transformation jobs in the future, however &lt;a href=&quot;/technologies/mapr-monitoring/&quot;&gt;MapR Monitoring&lt;/a&gt; is a really good reference example of what can be done. It combines collectd, OpenTSDB and Grafana for capturing, storing and visualising metrics and statistics, and fluentd, Elasticsearch and Kibana for capturing, storing and exploiting log files. It’s nice to see someone with an Hadoop distribution that uses the best of breed open source technologies rather than building yet more bespoke and custom solutions.&lt;/p&gt; &lt;p&gt;MapR provides MapR-Streams as their alternative to Kafka (and includes a Kafka compatible API for good measure), however there are parts of the Kafka ecosystem that are still useful, and &lt;a href=&quot;/technologies/mapr-streams-clients-and-tools/&quot;&gt;MapR Streams Clients and Tools&lt;/a&gt; provides these - specifically the Kafka REST Proxy and &lt;a href=&quot;/technologies/apache-kafka/kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt;. Which is nice.&lt;/p&gt; &lt;p&gt;And so on to &lt;a href=&quot;/technologies/mapr-fs&quot;&gt;MapR-FS&lt;/a&gt;. I have to admit to being surprised by MapR’s offerings. I’d always assumed they were a knock-off Hadoop distribution that was trying to find leverage by embedding a bunch of commercial components, however what’s become clear is that what they’re selling is not an Hadoop distribution but an enterprise data platform (based on MapR-FS) that just happens to have Hadoop compatibility. In short it’s highly resilient, scalable and performant, with support for full random read/write access, multi-tenancy, block level replication, snapshots, quotas, extensive and flexible access control, which supports a fully POSIX compliant filesystem with HDFS, NFS and FUSE APIs, a document and wide column datastore with OJAI and HBase APIs, a streaming data stores with Kafka compatible APIs, master-slave and master-master replication of database and streaming data stores, plus YARN support, meaning you can run any Hadoop compatible tool over the top. That’s a lot of capability in a single platform, which feels like it’s going to drive a strong TCO story.&lt;/p&gt; &lt;p&gt;I’ve broken out the database and streams capabilities into sub-projects, primarily because MapR talk about them as different products, even though they’re technically all part of the same solution. We’ve looked at &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; this week, and will look at MapR-Streams first thing next week.&lt;/p&gt; &lt;p&gt;It’s another public holiday here in the UK on Monday, so no update then, however we’ll be back on Tuesday, and will hopefully round out our look at MapR next week. If you’re in the UK enjoy your long weekend, otherwise have fun at work on Monday.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/28/the-week-that-was/</guid> </item> <item><title>MapR-DB</title><link>http://ondataengineering.net/technologies/mapr-file-system/mapr-db/</link><pubDate>Fri, 28 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Extension to MapR-FS to provide NoSQL capabilities, supporting JSON document and wide column tables and HBase and OJAI (Open JSON application interface) APIs. Tables are stored as first class objects in MapR-FS volumes, and are sharded into table regions / tablets. JSON document tables are schemaless, support read and write access to individual document fields, subsets of fields or whole documents, finding documents by id or via a full table scan query, a set of atomic operations for mutating documents, and integration with MapReduce. Wide column (binary) tables are largely equivalent to HBase tables, and partially support the HBase API, but without support for custom HBase filters or co-processors. Supports replication at the table, column family or column level, either synchronously or asynchronously, and in either master-master or master-slave configurations, with support for replicating to Elasticsearch. Authentication is managed through access control expressions (ACEs) at the field level (for JSON document tables) or at the column level (for wide column tables). Introduced in MapR v4.0 in Sept 2014, with document supported added in MapR 5.1 in Feb 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/&quot;&gt;MapR File System&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-db-in-hadoop-nosql/&quot;&gt;https://mapr.com/products/mapr-db-in-hadoop-nosql/&lt;/a&gt; - product homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapROverview/maprDB-overview.html&quot;&gt;http://maprdocs.mapr.com/home/MapROverview/maprDB-overview.html&lt;/a&gt; - overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapR-DB/developing_client_applications_for_mapr_db.html&quot;&gt;http://maprdocs.mapr.com/home/MapR-DB/developing_client_applications_for_mapr_db.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-file-system/mapr-db/</guid> </item> <item><title>MapR File System</title><link>http://ondataengineering.net/technologies/mapr-file-system/</link><pubDate>Thu, 27 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;An HDFS compatible, highly resilient distributed cluster file system that boasts of a number of improvements over HDFS, and includes support for NoSQL database tables (MapR-DB) and streaming data (MapR-Streams), both of which we treat as sub-projects. Supports the HDFS API, full NFS and FUSE support, POSIX compliance, arbitrary in place updates to files (unlike HDFS which is append only), distributed metadata (it has no equivalent of the HDFS Name Node), block level mirroring to a remote cluster for DR or load balancing, and snapshots (which provide point in time read only views). Data is stored in containers (which manage data blocks and the replication of these over the cluster), and logically organised into volumes (which manage files, directories and block allocation across one or more containers), which also provide multi-tenancy support, with administrative control, data placement, job execution, snapshots and mirroring all configurable against a volume. Supports encrypted communications, full auditing capabilities, Kerberos and Linux PAM for authentication, authorisation via ACLs (against clusters, volumes and job queues), POSIX file permissions (against files and directories) and Access Control Expressions (ACEs, arbitrary boolean expressions against volumes, files and directories). Comes with a browser based management interface (MapR Control System), a CLI and REST API. First releases as part of MapR v1.0 in 2010.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;MapR-FS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - 5.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; MapR File System&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Extension to MapR-FS to provide NoSQL capabilities, supporting JSON document and wide column tables and HBase and OJAI (Open JSON application interface) APIs. Tables are stored as first class objects in MapR-FS volumes, and are sharded into table regions / tablets. JSON document tables are schemaless, support read and write access to individual document fields, subsets of fields or whole documents, finding documents by id or via a full table scan query, a set of atomic operations for mutating documents, and integration with MapReduce. Wide column (binary) tables are largely equivalent to HBase tables, and partially support the HBase API, but without support for custom HBase filters or co-processors. Supports replication at the table, column family or column level, either synchronously or asynchronously, and in either master-master or master-slave configurations, with support for replicating to Elasticsearch. Authentication is managed through access control expressions (ACEs) at the field level (for JSON document tables) or at the column level (for wide column tables). Introduced in MapR v4.0 in Sept 2014, with document supported added in MapR 5.1 in Feb 2016.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; MapR File System&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Extension to MapR-FS to provide streaming data storage capabilities and a Kafka compatible API. Messages (key/value pairs where the key is optional) are organised into topics, which are partitioned and stored as first class objects within MapR-FS volumes, with topics then grouped into streams. Supports encryption of streams, automatic deletion of messages (via a time to live), consumer groups, authorisation using ACEs (access control expressions), plus replication of topics to one or more remote MapR-Streams instances either synchronously or asynchronously, including support for Kafka's MirrorMaker. Comes with Java, C and Python libraries and includes a Kafka compatible API. Introduced in MapR 5.1 in Feb 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-fs/&quot;&gt;https://mapr.com/products/mapr-fs/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-distribution-including-apache-hadoop/&quot;&gt;https://mapr.com/products/mapr-distribution-including-apache-hadoop/&lt;/a&gt; - links to whitepapers and further detail on key features&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapROverview/c_overview_intro.html&quot;&gt;http://maprdocs.mapr.com/home/MapROverview/c_overview_intro.html&lt;/a&gt; - overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/MapROverview/c_maprfs.html&quot;&gt;http://maprdocs.mapr.com/home/MapROverview/c_maprfs.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/mapr-fs-vs-hdfs-5-minute-guide-understanding-their-differences-whiteboard-walkthrough/&quot;&gt;https://mapr.com/blog/mapr-fs-vs-hdfs-5-minute-guide-understanding-their-differences-whiteboard-walkthrough/&lt;/a&gt; - comparison to HDFS&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Updates via MapR release announcements and blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-file-system/</guid> </item> <item><title>MapR Streams Clients and Tools</title><link>http://ondataengineering.net/technologies/mapr-streams-clients-and-tools/</link><pubDate>Wed, 26 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A number of clients and tools taken from Kafka that have been bundled and integrated with MapR-Streams. Includes Kafka REST Proxy, Kafka Connect, C client and Java client. Introduced in the MapR Ecosystem Pack v2.0, and can be considered a partial packaging of Kafka (focusing on the functionality isn't provided by MapR-Streams).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;MapR Streams Clients, MapR Streams Tools&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/kafka-connect-and-kafka-rest-api-mapr-streaming-just-became-whole-lot-easier/&quot;&gt;https://mapr.com/blog/kafka-connect-and-kafka-rest-api-mapr-streaming-just-became-whole-lot-easier/&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/Kafka/Kafka.html&quot;&gt;http://maprdocs.mapr.com/home/Kafka/Kafka.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/EcosystemRN/KafkaRN.html&quot;&gt;http://maprdocs.mapr.com/home/EcosystemRN/KafkaRN.html&lt;/a&gt; - tools release note&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/EcosystemRN/StreamsClientRN.html&quot;&gt;http://maprdocs.mapr.com/home/EcosystemRN/StreamsClientRN.html&lt;/a&gt; - clients release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Announcements via the MapR product announcements blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-streams-clients-and-tools/</guid> </item> <item><title>MapR Monitoring</title><link>http://ondataengineering.net/technologies/mapr-monitoring/</link><pubDate>Tue, 25 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A collection of open source components used to capture, store and visualise metrics and log messages across a MapR Converged Data Platform. Components used include collectd (to capture metrics), OpenTSDB (a time-series database that runs on top of MapR-DB to store metrics), Grafana (to visualise and graph metrics into dashboards), FluentD (to collect and parse log messages), Elasticsearch (to store and index log messages for search) and Kibana (to search and view log messages). Metrics captured include cpu, disk, memory and network metrics, plus metrics for Drill, YARN and the MapR components. Log messages are captured from system logs, plus YARN, ZooKeeper, Drill, Hbase, Hive, Oozie, Spark, the MapR component logs, and the logs for the MapR Monitoring components. Both Grafana and Kibana include starter sample dashboards. First released in June 2016 as part of the Spyglass initiative.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;Elasticsearch, FluentD, Grafana, Kibana, OpenTSDB, collectd&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/spyglass-initiative/&quot;&gt;https://mapr.com/products/spyglass-initiative/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/resources/mapr-monitoring/&quot;&gt;https://mapr.com/resources/mapr-monitoring/&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/AdministratorGuide/Monitoring.html&quot;&gt;http://maprdocs.mapr.com/home/AdministratorGuide/Monitoring.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/EcosystemRN/MapRMonitoringRN.html&quot;&gt;http://maprdocs.mapr.com/home/EcosystemRN/MapRMonitoringRN.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Announcements via the MapR product announcements blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-monitoring/</guid> </item> <item><title>Apache Myriad</title><link>http://ondataengineering.net/technologies/apache-myriad/</link><pubDate>Mon, 24 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Tool that allows YARN applications to run over Apache Mesos, allowing them to co-exist and share cluster resources. Consists of Myriad Executor, a Mesos managed task that in turns manages a YARN Node Manager, and Myriad Scheduler, a plugin for the YARN Resource Manager that delegates resource negotiation to Mesos (and launches Myriad Executor processes on required nodes via Mesos). Supports fixed resource allocation to YARN Node Managers, as well as fine-grained scaling where resources are dynamically requested from Mesos. Includes a web based user interface and REST API that includes support for scaling YARN resources when using fixed resource allocation. Originally created by eBay, MapR and Mesosphere and dondated to the Apache Foundation in March 2015. Has not yet graduated or reached a 1.0 release, with development activity seeming very quiet since October 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Myriad&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v0.2&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/&quot;&gt;http://myriad.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/docs/&quot;&gt;http://myriad.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/product-overview/apache-myriad/&quot;&gt;https://mapr.com/products/product-overview/apache-myriad/&lt;/a&gt; - MapR information&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://myriad.apache.org/news/&quot;&gt;http://myriad.apache.org/news/&lt;/a&gt; - news&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-myriad/</guid> </item> <item><title>The Week That Was - 21/04/2017</title><link>http://ondataengineering.net/blog/2017/04/21/the-week-that-was/</link><pubDate>Fri, 21 Apr 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;We’ve been a little bit all over the shop this week, but let’s try and summarise what we’ve looked at.&lt;/p&gt; &lt;p&gt;We started late having taken Monday off for Easter, with a look at &lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt; on Tuesday, closing out our review of them and their technologies. We then took another break on Wednesday to catchup on everything that’s changed in the technologies we’ve looked at to date, returning on Thursday with the start of our journey into MapR, the final Hadoop distribution we’re going to look at in detail. We’ve started by looking at their open source components, looking at the &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt; &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I think we’ve probably covered most of what there is to say on Cloudera in previous posts. At the moment they’re the biggest player in the Hadoop space, with a significant investment from Intel (an order of magnitude greater than any investment Hortonworks or MapR have secured), plus a recently announced IPO. What’s going to be interesting is how they transition from the “Hadoop’s the hot new thing come and get it from us” business model to one focused on specific business challenges and direct competition to more established BI and analytics vendors - you can see the start of that in the way they’ve recently re-organised their product offerings.&lt;/p&gt; &lt;p&gt;I don’t know a huge amount about MapR, so am looking forward to learning more. What I’ve looked at so far looks interesting - a commercial data repository that supports multiple interfaces (file orientated, database and messaging), addresses some of Hadoop’s limitations, and provides Hadoop compatible APIs (specifically HDFS, HBase and Kafka APIs), that’s blended with YARN to provide an Hadoop compatible analytics platform. It’s going to be interesting to dig into the detail and understand how this differentiates itself from vanilla Hadoop.&lt;/p&gt; &lt;p&gt;We’ve started off our look at MapR by looking at the &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt; - a bundle of open source Apache Hadoop components that are certified to work together and to run on the MapR platform. All your favourite Hadoop technologies are in there (bar Solr), and MapR seem to have given themselves licence to pick and choose from technolgies backed by both Cloudera and Hortonworks - an enviable position to be in.&lt;/p&gt; &lt;p&gt;There aren’t many technologies in the MapR Ecosystem Pack we’ve not looked at previously, the main one being &lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt;. It’s another interactive (low latency high throughput) SQL query engine, with the big differentiator being that it can query and join across data in multiple datastores (including all your favourite filesystems, NoSQL and RDBMS databases) without first having to define a schema. There’s a lot of power here - being able to query data where it is without having to first bring it all together first or do lots of preparation delivers a huge range of benefits. Drill’s facing off against &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Impala&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; in the emerging interactive SQL on Hadoop space - there’s much more to dig into here in the future, however if you’re looking to get started there’s an interesting write up of Impala vs Drill from Rittman Mead &lt;a href=&quot;https://www.rittmanmead.com/blog/2017/04/sql-on-hadoop-impala-vs-drill/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;That’ll do for this week - have a lovely weekend and we’ll see you on the other side.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/21/the-week-that-was/</guid> </item> <item><title>Apache Drill</title><link>http://ondataengineering.net/technologies/apache-drill/</link><pubDate>Fri, 21 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;An MPP query engine that supports queries over one or more underlying databases or datasets without first defining a schema and with the ability to join data from multiple datastores together. Supports a range of underlying technologies including HDFS, NAS, HBase, MongoDB, MapR-DB, MapR-FS, Amazon S3, Azure Blob Storage, Google Cloud Storage, JDBC, Avro, JSON and Parquet. Pushes queries down to underlying datastores where possible, and supports an in-memory columnar datastore based on a schema free JSON document model for performing cross datastore query operations. Supports dynamic schema discovery, with support for complex and nested types, including a number of SQL extensions. Supports standard SQL, UDFs (including Hive UDFs) and comes with JDBC and ODBC drivers, a REST API, plus a shell, web console and C++ API. Designed to be horizontally scalable and to support high throughput and low latency use cases, and can run over YARN. Supports Kerberos and username/password authentication, plus a full authorisation model. Created by MapR Based on Google's Dremel paper, donated to the Apache Foundation in September 2012, graduating in November 2014, with a 1.0 release in May 2015, and is still under active development&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Drill&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commerical Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v1.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/&quot;&gt;http://drill.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/docs/&quot;&gt;http://drill.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/51/Drill/intro_drill_on_yarn.html&quot;&gt;http://maprdocs.mapr.com/51/Drill/intro_drill_on_yarn.html&lt;/a&gt; - Drill on YARN information&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://drill.apache.org/blog/&quot;&gt;http://drill.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-drill/</guid> </item> <item><title>MapR Ecosystem Pack</title><link>http://ondataengineering.net/technologies/mapr-ecosystem-pack/</link><pubDate>Thu, 20 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A package of components certified to work together against one or more versions of the MapR Converged Data Platform. Has new major releases roughtly once a quarter, with most components kept resonably up to date with the open source version, with any patching done publically in GitHub. Available as RPMs, and installable via the MapR Installer. Also includes a plugin for OpenStack Sahara to allow OpenStack to create and manage MapR clusters. These components were originally bundled as part of the MapR Converged Data Platform, but were broken out as the MapR Ecosystem Pack in September 2016 to allow them to be released independantly.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;MEP&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v3.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-myriad/&quot;&gt;Apache Myriad&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Apache Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Apache Tez&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-monitoring/&quot;&gt;MapR Monitoring&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-streams-clients-and-tools/&quot;&gt;MapR Streams Clients and Tools&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Details of the component versions can be found in the release notes, along with detailed release nodes for each of the components and details of the packages for each component.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/products/mapr-ecosystem-pack/&quot;&gt;https://mapr.com/products/mapr-ecosystem-pack/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/c_ecosystem_intro.html&quot;&gt;http://maprdocs.mapr.com/home/c_ecosystem_intro.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/EcosystemRN/EcoPackRN.html&quot;&gt;http://maprdocs.mapr.com/home/EcosystemRN/EcoPackRN.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/InteropMatrix/r_release_mep_dates.html&quot;&gt;http://maprdocs.mapr.com/home/InteropMatrix/r_release_mep_dates.html&lt;/a&gt; - release history&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://maprdocs.mapr.com/home/AdvancedInstallation/InstallingEcoWithoutInstaller.html&quot;&gt;http://maprdocs.mapr.com/home/AdvancedInstallation/InstallingEcoWithoutInstaller.html&lt;/a&gt; - installation docs&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mapr&quot;&gt;https://github.com/mapr&lt;/a&gt; - component source ode&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://package.mapr.com/releases/MEP/&quot;&gt;http://package.mapr.com/releases/MEP/&lt;/a&gt; - package repository&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Announcements via the MapR product announcements blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mapr-ecosystem-pack/</guid> </item> <item><title>The Mid Week News - 19/04/2017</title><link>http://ondataengineering.net/blog/2017/04/19/the-mid-week-news/</link><pubDate>Wed, 19 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, I’ve been slack in getting this out there, which means we’ve built up a nasty backlog, but it’s time to talk about what’s changed since we originally wrote some of our technology summaries. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, there are new releases of the &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;. &lt;a href=&quot;https://hortonworks.com/blog/announcing-the-general-availability-of-hortonworks-data-platform-2-6/&quot;&gt;Version 2.6 of HDP&lt;/a&gt; brings two main features - &lt;a href=&quot;https://hortonworks.com/blog/top-5-performance-boosters-with-apache-hive-llap/&quot;&gt;Hive LLAP&lt;/a&gt;, the ability for Hive to target the real time interactive query space, and &lt;a href=&quot;https://hortonworks.com/blog/apache-hive-moving-beyond-analytics-offload-with-sql-merge/&quot;&gt;Hive ACID Merges&lt;/a&gt;, allowing data to be transactionally loaded into Hive. &lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/Announce-Cloudera-Enterprise-5-11-is-Now-Available/m-p/53808#M170&quot;&gt;Version 5.11 of CDH&lt;/a&gt; brings Navigator lineage support for Spark, the integration of Kudu with Kerberos, improvements to S3 support and support for Azure Data Lake Store.&lt;/p&gt; &lt;p&gt;There have also been a mass of projects that have seen new releases. Ordinarily I’d like to provide some sort of commentary on these, however given I’ve built up such a backlog we’ll just list them off this week. Each technology page includes a link to the relevent release announcement or details if you’re interested however. So, in no particular order the technologies that have seen new releases are: &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet C++&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In terms of other technologies news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sqoop2 has been deprecated by Cloudera as of CDH 5.9, and will be removed from CDH in version 6. Suggests that all is not well in Sqoop2 land.&lt;/li&gt; &lt;li&gt;Hadoop 3.0 is now into it’s second alpha release. Summary is &lt;a href=&quot;http://hadoop.apache.org/docs/r3.0.0-alpha2/index.html&quot;&gt;here&lt;/a&gt;, with some thoughts form &lt;a href=&quot;https://hortonworks.com/blog/data-lake-3-0-part-4-cutting-storage-overhead-in-half-with-hdfs-erasure-coding/&quot;&gt;Hortonworks&lt;/a&gt; and &lt;a href=&quot;http://blog.cloudera.com/blog/2017/02/apache-hadoop-3-0-0-alpha2-released/&quot;&gt;Cloudera&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt; has graduated to a top level Apache project. There’s an &lt;a href=&quot;https://www.infoq.com/news/2017/03/apache-ranger-top-level-project&quot;&gt;InfoQ write-up&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/linkedin/gobblin&quot;&gt;Gobblin&lt;/a&gt; has been donated to the Apache Foundation by LinkedIn&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We’ll try and do this weekly going forward - let’s just hope keeping up to date with everything doesn’t prove to be unsustainable! And next week we’ll have a look at some of the interesting blog posts I’ve been accumulating.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/19/the-mid-week-news/</guid> </item> <item><title>Cloudera</title><link>http://ondataengineering.net/tech-vendors/cloudera/</link><pubDate>Tue, 18 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Cloudera is a commercial company focusing on offerings based around an Apache Hadoop distribution that's supplemented with a number of commercial components, distributed as a free express version (with cut down versions of some of the commercial components), and as an enterprise version with an annual subscription fee. They are extreemly active in the Apache open source space, with committers on all the technologies they distribute, and with a history of donating projects to the Apache Foundation that they have either initiated or acquired. Formed in 2008 by ex-employees from Google, Yahoo, Facebook and Oracle, with Doug Cutting, the original author of Hadoop, joining in 2009 as Chief Architect.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;vendor-technologies&quot;&gt;Vendor Technologies&lt;/h2&gt; &lt;p&gt;Cloudera’s offerings are based around &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;, their distribution of Apache Hadoop, which includes a number of commercial components, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; (for creating and managing clusters), &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; (a data management and encryption solution) and &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; (for installing CDH on cloud based platforms), and comes in a number of editions, including a free version as “Cloudera Express”. They also sell &lt;a href=&quot;/technologies/cloudera-data-science-workbench&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt;, a docker powered analytics notebook.&lt;/p&gt; &lt;p&gt;Cloudera have donated a number of projects to the Apache Foundation, including &lt;a href=&quot;/technologies/apache-flume&quot;&gt;Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop&quot;&gt;Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-avro&quot;&gt;Avro&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet&quot;&gt;Parquet&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch&quot;&gt;Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Impala&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-kudu&quot;&gt;Kudu&lt;/a&gt;, and have a number of non-Apache open source projects including &lt;a href=&quot;/technologies/recordservice&quot;&gt;RecordService&lt;/a&gt;, &lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/livy&quot;&gt;Livy&lt;/a&gt;, &lt;a href=&quot;/technologies/kite&quot;&gt;Kite&lt;/a&gt; and &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/&quot;&gt;https://www.cloudera.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://vision.cloudera.com/&quot;&gt;https://vision.cloudera.com/&lt;/a&gt; - Leadership blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;http://blog.cloudera.com/&lt;/a&gt; - Engineering blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&quot;&gt;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&lt;/a&gt; - Release Announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/cloudera/</guid> </item> <item><title>The Week That Was - 14/04/2017</title><link>http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</link><pubDate>Fri, 14 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s the Easter holidays here in the UK, so no technology summary today, but let’s recap the last week before we forget everything we looked at.&lt;/p&gt; &lt;p&gt;This week, we’ve been looking at the Cloudera’s closed source products - &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;, their tool for creating and managing CDH hadoop clusters, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, a set of products for data management, data encryption and helping migrate SQL workloads to Hadoop, and &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, for doing CDH Hadoop in the cloud. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;The philosophical debate between Cloudera and Hortonworks on the used of closed source software is an interesting one, and lends almost a personal element to their commercial rivalry. The general view is that Cloudera have added closed source software into their offering to increase lock in, but I’m not entirely convinced by this - the cost of moving from Cloudera Manager/Navigator to an alternative doesn’t feel like it significantly impacts the fundamental costs of migrating from one distribution to another. Does it provide extra encouragement for companies to take up subscription licences - again I’m not entirely convinced, the risk with not having commercial support for critical systems is likely to be the driver here. Cloudera’s stated view is that it’s protection for their investment in Hadoop open source projects, to prevent a large company with deep pockets competing with them by distributing the open source software that they’ve put so much investment into. What’s clear is that most of the arguments are ideological in nature - I think if you look at it impartially the use of closed source software by Cloudera is unlikely to significantly impact any selection process.&lt;/p&gt; &lt;p&gt;And so on to the products themselves. I feel like I’ve probably done &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; a slight disservice in it’s technology summary - cold hard facts on how it compares to &lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Apache Ambari&lt;/a&gt; seem to be pretty scarce (perhaps we’ll try and do something about this at some point), however the general consensus seems to be that Cloudera Manager was more mature and more capable, but that Ambari has been catching up rapidly, and there’s probably not a huge amount in it any more.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; started off as Cloudera’s data (or metadata) management tool, and is probably slightly more mature and capable in this space than &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt;. Metadata management in general still feels very immature however - most tools don’t deliver on their promises, and the investment, time and effort to get value out of them is often under estimated, leading to the infamous data swamp if you’re working in the Hadoop space.&lt;/p&gt; &lt;p&gt;Today, in addition to it’s original &lt;a href=&quot;/technologies/cloudera-navigator/data-management/&quot;&gt;data management&lt;/a&gt; elements, Cloudera Navigator also includes &lt;a href=&quot;/technologies/cloudera-navigator/data-encryption/&quot;&gt;data encryption&lt;/a&gt; capabilities following Cloudera’s acquisition of Gazzang, and &lt;a href=&quot;/technologies/cloudera-navigator/optimizer/&quot;&gt;Optimizer&lt;/a&gt; following their acqusition of Xplain.io, an interesting technology I know very little about for helping to migrate SQL workloads to Hadoop and to then optimise these.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; - Cloudera’s tool for creating, scaling and managing CDH clusters in all your favourite cloud environments. I’m not sure there’s a huge amount more to say than that to be honest.&lt;/p&gt; &lt;p&gt;Right - I’m off to eat chocolate. If I’ve not exploded we’ll resume next Tuesday with our summary of Cloudera themselves, and then maybe on Wednesday we’ll do our first news post to catch up on the many technologies that have had new releases since we did their initial technology summary.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/04/14/the-week-that-was/</guid> </item> <item><title>Cloudera Director</title><link>http://ondataengineering.net/technologies/cloudera-director/</link><pubDate>Thu, 13 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for deploying and managing Cloudera CDH Hadoop clusters on cloud infrastructure based on automatically provisioned infrastructure with Hadoop provisioned on top via Cloudera Manager. Includes out of the box support for Amazon Web Services, Microsoft Azure and Google Cloud Platform, with support for vSphere available from VMWare, with a Service Provider Interface (SPI) for adding support for new providers. Supports the ability to scale clusters up and down, clone clusters, run post deployment scripts, and create Kerberized and highly available clusters. Manageable through a web UI, a REST API (with Python and Java APIs) and a CLI. Released at 1.0 in October 2014 as part of Cloudera Enterprise 5.2. Free to download and use, with commercial support available as part of a Cloudera Enterprise subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017 - v2.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Cloudera Director is available on AWS as &lt;a href=&quot;https://aws.amazon.com/quickstart/architecture/cloudera/&quot;&gt;Cloudera EDH AWS Quick Start&lt;/a&gt;, and as &lt;a href=&quot;https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudera.director-on-azure?tab=Overview&quot;&gt;Cloudera Director on the Azure Marketplace&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.4&lt;/td&gt; &lt;td&gt;2017-04-18&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2017/04/whats-new-in-cloudera-director-2-4/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt;CDH 5.11&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-director.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-director.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/director/latest.html&quot;&gt;https://www.cloudera.com/documentation/director/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera?q=director&quot;&gt;https://github.com/cloudera?q=director&lt;/a&gt; - plugins&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&quot;&gt;https://blogs.vmware.com/vsphere/2016/06/an-exciting-innovation-in-big-data-a-new-cloudera-director-plugin-for-vmware-vsphere.html&lt;/a&gt; - VMWare plugin announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-director/</guid> </item> <item><title>Cloudera Navigator Optimizer</title><link>http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://optimizer.cloudera.com/&quot;&gt;https://optimizer.cloudera.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator-optimizer.html&lt;/a&gt; - product information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/navopt/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/navopt/topics/navopt.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/optimizer/</guid> </item> <item><title>Cloudera Navigator Data Encryption</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</link><pubDate>Wed, 12 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Navigator Encrypt, Navigator Key Trustee Server, Navigator Key HSM, Navigator Key Trustee KMS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_encryption.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&quot;&gt;http://blog.cloudera.com/blog/2015/06/cloudera-navigator-encrypt-architecture-the-overview/&lt;/a&gt; - intro blog post to Navigator Encrypt&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_enc_overview.html&lt;/a&gt; - Cloudera security overview, including summary of encryption options&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_encryption.html&lt;/a&gt; - Cloudera encryption documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/</guid> </item> <item><title>Cloudera Navigator Data Management</title><link>http://ondataengineering.net/technologies/cloudera-navigator/data-management/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - overview documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navigator_data_mgmt.html&lt;/a&gt; - introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt.html&lt;/a&gt; - primary documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/datamgmt_extraction_indexing.html&lt;/a&gt; - list of metadata that is automatically extracted&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/navigator/apidocs/v3/&quot;&gt;http://cloudera.github.io/navigator/apidocs/v3/&lt;/a&gt; - REST API documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/navigator-sdk&quot;&gt;https://github.com/cloudera/navigator-sdk&lt;/a&gt; - Java SDK&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/data-management/</guid> </item> <item><title>Cloudera Navigator</title><link>http://ondataengineering.net/technologies/cloudera-navigator/</link><pubDate>Tue, 11 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of solutions covering Data Management (technical metadata management, lineage, cluster activity and analytics, cluster audit and automated policy actions), Data Encryption (filesystem level encryption, key management and integration with HDFS transparent encryption), and a solution for identifying SQL workloads that are candidates for migration to Hadoop and then optimising these once on Hadoop (Optimizer) build around the Cloudera CDH Hadoop distribution. All products are commercial closed source products, that are only available with an appropriate Cloudera Enterprise licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017 - v2.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-management/&quot;&gt;Cloudera Navigator Data Management&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Solution for managing data on a CDH Hadoop cluster. Automatically extracts metadata relating to HDFS, Hive, Impala, MapReduce, Oozie, Pig, S3, Spark, Sqoop and YARN, including data structures (databases, tables and columns) and jobs (relating to data transformation) based on activity within a cluster (rather than statically analysing code), allowing it to be searched, filtered and viewed, including displaying lineage diagrams showing how data moves through the system, a Data Stewardship dashboard of key data management information (including statistics on the data held in the cluster and the activity relating to this data), analytics on the data held in HDFS, and a full audit capability of all activity on the cluster. Allows custom metadata to be added to objects, including descriptions, key-value pairs and tags, with the option to define metadata namespaces and data types / value constraints (managed metadata), plus the ability to pre-set custom attributes (via job properties for MapReduce jobs and JSON .navigator files for HDFS files), and the ability to define data lifecycle management policies (allowing actions to be specified based on metadata, e.g. to archive any files that haven't been accessed for six months). Web based, with a full user security model, and a REST API and Java SDK for integrating external applications with metadata held in Navigator. Initial 1.0 release was in February 2013.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/data-encryption/&quot;&gt;Cloudera Navigator Data Encryption&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A suite of products that complement HDFS transparent encryption to provide data at rest encryption across an Hadoop cluster. Includes Navigator Encrypt (a solution for encrypting Linux filesystems, with access granted to approved processes), Navigator Key Trustee Server (a software based solution for managing encryption keys), Navigator Key HSM (allows Navigator Key Trustee Server to use a Hardware Security Module as the root of trust for keys) and Navigator Key Trustee KMS (an Hadoop Key Management Service that uses Navigator Key Trustee Server as the underlying key store). First released in 2014 following the acquisition of Gazzang.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/cloudera-navigator/optimizer/&quot;&gt;Cloudera Navigator Optimizer&lt;/a&gt; &lt;/td&gt; &lt;td&gt;A web based hosted service for analysing SQL logs from a range of relational databases to provide guidance on offloading workloads to Hadoop, and from Hive and Impala to provide guidance on optimising workloads running on Hadoop. Can analyse query logs, query metadata, schemas and statistics, and includes a Java utility to mask literal values in SQl queries and logs, and to encrypting schema identifiers before files are uploaded. Provides analytics on the overall query workload (including by similarity and risk, as well as by uploaded metrics such as cpu usage, memory usage and file system reads/writes) and recommendations for improvements to queries (to reduce risk, and to make external queries Hadoop compatible), with risk representing the level of Hadoop compatibility. Formally Xplain.io which was founded in 2013, acquired by Cloudera in February 2015, with a GA release as Cloudera Navigator Optimizer in July 2016.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.10&lt;/td&gt; &lt;td&gt;2017-04-18&lt;/td&gt; &lt;td&gt;See &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; 5.11 release links&lt;/td&gt; &lt;td&gt;CDH 5.11&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-navigator.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-navigator.html&lt;/a&gt; - Cloudera Navigator homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&quot;&gt;https://www.cloudera.com/resources/datasheet/cloudera-navigator-datasheet.html&lt;/a&gt; - Cloudera Navigator datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cn_iu_introduce_navigator.html&lt;/a&gt; - Data Management and Data Encryption introduction&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/navopt.html&lt;/a&gt; - Optimizer introduction&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/navigator/&quot;&gt;http://blog.cloudera.com/blog/category/navigator/&lt;/a&gt; - Cloudera blog posts&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-navigator/</guid> </item> <item><title>Cloudera Manager</title><link>http://ondataengineering.net/technologies/cloudera-manager/</link><pubDate>Mon, 10 Apr 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Platform for installing, managing and monitoring Cloudera CDH Hadoop clusters. Supports creation of clusters using step by step wizards, plus cluster templates for creating multiple clusters with the same configuration (e.g. dev, test and production), using either native OS packages or parcels (a Cloudera Manager distribution format that has a number of advantages over packages). Also supports the administration and configuration of clusters (including user and resource management, and the ability to manage multiple clusters); the automated Kerberization of clusters; monitoring of cluster, host and service statuses, health and metrics; generation of events and the use of custom triggers to take action on these; the visualisation of metrics; centralised log management; HDFS reports and automatic replication of data to a backup/DR cluster. Also integrates directly with Cloudera Support to enable proactive support. Web based, with a REST API and a full security model with auditing of all actions, and the ability to add support for custom services. Introduced in January 2012 as a replacement for the Cloudera Management Suite (CMS). Available for free without some enterprise features, or as part of a Cloudera CDH subscription.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2017 - v5.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.11&lt;/td&gt; &lt;td&gt;2017-04-18&lt;/td&gt; &lt;td&gt;See &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; 5.11 release links&lt;/td&gt; &lt;td&gt;CDH 5.11&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/product-components/cloudera-manager.html&quot;&gt;https://www.cloudera.com/products/product-components/cloudera-manager.html&lt;/a&gt; - Cloudera Manager homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_intro_primer.html&lt;/a&gt; - Documentation - link is to the Cloudera Manager introduction, with the rest of Cloudera documentation (e.g. Installation, Upgrade, Administration, Operation and Security documents) also referencing Cloudera Manager&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloudera.github.io/cm_api/&quot;&gt;https://cloudera.github.io/cm_api/&lt;/a&gt; - Cloudera Manager API documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;Blog updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-manager/</guid> </item> <item><title>The Week That Was - 31/03/2017</title><link>http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</link><pubDate>Fri, 31 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;No technology summary today for various reasons, one of which is that I’m taking a break next week and we’ve probably got to a pretty good place to pause. We’ve finished looking at the new open source technologies in the Cloudera stack this week, with their proprietary closed source technologies to come, but let’s save those for a fresh week.&lt;/p&gt; &lt;p&gt;So what exactly have we looked at this week? We started by looking at &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt;, Cloudera’s competitor to &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, Cloudera’s competitor to Hortonworks’ &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt;. We then looked at &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, a structured data store that supports both updates and deletes by primary key as well as efficient analytical table scans, and &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, a new technology that’s still in beta that provides an API for tools (such as Spark and MapReduce) to access structured data in Hadoop with fine grained access control. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;At some point, and I realise I keep saying this, I want to take a deeper look into the state of the security technologies in Hadoop, and more specifically a decent comparison of &lt;a href=&quot;/technologies/apache-sentry&quot;&gt;Apache Sentry&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt;. There’s some history behind how we’ve ended up with two Apache technologies that are essentially trying to solve the same problem, each has their pros and cons but either will probably do what you need them two, with Ranger possibly looking the slightly further ahead functionality wise. Note that I’ve make some minor tweaks to the &lt;a href=&quot;/technologies/apache-ranger&quot;&gt;Apache Ranger&lt;/a&gt; technology summary this week.&lt;/p&gt; &lt;p&gt;I’m not entirely sure where the whole “wrap Solr up with some tools and utilities and give it a new name” came from, but there are some interesting differences between &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-platform-search/&quot;&gt;HDP Search&lt;/a&gt; in the wraps that they put around Solr. Hortonworks bundle Banana (the Solr port of Kibana), they both support utilities for loading data from HDFS and moving data from HBase to Solr, but Hortonworks also bundle integrations with Solr for Hive, Pig, Storm and Spark. Note again that I’ve made some minor tweaks to the HDP Search technology summary this week.&lt;/p&gt; &lt;p&gt;Cloudera position &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; as the missing link between &lt;a href=&quot;/technologies/apache-hadoop/hdfs&quot;&gt;HDFS&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;HBase&lt;/a&gt; - able to perform updates and deletes by primary key (ala HBase), as well as analytical queries performing column and table scans (ala HDFS). It’s not going to replace either for their respective specialisms, but the ability to run analytical workloads over mutable data feels like a bit of a gap in the Hadoop ecosystem at the moment (that probably led to the rise of the &lt;a href=&quot;http://lambda-architecture.net/&quot;&gt;lambda architecture&lt;/a&gt;). Kudu only provides the storage engine, but its combination with &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt; to provide a SQL interface on top feels like yet more evidence that Cloudera is firmly targeting the established OLAP database vendors. The &lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;Kudu whitepaper&lt;/a&gt; is worth a skim if you’re interested, including the performance comparison between Kudu, Parquet on HDFS and Phoenix on HBase.&lt;/p&gt; &lt;p&gt;And finally &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;, the benefits of which seem twofold. Firstly, it provides a unified data access path for Hadoop technologies - rather than every technology (MapReduce, Spark, etc.) having to implement their own reader for each file format, they can just integrate with RecordService. This then enables the second - fine grained access control to this data. At the moment, when tools like MapReduce and Spark read data from HDFS, access can only be granted at the file level - RecordService will enable finer grained access control in this scenario, which can only be a good thing. Two thoughts however - you can achieve this today by forcing these tools to read data via Hive, however my guess is that there are some performance limitations on this at scale that RecordService will address, and that at the moment it’s very early days for RecordService, plus it’s tied to Apache Sentry, so it’s going to be interesting to see how much traction this gains into the wider Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;As mentioned above I’m taking a break next week so there’ll be no updates, but we’ll be back on Monday 10th with a look at Cloudera’s closed source commercial technologies.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/31/the-week-that-was/</guid> </item> <item><title>RecordService</title><link>http://ondataengineering.net/technologies/recordservice/</link><pubDate>Thu, 30 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Abstraction layer for accessing structured data in Hadoop that enforces fine grained access control (via Apache Sentry). Currently supports reading data from HDFS and S3 in Parquet, Text, Sequence File, RC and Avro format via a Hive table/view definition or a file path, with support for HBase and Kudu planned. Supports direct access to data via C++ and Java APIs, plus integration with MapReduce, Spark, Impala and Pig, with support for Hive planned. Supports the Apache Sentry security model, including table, view, file (via grants on uris to create external tables) and column level security, with row level filtering and data masking planned. Started in January 2015 and announced with an initial beta release in September 2015. Still in beta, with a stated plan for RecordService to be donated to the Apache Foundation in the future. Open sourced under Apache 2.0 licence, and implemented in C++ and Java.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v0.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/&quot;&gt;http://recordservice.io/&lt;/a&gt; - homepage and documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&quot;&gt;http://vision.cloudera.com/introducing-recordservice-the-future-of-security-authorization-in-hadoop/&lt;/a&gt; - vision for RecordService&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/betas/recordservice/latest.html&quot;&gt;https://www.cloudera.com/documentation/betas/recordservice/latest.html&lt;/a&gt; - Cloudera document home (links through to RecordService site)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/recordservice&quot;&gt;https://github.com/cloudera/recordservice&lt;/a&gt; - source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/RecordServiceClient/&quot;&gt;https://github.com/cloudera/RecordServiceClient/&lt;/a&gt; - client libraries source code repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://recordservice.io/ReleaseNotes/&quot;&gt;http://recordservice.io/ReleaseNotes/&lt;/a&gt; - RecordService release details&lt;/li&gt; &lt;li&gt;Other updates through Cloudera Engineering blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/recordservice/</guid> </item> <item><title>Apache Kudu</title><link>http://ondataengineering.net/technologies/apache-kudu/</link><pubDate>Wed, 29 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Columnar storage technology for tables of structured data, supporting low latency reads, updates and deletes by primary key, as well as analytical column/table scans. Provides Java, C++ and Python APIs, is queryable via Impala and Spark SQL, and provides Spark, Flume and MapReduce connectors. Supports cluster deployments (including co-existence with Hadoop), with tables partitioned into tablets (configurable on a per table basis), with tablets then replicated and distributed across the cluster, using the Raft Consensus Algorithm for consistency. Also supports variable column encoding (including bit shuffle, run length, dictionary and prefix encoding) and compression. Includes a web UI for reporting operational information, and metrics available from the command line, via HTTP or via a log file. Started in November 2012, with a initial beta release in September 2015. Donated to the Apache Foundation in December 2015, graduating in July 2016, with a 1.0 release in September 2016. Implemented in C++.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kudu&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/&quot;&gt;https://kudu.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/docs/&quot;&gt;https://kudu.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kudu.apache.org/kudu.pdf&quot;&gt;http://kudu.apache.org/kudu.pdf&lt;/a&gt; - whitepaper including comparison to Parquet/HDFS and Phoenix/HBase&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-kudu.html&lt;/a&gt; - Cloudera information&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/kudu/latest.html&quot;&gt;https://www.cloudera.com/documentation/kudu/latest.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/releases/&quot;&gt;https://kudu.apache.org/releases/&lt;/a&gt; - details of new releases&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/blog/&quot;&gt;https://kudu.apache.org/blog/&lt;/a&gt; - Apache Kudu blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/category/kudu/&quot;&gt;http://blog.cloudera.com/blog/category/kudu/&lt;/a&gt; - Cloudera blog posts on Kudu&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kudu/</guid> </item> <item><title>Cloudera Search</title><link>http://ondataengineering.net/technologies/cloudera-search/</link><pubDate>Tue, 28 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distribution of Apache Solr that also includes a number of tools for integrating with Solr using Morphlines. Includes two utilities for loading data from HDFS, the Crunch Indexer Tool (direct Solr inserts using Crunch over Spark or MapReduce), and the MapReduce Indexer Tool (creates Solr index files using Map Reduce, optionally putting these live), plus two utilities for loading data from HBase based on the Lily HBase Indexer, the Batch Indexer (for batch loads) and the NRT (Near Real Time) Indexer (for continuous replication of HBase events). First released in June 2013, with a GA release in September 2013 as part of CDH 4.3. Included tools are open sourced under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-solr.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/search.html&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/search/&quot;&gt;https://github.com/cloudera/search/&lt;/a&gt; - HDFS utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/hbase-indexer&quot;&gt;https://github.com/cloudera/hbase-indexer&lt;/a&gt; - HBase utilities code repository (note that the default branch isn’t the current branch and the README is out of date)&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;News via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-search/</guid> </item> <item><title>Apache Sentry</title><link>http://ondataengineering.net/technologies/apache-sentry/</link><pubDate>Mon, 27 Mar 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store, and plugins for Hadoop components (including Hive, Solr, Impala and HDFS, with support for Kafka and Sqoop2 in preview) to manage authorisation of user access to data, although HDFS support is limited to Hive data only. Also supports row level filtering policies for Solr, and historical support for defining policies in files per service (Sentry Policy Files). Integrates with the Hue security app (to manage permissions) and with Cloudera Navigator (for authorisation audit events). Started in 2012 as Cloudera Access, with an initial 1.0 release in 2013 as Sentry. Donated to the Apache Foundation in August 2013, graduating in March 2016. &lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Sentry&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v1.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://sentry.apache.org/index.html&quot;&gt;https://sentry.apache.org/index.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/apache-sentry.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/sg_sentry_overview.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&quot;&gt;https://cwiki.apache.org/confluence/display/SENTRY/Documentation&lt;/a&gt; - Apache documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/sentry/&quot;&gt;https://blogs.apache.org/sentry/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Other updates via the Cloudera blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-sentry/</guid> </item> <item><title>The Week That Was - 24/03/2017</title><link>http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</link><pubDate>Fri, 24 Mar 2017 08:00:00 +0000</pubDate> <description> &lt;p&gt;So this week we started our journey into the Cloudera technology stack. I covered the final Hortonworks bits &lt;a href=&quot;/blog/2017/03/20/hortonworks-to-cloudera/&quot;&gt;on Monday&lt;/a&gt;, but what have we looked at since then?&lt;/p&gt; &lt;p&gt;We started off by looking at Cloudera’s Hadoop distribution &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; and the technologies it bundles. We’ve covered a lot of these already (Hadoop being Hadoop there’s plenty of overlap between the various distributions), but there’s still plenty of new stuff here to keep us busy for a couple of weeks.&lt;/p&gt; &lt;p&gt;We then moved on to look at &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt;, a small piece of open source technology created to support Impala running over YARN, &lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt;, a now retired Apache open source project for deploying a number of technologies onto cloud platforms, and &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;, Cloudera’s SQL on Hadoop engine for low latency interactive queries. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I’m not sure there’s much to say about &lt;a href=&quot;/technologies/cloudera-cdh.md&quot;&gt;CDH&lt;/a&gt; right now - it’s a great Hadoop distribution, and although it’s a significantly more commercial offering that Hortonworks, you can get most of it for free (including Cloudera Manager minus some enterprise bits). There’s pros and cons all over the stack if you’re comparing it against the other distributions, but we’ll take a deeper look at this in a couple of weeks time.&lt;/p&gt; &lt;p&gt;There’s not much to say about &lt;a href=&quot;/technologies/llama&quot;&gt;Llama&lt;/a&gt; - it was a piece of technology created by Cloudera to allow Impala to play nicely with YARN, but it’s not be adopted outside of Cloudera, who have themselves now deprecated it and will no longer be including it in CDH from v6.0 onwards (this wasn’t originally referenced in the technology summary so I’ve since updated it).&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-whirr&quot;&gt;Apache Whirr&lt;/a&gt; feels like a bit of history. It’s well and truly dead now (with no development since September 2012, and having been moved into the Apache Attic in March 2015), however it was the first technology (I think I’m right in saying this) that allowed you to deploy Hadoop (and a whole pile of other technologies) into a cloud environment. It feels a little clunky and anachronistic now - there’s bespoke Java code written for each technology it supported to manage the software deployment and management using jclouds - but I’m guessing at the time it was almost revolutionary, paving the way for a whole pile of later technologies.&lt;/p&gt; &lt;p&gt;And on to &lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt;. At some point I want to dig into the whole Impala/Hive debate / religious war (because it’s a fascinating look into the relationship and cultural differences between Cloudera and Hortonworks as much as anything). Hive has always been a large batch data transformation engine (albeit executing SQL) - every query starting a new job (originally MapReduce but lately Spark or Tez) with all the associated overheads and latency, but with the ability to process as much data as your Hadoop cluster would hold. What it wouldn’t do is support large numbers of more targeted queries at a low latency, for example from a group of users running queries against a data mart (the so called interactive query use case) - this was the use case Impala (and Parquet - the columnar data format) were created to target. Impala was therefore never designed to replace or compete with Hive, it’s competition are the traditional OLAP database such as Greenplum, Netezza and Teradata, with Impala trying to deliver a roughly comparable capability at a much lower cost. Hortonworks of course felt that Hive should support both use cases, and its introduction of LLAP (which allows long running processes to execute multiple queries) was it’s answer to this.&lt;/p&gt; &lt;p&gt;And that’s us for this week - have a good weekend, and we’ll see you on the other side.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/03/24/the-week-that-was/</guid> </item> <item><title>Apache Impala</title><link>http://ondataengineering.net/technologies/apache-impala/</link><pubDate>Fri, 24 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore. Focus is on analytical (OLAP) use cases, and more specifically on low latency interactive queries (rather than long running batch queries), with some support for batch inserts of data. Supports DDL statements for updating the Hive Metastore, uses (broadly) the same SQL syntax as Hive (including UDFs and a range of aggregate and analytical functions), as well as the same JDBC / ODBC drivers, and is therefore compatible with any Hive query tool (such as Beeline). Supports querying over data in Parquet, Text, Avro, RCFile and SequenceFile formats, with the ability to write Parquet and Text data. Support Kerberos and LDAP authentication, and integration with Apache Sentry for authorisation. Includes a shell (Impala Shell) that supports some shell only commands for tuning performance and diagnosing problems. Created by Cloudera, started in May 2011 and first announced in October 2012, with a 1.0 GA release in May 2013. Donated to the Apache Foundation in December 2015, is still incubating, and is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Impala&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v2.8&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;, &lt;a href=&quot;/technologies/mapr-ecosystem-pack/&quot;&gt;MapR Ecosystem Pack&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://impala.incubator.apache.org/&quot;&gt;https://impala.incubator.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&quot;&gt;https://www.cloudera.com/products/open-source/apache-hadoop/impala.html&lt;/a&gt; - Cloudera homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/impala.html&lt;/a&gt; - Cloudera documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-impala/</guid> </item> <item><title>Apache Whirr</title><link>http://ondataengineering.net/technologies/apache-whirr/</link><pubDate>Thu, 23 Mar 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;A set of libraries (now moved to the Apache Attic and no longer maintained) for deploying and managing a supported set of services in a cloud environment. Written in Java, with explicit support for a set of standard services (including Hadoop, Cassandra, HBase, Elasticsearch and Solr) configured through property files. Uses jclouds to provision and manage cloud infrastructure, and provides both a CLI and Java API. Originally a set of python scripts maintained as an Hadoop contrib project. Donated to the Apache Foundation in May 2010, graduating in August 2011. Development ceased in September 2012, with the project being moved to the Apache Attic in March 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Whirr&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017 - v5.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://whirr.apache.org/&quot;&gt;https://whirr.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/WHIRR&quot;&gt;https://cwiki.apache.org/confluence/display/WHIRR&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://attic.apache.org/projects/whirr.html&quot;&gt;https://attic.apache.org/projects/whirr.html&lt;/a&gt; - Apache Attic page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-whirr/</guid> </item> <item><title>Llama</title><link>http://ondataengineering.net/technologies/llama/</link><pubDate>Wed, 22 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;Framework for long running low-latency distributed applications to request resources from YARN, built to support Apache Impala. Operates as an un-managed YARN application master (that handles resource requests over a Thrift API and delivers resource notifications) and a node manager plugin (that delivers resource availability information to co-located services). Created by Cloudera in August 2013 and hosted on GitHub under an Apache 2.0 licence. Maintained by Cloudera to support new Impala and CDH releases, but now deprecated and will no longer be included in CDH from v6.0 onwards.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - InActive&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://cloudera.github.io/llama/&quot;&gt;http://cloudera.github.io/llama/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/cloudera/llama&quot;&gt;https://github.com/cloudera/llama&lt;/a&gt; - code repository&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/llama/</guid> </item> <item><title>Cloudera CDH</title><link>http://ondataengineering.net/technologies/cloudera-cdh/</link><pubDate>Tue, 21 Mar 2017 07:00:00 +0000</pubDate> <description> &lt;p&gt;A distribution of Hadoop based on the addition of a number of closed source products, including Cloudera Manager (for installing and managing clusters) and Cloudera Navigator (for managing metadata and the encryption of data). Bundled projects tend to lag the open source versions and pull forward more patches than other distributions. Also comes with a number of add-ons, including ODBC and JDBC drivers for Hive and Impala, and a number of Apache projects that aren't (yet) part of the core distribution. Available via RPMs, or can be installed using Cloudera Manager (for local installs) or Cloudera Director (for installation on cloud platforms). Comes in a number of editions including Cloudera Enterprise (under an annual per node or elastic cloud licence model with commercial support) or Cloudera Express (a free version without some enterprise features), with Cloudera Enterprise coming in a range of licence options (listed on the Cloudera website under products) with each including support for different Apache products. First released in March 2009.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;CDH, Cloudera Express, Cloudera Enterprise&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Categories&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;April 2017 - v5.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-avro/&quot;&gt;Apache Avro&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Apache Crunch&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Apache Mahout&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Apache Sentry&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-whirr/&quot;&gt;Apache Whirr&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-search/&quot;&gt;Cloudera Search&lt;/a&gt;, &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt;, &lt;a href=&quot;/technologies/kite/&quot;&gt;Kite&lt;/a&gt;, &lt;a href=&quot;/technologies/llama/&quot;&gt;Llama&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt;, &lt;a href=&quot;/technologies/recordservice/&quot;&gt;RecordService&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt;, &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;See the &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; for details on installing CDH on cloud platforms.&lt;/p&gt; &lt;p&gt;Details of the Apache project versions bundled with each version of CDH are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball.html&quot;&gt;this page&lt;/a&gt; of the CDH release notes. Deprecated items and projects are detailed on &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_deprecated.html&quot;&gt;this page&lt;/a&gt;. New features, known issues and fixed issues are available under &lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes_cdh.html&quot;&gt;this page&lt;/a&gt;. See some of the links below for details on the different Cloudera versions and options.&lt;/p&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.11&lt;/td&gt; &lt;td&gt;2017-04-18&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/Announce-Cloudera-Enterprise-5-11-is-Now-Available/m-p/53808#M170&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/release-notes/topics/rg_release_notes.html&lt;/a&gt; - release notes&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-cdh-projects-and-specifications-datasheet.pdf&lt;/a&gt; - CDH bundled projects datasheet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&quot;&gt;https://www.cloudera.com/content/dam/www/marketing/resources/datasheets/cloudera-enterprise-datasheet.pdf&lt;/a&gt; - Cloudera Enterprise datasheet (including details of products supported under each licence option)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&quot;&gt;https://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_feature_differences.html&lt;/a&gt; - differences between Express and Enterprise editions&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/director/cloud.html&quot;&gt;https://www.cloudera.com/documentation/director/cloud.html&lt;/a&gt; - best practice for running CDH in the cloud&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/&quot;&gt;http://blog.cloudera.com/&lt;/a&gt; - Cloudera engineering blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&quot;&gt;http://community.cloudera.com/t5/Community-News-Release/bd-p/RelAnnounce&lt;/a&gt; - Release Announcements&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-cdh/</guid> </item> </channel> </rss>
