<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>The Plan For This Week - 30/10/2017</title><link>http://ondataengineering.net/blog/2017/10/30/the-plan-for-this-week/</link><pubDate>Mon, 30 Oct 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So, I think we’re probably done with looking at data storage and databases, however before we move on to data acquisition, processing and transformation tools, and the interesting set of supporting capabilities that live within a data ecosystem, there’s a bit of housekeeping to do.&lt;/p&gt; &lt;p&gt;So over this week (and maybe next), expect some random updates. I want to update and rework the technology categories home page to provide a bit more structure, and there are a few technologies I’ve been meaning to double back on now there should be some more documentation around beyond a press release (Hortonworks Data Plane, Cloudera SDX, MapR-XD/ES for starters). Plus I need to work out what technology categories might be coming up.&lt;/p&gt; &lt;p&gt;So hang in there - new content coming, but what and when might be a little random for the next few weeks…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/30/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Query Engines and Analytical Databases</title><link>http://ondataengineering.net/blog/2017/10/27/thoughts-on-query-engines-and-analytical-databases/</link><pubDate>Fri, 27 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, we’ve finally completed our look at &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt;, with a short stop to look at &lt;a href=&quot;/tech-categories/query-engines&quot;&gt;query engines&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So let’s summarise and spew some thoughts… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Let’s start with &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt;, with a bit of noddy pseudo-history tale telling. Once upon a time the relational database was invented, but these initially focused on transactional use creates - creating, finding, updating and deleting records - what’s now sometimes referred to as OLTP (online transaction processing). However SQL was a great and so people started using it to try and generate reports on the data in their relational databases - queries that focused on aggregating and joining significant portions of their data. And that was generally fine, until data volumes increased to the point where databases designed for transactional workloads struggled to handle the loads generated from these reports or analytics - fetching lots of data off disk and aggregating it was expensive.&lt;/p&gt; &lt;p&gt;And so the analytical OLAP (online analytical processing) databases were born - designed to primarily support the large full table scan aggregation queries, while still retaining the core relational database support for transactions. These were marketed as data warehouse or analytical databases, and with them came a bunch of new technologies - parallelism and the invention of the MPP (massively parallel processing) database, as full table scans and aggregations lend themselves well to partitioning and parallelisation (even if joins do not); columnar compression, which enables faster and more efficient table scans of columns from database tables; pre-aggregation of data, through materialized views and pre-generated cubes; and a range of new functionality designed to complement SQL as an analytical tool, such as support for machine learning, geographical analytics, map reduce and custom analytical functions. Today, these are often sold as appliances, bundling clusters of compute and storage servers with huge bandwidth interconnects between them, however many have now also started embracing the cloud, being available as a cloud service but also to a lesser extents as cloud native software. Open source projects in this space however are scarce.&lt;/p&gt; &lt;p&gt;Instead, the the charge of open source software into the space ended up being spearheaded by Hadoop. Whilst analytical databases have long separated storage and compute (with some interesting abilities to push some parts of the query down to the storage layer), it was Hadoop that’s formalised this by separating them into completely separate and interchangeable components. This can be seen from the very first versions of Hadoop, in that it was made up of two products - HDFS and MapReduce - storage and compute, and over time there’s been evolution on both sides. In storage, HDFS has remained a constant, but there’s been huge innovation in the storage formats of data (see our &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;Data Storage Formats&lt;/a&gt; page). On the compute side, there’s been a veritable explosion of &lt;a href=&quot;/tech-categories/query-engines&quot;&gt;query engines&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;These started out as batch query engines - every query starting up a new job (initial MapReduce) to go and read all the data and execute the query. However there’s been significant push into low latency high concurrency query engines, led by the big Hadoop vendors - Cloudera with &lt;a href=&quot;/technologies/apache-implala/&quot;&gt;Impala&lt;/a&gt; and Hortonworks with &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; - both trying to make Hadoop a realistic competitor in the analytical database market. Compared to analytical databases Hadoop query engines are new technologies - their query optimisers and SQL compliance generally lag the mature analytical databases, however they’re seeing significant investment, and they’re not at the point where they’ll probably support most of your use cases.&lt;/p&gt; &lt;p&gt;And this split of storage and compute has brought some interesting benefits. This first is support for the whole “schema-on-read” shtick - the idea that you can query your raw data without having to do any preparation first. It’s slow, and painful, but for an initial exploratory analysis it’s a valuable tool. And of course if there’s value in the data, you’re still feel to do some work that makes it quicker, easier and more efficient to query. The second is that these tools have naturally evolved some level of query federation - if I want to exploit raw un prepared data I have to accept that this data may be in multiple places in a range of formats, and if I have a query engine that’s separated from the underlying storage, why not make that storage pluggable, and support multiple storage platforms. And so many of these tools support querying over a range of data sources, from HDFS, to S3, to HBase, to relational and NoSQL database, and (interestingly) some emerging support for Kafka . They don’t have the level of sophistication around semantic layers and caching and materialisation of data the &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt; technologies do, but it can still be a hugely valuable capability.&lt;/p&gt; &lt;p&gt;And now we’re starting to see commercial vendors get involved, both large established vendors (Teradata, IBM, Oracle) who are updating their products to run over HDFS and external data stores, but also new vendors in this space who’ve seen an opportunity to sell commercial products in this space that offer a level of functionality and maturity that maybe some of the open source products can’t match. If you’re running open source Hadoop, some of these may well be worth a look.&lt;/p&gt; &lt;p&gt;Finally - a couple of footnotes…&lt;/p&gt; &lt;p&gt;Although many of these tools support SQL, there are many that have their own query languages - Pig has Pig Latin, MRQL has it’s own language - and of course you could probably count most of the graph and machine learning projects as query languages, which suggests I’ve probably not named this category particularly well. SQL is always going to be the dominant language in this space however, and anything with it’s own query language is unlikely to make an impact.&lt;/p&gt; &lt;p&gt;It’s also worth commenting on the role of the Hive metadata in the Hadoop query engine ecosystem. If you’re separating compute and storage, you need some way of telling the compute what data’s available for query and what format it’s in. Within Hive, this was the Hive Metastore, and this is now gradually being adopted as the standard in this space, giving some interesting interoperability options, in that if you define a table in the Hive Metastore, you can query that with either Hive or Impala (or any other technology that uses the Metastore). And now there’s a proposal to break the Metastore out of the Hive project into it’s own top level Apache project, to reflect the wider role it has in the Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;Right - that will do, and hopefully brings the protracted birth of our analytical databases content to and end. Have a good weekend everyone, and we’ll see you on Monday for a week or two of random catch up and clean up.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/27/thoughts-on-query-engines-and-analytical-databases/</guid> </item> <item><title>Analytical Databases</title><link>http://ondataengineering.net/tech-categories/analytical-databases/</link><pubDate>Thu, 26 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Full stack databases (supporting both storage and query of data) that focus on analytical or OLAP use cases that generally involve large scanning or aggregation operations. Typically support distributed parallel execution of queryies (and are therefore commonly referred to as MPP databases) with columnar compression, and often support a range of analytics beyond SQL queries, for example cube based MDX queries, machine learning or geographical analytics. Some technologies also support a level of query federation using external tables (for example over data in Hadoop).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;Gartner’s &lt;a href=&quot;https://www.gartner.com/doc/3614317&quot;&gt;Magic Quadrant for Data Management Solutions for Analytics - Feb 2017&lt;/a&gt; covers most of the technologies in this list (along with a range of others, including Hadoop vendors), and is available from many of the vendors, including &lt;a href=&quot;https://www.cloudera.com/content/dam/www/marketing/resources/analyst-reports/gartners-magic-quadrant-for-data-warehouse-and-data-management-solutions-for-analytics.png.landing.html&quot;&gt;Cloudera&lt;/a&gt;, &lt;a href=&quot;https://mapr.com/blog/gartner-2016-magic-quadrant-data-warehouse-and-database-management-solutions-analytics/&quot;&gt;MapR&lt;/a&gt; and &lt;a href=&quot;http://blog.memsql.com/gartner-magic-quadrant-analytics/&quot;&gt;MemSQL&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Forrester’s &lt;a href=&quot;https://www.forrester.com/report/The+Forrester+Wave+Big+Data+Warehouse+Q2+2017/-/E-RES136478&quot;&gt;Big Data Warehouse Wave Q2 2017&lt;/a&gt; covers a similar set of technologies, and is available from &lt;a href=&quot;https://hortonworks.com/info/big-data-solution-will-help-make-big-difference/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&quot;commercial-software&quot;&gt;Commercial Software&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;IBM Db2 Warehouse (formerly dashDB for Analytics)&lt;/td&gt; &lt;td&gt;IBM Db2 and BLU (in memory) for Docker container supported infrastructure (also available as an appliance and cloud service - see below) - &lt;a href=&quot;https://www.ibm.com/aw-en/marketplace/db2-warehouse&quot;&gt;https://www.ibm.com/aw-en/marketplace/db2-warehouse&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata Database&lt;/td&gt; &lt;td&gt;MPP database with support for a range of data warehouse and analytics functions; deployable on private or public cloud (also available as an appliance and a cloud service - see below) - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/teradata-database&quot;&gt;http://www.teradata.co.uk/products-and-services/teradata-database&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata Aster Analytics&lt;/td&gt; &lt;td&gt;Analytics platform that supports graph, text and IoT analysis plus machine learning (also available as an appliance and a cloud service - see below) - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/analytics-from-aster-overview&quot;&gt;http://www.teradata.co.uk/products-and-services/analytics-from-aster-overview&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Vertica&lt;/td&gt; &lt;td&gt;MPP columnar database with support for a range of analytical functions including machine learning; deployable on commodity infrastructure or public/private cloud - &lt;a href=&quot;https://www.vertica.com/overview/&quot;&gt;https://www.vertica.com/overview/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Actian Vector&lt;/td&gt; &lt;td&gt;MPP columnar database with support for vectorized execution, small incremental inserts and min-max indices, with a free community edition for databases under 1 Tb and an Hadoop edition that runs as a native YARN app but requires data to be loaded into its proprietary data format - &lt;a href=&quot;https://www.actian.com/analytic-database/vector-smp-analytic-database/&quot;&gt;https://www.actian.com/analytic-database/vector-smp-analytic-database/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;InfoBrightDB&lt;/td&gt; &lt;td&gt;Columnar database, now sold by Ignite Technologies - &lt;a href=&quot;http://www.ignitetech.com/solutions/information-technology/infobrightdb&quot;&gt;http://www.ignitetech.com/solutions/information-technology/infobrightdb&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;appliances&quot;&gt;Appliances&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Oracle Exadata&lt;/td&gt; &lt;td&gt;An appliance consisting of an Oracle RAC cluster combined with a set of storage nodes via high bandwidth interconnect, with support for hybrid columnar compression - &lt;a href=&quot;https://www.oracle.com/engineered-systems/exadata/index.html&quot;&gt;https://www.oracle.com/engineered-systems/exadata/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Microsoft Analytics Platform System&lt;/td&gt; &lt;td&gt;An appliance built around SQL Server Parallel Data Warehouse and PolyBase - &lt;a href=&quot;https://www.microsoft.com/en-us/sql-server/analytics-platform-system&quot;&gt;https://www.microsoft.com/en-us/sql-server/analytics-platform-system&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Integrated Analytics System&lt;/td&gt; &lt;td&gt;Appliance built around Db2 Warehouse and BLU (in memory) acceleration with support for Spark - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/integrated-analytics-system&quot;&gt;https://www.ibm.com/us-en/marketplace/integrated-analytics-system&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM PureData System for Analytics (formally Netezza)&lt;/td&gt; &lt;td&gt;Appliance utilising FPGA chips to run elements of queries in hardware, with support for a range of languages including R - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/puredata-system-for-analytics#product-header-top&quot;&gt;https://www.ibm.com/us-en/marketplace/puredata-system-for-analytics#product-header-top&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata Integrated Data Warehouses&lt;/td&gt; &lt;td&gt;A family of Teradata database appliances - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/data-warehouse-overview&quot;&gt;http://www.teradata.co.uk/products-and-services/data-warehouse-overview&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata Aster Analytics&lt;/td&gt; &lt;td&gt;Aster appliance - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/aster-big-analytics-appliance/&quot;&gt;http://www.teradata.co.uk/products-and-services/aster-big-analytics-appliance/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Pivotal EMC Data Computing Appliance (DCA)&lt;/td&gt; &lt;td&gt;Greenplum appliance - &lt;a href=&quot;https://pivotal.io/emc-dca&quot;&gt;https://pivotal.io/emc-dca&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;cloud-services&quot;&gt;Cloud Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Amazon Redshift&lt;/td&gt; &lt;td&gt;A MPP analytical database, with support for columnar storage and the ability to query data in Amazon S3 as external tables (Redshift Spectrum) - &lt;a href=&quot;https://aws.amazon.com/redshift/&quot;&gt;https://aws.amazon.com/redshift/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Big Query&lt;/td&gt; &lt;td&gt;Analytical SQL database service, with cost based on storage and query execution - &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;https://cloud.google.com/bigquery/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure SQL Data Warehouse&lt;/td&gt; &lt;td&gt;Scalable analytical database, with support for Azure Data Lake Store external tables - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/sql-data-warehouse/&quot;&gt;https://azure.microsoft.com/en-us/services/sql-data-warehouse/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle Exadata Cloud&lt;/td&gt; &lt;td&gt;Oracle Exadata as a managed cloud service (including as an Oracle managed on premises offering) - &lt;a href=&quot;https://cloud.oracle.com/database&quot;&gt;https://cloud.oracle.com/database&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Db2 Warehouse (formerly dashDB for Analytics)&lt;/td&gt; &lt;td&gt;IBM Db2 and BLU (in memory) acceleration as a cloud service - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/db2-warehouse-on-cloud&quot;&gt;https://www.ibm.com/us-en/marketplace/db2-warehouse-on-cloud&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata IntilliCloud&lt;/td&gt; &lt;td&gt;Teradata Database, Hadoop and Aster as a service - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/intellicloud&quot;&gt;http://www.teradata.co.uk/products-and-services/intellicloud&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Snowflake&lt;/td&gt; &lt;td&gt;Data Warehouse for the cloud, with separated compute and storage, columnar storage, vectorized execution, adaptive optimisation (no indexes, keys or tuning required) and support for semi-structured (JSON, Avro and XML) data - &lt;a href=&quot;https://www.snowflake.net/&quot;&gt;https://www.snowflake.net/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;open-source-software&quot;&gt;Open Source Software&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt;&lt;/td&gt; &lt;td&gt;MPP databased based on PostgreSQL, with support for multiple storage models and analytical capabilities; open sourced in October 2015&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MariaDB ColumnStore&lt;/td&gt; &lt;td&gt;Columnar storage for MariaDB (the open source fork of MySQL) based on a fork of InfiniDB - &lt;a href=&quot;https://mariadb.com/products/technology/columnstore&quot;&gt;https://mariadb.com/products/technology/columnstore&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MonetDB&lt;/td&gt; &lt;td&gt;Open source columnar database - &lt;a href=&quot;https://www.monetdb.org/&quot;&gt;https://www.monetdb.org/&lt;/a&gt; ; &lt;a href=&quot;https://www.monetdbsolutions.com/&quot;&gt;https://www.monetdbsolutions.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;InifiDB&lt;/td&gt; &lt;td&gt;Open source columnar database, inactive since March 2015 - &lt;a href=&quot;https://github.com/infinidb/infinidb&quot;&gt;https://github.com/infinidb/infinidb&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Pinot&lt;/td&gt; &lt;td&gt;Open source realtime distributed OLAP datastore from LinkedIn - &lt;a href=&quot;https://github.com/linkedin/pinot&quot;&gt;https://github.com/linkedin/pinot&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;open-source-hadoop-olap-cube-technologies&quot;&gt;Open Source Hadoop OLAP Cube Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/druid&quot;&gt;Druid&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Runs over HDFS/S3 and supports real time aggregations of streaming data&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Kylin&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Supports the creation and querying of OLAP cubes on Hadoop, building cubes from star schema data in Hive into HBase, and then providing a SQL interface that queries across Hive and HBase as required - &lt;a href=&quot;http://kylin.apache.org/&quot;&gt;http://kylin.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;in-memory-techs&quot;&gt;In Memory Techs&lt;/h2&gt; &lt;p&gt;A number of &lt;a href=&quot;/tech-categories/in-memory-databases/&quot;&gt;In Memory Databases&lt;/a&gt; support analytical capabilities, including:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MemSQL&lt;/td&gt; &lt;td&gt;Distributed in memory relational database, with wire compatibility with MySQL and support for row and columnar storage, and a free community edition - &lt;a href=&quot;http://www.memsql.com/&quot;&gt;http://www.memsql.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SAP HANA&lt;/td&gt; &lt;td&gt;In memory relational DBMS primarily focused on accelerating SAP applications - &lt;a href=&quot;https://www.sap.com/products/hana.html&quot;&gt;https://www.sap.com/products/hana.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;EXASOL&lt;/td&gt; &lt;td&gt;In memory MPP database with columnar compression and SQL support - &lt;a href=&quot;http://www.exasol.com/&quot;&gt;http://www.exasol.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MapD&lt;/td&gt; &lt;td&gt;In memory, column store, SQL relational database that runs on GPUs - &lt;a href=&quot;https://www.mapd.com/&quot;&gt;https://www.mapd.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Kinetica&lt;/td&gt; &lt;td&gt;Distributed in memory relational database that runs on GPUs - &lt;a href=&quot;https://www.kinetica.com&quot;&gt;https://www.kinetica.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/analytical-databases/</guid> </item> <item><title>The Mid Week News - 25/10/2017</title><link>http://ondataengineering.net/blog/2017/10/25/the-mid-week-news/</link><pubDate>Wed, 25 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s news time again… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit 5.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; has hit 1.2&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Some interesting slides from Todd Lipcon on the Kudu blog on Hybrid Transactional/Analytic Processing (HTAP) and how &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Kudu&lt;/a&gt; compares to Google Spanner - &lt;a href=&quot;https://kudu.apache.org/2017/10/23/nosql-kudu-spanner-slides.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A couple of updates from Neo4j from its GraphConnect conference in New York, including the contribution of a Cypher interface for &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;, and new analytical functions in Neo4J - &lt;a href=&quot;http://www.zdnet.com/article/sparkier-faster-more-graph-databases-and-neo4j-moving-on/&quot;&gt;ZDNet&lt;/a&gt;; &lt;a href=&quot;https://www.theregister.co.uk/2017/10/24/neo4j_native_graph_platform/&quot;&gt;The Register&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Comparison of &lt;a href=&quot;/technologies/apache-cassandra/&quot;&gt;Apache Cassandra&lt;/a&gt; and ScyllaDB (the Cassandra port to C++) from ZDNet - &lt;a href=&quot;http://www.zdnet.com/article/a-rock-and-a-hard-place-between-scylladb-and-cassandra/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From The Register - The Linux Foundation have a new open-data licence - &lt;a href=&quot;https://www.theregister.co.uk/2017/10/23/linux_foundation_community_data_license_agreement/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From the Influx blog - getting started with &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; in 5 minutes - &lt;a href=&quot;https://www.influxdata.com/blog/zero-awesome-in-5-minutes/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The John Snow Labs have released an NLP library for &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; - &lt;a href=&quot;https://databricks.com/blog/2017/10/19/introducing-natural-language-processing-library-apache-spark.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Gartner have released their latest Magic Quadrant for Distributed File Systems and Object Storage. No significant changes, thoughts from The Register are &lt;a href=&quot;https://www.theregister.co.uk/2017/10/19/gartner_2017_object_storage_magic_quadrant/&quot;&gt;here&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/25/the-mid-week-news/</guid> </item> <item><title>Query Engines</title><link>http://ondataengineering.net/tech-categories/query-engines/</link><pubDate>Tue, 24 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Engines that allow queries expressed in a high level language (often SQL) to be run over one or more underlying data stores or databases, often including HDFS (and often using table definitions from the Hive Metastore), but with support for other Hadoop, relational and NoSQL databases commonly supported. Many technologies started as batch query engines (with high query startup costs and limited support for concurrent queries), but most can now be considered interactive with support for multiple concurrent low latency queries. Given the propensity for querying over Hadoop data using SQL, many of these technologies are often refered to as SQL-on-Hadoop technologies.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;See our &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;Data Storage Formats&lt;/a&gt; page for information on file formats to use with these query engines.&lt;/p&gt; &lt;p&gt;If you’re looking for technologies that support query execution over multiple data sources, see also our &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt; page.&lt;/p&gt; &lt;h2 id=&quot;open-source-technologies&quot;&gt;Open Source Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Supports the execution of SQL queries over data in HDFS using MapReduce, Spark or Tez based on tables defined in the Hive Metastore&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;Apache HAWQ (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A port of the Greenplum MPP database (which itself is based on PostgreSQL) to run as a YARN application over in HDFS, Hive or HBase&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-tajo/&quot;&gt;Apache Tajo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Distributed analytical database engine supporting queries over data in HDFS, Amazon S3, Google Cloud Storage, OpenStack Swift and local storage, and querying over Postgres, HBase and Hive tables.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An MPP query engine that supports queries over one or more underlying databases or datasets without first defining a schema and with the ability to join data from multiple data stores together.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Apache Lens&lt;/td&gt; &lt;td&gt;Provides a cube based federated view over a range of data stores including HDFS, HBase, relational databases, S3 and Redshift - &lt;a href=&quot;http://lens.apache.org/&quot;&gt;http://lens.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/spark-sql/&quot;&gt;Apache Spark SQL&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Hive compatible SQL query engine that use Spark to execute queries over any Spark supported data source&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Presto&lt;/td&gt; &lt;td&gt;Distributed SQL query engine over data in HDFS, NoSQL and relational databases and Kafka, originally created and open sourced by Facebook - &lt;a href=&quot;https://prestodb.io/&quot;&gt;https://prestodb.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Apache Pig&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for running analytical and data processing jobs written in Pig Latin against data in Hadoop using MapReduce, Tez and Spark&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Apache MRQL (Incubating)&lt;/td&gt; &lt;td&gt;Supports the execution of MRQL queries over data in Hadoop using MapReduce, Hama, Spark or Flink - &lt;a href=&quot;http://mrql.apache.org/&quot;&gt;http://mrql.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-technologies&quot;&gt;Commercial Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Kognitio&lt;/td&gt; &lt;td&gt;In memory database engine that can run as a YARN application on Hadoop over data in HDFS (as a free offering) or as a standalone cluster over data in HDFS, the cloud and other databases (as a commercial offering with a free trial) - &lt;a href=&quot;https://kognitio.com/&quot;&gt;https://kognitio.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jethro&lt;/td&gt; &lt;td&gt;SQL query engine over HDFS and S3 that supports indexing, auto generation of cubes and results caching - &lt;a href=&quot;https://jethro.io/&quot;&gt;https://jethro.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Teradata Aster Analytics on Hadoop&lt;/td&gt; &lt;td&gt;Teradata Aster running natively on Hadoop as a YARN application - &lt;a href=&quot;http://www.teradata.co.uk/products-and-services/aster-analytics-on-hadoop/&quot;&gt;http://www.teradata.co.uk/products-and-services/aster-analytics-on-hadoop/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Vertica on Hadoop&lt;/td&gt; &lt;td&gt;Vertica running on Hadoop - &lt;a href=&quot;https://www.vertica.com/product/vertica-for-sql-on-hadoop/&quot;&gt;https://www.vertica.com/product/vertica-for-sql-on-hadoop/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Big SQL&lt;/td&gt; &lt;td&gt;SQL engine that runs on Hadoop over Hive tables, but that can also federate into RDMS and NoSQL databases and object stores - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/big-sql&quot;&gt;https://www.ibm.com/us-en/marketplace/big-sql&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle Big Data SQL&lt;/td&gt; &lt;td&gt;Allows federated queries from an Oracle databases over Hadoop and NoSQL databases, with push down of logic and support for Oracle security - &lt;a href=&quot;https://www.oracle.com/database/big-data-sql/index.html&quot;&gt;https://www.oracle.com/database/big-data-sql/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;cloud-technologies&quot;&gt;Cloud Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Amazon Athena&lt;/td&gt; &lt;td&gt;SQL query service over data in Amazon S3 - &lt;a href=&quot;https://aws.amazon.com/athena/&quot;&gt;https://aws.amazon.com/athena/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Data Lake Analytics&lt;/td&gt; &lt;td&gt;Massively parallel analytics job service, with support for U-SQL, R, Python, and .NET - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/data-lake-analytics/&quot;&gt;https://azure.microsoft.com/en-us/services/data-lake-analytics/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/query-engines/</guid> </item> <item><title>The Week That Was</title><link>http://ondataengineering.net/blog/2017/10/20/the-week-that-was/</link><pubDate>Fri, 20 Oct 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Another week, another apology.&lt;/p&gt; &lt;p&gt;For various reasons the new analytical databases technology category pages aren’t ready yet. They’re almost done however, and will be going up all next week.&lt;/p&gt; &lt;p&gt;Thank you for your patience.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/20/the-week-that-was/</guid> </item> <item><title>The Mid Week News - 18/10/2017</title><link>http://ondataengineering.net/blog/2017/10/18/the-mid-week-news/</link><pubDate>Wed, 18 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;News news news! A bunch of new technology releases and interested blog posts for your purusal this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; has seen a 5.13 release, with Kudu now fully bundled and Spark 1.x deprecated&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; is up to 5.13&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; is up to 2.12&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; is up to 2.6&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt; is up to 4.12&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt; is up to 7.1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Microsoft have released/updated &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/architecture/aws-professional/services&quot;&gt;their Azure to AWS services comparison&lt;/a&gt;&lt;/li&gt; &lt;li&gt;LinkedIn have posted about &lt;a href=&quot;https://engineering.linkedin.com/blog/2017/10/streaming-data-pipelines-with-brooklin&quot;&gt;Brooklin&lt;/a&gt; - their internal product (planned to be open sourced in 2018) for moving streaming data around and performing change data capture on source databases&lt;/li&gt; &lt;li&gt;Uber have posted about &lt;a href=&quot;https://eng.uber.com/athenax/&quot;&gt;AthenaX&lt;/a&gt; their technology for running SQL analytics over streaming data using Flink&lt;/li&gt; &lt;li&gt;An interesting post from DB Engines on &lt;a href=&quot;https://db-engines.com/en/blog_post/72&quot;&gt;multi-model databases&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks have posted on &lt;a href=&quot;https://hortonworks.com/blog/automated-validation-apache-hadoop-ecosystem/&quot;&gt;how they test their Hadoop distribution&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A post from Google on BigQuery, and how it’s separation of data and processing &lt;a href=&quot;https://hortonworks.com/blog/automated-validation-apache-hadoop-ecosystem/&quot;&gt;gives near linear scalability&lt;/a&gt;, comparing it’s performance to Impala, Spark, Hive and Presto&lt;/li&gt; &lt;li&gt;Cloudera have been looking at &lt;a href=&quot;/technologies/microsoft-azure-data-lake-store/&quot;&gt;Azure Data Lake Store&lt;/a&gt;, concluding that [performance “compares favourably” to using network-attached Azure disk storage - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/10/a-look-at-adls-performance-throughput-and-scalability/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And another benchmark - this time DataBricks claiming that Spark &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Structured Streaming&lt;/a&gt; is 5 times faster than Flink and Kafka Streams - &lt;a href=&quot;https://databricks.com/blog/2017/10/11/benchmarking-structured-streaming-on-databricks-runtime-against-state-of-the-art-streaming-systems.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And finally, there’s a new security vulnerability in Solr - &lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-12629&quot;&gt;CVE-2017-12629&lt;/a&gt; - a remote code execution issue&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/18/the-mid-week-news/</guid> </item> <item><title>The Week That Was</title><link>http://ondataengineering.net/blog/2017/10/13/the-week-that-was/</link><pubDate>Fri, 13 Oct 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;As suspected, no updates this week - I’m still trying to work out how to make sense of analytical database technologies and present these in a useful way.&lt;/p&gt; &lt;p&gt;So hold tight - a bunch (few) technology categories and some thoughts will be coming next week.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/13/the-week-that-was/</guid> </item> <item><title>The Mid Week News - 11/10/2017</title><link>http://ondataengineering.net/blog/2017/10/11/the-mid-week-news/</link><pubDate>Wed, 11 Oct 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;It’s news time again - come and see what new tech releases and interesting reading we have for you this week! &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/mesosphere-dcos/&quot;&gt;Mesosphere DC/OS&lt;/a&gt; is up to 1.10&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/mesosphere-marathon&quot;&gt;Mesosphere Marathon&lt;/a&gt; is up to 1.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/rex-ray/&quot;&gt;REX-Ray&lt;/a&gt; is up to 0.10&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; is up to 4.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-flume&quot;&gt;Flume&lt;/a&gt; is up to 1.8&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;From ZDNet, &lt;a href=&quot;http://www.zdnet.com/article/towards-a-unifying-data-theory-and-practice-combining-operations-analytics-and-streaming/&quot;&gt;thoughts&lt;/a&gt; on SnappyData, and the convergence of OLTP, OLAP and streaming analytics&lt;/li&gt; &lt;li&gt;From The Register, &lt;a href=&quot;/tech-vendors/microsoft-azure/&quot;&gt;Azure&lt;/a&gt; now supports a dedicated tool for provisioning Spark based on Azure Batch&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/tech-vendors/amazon-web-services/&quot;&gt;Amazon&lt;/a&gt; EMR now supports &lt;a href=&quot;/technologies/apache-livy&quot;&gt;Livy&lt;/a&gt;, as well as new versions of Hue, Presto, Flink and Pig.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://content.pivotal.io/blog/apache-madlib-comes-of-age&quot;&gt;Thoughts&lt;/a&gt; on MADLib from Pivotal following it’s graduation from the Apache incubator. We’ll be looking more at capabilities like this over this week and next.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache Nifi&lt;/a&gt; has security vulnerablity - &lt;a href=&quot;http://www.cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-12623&quot;&gt;CVE-2017-12623&lt;/a&gt; - authorized user could upload a template which contained malicious code and accessed sensitive files via an XML External Entity (XXE) attack&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.crail.io/&quot;&gt;Crail&lt;/a&gt; has been &lt;a href=&quot;https://wiki.apache.org/incubator/CrailProposal&quot;&gt;submitted&lt;/a&gt; to the Apache Incubator - looks like a high performance distributed and tiered (in memory, flash and disk) storage layer for temporary data that provides memory, storage and network access that bypasses the JVM and OS, and with integration to Spark (as a custom Spark Suffler that improves sort performance by a factor of five) and Hadoop (via an HDFS adaptor).&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/11/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 10/10/2017</title><link>http://ondataengineering.net/blog/2017/10/10/the-plan-for-this-week/</link><pubDate>Tue, 10 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;First up, yes, we’re a day late on this post - apologies. Don’t get confused - it is Tuesday today and not Monday.&lt;/p&gt; &lt;p&gt;So I think we have one last technology category to see off before we move on from data storage and database technologies, and that’s analytical databases - those that specialise in large scanning analytical queries and that combine support for SQL with a range of other analytical capabilities.&lt;/p&gt; &lt;p&gt;This feels like another monster category, so don’t expect much content this week, and I have a feeling it’s going to be next week before we can wrap everything up.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/10/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Hadoop Data Formats</title><link>http://ondataengineering.net/blog/2017/10/06/thoughts-on-hadoop-data-formats/</link><pubDate>Fri, 06 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;This week we looked at two file formats for Hadoop; &lt;a href=&quot;/technologies/apache-orc&quot;&gt;ORC&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-carbondata&quot;&gt;CarbonData&lt;/a&gt; and a new in-memory data structure specification; &lt;a href=&quot;/technologies/apache-arrow&quot;&gt;Arrow&lt;/a&gt;. Earlier on this year we looked at data serialisation frameworks - &lt;a href=&quot;/technologies/apache-avro&quot;&gt;Avro&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-parquet&quot;&gt;Parquet&lt;/a&gt;. File formats, data serialisation frameworks, specifications… Ahh, what a minefield! Today I’d like to try and make sense of it all by looking at the evolution of these various data formats to see how we got here. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Back in the old days, it wasn’t uncommon to process gzipped plain text delimited formatted data using MapReduce. However, if the data was supplied as lots of &lt;a href=&quot;https://blog.cloudera.com/blog/2009/02/the-small-files-problem&quot;&gt;small files&lt;/a&gt;, eventually, pressure would be put on HDFS because of a hard limit on the number of files it can physically track. At the same time if too few large files were supplied, MapReduce wouldn’t be able to efficiently carve up the data for parallel processing. SequenceFile was the first file format to address both of these issues by providing a container in which many small files could be put into a larger single file with synchronisation markers to permit efficient splitting of files to distribute the workload. The file format also allowed for different types of compressions to be used inside of the file to provide a finer level of compression control whilst still maintaining its splitability characteristics. And for a while, SequenceFile was fine if you were just using it to do large-scale distributed batch processing or building a self-contained system using Java, such a &lt;a href=&quot;/technologies/apache-hbase&quot;&gt;storage manager&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As a file format, &lt;a href=&quot;/technologies/apache-avro&quot;&gt;Avro&lt;/a&gt; builds on top of the &lt;a href=&quot;http://avro.apache.org/docs/current/spec.html#Object+Container+Files&quot;&gt;container file format&lt;/a&gt; and synchronisation marker ideas but adds the ability to model relational and complex data. It achieves this through the concept of a schema that allows you to specify the structure, type and the meaning of your data, and when distributed together with your data, you’ll have self describing data that can be used as both a wire format for communication and a serialisation format for persistent data. But Avro’s creator - Doug Cutting didn’t just stop there, Avro had a much grander aspiration. Its design accommodated schema evolution which allowed your data to be long lived and reusable by other applications outside of the Hadoop and Java ecosystem.&lt;/p&gt; &lt;p&gt;So far, when it comes to serialising data for persistence, our file formats have been writing consecutive elements of a row next to each other on disk. Around 2010/2011, there were several research projects experimenting with column-oriented data layout designs on HDFS. The idea behind a columnar data structure was to lay out your data so that column values were adjacent to one another. For read queries that only process a small subset of columns but over a large number of rows at a time (the so called typical analytical workload), it was possible to read only the required column values off disk, thereby minimising disk I/O. Contrary to the more traditional row-oriented data layout for the same type of query, you were forced to read all the other columns off disk, keep the columns required by the query and discard the unused ones. Column data being uniform in type, also had the additional benefit of being highly compressible, allowing the same data to be stored on disk in a smaller form and further reducing I/O. This approach to optimise data placement was popularised by databases such as &lt;a href=&quot;https://www.monetdb.org&quot;&gt;MonetDB&lt;/a&gt; and &lt;a href=&quot;https://www.vertica.com&quot;&gt;HP Vertica&lt;/a&gt;. The tradeoff would be slower writes, but this proved a good optimisation for analytical workloads. The record columnar file format (RCFile) came out of one of these research projects and became widely adopted in the Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;By 2013, there was gathering interest towards using Hadoop for interactive, data warehouse-style SQL queries, and combining Hive with RCFile for data storage was a popular choice. &lt;a href=&quot;/tech-vendors/hortonworks&quot;&gt;Hortonworks&lt;/a&gt; launched the &lt;a href=&quot;https://hortonworks.com/blog/100x-faster-hive&quot;&gt;Stinger initiative&lt;/a&gt; with the goal to dramatically speed up Hive and make it more enterprise-ready. Building on top of the columnar file format of RCFile, the team introduced Avro’s schema concept to allow the format to model complex nested structures which wasn’t previously supported by RCFile. Armed with this metadata, it was also possible to intelligently select an appropriate compression schema based on a column’s data type. The format also allowed additional metadata such as min and max indexes to be collected which could then be later used to intelligently skip irrelevant parts of the data without the need for large, complex, or manually maintained indexes. Other improvements introduced over Avro and RCFile was the ability to identify the boundaries on which files could be split with having to scan for synchronisation markers. This new file format was known as the &lt;a href=&quot;/technologies/apache-orc&quot;&gt;Optimized Record Columnar (ORC)&lt;/a&gt; File. The Avro team had also been experimenting with a columnar file format design called Trevni which was picked up by &lt;a href=&quot;/tech-vendors/cloudera&quot;&gt;Cloudera&lt;/a&gt; and Twitter to develop &lt;a href=&quot;/technologies/apache-parquet&quot;&gt;Parquet&lt;/a&gt;. On the other hand, ORC was spun out of Hive into a separate project but was initially kept closely integrated. Parquet was positioned as a more general-purpose columnar file format for use with any Hadoop framework, although essentially both projects shared the same fundamental ideas. Today, they both stand in their own right and are integrated with a number of different frameworks.&lt;/p&gt; &lt;p&gt;Up until now we’ve being looking at data formats that are primarily optimised for a single type of query analysis. This is not ideal if you want your data processing platform to support a wide spectrum of different types of query analysis. &lt;a href=&quot;/technologies/apache-carbondata&quot;&gt;CarbonData&lt;/a&gt; from Huawei aims to tackle the ‘one format to rule them all’ idea heads on. Building on the previous formats, CarbonData introduces multi-dimensional key indexes inspired from the likes of Mondrian (an early open source OLAP server) and Apache &lt;a href=&quot;/technologies/apache-kylin&quot;&gt;Kylin&lt;/a&gt; to support multi-dimensional OLAP style queries, inverted indexes for count distinct like operations, and the ability to group columns together to support detailed queries which fetch many columns out of a wide table.&lt;/p&gt; &lt;p&gt;Finally, we come to &lt;a href=&quot;/technologies/apache-arrow&quot;&gt;Apache Arrow&lt;/a&gt;. Unlike the previous data formats we’ve discussed, Arrow isn’t about serialising data to disk, but is an in-memory data format that focuses on CPU throughput for efficient processing and for data exchange between process/systems without serialisation and deserialisation. Similar to ORC and Parquet, data is structured in a columnar structure, so when it comes to analytical workloads, only the required data can be supplied to the CPU. This data placement strategy takes full advantage of the on-chip cache storage (which is 100x faster to access than main memory), pipelining, and SIMD (Single Instruction Multiple Data) instructions which work on multiple data values simultaneously in a single CPU clock cycle. As an in-memory data format, this concept wasn’t new and had already been implemented in both &lt;a href=&quot;/technologies/apache-drill&quot;&gt;Drill&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hive/hive-server&quot;&gt;Hive&lt;/a&gt;. What is special about Arrow is its goal to define a standard interchange format to allow sharing of data between processes without the overhead of moving or transforming the data. This is important when you want to put together a data processing platform that isn’t limited only to Hadoop.&lt;/p&gt; &lt;p&gt;In summary, we’ve seen that the original Hadoop data formats were designed to solve very specific use cases. As the drive to develop Hadoop into a more general purpose analytics platform and expand its use outside of the Java ecosystem, the data formats have rapidly evolved, with each new format building on top of the ideas of its predecessor. While the Hadoop ecosystem continues to evolve to cater for new use cases, I expect to see continued innovation in this space.&lt;/p&gt; &lt;p&gt;So I hope this little journey has helped you navigate your way through the complex and rapidly evolving collection of Hadoop data formats - on Monday I’ll hand you back over to Peter.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/06/thoughts-on-hadoop-data-formats/</guid> </item> <item><title>Data Storage Formats</title><link>http://ondataengineering.net/tech-categories/data-storage-formats/</link><pubDate>Thu, 05 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Libraries that support the storage of data on disk for data storage, real-time or batch analytics. Popularised by the use of distributed file systems in analytical platforms, common features include support for schema evolution (the ability to make changes to the schema but stil read all historical data), support for both row and columnar data layouts (supporting efficient batch processing and analytical workloads respectively), complex record formats including nested objects and arrays, indexing to support random data access, and support for efficient inserts, updates and deletes as well as ACID transactions.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;A good introduction from Silicon Valley Data Science to text, SequenceFile, Avro, Parquet and ORC, along with some benchmarks - &lt;a href=&quot;http://www.svds.com/dataformats/&quot;&gt;http://www.svds.com/dataformats/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Comparison of JSON, Avro, ORC and Parquet, including benchmarks, from August 2016 - &lt;a href=&quot;https://www.slideshare.net/HadoopSummit/file-format-benchmark-avro-json-orc-parquet-65740483&quot;&gt;https://www.slideshare.net/HadoopSummit/file-format-benchmark-avro-json-orc-parquet-65740483&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Comparison of Parquet, Avro, HBase and Kudu, from January 2017 - &lt;a href=&quot;https://db-blog.web.cern.ch/blog/zbigniew-baranowski/2017-01-performance-comparison-different-file-formats-and-storage-engines&quot;&gt;https://db-blog.web.cern.ch/blog/zbigniew-baranowski/2017-01-performance-comparison-different-file-formats-and-storage-engines&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&quot;text-based-formats&quot;&gt;Text Based Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Plain Text&lt;/td&gt; &lt;td&gt;Often formatted as either delimited (e.g. comma separated values (CSV) or pipe separated values (PSV)) or fixed width fields&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;XML&lt;/td&gt; &lt;td&gt;Supports the use of external schema definitions, but format can be verbose and serialisation/deserialisation performance often poor&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;JSON (Javascript Object Notation)&lt;/td&gt; &lt;td&gt;More efficient and terse than XML, but still suffers poor serialisation/deserialise performance&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;row-based-formats&quot;&gt;Row Based Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;SequenceFile&lt;/td&gt; &lt;td&gt;Part of the Hadoop project, a container of binary key/value pairs used to store multiple smaller files inside a single large file - &lt;a href=&quot;https://wiki.apache.org/hadoop/SequenceFile&quot;&gt;https://wiki.apache.org/hadoop/SequenceFile&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-avro/&quot;&gt;Avro&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Binary serialisation format supporting schema evolution and complex record types&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;column-based-formats&quot;&gt;Column Based Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;RCFile&lt;/td&gt; &lt;td&gt;Early implementation of a columnar record format as part of the Apache Hive project - &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/RCFile&quot;&gt;https://cwiki.apache.org/confluence/display/Hive/RCFile&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-orc/&quot;&gt;ORCFile&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Evolution of RCFile, spun out into it’s own Apache project&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Parquet&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Columnar format spun out from the Avro Trevni format&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-carbondata/&quot;&gt;CarbonData&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Columnar format created by Huawei to address a number of perceived shortcomings in existing formats&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;map-based-formats&quot;&gt;Map Based Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MapFile, SetFile, ArrayFile, BloomMapFile&lt;/td&gt; &lt;td&gt;Part of the Hadoop project and built on SequenceFile, with MapFile being the original file format used by HBase - &lt;a href=&quot;http://blog.cloudera.com/blog/2011/01/hadoop-io-sequence-map-set-array-bloommap-files/&quot;&gt;http://blog.cloudera.com/blog/2011/01/hadoop-io-sequence-map-set-array-bloommap-files/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TFile&lt;/td&gt; &lt;td&gt;Container of key-value pairs, part of the Hadoop project - &lt;a href=&quot;http://hadoop.apache.org/docs/r2.6.1/api/org/apache/hadoop/io/file/tfile/TFile.html&quot;&gt;http://hadoop.apache.org/docs/r2.6.1/api/org/apache/hadoop/io/file/tfile/TFile.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;HFile&lt;/td&gt; &lt;td&gt;HBase storage format based on TFile and the SSTable format from the Google BigTable paper - &lt;a href=&quot;http://hbase.apache.org/book.html#_hfile_format_2&quot;&gt;http://hbase.apache.org/book.html#_hfile_format_2&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;And of course, any &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;object store&lt;/a&gt;, NoSQL key value store or &lt;a href=&quot;/tech-categories/nosql-wide-column-stores/&quot;&gt;NoSQL wide column store&lt;/a&gt; can be used to store data by key.&lt;/p&gt; &lt;h2 id=&quot;data-storage-services&quot;&gt;Data Storage Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Kudu&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Storage engine that supports efficient storage of data, insert/update/deletes and strong query performance&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;in-memory-formats&quot;&gt;In Memory Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-arrow/&quot;&gt;Arrow&lt;/a&gt;&lt;/td&gt; &lt;td&gt;In memory columnar data format supporting high performance data exchange and fast analytical access&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/data-storage-formats/</guid> </item> <item><title>The Mid Week News - 04/10/2017</title><link>http://ondataengineering.net/blog/2017/10/04/the-mid-week-news/</link><pubDate>Wed, 04 Oct 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Time for the news again, with all our updates on new technology releases and interesting things to read… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt; is up to 1.14&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; is up to 1.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elastic-cloud/&quot;&gt;Elastic Cloud&lt;/a&gt; is now generally available on GCP (after being in beta since April)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt; now supports Azure&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; 6.0 release candidate 1 (RC1) (not for production) is out&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;From MapR, and these are always good for a read, a &lt;a href=&quot;https://mapr.com/blog/database-comparison-an-in-depth-look-at-mapr-db/&quot;&gt;post&lt;/a&gt; on why &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; is better than Cassandra, HBase and others&lt;/li&gt; &lt;li&gt;And another face-off - this time a &lt;a href=&quot;https://brewing.codes/2017/09/25/flink-vs-spark/&quot;&gt;post&lt;/a&gt; on &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Flink&lt;/a&gt; vs &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Spark&lt;/a&gt;&lt;/li&gt; &lt;li&gt;It’s &lt;a href=&quot;https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/&quot;&gt;another interesting Confluence post&lt;/a&gt; (YMMV), this time on machine learning with &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.zdnet.com/article/strata-nyc-2017-to-hadoop-go-jump-in-a-data-lake/&quot;&gt;Thoughts from ZDNet&lt;/a&gt; on the recent Strata NY event&lt;/li&gt; &lt;li&gt;HDInsights now support &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/general-availability-of-hdinsight-interactive-query-blazing-fast-data-warehouse-style-queries-on-hyper-scale-data-2/&quot;&gt;Interactive Query&lt;/a&gt;, aka Hive on LLAP as a service&lt;/li&gt; &lt;li&gt;There are a bunch of security vulnerability announcements this week &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-9792&quot;&gt;CVE-2017-9792&lt;/a&gt; - malicious user with “ALTER” permissions on an Impala table can access any other Kudu table data&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-9797&quot;&gt;CVE-2017-9797&lt;/a&gt; - unauthenticated client can enter multi-user authentication mode in Apache Geode&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-9794&quot;&gt;CVE-2017-9794&lt;/a&gt; - user with read privileges can use the gfsh command line utility to execute queries with Apache Geode&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/04/the-mid-week-news/</guid> </item> <item><title>Apache ORC</title><link>http://ondataengineering.net/technologies/apache-orc/</link><pubDate>Wed, 04 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Self-describing, type-aware, columnar file format to enable efficient querying and storage of data on Hadoop. Provides built-in storage indexes, column statistics and bloom filters to allow execution engines to implement predicate and projection push-down, partition pruning and cost based optimisation for low latency reads. Uses multi-version concurrency control to support ACID transactions and allow Hive to implement bulk insert, update, delete and streaming ingest (micro batch) use cases. Implements type-aware encoding for efficient compression (run-length for integer and dictionary for string). Schema definition is stored along side the data and supports all primitive data types and complex nested data structures. Uses protocol buffers to store meta data. Comes with a Java library for reading and writing the file format and includes a MapReduce compatible API, a C++ library for reading the file format (donated by Vertica) and a set of Java and C++ tools for inspecting and benchmarking ORC files. Created by Hortonworks in January 2013 as part of the initiative to massively speed up Hive and improve the storage efficiency of data stored in Hadoop, split off from Apache Hive to become a separate top level Apache project in April 2015 with a 1.0 release in January 2016.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;ORC&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;October 2017 - v1.4.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://orc.apache.org/&quot;&gt;https://orc.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://git-wip-us.apache.org/repos/asf/orc.git/&quot;&gt;https://git-wip-us.apache.org/repos/asf/orc.git/&lt;/a&gt; - source code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://orc.apache.org/docs/&quot;&gt;https://orc.apache.org/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/100x-faster-hive/&quot;&gt;https://hortonworks.com/blog/100x-faster-hive/&lt;/a&gt; - initial announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/apache-orc-launches-as-a-top-level-project/&quot;&gt;https://hortonworks.com/blog/apache-orc-launches-as-a-top-level-project/&lt;/a&gt; - top level project announcement, including summary of technology that support it&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://orc.apache.org/news/&quot;&gt;https://orc.apache.org/news/&lt;/a&gt; - news page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://orc.apache.org/docs/releases.html&quot;&gt;https://orc.apache.org/docs/releases.html&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-orc/</guid> </item> <item><title>Apache CarbonData</title><link>http://ondataengineering.net/technologies/apache-carbondata/</link><pubDate>Tue, 03 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Unified storage solution for Hadoop based on an indexed columnar data format, focusing on providing efficient processing and querying capabilities for disparate data access patterns. Data is loaded in batch, encoded, indexed using multiple strategies, compressed and written to HDFS using a columnar file format. Provides a number of highly configurable indexes (multi-dimensional key, min/max index, and inverted index), global dictionary encoding and column grouping to support interactive style OLAP queries, high throughput scan queries, low latency point queries and individual record queries. Also supports batch updates and deletes using delta bitmap files and compaction. Written in Java using Apache Thrift, supports all common primitive data types and complex nested data types including array and structures. Consists of several modules, the format specification and core implementation (columnar storage, indexing, compression, encoding), Hadoop input/output format interface, deep integration with Spark, interfacing to Spark SQL and the DataFrame API and connectors for Hive and Presto. Started back in 2013 at Huawei's India R&amp;D center, donated to the Apache Foundation in 2015, graduated in April 2017, with a stable (1.1.0) release in May 2017, and under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;CarbonData&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;October 2017 - 1.2.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://carbondata.apache.org&quot;&gt;http://carbondata.apache.org&lt;/a&gt; - CarbonData homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://carbondata.apache.org/mainpage.html&quot;&gt;http://carbondata.apache.org/mainpage.html&lt;/a&gt; - CarbonData documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/carbondata&quot;&gt;https://blogs.apache.org/carbondata&lt;/a&gt; - CarbonData blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/CARBONDATA/Releases&quot;&gt;https://cwiki.apache.org/confluence/display/CARBONDATA/Releases&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-carbondata/</guid> </item> <item><title>Apache Arrow</title><link>http://ondataengineering.net/technologies/apache-arrow/</link><pubDate>Mon, 02 Oct 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;In-memory data structure specification for building columnar based data systems. Provides a standard interchange format to allow sharing of data between processes on a node without the overhead of moving or transforming the data, permits O(1) random access and has the ability to represent both flat relational structures and complex hierarchical nested data. Data is organised using a columnar structure memory-layout making it cache efficient for analytical workloads (which typically group all data relevant to a column operation together) and allows execution engines to take advantage of modern CPU SIMD (Single Instruction Multiple Data) instructions which work on multiple data values simultaneously in a single CPU clock cycle. Comes with reference implementations in Java and C++ and a Python interface to the C++ libraries (Ruby and JavaScript language bindings are in progress). Seeded from the Apache Drill project and promoted directly to a top level Apache project in February 2016 followed by an initial 0.1 release in October 2016. Used in a range of other projects including Drill, Spark, Impala, Kudu, Pandas and others. Has not yet reached a v1.0 milestone, but is still under active development with a range of contributors from a number of other Apache and non-Apache data projects.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Arrow&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;October 2017 - v0.7&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h1 id=&quot;links&quot;&gt;Links&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://arrow.apache.org/&quot;&gt;https://arrow.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href=&quot;http://git.apache.org/arrow.git/&quot;&gt;http://git.apache.org/arrow.git/&lt;/a&gt; - source code&lt;/p&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://info.dataengconf.com/the-future-of-column-oriented-data-processing-with-arrow-and-parquet&quot;&gt;http://info.dataengconf.com/the-future-of-column-oriented-data-processing-with-arrow-and-parquet&lt;/a&gt; - introduction to Arrow&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces87&quot;&gt;https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces87&lt;/a&gt; - top level project announcement&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://arrow.apache.org/blog/&quot;&gt;https://arrow.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://arrow.apache.org/release/&quot;&gt;https://arrow.apache.org/release/&lt;/a&gt; - release and change summary&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-arrow/</guid> </item> <item><title>The Plan For This Week - 02/10/2017</title><link>http://ondataengineering.net/blog/2017/10/02/the-plan-for-this-week/</link><pubDate>Mon, 02 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s a guest publication week this week - our old friend Jeff Moszuti has a bunch of technology summaries on record format libraries (specifically Apache Arrow, CarbonData and ORCFile), and some thoughts to share with us at the end of the week.&lt;/p&gt; &lt;p&gt;We’ll start today with Apache Arrow…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/02/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Graph Technologies</title><link>http://ondataengineering.net/blog/2017/09/29/thoughts-on-graph-technologies/</link><pubDate>Fri, 29 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;So, I said four technology categories and three technology summaries this week. One day you’ll learn.&lt;/p&gt; &lt;p&gt;But let’s talk about what we did manage to achieve this week, specifically technology category pages on &lt;a href=&quot;/tech-categories/rdf-databases/&quot;&gt;RDF Databases&lt;/a&gt;, &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;Graph Databases&lt;/a&gt; and &lt;a href=&quot;/tech-categories/graph-analytics/&quot;&gt;Graph Analytics&lt;/a&gt;… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So I’m not going to go over what a graph is, but suffice it to say that if you have data that’s modelled (or can be modelled) as a graph, then you might want to consider using some graph technologies.&lt;/p&gt; &lt;p&gt;However, given it’s still just data, the primary use cases are exactly the same as any other type of data. We want to manage and master the data in some sort of operational system (giving us fine grained ACID transactions at the entity/relationship level - the so-called OLTP use case), and we want to analytics over the data (large scans over lots of data to generates insight - the so-called OLAP use case).&lt;/p&gt; &lt;p&gt;And as per other operational databases, we need to be able to query the data as well as create/update it. For operational graph databases this focuses on graph traversals - essentially finding a set of nodes and relationships that match a pattern (all books by an author named John Smith) by finding an initial subset of nodes (the name John Smith), and then following relationships to match the pattern (named and then wrote), with maybe some aggregations at the end.&lt;/p&gt; &lt;p&gt;For the operational management of graph data there are two primary technology categories:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/tech-categories/rdf-databases/&quot;&gt;RDF Databases&lt;/a&gt; implement the W3C RDF data model standard that describes data as subject–predicate–object expressions (or triples), with support for ontologies that define the list of valid subject/object and predicate types. The benefit of RDF databases is their maturity (they’ve been around forever in technology terms, with a wide range of commercial and open source technologies), but also the standardisation driven by the W3C. There’s a W3C standard query language (SPARQL) that all RDF databases support, there are standard ontologies (OWL and RDFS), and there are a vast range of RDF creation, extraction, processing and visualisation tools that will work with your data. There’s a vast amount more here around RDF and the semantic web (that allows exploitation of text content as RDF data) that I’d love to come back to one day.&lt;/p&gt; &lt;p&gt;Then you have your &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;Graph Databases&lt;/a&gt;. Again, these are operational databases, but they have a slightly more expressive data model that RDF databases by supporting both labels (or types, although RDF nodes are also typed) and properties (name/value pairs) against nodes and link, resulting in the term “labelled property graph”. That’s not to say you can’t do properties in RDF graphs (they’re just more relationships and nodes), however there are a number of RDF databases that explicitly support properties, as well as a number of graph databases that also support RDF/SPARQL. There’s no one standard query language for graph databases, however there are two popular options. The first is Cypher, the language used by Neo4j, which now has an open source specification (&lt;a href=&quot;http://www.opencypher.org/&quot;&gt;http://www.opencypher.org/&lt;/a&gt;) and has been adopted by a number of graph databases. The second is TinkerPop Gremlin (part of the Apache TinkerPop project), however rather than a language specification this is an entire abstraction layer that can be bolted on top of a graph database, with all the associated performance implications. Neo4j is the big cheese in the graph databases space, but it’s an active thriving technology area with a wide range of commercial and open source technologies to choose from.&lt;/p&gt; &lt;p&gt;However, before you piling into graph databases, have a look at &lt;a href=&quot;https://blog.acolyer.org/2017/07/07/do-we-need-specialized-graph-databases-benchmarking-real-time-social-networking-applications/&quot;&gt;The Morning Paper review of the “Do we need specialized graph databases? Benchmarking real-time social networking applications” paper from the University of Waterloo, Ontario from May 2017&lt;/a&gt;. Considering the technologies you already have before introducing a new one is never bad advice, and the paper looks at a number of graph use cases where relational databases actually perform better than dedicated graph databases. It also looks at the performance impact of using TinkerPop Gremlin over a native API, and the results aren’t good.&lt;/p&gt; &lt;p&gt;And so on to graph analytics. As per other types of data, there are options here for analytical databases (that focus on large scanning aggregation rather than transactional workloads) as well as analytical processing engines (batch engines that run over external data, for example MapReduce/Spark over HDFS for structured data).&lt;/p&gt; &lt;p&gt;Pragel feels like the originator here - Google’s technology that executed its PageRank algorithm. This implemented (and probably popularised) the BSP execution model (which can very crudely be describes as an equivalent of MapReduce for graph data). It’s another iterative model that can be distributed across a cluster, with each iteration generating “messages” between nodes that are used as the input for the next iteration.&lt;/p&gt; &lt;p&gt;Unlike batch analytics over structured data however, the use case for batch analytics over graph data is less clear. The specialist tools that have been created that implement the BSP modek (Giraph, Hama, GraphX) have never really taken off, and all are seeing limited active development. There are a number of analytical databases (Greenplum and Aster for starters) that support graph queries using a BSP execution model, but again this hasn’t seen widespread adoption in this space. And although TinkerPop now has a graph compute model, this is only supported by a limited number of databases.&lt;/p&gt; &lt;p&gt;It feels like time will tell in this space - there doesn’t appear to be clear use cases driving new technical capabilities at the moment, but maybe machine learning will change that.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/29/thoughts-on-graph-technologies/</guid> </item> <item><title>Graph Analytics</title><link>http://ondataengineering.net/tech-categories/graph-analytics/</link><pubDate>Thu, 28 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Technologies that support analytics over graph data, either as a processing platform over data stored elsewhere, or as an analytical database. Unlike graph databases which work on individual records or small portions of the graph, graph analytics technologies specialise in running analytics that run over the entire graph database to generate aggregated results, identify data of interest, or to enrich the graph. Processing is often bsaed on a BSP (Bulk Synchronous Processing) model made famous by Pregel, the model created by Google to run their PageRank algorithm.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;pregel&quot;&gt;Pregel&lt;/h2&gt; &lt;p&gt;The Morning Paper blog from Adrian Colyer has a good &lt;a href=&quot;https://blog.acolyer.org/2015/05/26/pregel-a-system-for-large-scale-graph-processing/&quot;&gt;introduction to Pragel&lt;/a&gt;, and the original paper is also &lt;a href=&quot;http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf&quot;&gt;available online&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&quot;analytics-engines&quot;&gt;Analytics Engines&lt;/h2&gt; &lt;p&gt;The following technologies all implement a graph analytics engine over external data, generally using a BSP execution model&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-giraph/&quot;&gt;Giraph&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An iterative, highly scalable graph processing system based on Pregel and built over MapReduce&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hama/&quot;&gt;Hama&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A general purpose BSP (Bulk Synchronous Parallel) processing engine inspired by Pregel and DistBelief that runs over Mesos or YARN.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/graphx/&quot;&gt;Spark/GraphX&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Spark library for processing graphs and running graph algorithms&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Flink&lt;/a&gt; Gelly&lt;/td&gt; &lt;td&gt;Graph processing API and library on top of Apache Flink&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gaffer&lt;/td&gt; &lt;td&gt;Open source project for running analytics over very large graphs in HDFS, Accumulo or HBase - &lt;a href=&quot;https://github.com/gchq/Gaffer&quot;&gt;https://github.com/gchq/Gaffer&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;tinkerpop-enabled-analytical-graph-databases&quot;&gt;TinkerPop enabled Analytical Graph Databases&lt;/h2&gt; &lt;p&gt;Apache TinkerPop provides an API for running analytics over graphs - a VertexProgram is executed by a pluggable GraphComputer in a BSP fashion, with an optional final MapReduce step to post process the data into a single results set. See &lt;a href=&quot;http://tinkerpop.apache.org/docs/3.3.0/reference/#graphcomputer&quot;&gt;http://tinkerpop.apache.org/docs/3.3.0/reference/#graphcomputer&lt;/a&gt; for further information.&lt;/p&gt; &lt;p&gt;Out of the box GraphComputer implementations include support for Spark and Giraph, with the ability to run analytics over any graph database that supports the execution of analytics via the TinkerPop GraphComputer (these are listed as OLAP databases at &lt;a href=&quot;http://tinkerpop.apache.org/#graph-systems&quot;&gt;http://tinkerpop.apache.org/#graph-systems&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;Databases that currently support graph analytics via TinkerPop include:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;DataStax Enterprise&lt;/td&gt; &lt;td&gt;Commercial product built on Apache Cassandra with the addition of graph and search capabilities - &lt;a href=&quot;https://www.datastax.com/&quot;&gt;https://www.datastax.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;GRAKN.AI&lt;/td&gt; &lt;td&gt;Open Source graph database designed for AI use cases that also supports graph analytics - &lt;a href=&quot;https://grakn.ai&quot;&gt;https://grakn.ai&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;JanusGraph&lt;/td&gt; &lt;td&gt;Open source distributed graph database that runs over a number of storage backends (including Cassandra, HBase and BigTable), with TinkerPop support including support for graph analytics; previously known as Titan - &lt;a href=&quot;http://janusgraph.org/&quot;&gt;http://janusgraph.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Complexible Stardog&lt;/td&gt; &lt;td&gt;RDF database that also support property graphs and data virtualisation, with a community edition available - &lt;a href=&quot;http://www.stardog.com/&quot;&gt;http://www.stardog.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TinkerGraph&lt;/td&gt; &lt;td&gt;In memory graph databases that’s part of TinkerPop as a reference implementation - &lt;a href=&quot;http://tinkerpop.apache.org&quot;&gt;http://tinkerpop.apache.org&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;other-analytical-graph-databases&quot;&gt;Other Analytical Graph Databases&lt;/h2&gt; &lt;p&gt;The following are analytical graph databases that provide their own APIs rather than leveraging Apache TinkerPop&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;TigerGraph&lt;/td&gt; &lt;td&gt;Commercial hybrid OLTP/OLAP graph database that claims order of magnitude performance and scalability improvements over it’s competitors; previously known as GraphSQL - &lt;a href=&quot;http://www.tigergraph.com&quot;&gt;http://www.tigergraph.com&lt;/a&gt;, &lt;a href=&quot;http://www.zdnet.com/article/tigergraph-a-graph-database-born-to-roar/&quot;&gt;http://www.zdnet.com/article/tigergraph-a-graph-database-born-to-roar/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Microsoft Graph Engine&lt;/td&gt; &lt;td&gt;Open source in memory graph computation engine, previously known as Trinity - &lt;a href=&quot;https://www.graphengine.io/&quot;&gt;https://www.graphengine.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;analytical-relational-databases&quot;&gt;Analytical Relational Databases&lt;/h2&gt; &lt;p&gt;A number of relational analytical databases also support graph analytics, including Teradata Aster (via SQL-GR which has a BSP execution model) and &lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;Apache HAWQ&lt;/a&gt; (via MADlib)&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/graph-analytics/</guid> </item> <item><title>The Mid Week News - 27/09/2017</title><link>http://ondataengineering.net/blog/2017/09/27/the-mid-week-news/</link><pubDate>Wed, 27 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s news time again, and there are big announcements from Cloudera and Hortonworks this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; has hit 7.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/alluxio/&quot;&gt;Alluxio&lt;/a&gt; is up to 1.6&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ingite&lt;/a&gt; is up to 2.2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt; C++ is up to 1.3&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Cloudera/Hortonworks technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The big news this week is the simultaneous big product announcements from Hortonworks and Cloudera that look like they might be similar capabilities, but I think are probably trying to solve subtly different problems - we’ll revisit these in a few weeks once there’s more information available and do some technology summaries.&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/sdx.html&quot;&gt;Cloudera SDX&lt;/a&gt; (Shared Data Experience, coming in CDH 5.13) appears to be trying to enable the “one” data platform experience that you get with an on premesis CDH cluster in the cloud, specifically a persistent shared storage layer with shared metadata, security and governance and a range of workloads on top. That looks different in the cloud - you probably don’t want persistent Cloudera cluster that you’re paying for by the hour even if you’re not using it - so SDX gives you a shared storage layer using cloud object storage, a shared metadata and management layer, and then the ability to run compute workloads in isolated transient workload clusters managed through Cloudera Altus. The original sales pitch of a single shared Hadoop data platform re-imagined for the cloud. More details via a &lt;a href=&quot;http://vision.cloudera.com/introducing-cloudera-sdx-a-shared-data-experience-for-the-hybrid-cloud/&quot;&gt;Cloudera VISION blog post&lt;/a&gt; and a &lt;a href=&quot;http://blog.cloudera.com/blog/2017/09/cloudera-sdx-under-the-hood/&quot;&gt;Cloudera Engineering blog post&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/data-management/dataplane-service/&quot;&gt;Hortonworks Data Plane&lt;/a&gt; is again all about shared metadata, security and data management, but this time across a range of different data platforms - Hadoop, relational databases and your EDW, either on-premesis or in the cloud, and for data in motion or at rest. It’s open source, extensible for adding new services, with data lifecycle management being first up, allowing you to replicate, backup &amp;amp; restore and tier your data across your data platforms. It’s another cloud service (because obviously), and they talk about it as a Global Data Management Platform. More details via a &lt;a href=&quot;https://hortonworks.com/blog/category-emerges-introducing-hortonworks-dataplane-service/&quot;&gt;Hortonworks blog post&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR DB&lt;/a&gt; 6.0 has &lt;a href=&quot;https://community.mapr.com/community/products/blog/2017/09/25/mapr-db-60-the-modern-database-for-global-data-intensive-applications&quot;&gt;been announced&lt;/a&gt; and will be available Q4 2017. There’s been a bunch of changes in the MapR stack over the last couple of months that I’ve not been keeping up to date with (the introduction of MapR XD for starters), so we’ll loop back round in a couple of weeks to refresh our MapR information.&lt;/li&gt; &lt;li&gt;Hortonworks are &lt;a href=&quot;https://hortonworks.com/blog/3x-faster-interactive-query-hive-llap/&quot;&gt;crowing&lt;/a&gt; about the increase in &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; performance in HDP 2.6 and its support for the full suite of 99 TPC-DS queries&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://kudu.apache.org/2017/09/18/kudu-consistency-pt1.html&quot;&gt;Part 1&lt;/a&gt; on the &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; consitency model&lt;/li&gt; &lt;li&gt;Looks like Hortonworks’ &lt;a href=&quot;https://hortonworks.com/blog/yinception-yarn-based-container-cloud-certify-hadoop-hadoop/&quot;&gt;are proud&lt;/a&gt; of the fact they run docker containers on &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/blog/introduction-to-influxdatas-influxdb-and-tick-stack/&quot;&gt;An introduction&lt;/a&gt; from InfluxData on &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; and the TICK stack&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/27/the-mid-week-news/</guid> </item> <item><title>Graph Databases</title><link>http://ondataengineering.net/tech-categories/graph-databases/</link><pubDate>Tue, 26 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Operational (OLTP) databases designed to support labelled property graph data models, where nodes and relationships have labels (types) and lists of property name-value pairs. Focus is on transactional ACID inserts/updates and traversal queries using index free adjacency (allows direct navigation between nodes without the use of indexes) over subsets of data rather than batch analytics over all data. Populate query interfaces/languages include Cypher (originated with Neo4J but now open source) and TinkerPop Gremlin (part of the TinkerPop framework that provides query capabilities and graph analytics over graph data).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The Morning Paper review of the “Do we need specialized graph databases? Benchmarking real-time social networking applications” paper from the University of Waterloo, Ontario from May 2017 is worth a read before you go any further - this covers a number of use cases where relational databases perform better than dedicated graph databases, and also looks at the performance impact of using TinkerPop over a native API - &lt;a href=&quot;https://blog.acolyer.org/2017/07/07/do-we-need-specialized-graph-databases-benchmarking-real-time-social-networking-applications/&quot;&gt;https://blog.acolyer.org/2017/07/07/do-we-need-specialized-graph-databases-benchmarking-real-time-social-networking-applications/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;DB Engines has a list of graph databases at &lt;a href=&quot;https://db-engines.com/en/ranking/graph+dbms&quot;&gt;https://db-engines.com/en/ranking/graph+dbms&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The Forrester Graph Databases Market Overview (&lt;a href=&quot;https://www.forrester.com/report/Market+Overview+Graph+Databases/-/E-RES121473&quot;&gt;https://www.forrester.com/report/Market+Overview+Graph+Databases/-/E-RES121473&lt;/a&gt;) covers a number of graph databases, including DataStax Enterprise, FlockDB, Neo4j and OrientDB, and has a good introduction to RDF and Graph databases.&lt;/p&gt; &lt;p&gt;The Gartner Magic Quadrant for Operational Database Management Systems (https://www.gartner.com/doc/3147919) also includes a number of graph databases, including Datastax Enterprise, Neo4j, NuoDB, and OrientDB. This can be downloaded from Microsoft (&lt;a href=&quot;https://info.microsoft.com/CO-SQL-CNTNT-FY16-09Sep-14-MQOperational-Register.html&quot;&gt;https://info.microsoft.com/CO-SQL-CNTNT-FY16-09Sep-14-MQOperational-Register.html&lt;/a&gt;) and Nuo (&lt;a href=&quot;http://go.nuodb.com/gartner-magic-quadrant.html&quot;&gt;http://go.nuodb.com/gartner-magic-quadrant.html&lt;/a&gt;) for free.&lt;/p&gt; &lt;p&gt;Bloor have a primer on graph technologies (&lt;a href=&quot;http://www.bloorresearch.com/research/spotlight/all-about-graphs-a-primer/&quot;&gt;http://www.bloorresearch.com/research/spotlight/all-about-graphs-a-primer/&lt;/a&gt;), a 2016 Graph and RDF Databases Market Report (&lt;a href=&quot;http://www.bloorresearch.com/research/market-report/graph-and-rdf-databases-2016/&quot;&gt;http://www.bloorresearch.com/research/market-report/graph-and-rdf-databases-2016/&lt;/a&gt;) and a 2016 Graph and RDF Databases Market Update (&lt;a href=&quot;http://www.bloorresearch.com/research/market-update/graph-and-rdf-databases-market-update-2016/&quot;&gt;http://www.bloorresearch.com/research/market-update/graph-and-rdf-databases-market-update-2016/&lt;/a&gt;), all of which are free to download for personal non-commercial use, and which cover a number of graph databases including ArangoDB, BlazeGraph, DataStax Enterprise, OrientDB and Neo4j.&lt;/p&gt; &lt;p&gt;And Neo4j have a number of eBooks available for free download from &lt;a href=&quot;https://neo4j.com/&quot;&gt;https://neo4j.com/&lt;/a&gt; and &lt;a href=&quot;https://neo4j.com/books/&quot;&gt;https://neo4j.com/books/&lt;/a&gt;, including a copy of O’Reilly’s Graph Databases.&lt;/p&gt; &lt;h2 id=&quot;query-languages&quot;&gt;Query Languages&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Cypher&lt;/td&gt; &lt;td&gt;Originally from Neo4j, now open source and used by a wide range of graph databases - &lt;a href=&quot;http://www.opencypher.org/&quot;&gt;http://www.opencypher.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TinkerPop Gremlin&lt;/td&gt; &lt;td&gt;Language for writing graph traversals that’s part of the Apache TinkerPop project - &lt;a href=&quot;https://tinkerpop.apache.org/gremlin.html&quot;&gt;https://tinkerpop.apache.org/gremlin.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-graph-databases&quot;&gt;Commercial Graph Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Neo4j&lt;/td&gt; &lt;td&gt;ACID-compliant transactional database with native graph storage and processing; open source with commercial edition; utilises Cypher - &lt;a href=&quot;https://neo4j.com/&quot;&gt;https://neo4j.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;DataStax Enterprise&lt;/td&gt; &lt;td&gt;Commercial product built on Apache Cassandra with the addition of graph and search capabilities - &lt;a href=&quot;https://www.datastax.com/&quot;&gt;https://www.datastax.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OrientDB&lt;/td&gt; &lt;td&gt;Multi-model (key-value, graph and document) NoSQL database with TinkerPop Gremlin compatibility and both community and enterprise editions - &lt;a href=&quot;http://orientdb.com/graph-database/&quot;&gt;http://orientdb.com/graph-database/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ArrangoDB&lt;/td&gt; &lt;td&gt;Multi-model (key-value, graph and document) NoSQL database with ACID transactions, TinkerPop compatibility and it’s own AQL query language with support for cluster deployments (including running over Mesos) - &lt;a href=&quot;http://www.arangodb.com&quot;&gt;http://www.arangodb.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TigerGraph&lt;/td&gt; &lt;td&gt;Commercial hybrid OLTP/OLAP graph database that claims order of magnitude performance and scalability improvements over it’s competitors; previously known as GraphSQL - &lt;a href=&quot;http://www.tigergraph.com&quot;&gt;http://www.tigergraph.com&lt;/a&gt;, &lt;a href=&quot;http://www.zdnet.com/article/tigergraph-a-graph-database-born-to-roar/&quot;&gt;http://www.zdnet.com/article/tigergraph-a-graph-database-born-to-roar/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sparksee&lt;/td&gt; &lt;td&gt;Graph database formally known as DEX, with support for a range of languages and use on mobile devices and TinkerPop support- &lt;a href=&quot;http://www.sparsity-technologies.com/&quot;&gt;http://www.sparsity-technologies.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;GraphBase&lt;/td&gt; &lt;td&gt;Commercial graph database designed for use in AI applications - &lt;a href=&quot;https://graphbase.ai/&quot;&gt;https://graphbase.ai/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;AgensGraph&lt;/td&gt; &lt;td&gt;Commercial multi-model (relational and graph) databases - &lt;a href=&quot;http://www.agensgraph.com/&quot;&gt;http://www.agensgraph.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Redis Graph&lt;/td&gt; &lt;td&gt;Graph database over Redis that supports a subset of neo4j’s Cypher query language - &lt;a href=&quot;http://redismodules.com/modules/redis-graph/&quot;&gt;http://redismodules.com/modules/redis-graph/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;open-source-graph-databases&quot;&gt;Open Source Graph Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;JanusGraph&lt;/td&gt; &lt;td&gt;Open source distributed graph database that runs over a number of storage backends (including Cassandra, HBase and BigTable), with TinkerPop support including support for graph analytics; previously known as Titan - &lt;a href=&quot;http://janusgraph.org/&quot;&gt;http://janusgraph.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Dgraph&lt;/td&gt; &lt;td&gt;Open source graph database written in Go - &lt;a href=&quot;https://dgraph.io/&quot;&gt;https://dgraph.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;HyperGraphDB&lt;/td&gt; &lt;td&gt;Open Source Java graph database - &lt;a href=&quot;http://hypergraphdb.org&quot;&gt;http://hypergraphdb.org&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;InfoGrid&lt;/td&gt; &lt;td&gt;Open Source Java graph database with support for building REST APIs over the top - &lt;a href=&quot;http://infogrid.org/trac/&quot;&gt;http://infogrid.org/trac/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;VelocityDB&lt;/td&gt; &lt;td&gt;Open Source C# .NET embeddable/distributed graph database - &lt;a href=&quot;https://velocitydb.com/&quot;&gt;https://velocitydb.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TinkerGraph&lt;/td&gt; &lt;td&gt;In memory graph databases that’s part of TinkerPop as a reference implementation - &lt;a href=&quot;http://tinkerpop.apache.org&quot;&gt;http://tinkerpop.apache.org&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;GRAKN.AI&lt;/td&gt; &lt;td&gt;Open Source graph database designed for AI use cases that also supports graph analytics - &lt;a href=&quot;https://grakn.ai&quot;&gt;https://grakn.ai&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Apache S2Graph (Incubating)&lt;/td&gt; &lt;td&gt;OLTP graph database built on Apache HBase - &lt;a href=&quot;https://s2graph.incubator.apache.org/&quot;&gt;https://s2graph.incubator.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;HGraphDB&lt;/td&gt; &lt;td&gt;Open Source implementation of TinkerPop API for Apache HBase - &lt;a href=&quot;https://github.com/rayokota/hgraphdb&quot;&gt;https://github.com/rayokota/hgraphdb&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Sqlg&lt;/td&gt; &lt;td&gt;Open Source implementation of TinkerPop API over relational databases - &lt;a href=&quot;http://www.sqlg.org/&quot;&gt;http://www.sqlg.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Unipop&lt;/td&gt; &lt;td&gt;Open source TinkerPop API over a range of backends including Elasticsearch and JDBC &lt;a href=&quot;https://github.com/unipop-graph/unipop&quot;&gt;https://github.com/unipop-graph/unipop&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;combined-graphrdf-databases&quot;&gt;Combined Graph/RDF Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;OpenLink Virtuoso Universal Server&lt;/td&gt; &lt;td&gt;Supports persistence of documents, relational, RDF and graph data - &lt;a href=&quot;https://virtuoso.openlinksw.com/&quot;&gt;https://virtuoso.openlinksw.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Franz AllegroGraph&lt;/td&gt; &lt;td&gt;Commercial ACID compliant that supports both RDF and property graphs, with a free edition available - &lt;a href=&quot;https://allegrograph.com/allegrograph/&quot;&gt;https://allegrograph.com/allegrograph/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Complexible Stardog&lt;/td&gt; &lt;td&gt;RDF database that also support property graphs and data virtualisation, with a community edition available - &lt;a href=&quot;http://www.stardog.com/&quot;&gt;http://www.stardog.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;BlazeGraph&lt;/td&gt; &lt;td&gt;Open Source RDF graph database with property graph features, queryable via SPARQL and Tinkerpop - &lt;a href=&quot;https://www.blazegraph.com/&quot;&gt;https://www.blazegraph.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;graph-databases-as-a-service&quot;&gt;Graph Databases as a Service&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Microsoft Azure Cosmos DB&lt;/td&gt; &lt;td&gt;Massively scalable, low latency multi-model (key-value, graph and document) cloud NoSQL database service, previously known as Azure DocumentDB - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cosmos-db/&quot;&gt;https://azure.microsoft.com/en-us/services/cosmos-db/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Graph&lt;/td&gt; &lt;td&gt;Graph database as a service built using JanusGraph - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/graph&quot;&gt;https://www.ibm.com/us-en/marketplace/graph&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;historical--deprecated-graph-databases&quot;&gt;Historical / Deprecated Graph Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Objectivity InfiniteGraph&lt;/td&gt; &lt;td&gt;End of life, with functionality being migrated into Objectivity/DB and ThingSpan - &lt;a href=&quot;http://www.objectivity.com/products/infinitegraph/&quot;&gt;http://www.objectivity.com/products/infinitegraph/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;FlockDB&lt;/td&gt; &lt;td&gt;Open Source distributed graph database from Twitter, however no longer maintained - &lt;a href=&quot;https://github.com/twitter-archive/flockdb&quot;&gt;https://github.com/twitter-archive/flockdb&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;GlobalsDB&lt;/td&gt; &lt;td&gt;Open Source, now dead - &lt;a href=&quot;https://github.com/Globals/GlobalsDB&quot;&gt;https://github.com/Globals/GlobalsDB&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/graph-databases/</guid> </item> <item><title>RDF Databases</title><link>http://ondataengineering.net/tech-categories/rdf-databases/</link><pubDate>Mon, 25 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Databases designed to support the storage of RDF (or triple) data. RDF (Resource Description Framework) is a W3C data model standard that describes data as subject–predicate–object expressions (or triples). This allows the creation of graphs of knowledge, however unlike more general purpose graph databases, there is no support for properties or labels - everything is represented using triples. Data is queried using the SPARQL query language (another W3C standard). Internally, data can be considered to be stored as a single table containing three columns (the subject, predicate and object), with indexing to support the traversal and enumeration of predicates (relationsips) for a given subject. A number of triple ontologies (or schemas) are also available that define standard subject/object and predicate types allowing for data interchange, including OWL and RDFS. The W3C standards were introduced to support semantic web and Linked Open Data use cases that focus on semantics and inference.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;The W3C standards for RDF and SPARQL are available online at &lt;a href=&quot;https://www.w3.org/RDF/&quot;&gt;https://www.w3.org/RDF/&lt;/a&gt; and &lt;a href=&quot;http://www.w3.org/TR/rdf-sparql-query/&quot;&gt;http://www.w3.org/TR/rdf-sparql-query/&lt;/a&gt; respectively. The relevant Wikipedia pages are also good places to start at &lt;a href=&quot;https://en.wikipedia.org/wiki/Resource_Description_Framework&quot;&gt;https://en.wikipedia.org/wiki/Resource_Description_Framework&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/SPARQL&quot;&gt;https://en.wikipedia.org/wiki/SPARQL&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;DB Engines has a list of RDF databases at &lt;a href=&quot;https://db-engines.com/en/ranking/rdf+store&quot;&gt;https://db-engines.com/en/ranking/rdf+store&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The Forrester Graph Databases Market Overview (&lt;a href=&quot;https://www.forrester.com/report/Market+Overview+Graph+Databases/-/E-RES121473&quot;&gt;https://www.forrester.com/report/Market+Overview+Graph+Databases/-/E-RES121473&lt;/a&gt;) covers a number of RDF databases, including StarDog, AllegroGraph and Oracle, and has a good introduction to RDF and Graph databases.&lt;/p&gt; &lt;p&gt;And Bloor have a primer on graph technologies (&lt;a href=&quot;http://www.bloorresearch.com/research/spotlight/all-about-graphs-a-primer/&quot;&gt;http://www.bloorresearch.com/research/spotlight/all-about-graphs-a-primer/&lt;/a&gt;), a 2016 Graph and RDF Databases Market Report (&lt;a href=&quot;http://www.bloorresearch.com/research/market-report/graph-and-rdf-databases-2016/&quot;&gt;http://www.bloorresearch.com/research/market-report/graph-and-rdf-databases-2016/&lt;/a&gt;) and a 2016 Graph and RDF Databases Market Update (&lt;a href=&quot;http://www.bloorresearch.com/research/market-update/graph-and-rdf-databases-market-update-2016/&quot;&gt;http://www.bloorresearch.com/research/market-update/graph-and-rdf-databases-market-update-2016/&lt;/a&gt;), all of which are free to download for personal non-commercial use, and which cover a number of RDF databases including AllegroGraph, BlazeGraph, Cray, GraphDB, MarkLogic, Stardog and Virtuoso.&lt;/p&gt; &lt;h2 id=&quot;rdf-frameworks&quot;&gt;RDF Frameworks&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Eclipse RDF4J&lt;/td&gt; &lt;td&gt;An Eclipse open source project for working with RDF data, including provision of a standard SPARQL interface that can be integrated with backend databases. Previously known as Sesame - &lt;a href=&quot;http://rdf4j.org/&quot;&gt;http://rdf4j.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jena&lt;/td&gt; &lt;td&gt;Framework for developing Semantic Web and Linked Data applications in Java - &lt;a href=&quot;http://jena.apache.org/&quot;&gt;http://jena.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Commons RDF&lt;/td&gt; &lt;td&gt;Commons library for working with RDF data - &lt;a href=&quot;http://commons.apache.org/proper/commons-rdf/&quot;&gt;http://commons.apache.org/proper/commons-rdf/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Redland&lt;/td&gt; &lt;td&gt;Open source C libraries for working with RDF data - &lt;a href=&quot;http://librdf.org/&quot;&gt;http://librdf.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CubicWeb&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.cubicweb.org/&quot;&gt;https://www.cubicweb.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-rdf-databases&quot;&gt;Commercial RDF Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MarkLogic&lt;/td&gt; &lt;td&gt;Commercial ACID compliant XML/JSON document store with support for creation of triple indexes over documents queryable via SPARQL - &lt;a href=&quot;http://www.marklogic.com/&quot;&gt;http://www.marklogic.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OpenLink Virtuoso Universal Server&lt;/td&gt; &lt;td&gt;Supports persistence of documents, relational, RDF and graph data - &lt;a href=&quot;https://virtuoso.openlinksw.com/&quot;&gt;https://virtuoso.openlinksw.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Franz AllegroGraph&lt;/td&gt; &lt;td&gt;Commercial ACID compliant that supports both RDF and property graphs, with a free edition available - &lt;a href=&quot;https://allegrograph.com/allegrograph/&quot;&gt;https://allegrograph.com/allegrograph/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Ontotext GraphDB&lt;/td&gt; &lt;td&gt;Commercial RDF database, previously known as OWLIM, and with a free edition available - &lt;a href=&quot;https://ontotext.com/products/graphdb/&quot;&gt;https://ontotext.com/products/graphdb/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Complexible Stardog&lt;/td&gt; &lt;td&gt;RDF database that also support property graphs and data virtualisation, with a community edition available - &lt;a href=&quot;http://www.stardog.com/&quot;&gt;http://www.stardog.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Dydra&lt;/td&gt; &lt;td&gt;Cloud based - &lt;a href=&quot;https://dydra.com/&quot;&gt;https://dydra.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SparkleDB&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.syssurge.com/Products/SparkleDB/Home.aspx&quot;&gt;https://www.syssurge.com/Products/SparkleDB/Home.aspx&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Cray Graph Engine&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.cray.com/products/analytics/cray-graph-engine&quot;&gt;https://www.cray.com/products/analytics/cray-graph-engine&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle Spatial and Graph option for Oracle Database&lt;/td&gt; &lt;td&gt;Adds RDF (and graph) capabilities to the Oracle database - &lt;a href=&quot;http://www.oracle.com/technetwork/database/options/spatialandgraph/overview/index.html&quot;&gt;http://www.oracle.com/technetwork/database/options/spatialandgraph/overview/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;RDF Graph for Oracle NoSQL Database&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www.oracle.com/technetwork/database/database-technologies/nosqldb/overview/index.html&quot;&gt;http://www.oracle.com/technetwork/database/database-technologies/nosqldb/overview/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;open-source-rdf-databases&quot;&gt;Open Source RDF Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;BlazeGraph&lt;/td&gt; &lt;td&gt;Open Source RDF graph database with property graph features, queryable via SPARQL and Tinkerpop - &lt;a href=&quot;https://www.blazegraph.com/&quot;&gt;https://www.blazegraph.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;4store&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://github.com/4store/4store&quot;&gt;https://github.com/4store/4store&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;RedStore&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.aelius.com/njh/redstore/&quot;&gt;https://www.aelius.com/njh/redstore/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mulgara&lt;/td&gt; &lt;td&gt;Open source java RDF database - &lt;a href=&quot;http://mulgara.org/&quot;&gt;http://mulgara.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;BrightstarDB&lt;/td&gt; &lt;td&gt;Open Source RDF database for the .NET platform - &lt;a href=&quot;http://brightstardb.com/&quot;&gt;http://brightstardb.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Strabon&lt;/td&gt; &lt;td&gt;Spatiotemporal RDF store - &lt;a href=&quot;http://www.strabon.di.uoa.gr/&quot;&gt;http://www.strabon.di.uoa.gr/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Rya (Incubating)&lt;/td&gt; &lt;td&gt;RDF triple store built on Apache Accumulo - &lt;a href=&quot;http://rya.apache.org/&quot;&gt;http://rya.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-virtualization&quot;&gt;Data Virtualization&lt;/h2&gt; &lt;p&gt;A number of &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt; support the exposure of data through RDF data models&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/rdf-databases/</guid> </item> <item><title>The Week That Was</title><link>http://ondataengineering.net/blog/2017/09/22/the-week-that-was/</link><pubDate>Fri, 22 Sep 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;When I decided this week was graph technologies week, I think I probably knew that it was too big a topic to do in one week, and so it’s proved. So, so new content this week, but to sweeten the blow, next week there should be four technology categories and at least three technology summaries coming down the pipe.&lt;/p&gt; &lt;p&gt;So apologies there’s not much this week, but next week should be a bumper week!&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/22/the-week-that-was/</guid> </item> <item><title>The Mid Week News - 20/09/2017</title><link>http://ondataengineering.net/blog/2017/09/20/the-mid-week-news/</link><pubDate>Wed, 20 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right - time for the mid week news again. There’s a few new software releases this week to cover, plus a bunch of interesting blog posts. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase&quot;&gt;Apache HBase&lt;/a&gt; has got a 2.0 alpha-2 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt; is up to 2.10&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kudu&quot;&gt;Apache Kudu&lt;/a&gt; is up to 1.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit the big 5.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/pravega/&quot;&gt;Pravega&lt;/a&gt; has hit 0.1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/events-data-points-and-messages-choosing-the-right-azure-messaging-service-for-your-data/&quot;&gt;Details&lt;/a&gt; from Microsoft on the different messaging services in &lt;a href=&quot;/tech-vendors/microsoft-azure/&quot;&gt;Azure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Another from Confluent trying to explain how technologies like &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt; might change the analytics space, this time on &lt;a href=&quot;https://www.confluent.io/blog/okay-store-data-apache-kafka/&quot;&gt;why it’s ok to store data in Kafka long term&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Again from Confluent, and this is always interesting - details on &lt;a href=&quot;https://www.confluent.io/blog/apache-kafka-tested/&quot;&gt;how they test Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;So it’s an advert for Waterline, but I think the principles are probably sound. From MapR - &lt;a href=&quot;https://mapr.com/blog/why-atlas-and-navigator-dont-cut-it/&quot;&gt;Why Atlas and Navigator don’t cut it&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-9803&quot;&gt;CVE-2017-903&lt;/a&gt; - Solr Kerberos issues with delegation tokens when using SecurityAwareZkACLProvider type of ACL provider e.g. SaslZkACLProvider&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;https://hortonworks.com/downloads/&quot;&gt;Hortonworks download page&lt;/a&gt; now includes links for IBM Data Science and IBM Big SQL&lt;/li&gt; &lt;li&gt;Fight time! Hortonworks have &lt;a href=&quot;https://hortonworks.com/blog/hbase-cassandra-benchmark/&quot;&gt;YCSB benchmark results&lt;/a&gt; for HBase vs Cassandra&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.zdnet.com/article/pivotal-greenplum-is-alive-and-kicking/&quot;&gt;Thoughts from ZDNet&lt;/a&gt; on &lt;a href=&quot;/technologies/greenplum&quot;&gt;Greenplum&lt;/a&gt; (which has just seen a 5.0 release)&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/20/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 18/09/2017</title><link>http://ondataengineering.net/blog/2017/09/18/the-plan-for-this-week/</link><pubDate>Mon, 18 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;So we’re got some big topics to look at before we finish our look through data storage and database technologies. This week, it’s time for a deep breath as we dive into graph technologies.&lt;/p&gt; &lt;p&gt;There’s a heady mix of different technologies in this space, from OLTP databases, to graph analytics frameworks, to RDF/triple technologies. Let’s see what sort of sense we can make of them all…&lt;/p&gt; &lt;p&gt;As usual, (at least one) technology category page on Friday with some associated thoughts, and maybe some technology summaries during the week.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/18/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Data Virtualization</title><link>http://ondataengineering.net/blog/2017/09/15/thoughts-on-data-virtualization/</link><pubDate>Fri, 15 Sep 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;That’s another week down (don’t worry, there are plenty to go), so let’s talk about &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt;, our topic for the week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;My personal view is that Data Virtualization is a really powerful component in your data integration story, but it’s probably not well known or understood. It’s also the first technology category we’ve looked at where the open source offerings significantly lag the commercial ones, with the first commercial technologies (Composite and Denodo) having been round since the turn of the millennium and a wide range of commercial offerings now available, whereas the open source offerings tend to focus on a slightly narrower use case and are relatively new.&lt;/p&gt; &lt;p&gt;So what is Data Virtualization (some times also known as Data Federation / Enterprise Information Integration)? It’s a technology that allows you to run analytics (queries) over data in multiple disparate sources, allowing that data to be exploited as an integrated set without having to physically move it into a single database or data store. Most technologies in this space also allow the definition of a logical schema or semantic model over the source data so that users don’t have to understand the complexities of the source data, in addition to being able to run ad-hoc queries over the raw source data. Fundamentally it’s a data integration tool - bringing multiple data sources together so they can be exploited as a single integrated data set.&lt;/p&gt; &lt;p&gt;So why are these tools useful?&lt;/p&gt; &lt;p&gt;Firstly, for some use cases you might be able to avoid having any analytical platform whatsoever - if you can generate all the analytics you want over the data in it’s original source, that’s a huge win. However, that obviously puts extra load on those sources, and all of the complexity in integrating the source data together is now embedded in your data virtualization layer and the cost of this is going to be incurred at query time.&lt;/p&gt; &lt;p&gt;The first of these issues (the load on the sources) can be addressed by moving the data from it’s original source into an analytical platform that can support this query load (let’s call this a Data Lake for arguments sake). No transformation or integration, but it’s now somewhere that can support the level and types of data access that our analytics via our virtualization layer requires.&lt;/p&gt; &lt;p&gt;The second of these issues can be addressed in two ways. Firstly, many of these technologies (including &lt;a href=&quot;/technologies/denodo-platform/&quot;&gt;Denodo&lt;/a&gt;, the technology we looked at in more detail this week), can cache tables defined within their semantic layer (and update these on an incremental or scheduled basis). So we now have a tool in which we define the rules and logic for integrating our set of data sources, which will then ensure that a materialised physical copy of the results of this logic is available at all times for querying. And that sounds exactly like what we would traditionally try to achieve with a traditional data integration tool.&lt;/p&gt; &lt;p&gt;And although there will be limits to the complexity of the data transformation and integration that a Data Virtualization tool can support that might require you to break out custom data transformation pipelines (and tools like Denodo support the use of external technologies for generating data in it’s materialised cache), it will generally always be quicker and easier to integrate data using a Data Virtualization tool, and therefore there is likely always a role for them to pay in either prototyping or the rapid development of some integrations (which some call Agile ETL).&lt;/p&gt; &lt;p&gt;By the second (and probably more important) reason that these tools are useful is that they allow you to run ad-hoc queries and analytics across data that hasn’t been integrated and prepared for analytics. No matter how much data preparation and integration you do, there will always be some ad-hoc questions you want to ask that aren’t supported by your integrated and prepared data. So what’s your option now - spend the time and effort integrating that data in (when perhaps you don’t yet know how valuable it’s going to be) or do a pile of bespoke one off integration work? And this is where (for me) a lot of the value of Data Virtualization tools lie - they allow analysts (for what of a better term) to run these exploratory ad-hoc analytics over raw (or rawer) source data without having to do a pile of painful and expensive integration work. And that can be an enormous win in exploring and understanding where the value is in your data, and where you should focus your efforts on pre integrating and preparing data.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/15/thoughts-on-data-virtualization/</guid> </item> <item><title>Data Virtualization</title><link>http://ondataengineering.net/tech-categories/data-virtualization/</link><pubDate>Fri, 15 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Tools that enable the execution of data queries across multiple data sources. Most support the ability to create a semantic layer or virtual data schema across the underlying data sources (including the caching or materialization of tables within this layer and the ability to update it and therefore the underlying data sources) alongside the ability to run arbitary queries across the underlying data (including in some cases the ability to do this without first defining the schema of the data in these sources). Query logic is pushed down where possible so that it's executed in the underlying data source, with joins and aggregation of data from multiple sources then performed within the data virtualisation layer. Sometimes refered to as data federation.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;There’s a wealth of information from analyst organisation on these tools.&lt;/p&gt; &lt;p&gt;Forrester publishes a Forrester Wave on Enterprise Data Virtualization, last published in 2015 (&lt;a href=&quot;https://www.forrester.com/report/The+Forrester+Wave+Enterprise+Data+Virtualization+Q1+2015/-/E-RES117844&quot;&gt;here&lt;/a&gt;), with an update scheduled for November 2017.&lt;/p&gt; &lt;p&gt;Gartner include Data Virtualisation tools as part of their &lt;a href=&quot;https://www.gartner.com/doc/3777464/magic-quadrant-data-integration-tools&quot;&gt;Data Integration Magic Quadrant&lt;/a&gt;. This can be acquired from a number of sources including Denodo &lt;a href=&quot;https://www.denodo.com/en/page/2017-gartner-magic-quadrant-data-integration-tools&quot;&gt;here&lt;/a&gt;, Informatica &lt;a href=&quot;https://www.informatica.com/gb/data-integration-magic-quadrant.html&quot;&gt;here&lt;/a&gt; and Talend &lt;a href=&quot;https://info.talend.com/gartnermqdi.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Garner also publish a &lt;a href=&quot;https://www.gartner.com/doc/3778873/market-guide-data-virtualization&quot;&gt;Market Guide for Data Virtualization&lt;/a&gt;, which is available for download from Rocket Software &lt;a href=&quot;http://info.rocketsoftware.com/rocket-data-virtualization-gartner-report.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2 id=&quot;enterprise-vendors&quot;&gt;“Enterprise” Vendors&lt;/h2&gt; &lt;p&gt;The following are capabilities that exist as part of wider data integration and management product suites:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Informatica Platform&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.informatica.com/gb/products/data-integration/real-time-integration/data-virtualization.html&quot;&gt;https://www.informatica.com/gb/products/data-integration/real-time-integration/data-virtualization.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Infosphere Federation Server&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www-03.ibm.com/software/products/da/ibminfofedeserv&quot;&gt;http://www-03.ibm.com/software/products/da/ibminfofedeserv&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SAS Federation Server&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.sas.com/en_us/software/federation-server.html&quot;&gt;https://www.sas.com/en_us/software/federation-server.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Oracle, SAP and Microsoft also claim capabilities in this space, however these generally aren’t through specific federation / virtualization products.&lt;/p&gt; &lt;h2 id=&quot;specialist-vendors&quot;&gt;Specialist Vendors&lt;/h2&gt; &lt;p&gt;The following are capabilities from specialist vendors:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Cisco Information Server&lt;/td&gt; &lt;td&gt;Originally Composite, one of the first and most established products in this space &lt;a href=&quot;http://www.compositesw.com/data-virtualization/&quot;&gt;http://www.compositesw.com/data-virtualization/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/denodo-platform/&quot;&gt;Denodo Platform&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Very well established and mature product, with free express edition&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;AtScale&lt;/td&gt; &lt;td&gt;Cube based semantic layer over with query optimisation, virtual cube caching and row level security over Hadoop and SQL data sources - &lt;a href=&quot;https://atscale.com/&quot;&gt;https://atscale.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;RedHat JBoss Data Virtualization&lt;/td&gt; &lt;td&gt;Originally Metamatrix - &lt;a href=&quot;https://www.redhat.com/en/technologies/jboss-middleware/data-virtualization&quot;&gt;https://www.redhat.com/en/technologies/jboss-middleware/data-virtualization&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Stone Bond Enterprise Enabler&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://stonebond.com/&quot;&gt;http://stonebond.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Data Virtuality&lt;/td&gt; &lt;td&gt;Marketed as a logical data warehouse tool - &lt;a href=&quot;https://datavirtuality.com/&quot;&gt;https://datavirtuality.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Information Builders iWay Data Hub&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www.informationbuilders.com/products/eii&quot;&gt;http://www.informationbuilders.com/products/eii&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Querona&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.querona.com/&quot;&gt;https://www.querona.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;K2View&lt;/td&gt; &lt;td&gt;Specialises in entity (e.g. customer) based views of data aggregated from multple sources - &lt;a href=&quot;http://www.k2view.com&quot;&gt;http://www.k2view.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OpenLink Virtuoso Universal Server&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://virtuoso.openlinksw.com/&quot;&gt;https://virtuoso.openlinksw.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Progress DataDirect&lt;/td&gt; &lt;td&gt;Connectors for vast range of data sources - &lt;a href=&quot;https://www.progress.com/datadirect-connectors&quot;&gt;https://www.progress.com/datadirect-connectors&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Rocket Data Virtualization&lt;/td&gt; &lt;td&gt;Focus on mainframe data - &lt;a href=&quot;http://www.rocketsoftware.com/products/rocket-data&quot;&gt;http://www.rocketsoftware.com/products/rocket-data&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;semantic-web-technologies&quot;&gt;Semantic Web Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Capsenta Ultrawrap&lt;/td&gt; &lt;td&gt;Virtualizes relational databases as an RDF semantic web data source - &lt;a href=&quot;https://capsenta.com/&quot;&gt;https://capsenta.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;D2RQ&lt;/td&gt; &lt;td&gt;Opens source platform for accessing relational databases as an RDF graph - &lt;a href=&quot;http://d2rq.org/&quot;&gt;http://d2rq.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Complexible Stardog&lt;/td&gt; &lt;td&gt;RDF database that also support property graphs and data virtualisation - &lt;a href=&quot;http://www.stardog.com/&quot;&gt;http://www.stardog.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;query-engines&quot;&gt;Query Engines&lt;/h2&gt; &lt;p&gt;A number of &lt;a href=&quot;/tech-categories/query-engines/&quot;&gt;Query Engines&lt;/a&gt; support joins and aggregation of data from multiple data sources&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/data-virtualization/</guid> </item> <item><title>Denodo Platform</title><link>http://ondataengineering.net/technologies/denodo-platform/</link><pubDate>Thu, 14 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Data Virtualisation platform, enabling a logical schema to be defined over a range of relational, NoSQL, flat file and application / data APIs that can then be queried through a range of end points. Supported data sources include a wide range of databases (relational, in memory, MPP, Hadoop, cloud, OLAP cube and NoSQL), flat files (Hadoop, text, binary, Office, including support for (S)FTP, compression and encryption), application APIs (e.g. Salesforce, SAP, Oracle e-business, Twitter), RDF semantic repositories via SPARQL, mainframes, data APIs (SOAP and REST), JMS queues and the ability to scrape web pages, with data accessible via SQL (JDBC, ODBC), data APIs (SOAP and REST) and web widgets (Sharepoint, Java, AJAX), with the ability to transform, cleanse and combine data from multiple sources into a single semantic model using the relevant source system query language. Supports a dynamic query optimiser (which pushes query logic down to the underlying data source, with the ability to move data between sources and take advantage of data replicated in multiple sources to maximise logic pushdown), caching (either by query or by full materialisation, allowing tables in the semantic layer to be pre-generated, with support for scheduled and incremental updates and the use of external ETL tools), data writes back to source (with support for a distributed transaction manager and 2-phase commits), a full security model (role based access control at the row/column level, with authentication pass-through to data sources), resource and workload management, metadata visualisation (including search and lineage views), self service data discovery (execution of ad-hoc queries outside of the semantic layer), search (over data and metadata, including support for semantic mining and extraction of text sources), an SDK (for adding new source adapters, custom functions and stored procedures), and a graphical UI (supporting wizard-driven configuration, integration with external configuration management tools and release management). Can we deployed stand alone or as a cluster (supporting both active/active and active/passive configurations and shared caches, with support for geo-replication), and is also available for AWS and as a free Denodo Express version (with limits on the number of active queries and results). A commercial product from Denodo Technologies Inc, who were founded in 1999 with the first release of the Denodo Platform shortly afterwards.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;September 2017 - v6.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.denodo.com/en&quot;&gt;https://www.denodo.com/en&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://community.denodo.com/&quot;&gt;https://community.denodo.com/&lt;/a&gt; - community site, including documentation and tutorials&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.datavirtualizationblog.com/&quot;&gt;http://www.datavirtualizationblog.com/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/denodo-platform/</guid> </item> <item><title>The Mid Week News - 13/09/2017</title><link>http://ondataengineering.net/blog/2017/09/13/the-mid-week-news/</link><pubDate>Wed, 13 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s the middle of the week, which means it’s time for the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt;, &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;Elastic X-Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch Hadoop&lt;/a&gt; have all seen a 5.6 release - a minor point release before the big upcoming 6.0 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Data Artisans have &lt;a href=&quot;https://data-artisans.com/blog/da-platform-2-stateful-stream-processing-with-apache-flink-made-easier&quot;&gt;announced dA Platform 2&lt;/a&gt; - which adds application lifecycle managment and components for logging and metrics to &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Amazon have &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/09/new-quick-start-build-a-data-lake-foundation-on-the-aws-cloud-with-aws-services/&quot;&gt;announced&lt;/a&gt; a new full stack data lake quickstart that runs on &lt;a href=&quot;/tech-vendors/amazon-web-services/&quot;&gt;AWS&lt;/a&gt; - we should take a look at full stack solutions at some point&lt;/li&gt; &lt;li&gt;Amazon also have a &lt;a href=&quot;https://aws.amazon.com/blogs/big-data/unite-real-time-and-batch-analytics-using-the-big-data-lambda-architecture-without-servers/&quot;&gt;post&lt;/a&gt; on implementing the Lambda architecture on &lt;a href=&quot;/tech-vendors/amazon-web-services/&quot;&gt;AWS&lt;/a&gt; without having to deploy or manage any servers&lt;/li&gt; &lt;li&gt;And it’s &lt;a href=&quot;https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-3/&quot;&gt;part 3&lt;/a&gt; from Confluent on how to get started with &lt;a href=&quot;/technologies/apache-kafka/kafka-connect/&quot;&gt;Kafka Connect&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/13/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 11/09/2017</title><link>http://ondataengineering.net/blog/2017/09/11/the-plan-for-this-week/</link><pubDate>Mon, 11 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right - time for a new week.&lt;/p&gt; &lt;p&gt;The observant among you may have spotted that we’re working our way through data storage and database technologies before we make a start on data transformation. There’s not far to go - graph databases and analytical databases are the big ones, but we’ll touch on data format libraries (Avro, Parquet et al) as well before we finish, and I need to have a think about whether I want to cover any more NoSQL technologies.&lt;/p&gt; &lt;p&gt;But this week, I want to look at data virtualisation technologies - those that allow you to query over and across data stored in multiple underlying platforms. As always, we’ll publish a technology category page on Friday along with some thoughts, and try and crank out some technology summaries during the week.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/11/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on In Memory Databases</title><link>http://ondataengineering.net/blog/2017/09/08/thoughts-on-in-memory-databases/</link><pubDate>Fri, 08 Sep 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;So this week has been a bit of a mess, with late posts and no technology summaries. My apologies - I’m going to blame technology issues, and promise that it won’t happen again (even though it undoubtedly will).&lt;/p&gt; &lt;p&gt;Anyway, this week I’ve been looking at &lt;a href=&quot;/tech-categories/in-memory-databases/&quot;&gt;In Memory Databases&lt;/a&gt;, and I’ll warn you in advance that there’s going to be heavy use of quotes around “in memory”… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I guess my first thought is that this probably isn’t a technology category in it’s own right - all the technologies on the technology category page (&lt;a href=&quot;/tech-categories/in-memory-databases/&quot;&gt;here&lt;/a&gt; if you missed the link in the paragraph above) are in memory versions of other technology categories - primarily relational databases, NoSQL key value stores and Hadoop compatible filesystems. So, don’t be surprised at some point if this technology category disappears as all the technologies on it get added to other technology category pages.&lt;/p&gt; &lt;p&gt;So, why go “in memory”? Well, the short and simple answer is speed - memory is faster than SSDs which in turn is faster than disks, and if all your data is in memory, you’re going to be able to execute queries and return data an order of magnitude faster than if you were having to pull it off disk. But having an “in memory” database doesn’t mean that you don’t want your data persisted (in almost all use cases you do), and so even “in memory” databases need to support durable writes of new data to disk and restoration of state on startup. And so the conceptual difference between “on disk” and “in memory” databases is all about when and how much data is loaded from disk into memory - for “in memory” databases it’s all data on startup and sod the memory usage, for “on disk” databases it’s just enough data when required and we’ll be frugal with your memory sir. But this distinction has pretty significant architectural implications - just sticking a RAM disk underneath an “on disk” database, or throwing more memory at it, tends to have limited benefit - the entire data access path needs to change to reflect the fact the data is in memory rather than on disk (and doesn’t need to be fetched dynamically into memory when required for starters).&lt;/p&gt; &lt;p&gt;First up were the in memory caches (memcached, Redis and the like), simple key value data stores that allowed applications to cache the results of queries or operations or hold state, with their simplicity supporting robust high performance data stores. They’ve now been given fancy names (like data grids), but at the moment I’m not entirely convinced of the use case for these within an analytics ecosystem so am not proposing to create a technology category page for them, but I look forward to being corrected and educated.&lt;/p&gt; &lt;p&gt;The big technologies for us that have started moving to “in memory” are relational SQL databases. All the big enterprise vendors are investing in this space, allowing entire tables to be permanently cached into memory, and making much better use of any memory available., but the technologies that are probably more interesting are the new specialist “in memory” technologies. There’s a range of these listed on the technology page, but there’s a couple I want to call out.&lt;/p&gt; &lt;p&gt;Firstly, there are a some (&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;GridGain/Apache Ignite&lt;/a&gt; and Oracle Times Ten for starters) that can use other relational databases for their backing storage (a range for Ignite, Oracle for Time Tens), meaning that can be used as a drop in cache between your application and your “on disk” database, providing performance improvements without significant application changes.&lt;/p&gt; &lt;p&gt;The others are MapD and Kinetica - not only do these run in memory but they can also exploit GPUs for even further acceleration. If you’re really looking at pushing the boundaries of relational database performance, this would be a fascinating place to start.&lt;/p&gt; &lt;p&gt;And finally we get to the Hadoop compatible / distributed parallel “in memory” filesystems - same principle, different use case. There are two technologies in this space - &lt;a href=&quot;/technologies/alluxio/&quot;&gt;Alluxio&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-ignite&quot;&gt;GridGain/Apache Ignite&lt;/a&gt;. Alluxio is focused on filesystems, supporting a FUSE driver (allowing an in memory filesystem to be mounted in Linux) as well as Hadoop compatibility, with the ability to tier data onto a range of different persistent storage technologies, allowing it to support larger filesystems that will fit in memory. Ignite seems to be the Swiss Army knife in the in memory space, supporting key value, SQL and filesystem APIs (amongst a raft of other capabilities).&lt;/p&gt; &lt;p&gt;Right - I’ve had enough of this week. See you on Monday for a fresh start.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/08/thoughts-on-in-memory-databases/</guid> </item> <item><title>In Memory Databases</title><link>http://ondataengineering.net/tech-categories/in-memory-databases/</link><pubDate>Fri, 08 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Technologies that serve data entirely or primarily from memory, with the aim of providing significant higher performance for querying and accessing data. They are generally backed by some sort of persistent storage with guarentees around durability, with some technologies able to act as in memory caches over equivalent disk based technologies. The technologies listed on this page span a number of different technology categories, including relational databases, Hadoop compatible filesystems and key value stores, and will also appear under the relevent technology category page where they exist.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;https://www.forrester.com/report/The+Forrester+Wave+InMemory+Databases+Q1+2017/-/E-RES132143&quot;&gt;The Forrester Wave: In Memory Database, Q1 2017&lt;/a&gt; provides a view of “enterprise” in memory technologies, with a mix of NoSQL, enterprise RDBMS and and dedicated in memory relational technologies, however the list is limited and includes some technologies that aren’t in memory at all. It’s available from Oracle &lt;a href=&quot;http://www.oracle.com/us/corporate/analystreports/forrester-imdb-wave-2017-3616348.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There is also a list of in memory databases on Wikipedia &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_in-memory_databases&quot;&gt;here&lt;/a&gt;, however it does not clearly distinguish between the different types of databases.&lt;/p&gt; &lt;h2 id=&quot;in-memory-relational-databases&quot;&gt;In Memory Relational Databases&lt;/h2&gt; &lt;p&gt;There are a wide range of Relational Databases that operate entirely in memory, but with the ability to persist data to disk and provide durability guarantees:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MemSQL&lt;/td&gt; &lt;td&gt;Distributed in memory relational database, with wire compatibility with MySQL and support for row and columnar storage, and a free community edition - &lt;a href=&quot;http://www.memsql.com/&quot;&gt;http://www.memsql.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SAP HANA&lt;/td&gt; &lt;td&gt;In memory relational DBMS primarily focused on accelerating SAP applications - &lt;a href=&quot;https://www.sap.com/products/hana.html&quot;&gt;https://www.sap.com/products/hana.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;VoltDB&lt;/td&gt; &lt;td&gt;Scale out in memory relational from Mike Stonebraker, with open source community edition - &lt;a href=&quot;https://www.voltdb.com/&quot;&gt;https://www.voltdb.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;EXASOL&lt;/td&gt; &lt;td&gt;In memory MPP database with columnar compression and SQL support - &lt;a href=&quot;http://www.exasol.com/&quot;&gt;http://www.exasol.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle TimesTen&lt;/td&gt; &lt;td&gt;In memory relational database that can also act as a cache over Oracle Database - &lt;a href=&quot;https://www.oracle.com/database/timesten-in-memory-database/index.html&quot;&gt;https://www.oracle.com/database/timesten-in-memory-database/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;GridGain/Apache Ignite&lt;/a&gt;&lt;/td&gt; &lt;td&gt;In memory relational database that also supports in memory filesystem and key value stores&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MapD&lt;/td&gt; &lt;td&gt;In memory, column store, SQL relational database that runs on GPUs - &lt;a href=&quot;https://www.mapd.com/&quot;&gt;https://www.mapd.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Kinetica&lt;/td&gt; &lt;td&gt;Distributed in memory relational database that runs on GPUs - &lt;a href=&quot;https://www.kinetica.com&quot;&gt;https://www.kinetica.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;All the big enterprise relational databases now have (or are starting to add) in memory capabilities, including IBM DB2, IBM PureData, SQL Server, Oracle Database and Teradata.&lt;/p&gt; &lt;p&gt;And a number of databases support in-memory only storage engines (for example MySQL), however these generally don’t provide persistent storage.&lt;/p&gt; &lt;h2 id=&quot;in-memory-hadoop-compatible-filesystems&quot;&gt;In Memory Hadoop Compatible Filesystems&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/alluxio/&quot;&gt;Alluxio&lt;/a&gt;&lt;/td&gt; &lt;td&gt;In memory (HDFS compatible) distributed filesystem, with support for tiering data onto persistent storage&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;GridGain/Apache Ignite&lt;/a&gt;&lt;/td&gt; &lt;td&gt;In memory (HDFS compatible) distributed filesystem that also supports in memory relational database and key value stores&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;See out &lt;a href=&quot;/tech-categories/hadoop-compatible-filesystems/&quot;&gt;Hadoop Compatible Filesystems&lt;/a&gt; for more information on Hadoop Compatible Filesystems.&lt;/p&gt; &lt;h2 id=&quot;in-memory-nosql-key-value-stores&quot;&gt;In Memory NoSQL Key Value Stores&lt;/h2&gt; &lt;p&gt;Many NoSQL Key Value stores operated entirely in memory. These technologies aren’t a focus for us, but include Redis, Memcached, HazelCast, EhCache, Riak KV, Aerospike, Oracle Coherance, Infinispan / JBoss Data Grid and Pivotal Gemfire / Apache Geode.&lt;/p&gt; &lt;h2 id=&quot;in-memory-embeddable-databases&quot;&gt;In Memory Embeddable Databases&lt;/h2&gt; &lt;p&gt;A range of in memory databases are also available that can be embedded into custom applications. Again, these technologies aren’t a focus for us, but Baeldung has a good list of Java options from April 2017 &lt;a href=&quot;http://www.baeldung.com/java-in-memory-databases&quot;&gt;here&lt;/a&gt;. Alternatives are also available for .Net (e.g. inmemory.net) and embedded systems (e.g. FairCom or Raima)&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/in-memory-databases/</guid> </item> <item><title>The Mid Week News - 06/09/2017</title><link>http://ondataengineering.net/blog/2017/09/06/the-mid-week-news/</link><pubDate>Wed, 06 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Although it’s a quiet week this week, we’re still got time for the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;No new releases this week, but I’ve added more links to the &lt;a href=&quot;/technologies/apache-spark&quot;&gt;Spark&lt;/a&gt; 2.2 and &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Solr&lt;/a&gt; 6.6 release information&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Facebook have &lt;a href=&quot;https://code.facebook.com/posts/357056558062811/logdevice-a-distributed-data-store-for-logs/&quot;&gt;posted about LogDevice&lt;/a&gt;, their distributed log data store, due to be open sourced later this year. Along with DistributedLog (Twitter), Pulsar (Yahoo) and BookKeeper (also Yahoo), it feels like the open source technologies in our &lt;a href=&quot;/tech-categories/streaming-data-stores/&quot;&gt;streaming data stores&lt;/a&gt; category are starting to multiply.&lt;/li&gt; &lt;li&gt;Analytics on video (and image and audio) sources is an interesting area (here I go again) that I’d like to come back to at some point, but in the meantime, from Amit Baghel via InfoQ, a post on &lt;a href=&quot;https://www.infoq.com/articles/video-stream-analytics-opencv&quot;&gt;using OpenCV, Kafka and Spark to do video stream analysis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Following Confluent’s KSQL announcement last week, &lt;a href=&quot;https://data-artisans.com/blog/flink-streaming-sql-ksql-stream-processing&quot;&gt;Data Artisans’ thoughts and comparison&lt;/a&gt; to &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Flink&lt;/a&gt; SQL&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.theregister.co.uk/2017/08/30/open_source_ml_and_ai/&quot;&gt;Thoughts&lt;/a&gt; from The Register on machine learning, open source and the current skills gap&lt;/li&gt; &lt;li&gt;Interesting &lt;a href=&quot;https://beam.apache.org/blog/2017/08/28/timely-processing.html&quot;&gt;post&lt;/a&gt; on window processing in &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; that’s a good introduction to the subject&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/06/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 04/09/2017</title><link>http://ondataengineering.net/blog/2017/09/04/the-plan-for-this-week/</link><pubDate>Mon, 04 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Good morning, and welcome back.&lt;/p&gt; &lt;p&gt;This week we will mostly be looking at in memory databases, grids and whatever else they want to call themselves. If I come across some interesting technologies I’ll try and knock out a couple of technology summaries, but my guess is that most of this week will be spent reading to try and get my head around this space.&lt;/p&gt; &lt;p&gt;So news on Wednesday, a technology category page and associated thoughts on Friday, and maybe a technology summary or two somewhere along the way.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/04/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Time Series Databases</title><link>http://ondataengineering.net/blog/2017/09/01/thoughts-on-time-series-databases/</link><pubDate>Fri, 01 Sep 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;It feels like it’s been a bit of a rush this week (probably because I lost a day due to public holidays), but let’s quickly summarise what we’ve learnt this week about &lt;a href=&quot;/tech-categories/time-series-databases/&quot;&gt;Time Series Databases&lt;/a&gt; &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, before you go any further, read &lt;a href=&quot;https://blog.outlyer.com/top10-open-source-time-series-databases&quot;&gt;Steven Acreman’s post&lt;/a&gt; from the Outlyer blog where he reviews a number of time series databases, provides some interesting commentary, and provides a link to his detailed analysis including some benchmark timing. And while you’reo outside the safe confines of this site, can I recommend DB Engines’ &lt;a href=&quot;https://db-engines.com/en/ranking/time+series+dbms&quot;&gt;list of time series databases&lt;/a&gt; (and their site in general).&lt;/p&gt; &lt;p&gt;So, first things first, what are time series databases and why might we be interested in them. Fundamentally, they’re databases optimised for storing point in time metrics and aggregating them by a range of dimensions (commonly called tags) to generate pretty graphs and support a range of analytics. Generally what you’re looking for is deviations from the norm, which suggests something interesting is happening in your sources, or you’re looking at trends over time. And with metrics you’re talking about potentially huge volumes of data, so we’re looking for databases that both store huge volumes of metrics efficiently on disk and can handle the ingest rates that we might through at it.&lt;/p&gt; &lt;p&gt;And why might we be interested in them? Well firstly because time series metrics are (and always have been) a big part of analytical systems (think financial transactions, invoices, call detail records and now the internet of things, and the functional similarities between time series databases and OLAP cube / star schema technologies), but also because one of the key use cases for this data (monitoring of infrastructure and applications) is a capability that we need for the infrastructure and applications in our analytical systems, and that’s before we start to talk about data quality and how we might track and manage data quality metrics. So for the analytical systems we build, we’re probably as much a consumer of this sort of analytics as we are a provider. We’ll come back and talk more about monitoring and data quality in the future, as they’re both huge topics.&lt;/p&gt; &lt;p&gt;So you want a time series database? What are the options…&lt;/p&gt; &lt;p&gt;Firstly, if you’re looking for a commercial option they there are some good ones. &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; seems to be the market leader, but there are some good alternatives as well, and a number of these have open source versions. TimescaleDB is an interesting one to call out, as this is a plugin to PostgreSQL to add time series data storage, which gives you a PostgreSQL database that supports both relational and time series data, potentially making this an interesting technology choice for star schema like use cases.&lt;/p&gt; &lt;p&gt;If you have a &lt;a href=&quot;/tech-categories/nosql-wide-column-stores/&quot;&gt;NoSQL Wide Column Stores&lt;/a&gt; already, then there are a number of open source options for leveraging these. &lt;a href=&quot;/technologies/opentsdb/&quot;&gt;OpenTSDB&lt;/a&gt; which runs over &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;HBase&lt;/a&gt; is tried and tested, but there are others that run over &lt;a href=&quot;/technologies/apache-cassandra/&quot;&gt;Cassandra&lt;/a&gt; and Google Cloud Bigtable, as well as one (Chronix) that runs over Solr. Warp 10 is an interesting one to call out in this space, as a time series database over HBase that also supports geo co-ordinates.&lt;/p&gt; &lt;p&gt;And there are also a range of open source technologies that implement their own datastores. RRDtool is the grandfather of time series databases, being created in 1999, &lt;a href=&quot;/technologies/druid/&quot;&gt;Druid&lt;/a&gt; we’ve talked about before, and both Facebook and Netflix have very high performance in memory solutions (Beringei and Atlas) that are probably way over the top for anyone else.&lt;/p&gt; &lt;p&gt;And then there are a bunch of full stack solutions, which I’ve lumped into this technology category page as well for the time being. Firstly, infrastructure/application monitoring stacks that include capabilities for hoovering up metrics, visualising these and alerting on them. Secondly, IoT stacks, which do much the same I guess, but differentiate themselves in some way I don’t understand yet. We’ll come back to these in the future…&lt;/p&gt; &lt;p&gt;And that will, I think, do for the week. Apologies this post is slightly late, but that’s life for you.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/09/01/thoughts-on-time-series-databases/</guid> </item> <item><title>Time Series Databases</title><link>http://ondataengineering.net/tech-categories/time-series-databases/</link><pubDate>Fri, 01 Sep 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Databases optimised for storing very large numbers of metrics and allowing these to be aggregated and analysed. Metrics are usually organised by measurements or metric names and one or more tags (e.g. to represent a server or instance). Many implement their own data storage layers, however many also run over external databases, typically NoSQL wide data stores. Use cases traditionally focus on monitoring infrastructure and applications or more recently IoT use cases, but analytics over any timestamped data is fair game.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;DB Engines maintain a list of time series databases along with their current popularity: &lt;a href=&quot;https://db-engines.com/en/ranking/time+series+dbms&quot;&gt;https://db-engines.com/en/ranking/time+series+dbms&lt;/a&gt;&lt;/p&gt; &lt;p&gt;From Steven Acreman on the Outlyer blog, a review of Time Series Databases from August 2016, some interesting thoughts, and a detailed analysis Google spreadsheet: &lt;a href=&quot;https://blog.outlyer.com/top10-open-source-time-series-databases&quot;&gt;https://blog.outlyer.com/top10-open-source-time-series-databases&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&quot;open-source-over-external-data-stores&quot;&gt;Open Source over external data stores&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/opentsdb/&quot;&gt;OpenTSDB&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Time Series DB that runs over Apache HBase&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;KairosDB&lt;/td&gt; &lt;td&gt;Fork of OpenTSDB that runs over Apache Cassandra - &lt;a href=&quot;https://kairosdb.github.io/&quot;&gt;https://kairosdb.github.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Chronix&lt;/td&gt; &lt;td&gt;Time Series DB that runs over Apache Solr - &lt;a href=&quot;http://www.chronix.io/&quot;&gt;http://www.chronix.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Heroic&lt;/td&gt; &lt;td&gt;Time Series DB from Spotify based on Bigtable/Cassandra, and Elasticsearch - &lt;a href=&quot;https://github.com/spotify/heroic&quot;&gt;https://github.com/spotify/heroic&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Blueflood&lt;/td&gt; &lt;td&gt;Time Series DB over Cassandra from Rackspace - &lt;a href=&quot;http://blueflood.io/&quot;&gt;http://blueflood.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Warp 10&lt;/td&gt; &lt;td&gt;Geo Time Series DB that also geo co-ordinates and/or elevation alongside timestamps that runs over HBase and Kafka - &lt;a href=&quot;http://www.warp10.io/&quot;&gt;http://www.warp10.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Newts&lt;/td&gt; &lt;td&gt;Time Series DB over Cassandra - &lt;a href=&quot;http://opennms.github.io/newts/&quot;&gt;http://opennms.github.io/newts/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;open-source-using-custom-storage&quot;&gt;Open Source using custom storage&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;RRDtool&lt;/td&gt; &lt;td&gt;Open source data logging and graphing for time series data, originally created in 1999 - &lt;a href=&quot;https://oss.oetiker.ch/rrdtool/&quot;&gt;https://oss.oetiker.ch/rrdtool/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/druid&quot;&gt;Druid&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Runs over HDFS/S3 and supports real time aggregations of streaming data&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;DalmatinerDB&lt;/td&gt; &lt;td&gt;High performance Time Series DB written in Erlang and based on Riak Core that runs over ZFS - &lt;a href=&quot;https://dalmatiner.io/&quot;&gt;https://dalmatiner.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Beringei&lt;/td&gt; &lt;td&gt;In memory Time Series DB from Facebook - &lt;a href=&quot;https://github.com/facebookincubator/beringei&quot;&gt;https://github.com/facebookincubator/beringei&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Atlas&lt;/td&gt; &lt;td&gt;In memory Time Series DB from Netflix - &lt;a href=&quot;https://github.com/Netflix/atlas/wiki/Overview&quot;&gt;https://github.com/Netflix/atlas/wiki/Overview&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SiriDB&lt;/td&gt; &lt;td&gt;Open source Time Series DB - &lt;a href=&quot;http://siridb.net/&quot;&gt;http://siridb.net/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Akumuli&lt;/td&gt; &lt;td&gt;C++ Time Series DB that can be used as an embedded library - &lt;a href=&quot;http://akumuli.org/&quot;&gt;http://akumuli.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gnocchi&lt;/td&gt; &lt;td&gt;Open source Time Series DB that was spun off from the OpenStack Ceilometer project - &lt;a href=&quot;http://gnocchi.xyz/&quot;&gt;http://gnocchi.xyz/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-open-source&quot;&gt;Commercial Open Source&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Implemented in Go, with commercial and cloud versions also available&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Axibase&lt;/td&gt; &lt;td&gt;Time Series DB built on HDFS, with a commercial Enterprise edition available - &lt;a href=&quot;https://axibase.com/&quot;&gt;https://axibase.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Riak TS &lt;/td&gt; &lt;td&gt;Time Series DB built on the core of Riak KV, and available in a number of commercial editions - &lt;a href=&quot;http://basho.com/products/riak-ts/&quot;&gt;http://basho.com/products/riak-ts/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TimescaleDB&lt;/td&gt; &lt;td&gt;Plugin to PostgreSQL to add time series data storage - &lt;a href=&quot;https://www.timescale.com/&quot;&gt;https://www.timescale.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-closed-source&quot;&gt;Commercial Closed Source&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MachBase&lt;/td&gt; &lt;td&gt;Commercial Time Series DB previously known as InfiniFlux - &lt;a href=&quot;http://www.infiniflux.com/machbase/&quot;&gt;http://www.infiniflux.com/machbase/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;KDB+&lt;/td&gt; &lt;td&gt;Time Series DB from KX Systems that used heavily in financial organisations - &lt;a href=&quot;https://kx.com/discover/#time-series-database&quot;&gt;https://kx.com/discover/#time-series-database&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;monitoring-stacks-open-source&quot;&gt;Monitoring Stacks (open source)&lt;/h2&gt; &lt;p&gt;The following stacks support monitoring infrastructure and applications, with connectors to import metrics from a number of sources:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Graphite&lt;/td&gt; &lt;td&gt;Three tier stack consisting of Whisper (simple time series database, graphite-web (a graph/dashboard UI) and Carbon (for ingestion of data)- &lt;a href=&quot;https://graphiteapp.org/&quot;&gt;https://graphiteapp.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Prometheus&lt;/td&gt; &lt;td&gt;Open source monitoring solution that includes a time series database and alerting; part of the Cloud Native Computing Foundation - &lt;a href=&quot;https://prometheus.io/&quot;&gt;https://prometheus.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hawkular&lt;/td&gt; &lt;td&gt;Open source monitoring solution over Cassandra with alerting and visualisation capabilities, backed by RedHat - &lt;a href=&quot;http://www.hawkular.org/&quot;&gt;http://www.hawkular.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;NetData&lt;/td&gt; &lt;td&gt;Local in memory metrics dashboards for monitoring servers and applications, with the ability to forward metrics to downstream time series dbs - &lt;a href=&quot;https://my-netdata.io/&quot;&gt;https://my-netdata.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Icinga&lt;/td&gt; &lt;td&gt;Commercial support available - &lt;a href=&quot;https://www.icinga.com/&quot;&gt;https://www.icinga.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;monitoring-stacks-as-a-service&quot;&gt;Monitoring Stacks (as a service)&lt;/h2&gt; &lt;p&gt;If you’re looking for a time series database to handle monitoring and management of infrastructure and applications, there are also a number of cloud based services you could consider:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;AWS CloudWatch&lt;/td&gt; &lt;td&gt;Collects and tracks metrics for AWS services, with support for custom metrics - &lt;a href=&quot;https://aws.amazon.com/cloudwatch/&quot;&gt;https://aws.amazon.com/cloudwatch/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outlyer&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.outlyer.com/&quot;&gt;https://www.outlyer.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;VMWare Wavefront&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.wavefront.com/&quot;&gt;https://www.wavefront.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;VividCortex&lt;/td&gt; &lt;td&gt;Specialist database performance metrics monitoring - &lt;a href=&quot;https://www.vividcortex.com/&quot;&gt;https://www.vividcortex.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SignalFX&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://signalfx.com&quot;&gt;https://signalfx.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Circonus&lt;/td&gt; &lt;td&gt;Also available for installation on premises - &lt;a href=&quot;https://www.circonus.com&quot;&gt;https://www.circonus.com&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Datadog&lt;/td&gt; &lt;td&gt;Available for free for up to 5 hosts - &lt;a href=&quot;https://www.datadoghq.com/&quot;&gt;https://www.datadoghq.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Librato&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.librato.com/&quot;&gt;https://www.librato.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ServerDensity&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.serverdensity.com/&quot;&gt;https://www.serverdensity.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;iot-stacks&quot;&gt;IoT Stacks&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;TempoIQ&lt;/td&gt; &lt;td&gt;Commercial IoT collection, storage and analytics service - &lt;a href=&quot;https://www.tempoiq.com/&quot;&gt;https://www.tempoiq.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SiteWhere&lt;/td&gt; &lt;td&gt;Commercial open source IoT platform built over MongoDB/HBase/InfluxDB - &lt;a href=&quot;http://www.sitewhere.org/&quot;&gt;http://www.sitewhere.org/&lt;/a&gt; / &lt;a href=&quot;http://www.sitewhere.com/&quot;&gt;http://www.sitewhere.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/time-series-databases/</guid> </item> <item><title>InfluxDB</title><link>http://ondataengineering.net/technologies/influxdb/</link><pubDate>Thu, 31 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A time series database implemented in Go available in both open source and enterprise editions. Each data point consists of a metric name (measurement), a UNIX nano timestamp, a set of tag key value pairs, and a set of value key value pairs, with the combination of measurement and tag keys refered to as a series. Data is stored in a custom time series index (TSI) engine which supports very large numbers of series allowing for huge cardinalities of tag and value keys. Queries are written in InfluxQL (a varient of SQL), which includes support for creating and managing databases and series, listing series metadata (including measurements, tag keys and values and field keys), managing queries, writing the results of queries back into InfluxDB into a new series, a range of analytical SQL functions including aggregations (e.g. sum, count, spread, stddev), selections (e.g. first, last, percentile, sample) and transformations (e.g. ceiling, derivative, moving_average), and support for registering continuous queries that are run automatically and periodically within a database to create aggregate tables. Also supports retention policies for the automatic deletion of historic data, basic authentication and authorisation (at the database level), HTTPS connections, service plugins that allow data to be written to InfluxDB in alternative protocols (with out of the box support for UDP, Graphite, CollectD, Prometheus and OpenTSDB protocols), snapshot backups, statistics and diagnostic information, and an HTTP API and CLI for writing and querying data. Available as an open source version (under an MIT licence but limited to a single node), and as two commercial products - InfluxEnterprise (with support for clustering, access control and incremental backups) and InfluxCloud (InfluxEnterprise as a cloud based service). Originally created in 2013, and is part of the open source TICK suite along with Telegraf (ingestion of data), Chronograf (admin UI and visualisation) and Kapacitor (streaming analytics and actions).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;hr /&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.4&lt;/td&gt; &lt;td&gt;tbc&lt;/td&gt; &lt;td&gt;tbc&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.influxdata.com/blog/influxdb-now-supports-prometheus-remote-read-write-natively/&quot;&gt;Prometheus compatible API&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/time-series-platform/influxdb/&quot;&gt;https://www.influxdata.com/time-series-platform/influxdb/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/time-series-platform/&quot;&gt;https://www.influxdata.com/time-series-platform/&lt;/a&gt; - TICK platform overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/products/editions/&quot;&gt;https://www.influxdata.com/products/editions/&lt;/a&gt; - comparison of the different editions&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.influxdata.com/influxdb/latest/&quot;&gt;https://docs.influxdata.com/influxdb/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/influxdata/influxdb&quot;&gt;https://github.com/influxdata/influxdb&lt;/a&gt; - source code&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.influxdata.com/blog/&quot;&gt;https://www.influxdata.com/blog/&lt;/a&gt; - InfluxData blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.influxdata.com/influxdb/latest/about_the_project/releasenotes-changelog/&quot;&gt;https://docs.influxdata.com/influxdb/latest/about_the_project/releasenotes-changelog/&lt;/a&gt; - current release versions&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/influxdb/</guid> </item> <item><title>The Mid Week News - 30/08/2017</title><link>http://ondataengineering.net/blog/2017/08/30/the-mid-week-news/</link><pubDate>Wed, 30 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Right, time for this weeks news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;We’ve only just covered it, but &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Beam&lt;/a&gt; has already seen a point release to 2.1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A topical follow-up to our look at &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt; last week - Confluent have &lt;a href=&quot;https://www.confluent.io/blog/ksql-open-source-streaming-sql-for-apache-kafka/&quot;&gt;just announced&lt;/a&gt; KSQ, which provides the ability to create continuously updated tables and new streams from data in Kafka using SQL&lt;/li&gt; &lt;li&gt;And on the subject of KSQL, &lt;a href=&quot;http://www.zdnet.com/article/ksql-kafka-gets-sql/&quot;&gt;an interview&lt;/a&gt; with Confluent on KSQL from ZDNet&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/search-engines-and-big-data-a-perfect-match-part-2/&quot;&gt;Part 2&lt;/a&gt; from Cloudera on the role &lt;a href=&quot;/tech-categories/analytical-search/&quot;&gt;Analytical Search&lt;/a&gt; capabilities play in big data analytics&lt;/li&gt; &lt;li&gt;LinkedIn have &lt;a href=&quot;https://engineering.linkedin.com/blog/2017/08/open-sourcing-kafka-cruise-control&quot;&gt;opened sourced Cruise Control&lt;/a&gt;, their technology for monitoring, balancing and managing their &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; clusters&lt;/li&gt; &lt;li&gt;An &lt;a href=&quot;https://www.theregister.co.uk/2017/08/25/bet365_to_buy_basho_release_code/&quot;&gt;update&lt;/a&gt; from The Register on Basho - it looks like Bet365 are planning to buy up Basho’s assets (including Riak), and open source all of their products&lt;/li&gt; &lt;li&gt;A &lt;a href=&quot;https://www.confluent.io/blog/blogthe-simplest-useful-kafka-connect-data-pipeline-in-the-world-or-thereabouts-part-2/&quot;&gt;follow up&lt;/a&gt; from Confluent on how to get started with &lt;a href=&quot;/technologies/apache-kafka/kafka-connect/&quot;&gt;Kafka Connect&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A &lt;a href=&quot;https://databricks.com/blog/2017/08/24/anthology-of-technical-assets-on-apache-sparks-structured-streaming.html&quot;&gt;big dump&lt;/a&gt; from DataBricks on useful links and information relating to &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt; is gaining the ability to do ad-hoc imports to HDFS from databases via &lt;a href=&quot;/technologies/apache-sqoop&quot;&gt;Sqoop&lt;/a&gt; in it’s next release (4.1), building on the existing functionality to be able to import flat files&lt;/li&gt; &lt;li&gt;A two part series from Hortonworks (&lt;a href=&quot;https://hortonworks.com/blog/update-hive-tables-easy-way/&quot;&gt;part 1&lt;/a&gt; and &lt;a href=&quot;https://hortonworks.com/blog/update-hive-tables-easy-way-2/&quot;&gt;part 2&lt;/a&gt;) on doing &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; table updates, including how to do type 1, 2 and 3 slowly changing dimensions in Hive&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/contracts-streaming-microservices&quot;&gt;A presentation&lt;/a&gt; from Gwen Shapira at Confluent (via InfoQ) on schema management and the role of schema management tools such as the Confluent Schema Registry (bundled with &lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt;) and Hortonworks Schema Registry (/technologies/schema-registry/)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mapr.com/blog/5-ways-business-cultivate-data-driven-culture/&quot;&gt;Thoughts&lt;/a&gt; from the MapR blog on how Businesses Can Cultivate a Data-Driven Culture. Normally I’d avoid these articles like the plague, but this one seems to keep it simple and the advice sensible.&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/30/the-mid-week-news/</guid> </item> <item><title>OpenTSDB</title><link>http://ondataengineering.net/technologies/opentsdb/</link><pubDate>Wed, 30 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A time series database built on top of Apache HBase (with support for Google BigTable and Apache Cassandra recently added). Each data point consists of a metric name, a UNIX timestamp, a value (either integer or floating point) and a set of key value pair tags, where the tags define the potentially aggregations required. Data is stored with one row per metric, tag combination and hour, with all data points for that hour stored in that row under different column qualifiers based on the timestamp, allowing for more efficient in memory aggregations. Supports the recording (but not generation) of pre-aggregated data that will be used to accelerate queries, annotations (short text strings associated with timestamps and optionally time series that represent events), the organisation of metrics and tags into hierarchical trees, and the generation of statistics relating to performance, however currently does not support incrementing counters. Consists of a Time Series Daemon (TSD) (that exposes a Telnet RPC and HTTP JSON REST APIs and a simple web based UI for querying data) and a CLI (including the ability to batch import data), with each TSD opperating independantly of each other with no master or shared state allowing for horizontal scalability over a single underlying database. Supports a range of plugins, including the ability to support different deserialisation and authentication for HTTP REST calls, emmission of meta data (metrics, tags and annotations) to a search engine, real time publishing of data points to another destination and support for other RPC protocols. Open sourced on GitHub under both an LGPLv2.1+ and GPLv3+ licence, with development started in 2010, and has been adopted but a number of large organisations including MapR, Yahoo, Tumblr and ebay.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Quiet&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - v2.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-monitoring/&quot;&gt;MapR Monitoring&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://opentsdb.net/&quot;&gt;http://opentsdb.net/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://opentsdb.net/docs/build/html/index.html&quot;&gt;http://opentsdb.net/docs/build/html/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/HBaseCon/ecosystem-session-6&quot;&gt;https://www.slideshare.net/HBaseCon/ecosystem-session-6&lt;/a&gt; - introductory presentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/OpenTSDB/opentsdb/releases&quot;&gt;https://github.com/OpenTSDB/opentsdb/releases&lt;/a&gt; - release history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/opentsdb/</guid> </item> <item><title>The Plan For This Week - 29/08/2017</title><link>http://ondataengineering.net/blog/2017/08/29/the-plan-for-this-week/</link><pubDate>Tue, 29 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Yes - it’s a Tuesday and not a Monday. Apologies, forgot to say on Friday that it was a public holiday in the UK this Monday, and therefore they’d be no update. I hope you’ll forgive me.&lt;/p&gt; &lt;p&gt;So, a shorter week this week. The plan is to look at event series databases, both for analysing external event data, but also as a capability for analysing event logs and metrics that our analytical systems may generate.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/29/the-plan-for-this-week/</guid> </item> <item><title>The Week That Was - 25/08/2017</title><link>http://ondataengineering.net/blog/2017/08/25/the-week-that-was/</link><pubDate>Fri, 25 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;So, a bit of a mixed bag this week, but what did we look at.&lt;/p&gt; &lt;p&gt;We started with three technologies summaries from Jeff Moszuti, looking at &lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; and &lt;a href=&quot;/technologies/rex-ray/&quot;&gt;Dell EMC REX-Ray&lt;/a&gt;. We then finished up the week by looking at &lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;We last looked at OLAP cube technologies with &lt;a href=&quot;/technologies/druid&quot;&gt;Druid&lt;/a&gt;, which like &lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt; is tightly integrated with the Hadoop ecosystem. Unlike Druid however, Kylin doesn’t introduce new data storage, instead leveraging Hive and HBase, which potentially makes it more palatable if you don’t want more data management engines running on your cluster. What it lacks however is Druid’s support for combining streaming and batch data. And Kylin is an Apache project (if that’s important to you), however given Hortonwork’s recent commitment to Druid, it wouldn’t surprise me if Druid was heading that way as well.&lt;/p&gt; &lt;p&gt;I have to say I’m a little conflicted around &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt;. It aims to introduce a standard model for batch and stream processing that a range of different technologies can then support. The model feels ok, certainly Data Artisans liked it enough to completely rework the Flink API to be more aligned (&lt;a href=&quot;https://data-artisans.com/blog/why-apache-beam&quot;&gt;details here&lt;/a&gt;), but I’m struggling to see the value. I have to admin to be slightly biased against abstractions like these - my feeling is that they’re great in concept, however there’s always a cost associated with an abstraction layer, either in not being able to achieve something easily because you’re fighting the abstraction, or in performance overheads from the translations involved, and switching between back end runners will never be as easy as you hope. And does anyone really care about being able to take batch/streaming code and easily migrate it between different back end execution engines? I can see what’s in it for Google - having Google Cloud Dataflow being the de-facto runner for running Beam code in the cloud puts them in a good position. Perhaps I’m just being cynical.&lt;/p&gt; &lt;p&gt;I’ve not much to say about &lt;a href=&quot;/technologies/rex-ray/&quot;&gt;Dell EMC REX-Ray&lt;/a&gt;, but hopefully we’ll look more at containerisation technologies and how they support persistent storage and how you might use them for analytics at some point in the future.&lt;/p&gt; &lt;p&gt;We looked at Scality’s open sourced S3 Server back when we were looking at &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;object store&lt;/a&gt;. Just as a reminder, it was a Node based single process (i.e. not clustered or distributed) S3 compatible object store service, that could either proxy requests onto &lt;a href=&quot;/technologies/scality-ring/&quot;&gt;Scality Ring&lt;/a&gt; or &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;Amazon S3&lt;/a&gt;, or could serve them from local or in memory storage. Useful for development and test, but probably not anything significant in production. It seems like it was pretty successful (they keep banging on about how it was downloaded over 600,000 times), and they’re therefore trying to make something more significant of it.&lt;/p&gt; &lt;p&gt;The result is that they’ve renamed S3 Server into &lt;a href=&quot;/technologies/zenko/cloudserver/&quot;&gt;Zenko Cloudserver&lt;/a&gt;, and made it part of a new much larger open source project called &lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;. At the moment all Zenko does is provide a Docker Swarm stack definition that allows multiple Cloudservers to be clustered behind a load balancer, but what they have planned is more interesting. First up is support for more backend services, including Azure Blob Storage and potentially Google Storage, also support for other container management systems such as Kubernetes, and then new new sub-projects - Backbeat (which will provide policy-based data workflows such as replication or migration) and Clueso (which will provide object metadata search and analytics using Apache Spark). The aim is to provide a gateway into multiple back end object stores with federation capabilities over the top. Sounds like a nice idea, and probably one to track.&lt;/p&gt; &lt;p&gt;And finally, I’ve refreshed all our &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; technology summaries (including all the sub-projects) to make sure they’re up to date (which is odd given there’s only been one point release since they were written). The big bit that was missing was information on &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt;, which provides the ability to run a DataFrame or SQL query over streaming data (using the standard &lt;a href=&quot;/technologies/apache-spark/spark-sql/&quot;&gt;Spark SQL&lt;/a&gt; APIs), and have the result calculated and then updated/maintained as new data comes in. The result being that I think it’s probably time we took a deeper look into streaming technologies and understood the differences. It does feel like Spark is moving forward at a pace however, both the original Spark RDD API, and the original Spark Streaming API appear to now be effectively in maintenance mode, DataFrames being the future across both, including for machine learning with &lt;a href=&quot;/technologies/apache-spark/mllib/&quot;&gt;MLLib&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Right - enough for next week. See you after the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/25/the-week-that-was/</guid> </item> <item><title>Structured Streaming</title><link>http://ondataengineering.net/technologies/apache-spark/structured-streaming/</link><pubDate>Fri, 25 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Extension to the Spark SQL DataFrame API to allow Spark SQL queries to be executed over streams of data, with the engine continuously updating and maintaining the result as new data arrives. Uses the full Spark SQL engine (including the Catalyst optimiser), and supports end-to-end exactly-once semantics via checkpointing when sources have sequential offsets. Supports aggregations over sliding event-time windows, including support for late data and watermarking. Introduced in Spark 2.0 with a production release in Spark 2.2.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&quot;&gt;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html&quot;&gt;https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html&lt;/a&gt; - intro blog post&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/structured-streaming/</guid> </item> <item><title>Zenko CloudServer</title><link>http://ondataengineering.net/technologies/zenko/cloudserver/</link><pubDate>Thu, 24 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Open source object storage server based on the S3 compatible API from Scality RING, with the ability to proxy requests to other S3 services (with support for Scality RING and Amazon S3), or to store data in persistent local storage or transient in-memory storage, with support for concurrent use of multiple backends. Supports broad compatibility with the Amazon S3 API including bucket and object versioning, and has been tested against a range of Amazon S3 utilities, CLIs and SDKs. Written in Node.js, available as a Docker container, and can be deployed and used independantly of the rest of Zenko. Metadata and (locally persisted) data is managed by a data and metadata daemon (dmd), with the option to use a shared remote daemon (for example when running a cluster of CloudServers). First released in June 2016 as S3 Server before becoming being renamed to CloudServer and becoming part of Zenko in July 2017. Hosted on GitHub under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;S3 Server, Scality S3 Server&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/cloudserver/&quot;&gt;http://www.zenko.io/cloudserver/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://s3-server.readthedocs.io/en/latest/&quot;&gt;http://s3-server.readthedocs.io/en/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3&quot;&gt;https://github.com/scality/S3&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/about-us/press/scality-announces-s3-server/&quot;&gt;http://www.scality.com/about-us/press/scality-announces-s3-server/&lt;/a&gt; - original press release&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/zenko/cloudserver/</guid> </item> <item><title>Zenko</title><link>http://ondataengineering.net/technologies/zenko/</link><pubDate>Thu, 24 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distributed and resilient Amazon S3 API compatible object storage gateway / proxy. Current scope is a Docker Swarm stack of a cluster of Zenko CloudServer (previously S3 Server) instances with nginx as a front end load balancer, which provide the S3 compatible API backed by Scality RING or Amazon S3, as well as persistent local storage or transient in-memory storage via a shared CloudServer data and metadata daemon. Roadmap includes support for Azure Blob Storage, support for other container management systems such as Kubernetes, plus two new sub-projects - Backbeat (which will provide policy-based data workflows such as replication or migration) and Clueso (which will provide object metadata search and analytics using Apache Spark). First released in July 2017, and hosted on GitHub under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Zenko Multi-Cloud Data Controller&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Zenko&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/zenko/cloudserver/&quot;&gt;Zenko CloudServer&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Open source object storage server based on the S3 compatible API from Scality RING, with the ability to proxy requests to other S3 services (with support for Scality RING and Amazon S3), or to store data in persistent local storage or transient in-memory storage, with support for concurrent use of multiple backends. Supports broad compatibility with the Amazon S3 API including bucket and object versioning, and has been tested against a range of Amazon S3 utilities, CLIs and SDKs. Written in Node.js, available as a Docker container, and can be deployed and used independantly of the rest of Zenko. Metadata and (locally persisted) data is managed by a data and metadata daemon (dmd), with the option to use a shared remote daemon (for example when running a cluster of CloudServers). First released in June 2016 as S3 Server before becoming being renamed to CloudServer and becoming part of Zenko in July 2017. Hosted on GitHub under an Apache 2.0 licence.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/&quot;&gt;http://www.zenko.io/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://zenko.readthedocs.io/en/latest/index.html&quot;&gt;http://zenko.readthedocs.io/en/latest/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/blog/zenko-rollout-plan/&quot;&gt;http://www.zenko.io/blog/zenko-rollout-plan/&lt;/a&gt; - Roadmap&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3&quot;&gt;https://github.com/scality/S3&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/products/zenko-multi-cloud-data-controller/&quot;&gt;http://www.scality.com/products/zenko-multi-cloud-data-controller/&lt;/a&gt; - Scality Zenko product page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/about-us/press/scality-zenko-multi-cloud-controller/&quot;&gt;http://www.scality.com/about-us/press/scality-zenko-multi-cloud-controller/&lt;/a&gt; - original press release&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/blog/&quot;&gt;http://www.zenko.io/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3/releases&quot;&gt;https://github.com/scality/S3/releases&lt;/a&gt; - release history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/zenko/</guid> </item> <item><title>REX-Ray</title><link>http://ondataengineering.net/technologies/rex-ray/</link><pubDate>Wed, 23 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Open source, storage management solution providing containers to access external storage systems outside of the container's host thus enabling stateful applications such as databases to be run inside containers. Allows applications to save data beyond the lifecycle of a container and provides high-availability features for container restarts across hosts. Operates as a command line interface and lightweight agent that can be integrated into container runtimes (e.g. Docker, Mesos) to provide storage functionality such as volume creation, attaching, and mounting processes as well as container orchestrators (e.g. Docker Swarm, Kubernetes, or Marathon for Mesos) to attach a volume to a new host and resume state in the event of a host failure. Built on top of the libStorage library (also from Dell EMC), provides a storage plugin framework that allows access to multiple storage providers and platforms (Amazon EBS, EFS, S3FS, Dell EMC ScaleIO, Isilon etc.) and a flexible architecture that allows it to be deployed in a standalone, decentralised fashion on each container host or as a centralised service for easier management at large scale. Written in Go, open sourced under the Apache 2.0 licence, hosted on GitHub, with development led by Dell EMC. Has not yet reached a v1.0 milestone, but is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Dell EMC&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;October 2017 - 0.10&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.10&lt;/td&gt; &lt;td&gt;2017-09-11&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://rexray.readthedocs.io/en/stable/about/release-notes/#version-0100-20170911&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://rexray.codedellemc.com/&quot;&gt;https://rexray.codedellemc.com/&lt;/a&gt; - Home&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://rexray.readthedocs.io/&quot;&gt;https://rexray.readthedocs.io/&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/codedellemc/rexray/&quot;&gt;https://github.com/codedellemc/rexray/&lt;/a&gt; - Code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/u/rexray/&quot;&gt;https://hub.docker.com/u/rexray/&lt;/a&gt; - Docker volume plugin for various storage providers&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/codedellemc/rexray/releases/&quot;&gt;https://github.com/codedellemc/rexray/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/rex-ray/</guid> </item> <item><title>The Mid Week News - 23/08/2017</title><link>http://ondataengineering.net/blog/2017/08/23/the-mid-week-news/</link><pubDate>Wed, 23 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;After last weeks monster update, it very slim pickings this week - two new technology releases and a couple of (semi) interesting blog posts… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; is prepping for it’s big 2.0 release, with a second alpha release of 2.0 announced this week. The HBase page includes a link to a presentation with more information on the 2.0 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt; has hit 0.13, with support for some new serivces and a bunch of improvements&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href=&quot;https://www.confluent.io/blog/leveraging-power-database-unbundled/&quot;&gt;latest&lt;/a&gt; post from Confluent in their series on how Kafka (and similar tools) can fundamentally re-shape the way you think about your architecture and the way you manage data. Well worth a read, and I’ve got a feeling we’ll be talking more about this in the future.&lt;/li&gt; &lt;li&gt;A post from Hortonworks on &lt;a href=&quot;https://hortonworks.com/blog/data-science-workbench-data-scientists-need-one/&quot;&gt;why you need a Data Science Workbench&lt;/a&gt;. There’s not a huge amount of content, and the phrasing echos Cloudera’s new product, so I’m wondering why they’ve pulished this…&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/23/the-mid-week-news/</guid> </item> <item><title>Apache Beam</title><link>http://ondataengineering.net/technologies/apache-beam/</link><pubDate>Tue, 22 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Unified batch and streaming programming model to define portable data processing pipelines and execute these using a range of different engines. Originating from the Google Dataflow model, focuses on unifying both styles of processing by treating static data sets as streams (which happen to have a beginning and an end), while achieving data correctness and the ability to handle late-arriving data through a set of abstractions and concepts that give users control over estimated quality of arrived data (completeness), duration to wait for results (latency) and how much speculative/redundant computation to do (cost). Allows business logic, data characteristics and trade-off strategies to be defined via different programming languages through pluggable language SDKs (with out of the box support for Java and Python). Supports a range of pluggable runtime platforms through pipeline runners, with support for a direct runner (for development and testing pipelines in a non-distributed environment), Apache Apex, Flink, Spark, and (under development) Gearpump runners, and a Google Cloud Dataflow runner. Also supports a growing set of connectors that allow pipelines to read and write data to various data storage systems (IOs). An Apache project, opened sourced by Google in January 2016, graduated in January 2017, with a first stable release (2.0) in May 2017. Written in Java and Python and under active development with a large number of contributors including Google, data Artisans, Talend and PayPal.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Beam&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - 2.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2.1&lt;/td&gt; &lt;td&gt;2017-08-23&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&amp;amp;version=12340528&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org&quot;&gt;https://beam.apache.org&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/documentation/&quot;&gt;https://beam.apache.org/documentation/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/documentation/runners/capability-matrix/&quot;&gt;https://beam.apache.org/documentation/runners/capability-matrix/&lt;/a&gt; - defines capabilities of individual runners&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/blog/big-data/2016/05/why-apache-beam-a-google-perspective&quot;&gt;https://cloud.google.com/blog/big-data/2016/05/why-apache-beam-a-google-perspective&lt;/a&gt; - motivation behind Beam&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/blog/&quot;&gt;https://beam.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/get-started/downloads/&quot;&gt;https://beam.apache.org/get-started/downloads/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-beam/</guid> </item> <item><title>Apache Kylin</title><link>http://ondataengineering.net/technologies/apache-kylin/</link><pubDate>Mon, 21 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;An open source distributed analytic engine built to support sub-second OLAP / star schema style queries using SQL on extremely large datasets on Hadoop. Data is read from a star schema data model in Hive to build a data cube of pre-calculated metrics by dimensions using MapReduce with the results stored in a key-value datastore (HBase). SQL queries can be submitted to the query engine, with results returned with sub-second latency if the required data exists in an HBase cube, otherwise the query is optionally routed back to its original source on Hadoop. Supports compression of large datasets by dictionary encoding cube data using a triple data structure, combination pruning and aggregation grouping of dimensions for efficient data storage, and uses approximation query capability (HyperLogLog) to estimate distinct items and TopN to answer top-k queries. Row keys are composed by dimension encoded values and HBase's fuzzy row filtering is performed directly on the storage nodes to implement low latency lookups. Simple additive and aggregation operations (sum, count or like) are also performed on the storage nodes using HBase coprocessors to provide efficient computational parallelism and minimise network latency. Uses Apache Calcite for SQL parsing and optimisation, comes with an ODBC driver, a JDBC driver and a REST API to integrate with third party business intelligence tools such as Tableau, Microsoft Excel and PowerBI. Includes a web interface and REST API for model building and cube design (with support for hierarchy, joint and derived dimensions), job management (full, incremental and streaming builds) and monitoring and permission management (providing security at a project or cube level). New beta features include building cubes from Kafka streaming data and cube building using Spark instead of MapReduce. Originally developed at Ebay, donated to the Apache Foundation in November 2014, graduating in November 2015, with a 1.0 release in September 2015, and still under active development. Commercial support available from Kyligence, who distribute their own product based on Kylin replacing HBase with a custom columnar storage engine (with cell level access control and integration with LDAP), along with a web based BI tool for self service analysis and a dashboard for Kylin cluster management.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kylin&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Kyligence&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - 2.1.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org&quot;&gt;http://kylin.apache.org&lt;/a&gt; - Kylin homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/docs20&quot;&gt;http://kylin.apache.org/docs20&lt;/a&gt; - Kylin documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.ebaytechblog.com/2014/10/20/announcing-kylin-extreme-olap-engine-for-big-data&quot;&gt;http://www.ebaytechblog.com/2014/10/20/announcing-kylin-extreme-olap-engine-for-big-data&lt;/a&gt; - open source announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kyligence.io/products&quot;&gt;http://kyligence.io/products&lt;/a&gt; - Kylience Analytics Platform&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://manual.kyligence.io/v2.4/en&quot;&gt;http://manual.kyligence.io/v2.4/en&lt;/a&gt; - Kylience Analytics Platform documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/blog&quot;&gt;http://kylin.apache.org/blog&lt;/a&gt; - Kylin blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/download/&quot;&gt;http://kylin.apache.org/download/&lt;/a&gt; - list of recent versions&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kylin/</guid> </item> <item><title>The Plan For This Week - 21/08/2017</title><link>http://ondataengineering.net/blog/2017/08/21/the-plan-for-this-week/</link><pubDate>Mon, 21 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Something slightly different this week - I’ve got a bunch of technology summaries to put live, most of them from Jeff Moszuti (who contributed all the recent Mesos stuff), so we’re going to do a random week. Five technology summaries, with no relationship to each other and no overlying theme.&lt;/p&gt; &lt;p&gt;See you on Friday for the wrap-up…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/21/the-plan-for-this-week/</guid> </item> <item><title>The Apache Big Data Project List</title><link>http://ondataengineering.net/blog/2017/08/18/the-apache-big-data-project-list/</link><pubDate>Fri, 18 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;It’s a day late, but the new and refreshed list of Apache technologies that I think are of interest to us is now live on the &lt;a href=&quot;/tech-vendors/apache/&quot;&gt;Apache Foundation&lt;/a&gt; vendor page. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;There’s 98 technologies in total, which talks to the breadth of projects that the Apache Foundation now supports, and the range of (just one small slice of) technology options in the space we’re looking at. And just for reference, we have technology summaries and technology pages for 53 (at the time of writing) of these technologies if you want more information on them.&lt;/p&gt; &lt;p&gt;I’ve split the technologies up into some very broad categories, but I’m looking to refine these as we continue our journey through the technology categories that I think are of interest to us. If you’re reading this in the future, the categories on the Apache technologies page should link to technology category pages that provide an insight into available technologies across the open source and commercial space.&lt;/p&gt; &lt;p&gt;I think that’s probably all for this week - see you after the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/18/the-apache-big-data-project-list/</guid> </item> </channel> </rss>
