<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>The Plan For This Week - 29/08/2017</title><link>http://ondataengineering.net/blog/2017/08/29/the-plan-for-this-week/</link><pubDate>Tue, 29 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Yes - it’s a Tuesday and not a Monday. Apologies, forgot to say on Friday that it was a public holiday in the UK this Monday, and therefore they’d be no update. I hope you’ll forgive me.&lt;/p&gt; &lt;p&gt;So, a shorter week this week. The plan is to look at event series databases, both for analysing external event data, but also as a capability for analysing event logs and metrics that our analytical systems may generate.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/29/the-plan-for-this-week/</guid> </item> <item><title>The Week That Was - 25/08/2017</title><link>http://ondataengineering.net/blog/2017/08/25/the-week-that-was/</link><pubDate>Fri, 25 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;So, a bit of a mixed bag this week, but what did we look at.&lt;/p&gt; &lt;p&gt;We started with three technologies summaries from Jeff Moszuti, looking at &lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; and &lt;a href=&quot;/technologies/rex-ray/&quot;&gt;Dell EMC REX-Ray&lt;/a&gt;. We then finished up the week by looking at &lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt;. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;We last looked at OLAP cube technologies with &lt;a href=&quot;/technologies/druid&quot;&gt;Druid&lt;/a&gt;, which like &lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt; is tightly integrated with the Hadoop ecosystem. Unlike Druid however, Kylin doesn’t introduce new data storage, instead leveraging Hive and HBase, which potentially makes it more palatable if you don’t want more data management engines running on your cluster. What it lacks however is Druid’s support for combining streaming and batch data. And Kylin is an Apache project (if that’s important to you), however given Hortonwork’s recent commitment to Druid, it wouldn’t surprise me if Druid was heading that way as well.&lt;/p&gt; &lt;p&gt;I have to say I’m a little conflicted around &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt;. It aims to introduce a standard model for batch and stream processing that a range of different technologies can then support. The model feels ok, certainly Data Artisans liked it enough to completely rework the Flink API to be more aligned (&lt;a href=&quot;https://data-artisans.com/blog/why-apache-beam&quot;&gt;details here&lt;/a&gt;), but I’m struggling to see the value. I have to admin to be slightly biased against abstractions like these - my feeling is that they’re great in concept, however there’s always a cost associated with an abstraction layer, either in not being able to achieve something easily because you’re fighting the abstraction, or in performance overheads from the translations involved, and switching between back end runners will never be as easy as you hope. And does anyone really care about being able to take batch/streaming code and easily migrate it between different back end execution engines? I can see what’s in it for Google - having Google Cloud Dataflow being the de-facto runner for running Beam code in the cloud puts them in a good position. Perhaps I’m just being cynical.&lt;/p&gt; &lt;p&gt;I’ve not much to say about &lt;a href=&quot;/technologies/rex-ray/&quot;&gt;Dell EMC REX-Ray&lt;/a&gt;, but hopefully we’ll look more at containerisation technologies and how they support persistent storage and how you might use them for analytics at some point in the future.&lt;/p&gt; &lt;p&gt;We looked at Scality’s open sourced S3 Server back when we were looking at &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;object store&lt;/a&gt;. Just as a reminder, it was a Node based single process (i.e. not clustered or distributed) S3 compatible object store service, that could either proxy requests onto &lt;a href=&quot;/technologies/scality-ring/&quot;&gt;Scality Ring&lt;/a&gt; or &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;Amazon S3&lt;/a&gt;, or could serve them from local or in memory storage. Useful for development and test, but probably not anything significant in production. It seems like it was pretty successful (they keep banging on about how it was downloaded over 600,000 times), and they’re therefore trying to make something more significant of it.&lt;/p&gt; &lt;p&gt;The result is that they’ve renamed S3 Server into &lt;a href=&quot;/technologies/zenko/cloudserver/&quot;&gt;Zenko Cloudserver&lt;/a&gt;, and made it part of a new much larger open source project called &lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;. At the moment all Zenko does is provide a Docker Swarm stack definition that allows multiple Cloudservers to be clustered behind a load balancer, but what they have planned is more interesting. First up is support for more backend services, including Azure Blob Storage and potentially Google Storage, also support for other container management systems such as Kubernetes, and then new new sub-projects - Backbeat (which will provide policy-based data workflows such as replication or migration) and Clueso (which will provide object metadata search and analytics using Apache Spark). The aim is to provide a gateway into multiple back end object stores with federation capabilities over the top. Sounds like a nice idea, and probably one to track.&lt;/p&gt; &lt;p&gt;And finally, I’ve refreshed all our &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; technology summaries (including all the sub-projects) to make sure they’re up to date (which is odd given there’s only been one point release since they were written). The big bit that was missing was information on &lt;a href=&quot;/technologies/apache-spark/structured-streaming/&quot;&gt;Spark Structured Streaming&lt;/a&gt;, which provides the ability to run a DataFrame or SQL query over streaming data (using the standard &lt;a href=&quot;/technologies/apache-spark/spark-sql/&quot;&gt;Spark SQL&lt;/a&gt; APIs), and have the result calculated and then updated/maintained as new data comes in. The result being that I think it’s probably time we took a deeper look into streaming technologies and understood the differences. It does feel like Spark is moving forward at a pace however, both the original Spark RDD API, and the original Spark Streaming API appear to now be effectively in maintenance mode, DataFrames being the future across both, including for machine learning with &lt;a href=&quot;/technologies/apache-spark/mllib/&quot;&gt;MLLib&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Right - enough for next week. See you after the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/25/the-week-that-was/</guid> </item> <item><title>Structured Streaming</title><link>http://ondataengineering.net/technologies/apache-spark/structured-streaming/</link><pubDate>Fri, 25 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Extension to the Spark SQL DataFrame API to allow Spark SQL queries to be executed over streams of data, with the engine continuously updating and maintaining the result as new data arrives. Uses the full Spark SQL engine (including the Catalyst optimiser), and supports end-to-end exactly-once semantics via checkpointing when sources have sequential offsets. Supports aggregations over sliding event-time windows, including support for late data and watermarking. Introduced in Spark 2.0 with a production release in Sprint 2.2.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&quot;&gt;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html&quot;&gt;https://databricks.com/blog/2016/07/28/structured-streaming-in-apache-spark.html&lt;/a&gt; - intro blog post&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-spark/structured-streaming/</guid> </item> <item><title>Zenko CloudServer</title><link>http://ondataengineering.net/technologies/zenko/cloudserver/</link><pubDate>Thu, 24 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Open source object storage server based on the S3 compatible API from Scality RING, with the ability to proxy requests to other S3 services (with support for Scality RING and Amazon S3), or to store data in persistent local storage or transient in-memory storage, with support for concurrent use of multiple backends. Supports broad compatibility with the Amazon S3 API including bucket and object versioning, and has been tested against a range of Amazon S3 utilities, CLIs and SDKs. Written in Node.js, available as a Docker container, and can be deployed and used independantly of the rest of Zenko. Metadata and (locally persisted) data is managed by a data and metadata daemon (dmd), with the option to use a shared remote daemon (for example when running a cluster of CloudServers). First released in June 2016 as S3 Server before becoming being renamed to CloudServer and becoming part of Zenko in July 2017. Hosted on GitHub under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;S3 Server, Scality S3 Server&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/cloudserver/&quot;&gt;http://www.zenko.io/cloudserver/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://s3-server.readthedocs.io/en/latest/&quot;&gt;http://s3-server.readthedocs.io/en/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3&quot;&gt;https://github.com/scality/S3&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/about-us/press/scality-announces-s3-server/&quot;&gt;http://www.scality.com/about-us/press/scality-announces-s3-server/&lt;/a&gt; - original press release&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/zenko/cloudserver/</guid> </item> <item><title>Zenko</title><link>http://ondataengineering.net/technologies/zenko/</link><pubDate>Thu, 24 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distributed and resilient Amazon S3 API compatible object storage gateway / proxy. Current scope is a Docker Swarm stack of a cluster of Zenko CloudServer (previously S3 Server) instances with nginx as a front end load balancer, which provide the S3 compatible API backed by Scality RING or Amazon S3, as well as persistent local storage or transient in-memory storage via a shared CloudServer data and metadata daemon. Roadmap includes support for Azure Blob Storage, support for other container management systems such as Kubernetes, plus two new sub-projects - Backbeat (which will provide policy-based data workflows such as replication or migration) and Clueso (which will provide object metadata search and analytics using Apache Spark). First released in July 2017, and hosted on GitHub under an Apache 2.0 licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Zenko Multi-Cloud Data Controller&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Sub-projects&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; Zenko&amp;nbsp;&gt;&amp;nbsp; &lt;a href=&quot;http://ondataengineering.net/technologies/zenko/cloudserver/&quot;&gt;Zenko CloudServer&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Open source object storage server based on the S3 compatible API from Scality RING, with the ability to proxy requests to other S3 services (with support for Scality RING and Amazon S3), or to store data in persistent local storage or transient in-memory storage, with support for concurrent use of multiple backends. Supports broad compatibility with the Amazon S3 API including bucket and object versioning, and has been tested against a range of Amazon S3 utilities, CLIs and SDKs. Written in Node.js, available as a Docker container, and can be deployed and used independantly of the rest of Zenko. Metadata and (locally persisted) data is managed by a data and metadata daemon (dmd), with the option to use a shared remote daemon (for example when running a cluster of CloudServers). First released in June 2016 as S3 Server before becoming being renamed to CloudServer and becoming part of Zenko in July 2017. Hosted on GitHub under an Apache 2.0 licence.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/&quot;&gt;http://www.zenko.io/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://zenko.readthedocs.io/en/latest/index.html&quot;&gt;http://zenko.readthedocs.io/en/latest/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/blog/zenko-rollout-plan/&quot;&gt;http://www.zenko.io/blog/zenko-rollout-plan/&lt;/a&gt; - Roadmap&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3&quot;&gt;https://github.com/scality/S3&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/products/zenko-multi-cloud-data-controller/&quot;&gt;http://www.scality.com/products/zenko-multi-cloud-data-controller/&lt;/a&gt; - Scality Zenko product page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.scality.com/about-us/press/scality-zenko-multi-cloud-controller/&quot;&gt;http://www.scality.com/about-us/press/scality-zenko-multi-cloud-controller/&lt;/a&gt; - original press release&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zenko.io/blog/&quot;&gt;http://www.zenko.io/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/scality/S3/releases&quot;&gt;https://github.com/scality/S3/releases&lt;/a&gt; - release history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/zenko/</guid> </item> <item><title>REX-Ray</title><link>http://ondataengineering.net/technologies/rex-ray/</link><pubDate>Wed, 23 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Open source, storage management solution providing containers to access external storage systems outside of the container's host thus enabling stateful applications such as databases to be run inside containers. Allows applications to save data beyond the lifecycle of a container and provides high-availability features for container restarts across hosts. Operates as a command line interface and lightweight agent that can be integrated into container runtimes (e.g. Docker, Mesos) to provide storage functionality such as volume creation, attaching, and mounting processes as well as container orchestrators (e.g. Docker Swarm, Kubernetes, or Marathon for Mesos) to attach a volume to a new host and resume state in the event of a host failure. Built on top of the libStorage library (also from Dell EMC), provides a storage plugin framework that allows access to multiple storage providers and platforms (Amazon EBS, EFS, S3FS, Dell EMC ScaleIO, Isilon etc.) and a flexible architecture that allows it to be deployed in a standalone, decentralised fashion on each container host or as a centralised service for easier management at large scale. Written in Go, open sourced under the Apache 2.0 licence, hosted on GitHub, with development led by Dell EMC. Has not yet reached a v1.0 milestone, but is still under active development.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Dell EMC&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - 0.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://rexray.codedellemc.com/&quot;&gt;https://rexray.codedellemc.com/&lt;/a&gt; - Home&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://rexray.readthedocs.io/&quot;&gt;https://rexray.readthedocs.io/&lt;/a&gt; - Documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/codedellemc/rexray/&quot;&gt;https://github.com/codedellemc/rexray/&lt;/a&gt; - Code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/u/rexray/&quot;&gt;https://hub.docker.com/u/rexray/&lt;/a&gt; - Docker volume plugin for various storage providers&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/codedellemc/rexray/releases/&quot;&gt;https://github.com/codedellemc/rexray/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/rex-ray/</guid> </item> <item><title>The Mid Week News - 23/08/2017</title><link>http://ondataengineering.net/blog/2017/08/23/the-mid-week-news/</link><pubDate>Wed, 23 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;After last weeks monster update, it very slim pickings this week - two new technology releases and a couple of (semi) interesting blog posts… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; is prepping for it’s big 2.0 release, with a second alpha release of 2.0 announced this week. The HBase page includes a link to a presentation with more information on the 2.0 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt; has hit 0.13, with support for some new serivces and a bunch of improvements&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href=&quot;https://www.confluent.io/blog/leveraging-power-database-unbundled/&quot;&gt;latest&lt;/a&gt; post from Confluent in their series on how Kafka (and similar tools) can fundamentally re-shape the way you think about your architecture and the way you manage data. Well worth a read, and I’ve got a feeling we’ll be talking more about this in the future.&lt;/li&gt; &lt;li&gt;A post from Hortonworks on &lt;a href=&quot;https://hortonworks.com/blog/data-science-workbench-data-scientists-need-one/&quot;&gt;why you need a Data Science Workbench&lt;/a&gt;. There’s not a huge amount of content, and the phrasing echos Cloudera’s new product, so I’m wondering why they’ve pulished this…&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/23/the-mid-week-news/</guid> </item> <item><title>Apache Beam</title><link>http://ondataengineering.net/technologies/apache-beam/</link><pubDate>Tue, 22 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Unified batch and streaming programming model to define portable data processing pipelines and execute these using a range of different engines. Originating from the Google Dataflow model, focuses on unifying both styles of processing by treating static data sets as streams (which happen to have a beginning and an end), while achieving data correctness and the ability to handle late-arriving data through a set of abstractions and concepts that give users control over estimated quality of arrived data (completeness), duration to wait for results (latency) and how much speculative/redundant computation to do (cost). Allows business logic, data characteristics and trade-off strategies to be defined via different programming languages through pluggable language SDKs (with out of the box support for Java and Python). Supports a range of pluggable runtime platforms through pipeline runners, with support for a direct runner (for development and testing pipelines in a non-distributed environment), Apache Apex, Flink, Spark, and (under development) Gearpump runners, and a Google Cloud Dataflow runner. Also supports a growing set of connectors that allow pipelines to read and write data to various data storage systems (IOs). An Apache project, opened sourced by Google in January 2016, graduated in January 2017, with a first stable release (2.0) in May 2017. Written in Java and Python and under active development with a large number of contributors including Google, data Artisans, Talend and PayPal.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Beam&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - 2.0.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org&quot;&gt;https://beam.apache.org&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/documentation/&quot;&gt;https://beam.apache.org/documentation/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/documentation/runners/capability-matrix/&quot;&gt;https://beam.apache.org/documentation/runners/capability-matrix/&lt;/a&gt; - defines capabilities of individual runners&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/blog/&quot;&gt;https://beam.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://beam.apache.org/get-started/downloads/&quot;&gt;https://beam.apache.org/get-started/downloads/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-beam/</guid> </item> <item><title>Apache Kylin</title><link>http://ondataengineering.net/technologies/apache-kylin/</link><pubDate>Mon, 21 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;An open source distributed analytic engine built to support sub-second OLAP / star schema style queries using SQL on extremely large datasets on Hadoop. Data is read from a star schema data model in Hive to build a data cube of pre-calculated metrics by dimensions using MapReduce with the results stored in a key-value datastore (HBase). SQL queries can be submitted to the query engine, with results returned with sub-second latency if the required data exists in an HBase cube, otherwise the query is optionally routed back to its original source on Hadoop. Supports compression of large datasets by dictionary encoding cube data using a triple data structure, combination pruning and aggregation grouping of dimensions for efficient data storage, and uses approximation query capability (HyperLogLog) to estimate distinct items and TopN to answer top-k queries. Row keys are composed by dimension encoded values and HBase's fuzzy row filtering is performed directly on the storage nodes to implement low latency lookups. Simple additive and aggregation operations (sum, count or like) are also performed on the storage nodes using HBase coprocessors to provide efficient computational parallelism and minimise network latency. Uses Apache Calcite for SQL parsing and optimisation, comes with an ODBC driver, a JDBC driver and a REST API to integrate with third party business intelligence tools such as Tableau, Microsoft Excel and PowerBI. Includes a web interface and REST API for model building and cube design (with support for hierarchy, joint and derived dimensions), job management (full, incremental and streaming builds) and monitoring and permission management (providing security at a project or cube level). New beta features include building cubes from Kafka streaming data and cube building using Spark instead of MapReduce. Originally developed at Ebay, donated to the Apache Foundation in November 2014, graduating in November 2015, with a 1.0 release in September 2015, and still under active development. Commercial support available from Kyligence, who distribute their own product based on Kylin replacing HBase with a custom columnar storage engine (with cell level access control and integration with LDAP), along with a web based BI tool for self service analysis and a dashboard for Kylin cluster management.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Kylin&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, Kyligence&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - 2.1.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org&quot;&gt;http://kylin.apache.org&lt;/a&gt; - Kylin homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/docs20&quot;&gt;http://kylin.apache.org/docs20&lt;/a&gt; - Kylin documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.ebaytechblog.com/2014/10/20/announcing-kylin-extreme-olap-engine-for-big-data&quot;&gt;http://www.ebaytechblog.com/2014/10/20/announcing-kylin-extreme-olap-engine-for-big-data&lt;/a&gt; - open source announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kyligence.io/products&quot;&gt;http://kyligence.io/products&lt;/a&gt; - Kylience Analytics Platform&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://manual.kyligence.io/v2.4/en&quot;&gt;http://manual.kyligence.io/v2.4/en&lt;/a&gt; - Kylience Analytics Platform documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/blog&quot;&gt;http://kylin.apache.org/blog&lt;/a&gt; - Kylin blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://kylin.apache.org/download/&quot;&gt;http://kylin.apache.org/download/&lt;/a&gt; - list of recent versions&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-kylin/</guid> </item> <item><title>The Plan For This Week - 21/08/2017</title><link>http://ondataengineering.net/blog/2017/08/21/the-plan-for-this-week/</link><pubDate>Mon, 21 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Something slightly different this week - I’ve got a bunch of technology summaries to put live, most of them from Jeff Moszuti (who contributed all the recent Mesos stuff), so we’re going to do a random week. Five technology summaries, with no relationship to each other and no overlying theme.&lt;/p&gt; &lt;p&gt;See you on Friday for the wrap-up…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/21/the-plan-for-this-week/</guid> </item> <item><title>The Apache Big Data Project List</title><link>http://ondataengineering.net/blog/2017/08/18/the-apache-big-data-project-list/</link><pubDate>Fri, 18 Aug 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;It’s a day late, but the new and refreshed list of Apache technologies that I think are of interest to us is now live on the &lt;a href=&quot;/tech-vendors/apache/&quot;&gt;Apache Foundation&lt;/a&gt; vendor page. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;There’s 98 technologies in total, which talks to the breadth of projects that the Apache Foundation now supports, and the range of (just one small slice of) technology options in the space we’re looking at. And just for reference, we have technology summaries and technology pages for 53 (at the time of writing) of these technologies if you want more information on them.&lt;/p&gt; &lt;p&gt;I’ve split the technologies up into some very broad categories, but I’m looking to refine these as we continue our journey through the technology categories that I think are of interest to us. If you’re reading this in the future, the categories on the Apache technologies page should link to technology category pages that provide an insight into available technologies across the open source and commercial space.&lt;/p&gt; &lt;p&gt;I think that’s probably all for this week - see you after the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/18/the-apache-big-data-project-list/</guid> </item> <item><title>The Apache Software Foundation</title><link>http://ondataengineering.net/tech-vendors/apache/</link><pubDate>Fri, 18 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;The Apache Software Foundation is a non-profit organisation that supports a wide range of open source projects, including providing and mandating a standard governance model (including the use of the Apache license), holding all trademarks for project names and logos, and providing legal protection to developers. It was founded in 1999 and now oversees nearly 200 projects.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Vendor Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Apache&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;analytical-query-capabilities&quot;&gt;Analytical Query Capabilities&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;HAWQ (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A port of the Greenplum MPP database (which itself is based on PostgreSQL) to run over YARN and HDFS.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-tajo/&quot;&gt;Tajo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Distributed analytical database engine supporting queries over data in HDFS, Amazon S3, Google Cloud Storage, OpenStack Swift and local storage, and querying over Postgres, HBase and Hive tables.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Kudu&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Columnar storage technology for tables of structured data, supporting low latency reads, updates and deletes by primary key, as well as analytical column/table scans.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Quickstep (Incubating)&lt;/td&gt; &lt;td&gt;High performance database engine supporting SQL queries based on a University of Wisconsin-Madison project - &lt;a href=&quot;http://quickstep.apache.org/&quot;&gt;http://quickstep.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Supports the execution of SQL queries over data in HDFS using MapReduce, Spark or Tez based on tables defined in the Hive Metastore&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-pig/&quot;&gt;Pig&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for running analytical and data processing jobs written in Pig Latin against data in Hadoop using MapReduce, Tez and Spark&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MRQL (Incubating)&lt;/td&gt; &lt;td&gt;Supports the execution of MRQL queries over data in Hadoop using MapReduce, Hama, Spark or Flink - &lt;a href=&quot;http://mrql.apache.org/&quot;&gt;http://mrql.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Impala (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Drill&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An MPP query engine that supports queries over one or more underlying databases or datasets without first defining a schema and with the ability to join data from multiple datastores together.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Lens&lt;/td&gt; &lt;td&gt;Provides a federated view over multiple data stores using a single shared schema server based on the Hive Metastore - &lt;a href=&quot;http://lens.apache.org/&quot;&gt;http://lens.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Kylin&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Supports the creation and querying of OLAP cubes on Hadoop, building cubes from star schema data in Hive into HBase, and then providing a SQL interface that queries across Hive and HBase as required - &lt;a href=&quot;http://kylin.apache.org/ &quot;&gt;http://kylin.apache.org/ &lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;analytical-search-capabilities&quot;&gt;Analytical Search Capabilities&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Solr&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A search server built on Apache Lucene with a REST-like API for loading and searching data.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;compute-cluster-management&quot;&gt;Compute Cluster Management&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;Hadoop/YARN&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Resource management and job scheduling &amp;amp; monitoring for the Hadoop ecosystem.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Mesos&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Resource management over large clusters of machines&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-myriad/&quot;&gt;Myriad (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Tool that allows YARN applications to run over Apache Mesos, allowing them to co-exist and share cluster resources.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Slider (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Application for deploying long running cluster applications on YARN, now effectively dead following the plan to add support for long running services directly into YARN&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Twill&lt;/td&gt; &lt;td&gt;Abstraction over YARN that reduces the complexity of developing distributed applications - &lt;a href=&quot;http://twill.apache.org/&quot;&gt;http://twill.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-aurora/&quot;&gt;Aurora&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Mesos framework for long-running services and cron jobs - &lt;aurora.apache.org&gt;&lt;/aurora.apache.org&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Helix&lt;/td&gt; &lt;td&gt;A framework for building long lived persistent distributed systems - &lt;a href=&quot;http://helix.apache.org/&quot;&gt;http://helix.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;REEF&lt;/td&gt; &lt;td&gt;A framework for developing distributed apps on top of cluster frameworks such as YARN or Mesos - &lt;a href=&quot;http://reef.apache.org/&quot;&gt;http://reef.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-formats&quot;&gt;Data Formats&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-avro/&quot;&gt;Avro&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Data serialisation framework that supports both messaging and data storage, primarily using a compact binary format but also supports a JSON format.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Parquet&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Data serialisation framework that supports a columnar storage format to enable efficient querying of data.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Arrow&lt;/td&gt; &lt;td&gt;In-memory columnar data serialisation framework - &lt;a href=&quot;http://arrow.apache.org/&quot;&gt;http://arrow.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CarbonData&lt;/td&gt; &lt;td&gt;Data serialisation framework that supports an indexed columnar storage format - &lt;a href=&quot;http://carbondata.apache.org/&quot;&gt;http://carbondata.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ORC&lt;/td&gt; &lt;td&gt;Data serialisation framework that supports a columnar storage format to enable efficient querying of data - &lt;a href=&quot;https://orc.apache.org/&quot;&gt;https://orc.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-movement&quot;&gt;Data Movement&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Flume&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Specialist technology for the continuous movement of data using a set of independent agents connected together into pipelines.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Nifi&lt;/a&gt;&lt;/td&gt; &lt;td&gt;General purpose technology for the movement of data between systems, including the ingestion of data into an analytical platform.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Sqoop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Specialist technology for moving bulk data between Hadoop and structured (relational) databases.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ManifoldCF&lt;/td&gt; &lt;td&gt;Framework for replicating data from content repositories to analytical search technologies - &lt;a href=&quot;http://manifoldcf.apache.org/&quot;&gt;http://manifoldcf.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-processing&quot;&gt;Data Processing&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/mapreduce/&quot;&gt;Hadoop/MapReduce&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A data transformation and aggregation technology proven at extreme scale that works on key value pairs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Spark&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A high performance general purpose distributed data processing engine based on directed acyclic graphs that primarily runs in memory, but can spill to disk if required&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-tez/&quot;&gt;Tez&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Data processing framework based on Directed Acyclic Graphs (DAGs), that runs natively on YARN and was designed to be a replacement for the use of MapReduce within Hadoop analytical tools&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gobblin (Incubating)&lt;/td&gt; &lt;td&gt;Framework for managing big data integration, including replication, organization and lifecycle management - &lt;a href=&quot;http://gobblin.apache.org/&quot;&gt;http://gobblin.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-crunch/&quot;&gt;Crunch&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An abstraction layer over MapReduce (and now Spark) that provides a high level Java API for creating data transformation pipelines&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;graph-technologies&quot;&gt;Graph Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-giraph/&quot;&gt;Giraph&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An iterative, highly scalable graph processing system built on top of MapReduce and based on Pregel&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hama/&quot;&gt;Hama&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A general purpose BSP (Bulk Synchronous Parallel) processing engine inspired by Pregel and DistBelief that runs over Mesos or YARN.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Commons RDF (0)&lt;/td&gt; &lt;td&gt;Commons library for working with RDF data - &amp;lt;commons.apache.org/proper/commons-rdf/&amp;gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jena&lt;/td&gt; &lt;td&gt;Framework for developing Semantic Web and Linked Data applications in Java - &lt;a href=&quot;http://jena.apache.org/&quot;&gt;http://jena.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Rya (Incubating)&lt;/td&gt; &lt;td&gt;RDF triple store built on Apache Accumulo - &lt;a href=&quot;http://rya.apache.org/&quot;&gt;http://rya.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;S2Graph (Incubating)&lt;/td&gt; &lt;td&gt;OLTP graph database built on Apache HBase - &lt;a href=&quot;https://s2graph.incubator.apache.org/&quot;&gt;https://s2graph.incubator.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;TinkerPop&lt;/td&gt; &lt;td&gt;Graph compute framework for transactional and analytical use cases that’s integrated with a number of graph database technologies - &lt;a href=&quot;http://tinkerpop.apache.org&quot;&gt;http://tinkerpop.apache.org&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/graphx/&quot;&gt;Spark/GraphX&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Spark library for processing graphs and running graph algorithms&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;hadoop-and-related-technologies&quot;&gt;Hadoop and Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distributed storage and compute platform consisting of a distributed filesystem (HDFS), a cluster resource management layer (YARN), and MapReduce, a solution built on HDFS and YARN for massive scale parallel processing of data&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Bigtop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Apache open source distribution of Hadoop&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Ambari&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Platform for installing, managing and monitoring Apache Hadoop clusters&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Atlas&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A metadata and data governance solution for Hadoop.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Knox&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A stateless gateway for the Apache Hadoop ecosystem that provides perimeter security&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Ranger&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A centralised security framework for managing access to data in Hadoop&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sentry/&quot;&gt;Sentry&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A centralised security framework for managing access to data in Hadoop&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Eagle&lt;/td&gt; &lt;td&gt;Security and performance monitoring solution for Hadoop, donated by eBay - &lt;a href=&quot;http://eagle.apache.org/&quot;&gt;http://eagle.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-falcon/&quot;&gt;Falcon&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Data feed management system for Hadoop, although no longer appears under development and is deprecated from HDP.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;in-memory-technologies&quot;&gt;In Memory Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Ignite&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distributed in-memory data fabric/grid, supporting a range of different use cases and capabilities&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Geode&lt;/td&gt; &lt;td&gt;In memory data management platform, born of Pivotal Gemfire - &lt;a href=&quot;http://geode.apache.org/&quot;&gt;http://geode.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Mnemonic (Incubating)&lt;/td&gt; &lt;td&gt;Hybrid memory / storage object model framework - &lt;a href=&quot;http://mnemonic.apache.org/&quot;&gt;http://mnemonic.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;machine-learning-technologies&quot;&gt;Machine Learning Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/mllib/&quot;&gt;Spark/MLLib&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Spark library for running Machine Learning algorithms&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mahout/&quot;&gt;Mahout&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Machine learning technology comprising of a Scala based linear algebra engine (codenamed Samsara) with an R-like DSL/API that runs over Spark (with experimental support for H2O and Flink)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MADlib&lt;/td&gt; &lt;td&gt;Machine learning in SQL for PostgreSQL, Greenplum and Apache HAWQ - &lt;a href=&quot;http://madlib.apache.org/&quot;&gt;http://madlib.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OpenNLP&lt;/td&gt; &lt;td&gt;Machine learning based toolkit for the processing of natural language text - &lt;a href=&quot;http://opennlp.apache.org/&quot;&gt;http://opennlp.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SAMOA (Incubating)&lt;/td&gt; &lt;td&gt;Machine learning framework that runs over multiple stream processing engines including Storm, Flink and Samza - &lt;a href=&quot;http://samoa.apache.org/&quot;&gt;http://samoa.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SINGA (Incubating)&lt;/td&gt; &lt;td&gt;Framework for developing machine learning libraries over a range of hardware - &lt;a href=&quot;https://singa.apache.org/&quot;&gt;https://singa.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SystemML&lt;/td&gt; &lt;td&gt;Delarative machine learning over local, Spark or MapReduce execution engines - &lt;a href=&quot;http://systemml.apache.org/&quot;&gt;http://systemml.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;nosql-wide-column-stores&quot;&gt;NoSQL Wide Column Stores&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Accumulo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;NoSQL wide-column datastore based on Google BigTable that runs on Hadoop and HDFS&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-cassandra/&quot;&gt;Cassandra&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Distributed wide-column datastore based on Amazon Dynamo and Google BigTable&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;HBase&lt;/a&gt;&lt;/td&gt; &lt;td&gt;NoSQL wide-column datastore based on Google BigTable that runs on Hadoop and HDFS&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Fluo&lt;/td&gt; &lt;td&gt;Implementation of Google Percolator for maintaining aggregations in Accumulo - &lt;a href=&quot;https://fluo.apache.org/&quot;&gt;https://fluo.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Omid (Incubating)&lt;/td&gt; &lt;td&gt;ACID transaction support over MVCC key/value NoSQL datastores with support for Apache Hbase - &lt;a href=&quot;http://omid.apache.org/&quot;&gt;http://omid.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Tephra (Incubating)&lt;/td&gt; &lt;td&gt;ACID transaction support over Apache Hbase, used by Tigon and Apache Phoenix - &lt;a href=&quot;http://tephra.apache.org/&quot;&gt;http://tephra.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;oltp-databases&quot;&gt;OLTP Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Phoenix&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An OLTP SQL query engine over Apache HBase tables that supports a subset of SQL 92 (including joins), and comes with a JDBC driver.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Trafodion (Incubating)&lt;/td&gt; &lt;td&gt;OLTP on Hadoop solution based on Tandom NoStop database IP with commercial support from Esgyn - &lt;a href=&quot;https://trafodion.incubator.apache.org/&quot;&gt;https://trafodion.incubator.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-analytics&quot;&gt;Streaming Analytics&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Storm&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Specialised distributed stream processing technology based on a single record (not micro batch) model with at least once processing semantics.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Flink&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Specialised stream processing technology inspired by the Google Data Flow model based on a single record (not micro batch) model, with exactly once processing semantics (for supported sources and sinks) via light weight checkpointing and support for batch processing.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-spark/streaming/&quot;&gt;Spark/Streaming&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Spark library for continuous stream processing, that allows stream and batch processing (including Spark SQL and MLlib operations) to be combined&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-beam&quot;&gt;Beam&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Model and SDKs for running batch and streaming workflows over Apex, Flink, Spark and Google Dataflow - &lt;a href=&quot;https://beam.apache.org/&quot;&gt;https://beam.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apex&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Data transformation engine based on Directed Acyclic Graph (DAG) flows configured through a Java API or via JSON that runs over YARN and HDFS with native support for both micro-batch streaming and batch uses cases&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Heron&lt;/td&gt; &lt;td&gt;The stream processing framework that Twitter built after Storm, with a Storm compatible API&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Samza&lt;/td&gt; &lt;td&gt;Stream processing framework built on Kafka and YARN - &lt;a href=&quot;http://samza.apache.org/&quot;&gt;http://samza.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Bahir&lt;/td&gt; &lt;td&gt;A suite of streaming connectors for Spark and Flink, including support for Akka, MQTT, Twitter and ZeroMQ - &lt;a href=&quot;http://bahir.apache.org/&quot;&gt;http://bahir.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gearpump (Incubating)&lt;/td&gt; &lt;td&gt;Real-time streaming engine based on the micro-service Actor model - &lt;a href=&quot;http://gearpump.apache.org/&quot;&gt;http://gearpump.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-data-stores&quot;&gt;Streaming Data Stores&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for buffering and storing real-time streams of data between producers and consumers, with a focus on high throughput at low latency.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;workflow-management&quot;&gt;Workflow Management&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Oozie&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for managing workflows of jobs on Hadoop clusters.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Airflow (Incubating)&lt;/td&gt; &lt;td&gt;Workflow automation and scheduling system that can be used to author and manage data pipelines - &lt;a href=&quot;http://airflow.apache.org/&quot;&gt;http://airflow.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;other-technologies&quot;&gt;Other Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;DataFu (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A set of libraries for working with data in Hadoop, consisting of two sub-projects - DataFu Pig (a set of Pig User Defined Functions) and DataFu Hourglass (a framework for incremental processing using MapReduce).&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;ZooKeeper&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Service for managing coordination (e.g. configuration information and synchronisation) of distributed and clustered systems.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;AsterixDB&lt;/td&gt; &lt;td&gt;Scalable “Big Data Management System” - &lt;a href=&quot;https://asterixdb.apache.org/&quot;&gt;https://asterixdb.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Chukwa&lt;/td&gt; &lt;td&gt;Specialist technology for the ingestion of continuous data flows into an Hadoop cluster, and the subsequent management and analysis of the data - &lt;a href=&quot;https://chukwa.apache.org/ &quot;&gt;https://chukwa.apache.org/ &lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Edgent (Incubating)&lt;/td&gt; &lt;td&gt;Stream processing programming model and lightweight runtime to execute analytics at devices on the edge or at the gateway, previously known as Quarks - &lt;a href=&quot;http://edgent.apache.org/&quot;&gt;http://edgent.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gora&lt;/td&gt; &lt;td&gt;ORM with support for a range of NoSQL, Search and Hadoop data formats - &lt;a href=&quot;http://gora.apache.org/&quot;&gt;http://gora.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;MetaModel&lt;/td&gt; &lt;td&gt;Technology for reading and writing database metadata with connectors for a wide range of databases - &lt;a href=&quot;http://metamodel.apache.org/&quot;&gt;http://metamodel.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Toree (Incubating)&lt;/td&gt; &lt;td&gt;Framework to allow interactive applications to communicate with a remote Spark cluster - &lt;a href=&quot;http://toree.apache.org/&quot;&gt;http://toree.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Curator&lt;/td&gt; &lt;td&gt;A set of Java libraries that make using Apache ZooKeeper much easier - &lt;a href=&quot;http://curator.apache.org/&quot;&gt;http://curator.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Calcite&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A framework for building SQL based data access capabilities, supporting a SQL parser and validator and tools for the transformation and (cost based) optimisation of SQL expression trees.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-livy/&quot;&gt;Livy (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A service that allows Spark jobs (pre-compiled JARs) or code snippets (Scala or Python) to be executed by remote systems over a REST API or via clients for Java, Scala and Python.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-superset/&quot;&gt;Superset (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Web based tool for interactive exploration for OLAP style data, supporting interactive drag and drop querying, composable dashboards and a SQL workspace (SQL Lab).&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Zeppelin&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A web based notebook for interactive data analytics.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Commons Compress&lt;/td&gt; &lt;td&gt;Suite of Java libraries for working with a range of compression and packaging formats - &lt;a href=&quot;https://commons.apache.org/proper/commons-compress/&quot;&gt;https://commons.apache.org/proper/commons-compress/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Griffin (Incubating)&lt;/td&gt; &lt;td&gt;Data Quality Service platform built on Apache Hadoop and Apache Spark - &lt;a href=&quot;http://griffin.incubator.apache.org/&quot;&gt;http://griffin.incubator.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Tika&lt;/td&gt; &lt;td&gt;Toolkit for extracting text from a wide range of document formats - &lt;a href=&quot;http://tika.apache.org/&quot;&gt;http://tika.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;UIMA&lt;/td&gt; &lt;td&gt;Framework for unstructured data analysis - &lt;a href=&quot;http://uima.apache.org/&quot;&gt;http://uima.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.apache.org/&quot;&gt;https://www.apache.org/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.apache.org/foundation/how-it-works.html&quot;&gt;https://www.apache.org/foundation/how-it-works.html&lt;/a&gt; - information on the foundation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://apache.org/foundation/mailinglists.html#foundation-announce&quot;&gt;http://apache.org/foundation/mailinglists.html#foundation-announce&lt;/a&gt; - the Apache Foundation announcements mailing list&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/&quot;&gt;https://blogs.apache.org/&lt;/a&gt;; &lt;a href=&quot;https://blogs.apache.org/planet/feed/entries/rss&quot;&gt;https://blogs.apache.org/planet/feed/entries/rss&lt;/a&gt; - The set of Apache Foundation blogs&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/apache/</guid> </item> <item><title>The Mid Week News - 16/08/2017</title><link>http://ondataengineering.net/blog/2017/08/16/the-mid-week-news/</link><pubDate>Wed, 16 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Bumper week this week given we’ve been off for a while - let’s crack on… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/apache-parquet&quot;&gt;Apache Parquet&lt;/a&gt; C++ library has hit 1.2&lt;/li&gt; &lt;li&gt;Confluent &lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/conflient-enterprise&quot;&gt;Enterprise&lt;/a&gt; have hit 3.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Apache Ignite&lt;/a&gt; is up to 2.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-drill&quot;&gt;Apache Drill&lt;/a&gt; is up to 1.11&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-tez&quot;&gt;Apache Tez&lt;/a&gt; has hit 0.9&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hive&quot;&gt;Apache Hive&lt;/a&gt; has seen 2.2 and 2.3 releases, with the 2.3 coming first. No idea what’s going on hear - if you can enlighten me please do!&lt;/li&gt; &lt;li&gt;There’s are also new links added to the &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; 5.12, &lt;a href=&quot;/technologies/cloudera-director&quot;&gt;Cloudera Director&lt;/a&gt; 2.5, &lt;a href=&quot;/technologies/cloudera-data-science-workbench&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; 1.1, &lt;a href=&quot;/technologies/hue&quot;&gt;Hue&lt;/a&gt; 4, &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt; 0.11, &lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Ignite&lt;/a&gt; 2.0 and &lt;a href=&quot;/technologies/apache-ambari&quot;&gt;Ambari&lt;/a&gt; 2.5 release entries from recent blog posts exploring the new functionality&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Apache Pulsar (&lt;a href=&quot;https://pulsar.incubator.apache.org/&quot;&gt;homepage&lt;/a&gt; has entered Apache incubation - looks like another potential Kafka alternative, this time from Yahoo. We’ll try and take a look at this next week.&lt;/li&gt; &lt;li&gt;It looks like &lt;a href=&quot;https://cwiki.apache.org/confluence/display/Hive/Metastore+TLP+Proposal&quot;&gt;there are plans&lt;/a&gt; to split the &lt;a href=&quot;/technologies/apache-hive/hive-metastore/&quot;&gt;Hive Metastore&lt;/a&gt; off into it’s own top level Apache project&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/top-reasons-why-search-engines-and-big-data-go-hand-in-hand-part-1/&quot;&gt;Cloudera’s thoughts&lt;/a&gt; (part 1) on the role &lt;a href=&quot;/tech-categories/analytical-search/&quot;&gt;Analytical Search&lt;/a&gt; capabilities play in big data analytics&lt;/li&gt; &lt;li&gt;From DB-Engines, &lt;a href=&quot;https://db-engines.com/en/blog_post/71&quot;&gt;thoughts&lt;/a&gt; on time series databases&lt;/li&gt; &lt;li&gt;The Confluent blog has been busy, with a bunch of interesting posts &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/&quot;&gt;An introduction&lt;/a&gt; to creating a flows using &lt;a href=&quot;/technologies/apache-kafka/kafka-streams&quot;&gt;Kafka Streams&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/apache-kafka-for-service-architectures/&quot;&gt;An excellent introduction&lt;/a&gt; to the architectural principles behind &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/messaging-single-source-truth/&quot;&gt;Thoughts&lt;/a&gt; on the use of &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; as the single source of truth (including history) of your data&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;From The Morning Paper, &lt;a href=&quot;https://blog.acolyer.org/2017/08/11/automatic-database-management-system-tuning-through-large-scale-machine-learning/&quot;&gt;an article&lt;/a&gt; on how machine learning can optimise database tuning, which probably speaks to the complexity of tuning databases as much as anything else&lt;/li&gt; &lt;li&gt;AWS Glue is &lt;a href=&quot;https://aws.amazon.com/blogs/aws/launch-aws-glue-now-generally-available/&quot;&gt;now generally available&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Another &lt;a href=&quot;https://blog.knoldus.com/2017/07/21/kafka-streams-more-than-just-a-dumb-storage/&quot;&gt;useful introduction&lt;/a&gt; to &lt;a href=&quot;/technologies/apache-kafka/kafka-streams/&quot;&gt;Kafka Streams&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Cloudera, a &lt;a href=&quot;http://blog.cloudera.com/blog/2017/07/quicker-insight-into-apache-solr-and-collection-health/&quot;&gt;post&lt;/a&gt; on monitoring Solr with &lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And another from Cloudera, &lt;a href=&quot;http://blog.cloudera.com/blog/2017/07/implyr-r-interface-for-apache-impala/&quot;&gt;querying&lt;/a&gt; &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Impala&lt;/a&gt; from R&lt;/li&gt; &lt;li&gt;And one more from Cloudera, detailing &lt;a href=&quot;http://blog.cloudera.com/blog/2017/08/introducing-s3guard-s3-consistency-for-apache-hadoop/&quot;&gt;S3Guard&lt;/a&gt;, providing consistency when running &lt;a href=&quot;/technologies/apache-hadoop/hdfs/&quot;&gt;HDFS&lt;/a&gt; over Amazon S3&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/16/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 14/08/2017</title><link>http://ondataengineering.net/blog/2017/08/14/the-plan-for-this-week/</link><pubDate>Mon, 14 Aug 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;And we’re back from our short break.&lt;/p&gt; &lt;p&gt;The plan for this week is to publish the list of Apache technologies that I think are of interest to us. I know we’re meant to be working through technology categories at the moment, but I’ve had this list lying around for a while and it’s time to get it out of my notes and onto the site.&lt;/p&gt; &lt;p&gt;So no update tomorrow, news on Wednesday, Apache technology list on Thursday and some thoughts on Friday - aka back to business as usual.&lt;/p&gt; &lt;p&gt;And I’m still working on tidying up some bits and pieces on the site - I’ll try and summarise these as and when they’re ready.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/08/14/the-plan-for-this-week/</guid> </item> <item><title>The Plan For The Next Three Weeks - 24/07/2017</title><link>http://ondataengineering.net/blog/2017/07/24/the-plan-for-next-three-weeks/</link><pubDate>Mon, 24 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s time for me to take a short break, both to recharge and try and get ahead of the upcoming content for the site, but also to do some work on the site itself which is starting to accumulate a few to many bodges and hacks (and an exponentially increasing build time!)&lt;/p&gt; &lt;p&gt;It’ll be back in three weeks on Monday 14th August, and although there may be a few updates here and there between now and then, expect things to be generally quite.&lt;/p&gt; &lt;p&gt;Here’s hoping your having a nice summer wherever you are, and we’ll speak soon…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/24/the-plan-for-next-three-weeks/</guid> </item> <item><title>Thoughts on Compute Cluster Managers</title><link>http://ondataengineering.net/blog/2017/07/21/thoughts-on-compute-cluster-management/</link><pubDate>Fri, 21 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Let’s talk about compute clusters, and the management thereof, technologies that we’re snappily calling &lt;a href=&quot;/tech-categories/compute-cluster-managers/&quot;&gt;compute cluster managers&lt;/a&gt;… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I’m assuming we’re all happy with database and application clusters - persistent processes running across a set of machines that co-ordinate with each other to serve requests and do work. The keyword here being persistent - you install the software on all the nodes, configure everything up, start it and it runs (hopefully forever).&lt;/p&gt; &lt;p&gt;Compute clusters are slightly different, in that work is not done by persistent processes, but instead by transitory jobs that start up, do some data processing work and then go away again. Some technologies implement their own clustering - Spark for example has a standalone mode with a simple cluster manager, and Hadoop 1.x MapReduce would manage it’s own distributed processing across an HDFS cluster. Of course you could run multiple technologies (or maybe even multiple jobs in the same technology) on a single cluster, however they’re going to compete for resources and if you’re being too ambitious, overwhelm your hardware.&lt;/p&gt; &lt;p&gt;What therefore emerged over the last 10 years are compute cluster management technologies. Rather than every technology having to implement their own clustering, they can talk to a cluster manager, ask for a bunch of processes to be started up, and relax safe in the knowledge that the cluster manager is going to take care of all the hard work of starting and managing these for them. And the key thing about these is that they can be used by multiple technologies - a single cluster can handle the execution of multiple simultaneous jobs in multiple technologies, with the cluster manager performing resource management to ensure that these multiple workloads execute in a harmonious and collaborative way.&lt;/p&gt; &lt;p&gt;The first of these was &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;Apache YARN&lt;/a&gt;, the big addition in Hadoop 2.0. Once YARN support was added to the common Hadoop data processing frameworks, this allowed multiple jobs in different technologies to run on your Hadoop cluster in a controlled and managed way under the oversight of the YARN resource manager.&lt;/p&gt; &lt;p&gt;And then a few years later came &lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;, the technology (along with it’s ecosystem) that we’ve been looking at this week. Mesos was born out of UC Berkeley RAD Lab and has seen rapid growth, with a commercial backer now in place in Mesosphere, and adoption by some significant customers. It’s a much more general purpose capability than YARN, with support for long running containerised applications via &lt;a href=&quot;/technologies/mesospher-marathon/&quot;&gt;Marathon&lt;/a&gt; also positioning it as an alternative to Kubernetes and Docker Swarm. It’s resource management model is also interestingly different to YARN, with Mesos making resource offers to applications which can then accept or reject them, as opposed to YARN which makes decisions about resources on behalf of applications, meaning applications can make decisions about data locality and resource usage, but removing the ability to manage this centrally.&lt;/p&gt; &lt;p&gt;YARN also has support for long running services coming, originally via &lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Apache Slider&lt;/a&gt; but with this functionality now being added directly into YARN (and work on Slider stopped), although there’s no current work on making it able to run or manager generic docker images ala Mesos / Marathon (beyond an aborted attempt by Hortonworks a few years ago to support Kubernetes on YARN). But YARN does has some interesting new capabilities for running spawned processes inside containers, something that appears to require application level support on Mesos.&lt;/p&gt; &lt;p&gt;And then there’s &lt;a href=&quot;/technologies/apache-myriad/&quot;&gt;Apache Myriad&lt;/a&gt;, which allows you to run YARN jobs over Mesos that maybe allow you to have your cake and eat it if you have a Mesos cluster (although it’s probably not quite mature yet). And Apache REEF - a library that provides an abstraction layer over YARN and Mesos, allowing applications to support both (and future technologies) via a single API.&lt;/p&gt; &lt;p&gt;It’s an evolving area, and one we’ll track. And we’ll talk more about container management, and the use of containers for running data processing jobs and managing data platforms in the not too distant future as well.&lt;/p&gt; &lt;p&gt;Right - that’s us for the week. Thanks to Jeff again for the content this week, and we’ll see you after the weekend.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/21/thoughts-on-compute-cluster-management/</guid> </item> <item><title>Compute Cluster Managers</title><link>http://ondataengineering.net/tech-categories/compute-cluster-managers/</link><pubDate>Fri, 21 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Technologies that start and manage the executor processes for distributed and transient data processing jobs, and then manage the use of resources (primarily cpu and memory) across the jobs running on the cluster. Should provide a way of packaging jobs and ensuring jobs are isolated from each other during execution, for example to allow different jobs to run in different environments against different versions of libraries. When running over a combined compute / storage cluster (like Hadoop), should also support data locaility ensuring that individual executors are running next to the data they require.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt; &lt;p&gt;There are two main technologies in this space:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;Apache YARN&lt;/a&gt;&lt;/td&gt; &lt;td&gt;The resource manager within the Apache Hadoop project, supporting transient jobs running on an Hadoop cluster, and with support for long running services coming.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Stand alone more general purpose cluster manager, with additional support for long running containerised applications ala Kerberos or Docker Swarm.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;apache-yarn&quot;&gt;Apache YARN&lt;/h2&gt; &lt;p&gt;For more information on deploying Hadoop (and YARN), see our &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt; page.&lt;/p&gt; &lt;h2 id=&quot;apache-mesos&quot;&gt;Apache Mesos&lt;/h2&gt; &lt;p&gt;Apache Mesos is also available as a commercial enterprise product:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mesosphere-dcos/&quot;&gt;Mesosphere DC/OS&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Commercial distribution of Apache Mesos with additional enterprise features&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Apache Mesos has an ecosystem of associated technologies, all of which are linked from our &lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt; page.&lt;/p&gt; &lt;h2 id=&quot;other-technologies&quot;&gt;Other Technologies&lt;/h2&gt; &lt;p&gt;Other technologies of interest in this space are:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-myriad/&quot;&gt;Apache Myriad&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Allows execution of YARN jobs over Apache Mesos&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Apache REEF&lt;/td&gt; &lt;td&gt;A library that provides an abstraction layer over YARN and Mesos, allowing applications to support both (and future technologies) via a single API - &lt;a href=&quot;http://reef.apache.org/&quot;&gt;http://reef.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;storage&quot;&gt;Storage&lt;/h2&gt; &lt;p&gt;Distributed jobs running on compute clusters will require access to storage, for which is there a number of options:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A cluster filesystem, either running over the compute cluster (e.g. Hadoop) or external to the cluster&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;Object Storage&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Simple network available storage that doesn’t provide parallel data access&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/compute-cluster-managers/</guid> </item> <item><title>Mesosphere DC/OS</title><link>http://ondataengineering.net/technologies/mesosphere-dcos/</link><pubDate>Thu, 20 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distributed, hybrid-cloud operating system for elastic stateless micro services running in containers and stateful big data services, ensuring high datacenter utilization. At its core, Apache Mesos handles job scheduling, resource management and abstraction, high availability, infrastructure-level processes and pluggable containerizers for both Docker and native Mesos containers. Combined with Marathon, provides a container orchestration platform with support for launching, managing, scaling and networking containers. Focused on ease of use, provides an app-store-like service catalog (Universe) to install complex distributed systems including HDFS, Apache Spark, Apache Kafka, Apache Cassandra, CI/CD applications such as Jenkins, all of which have been optimised to run on Apache Mesos and a web interface for monitoring and management. Comes in two flavors; a free community edition for installation in the cloud and a commercial enterprise edition for on-premises, in the cloud, or across a hybrid environment and includes monitoring tools, support for enterprise security and compliance tools, advanced networking, and load balancing features. Offered via a subscription license, the enterprise edition also includes product support. Open sourced in April 2016 under the Apache 2.0 license, under active development led by Mesosphere with a range of contributors including Microsoft.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;DC/OS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v1.9&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Uses&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mesosphere-marathon/&quot;&gt;Mesosphere Marathon&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://dcos.io/&quot;&gt;https://dcos.io/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/dcos/dcos/&quot;&gt;https://github.com/dcos/dcos/&lt;/a&gt; - source code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://dcos.io/docs/&quot;&gt;https://dcos.io/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mesosphere.com/blog/2016/04/19/open-source-dcos/&quot;&gt;https://mesosphere.com/blog/2016/04/19/open-source-dcos/&lt;/a&gt; - Introduction to open source DC/OS&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://dcos.io/blog/&quot;&gt;https://dcos.io/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://dcos.io/releases/&quot;&gt;https://dcos.io/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mesosphere-dcos/</guid> </item> <item><title>Mesosphere</title><link>http://ondataengineering.net/tech-vendors/mesosphere/</link><pubDate>Thu, 20 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Mesosphere is a commercial company developing the Mesosphere Datacenter Operating System (DC/OS). DC/OS is built around Apache Mesos and is itself an open source project. They are therefore extremely active in the open source space. Their business model is to sell subscription licenses based around an Enterprise version of DC/OS, provide training and support for DC/OS and partner-supported technologies. Mesosphere was founded in May 2013 by ex-engineers from Twitter and Airbnb.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Vendor Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;a href=&quot;http://ondataengineering.net/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt; &lt;/td&gt; &lt;td&gt;Open source cluster manager for providing efficient resource utilization across a cluster of servers through resource sharing and isolation. Allows a cluster of servers to be shared across diverse cluster computing frameworks so that different distributed workloads such as container orchestration, machine learning, analytics and stateful big data technologies can be run without interfering with each other. Has the ability to dynamically allocate resources across the servers as needed and delegates control over scheduling to the frameworks through an abstraction layer called a resource offer to support a wide array of computing frameworks. Resource isolation is implemented using a universal containeriser, supporting numerous containers including native Mesos containers and Docker containers. Fault tolerance of the Mesos instance in control of the cluster is implemented using Zookeeper. Started as a research project in the UC Berkeley RAD Lab, open sourced in 2011, with a v1.0 release in July 2016, which, included the 'unified containeriser' and GPU-based scheduling. Written in C++, uses Google Protocol Buffers for messaging and serialization to allow frameworks to be written in a variety of languages including C++, Java, Python, Go, Haskell, and Scala. Under active development, open sourced under the Apache 2.0 license, hosted on the Apache git repository and mirrored on GitHub. Software startup Mesosphere sells the Datacenter Operating System, a distributed operating system, based on Apache Mesos.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mesosphere.com/&quot;&gt;https://mesosphere.com/&lt;/a&gt; - homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mesosphere.com/blog/&quot;&gt;https://mesosphere.com/blog/&lt;/a&gt; - Mesosphere blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/mesosphere/</guid> </item> <item><title>Mesosphere Marathon</title><link>http://ondataengineering.net/technologies/mesosphere-marathon/</link><pubDate>Wed, 19 Jul 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;A framework for Apache Mesos and Mesosphere's Datacenter Operating System (DC/OS) to launch long-running services in a clustered environment and ensure that they continue to run in the event of a hardware or software failure. Implemented as a Mesos framework, leverages Mesos for resource allocation and isolation and provides a REST API and web interface for service definition, discovery and management. Provides constraints control to support service placement for high-available and locality, an event bus and health checking to support rolling deployments and upgrades. Provides local and external persistent storage and resurrection on the same node in the event of a failure to support stateful services (in beta). Often used as an orchestrator for other applications and services, can be run in highly-available mode by running multiple copies of the framework and using ZooKeeper to perform leader election in the event on an failure. Written in Scala, open sourced under the Apache 2.0 license, hosted on GitHub, with development led by Mesosphere who also distribute it as part of their Mesosphere's Datacenter Operating System (DC/OS) commercial offering.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Marathon&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v1.4&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Uses&lt;/td&gt;&lt;td&gt;Zookeeper&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mesosphere-dcos/&quot;&gt;Mesosphere DC/OS&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mesosphere.github.io/marathon/&quot;&gt;https://mesosphere.github.io/marathon/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mesosphere/marathon/&quot;&gt;https://github.com/mesosphere/marathon/&lt;/a&gt; - source code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mesosphere.github.io/marathon/docs/&quot;&gt;https://mesosphere.github.io/marathon/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mesosphere/marathon/releases/&quot;&gt;https://github.com/mesosphere/marathon/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/mesosphere-marathon/</guid> </item> <item><title>The Mid Week News - 19/07/2017</title><link>http://ondataengineering.net/blog/2017/07/19/the-mid-week-news/</link><pubDate>Wed, 19 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, time for the news again, and it feels like a busy release week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It’s Cloudera release time, with lots of Cloudera software seeing new releases: &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; is up to 5.12&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; is also up to 5.12&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; is up to 2.11&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; is up to 2.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; is up to 1.1&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; has hit 2.2, and it seems like our technology summaries are a bit out of date, so we’ll revisit them soon&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;Apache HAWQ&lt;/a&gt; still seems to be going, with a 2.2 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hue/&quot;&gt;Apache Hue&lt;/a&gt; has hit 4.0, with a new UI&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;An &lt;a href=&quot;https://www.elastic.co/blog/a-practical-introduction-to-elasticsearch&quot;&gt;introduction&lt;/a&gt; to &lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; from Elastic&lt;/li&gt; &lt;li&gt;And also from Elastic on machine learning which is part of the &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;Elastic X-Pack&lt;/a&gt; - &lt;a href=&quot;https://www.elastic.co/blog/alerting-on-machine-learning-jobs-in-elasticsearch-v55&quot;&gt;Alerting on Machine Learning Jobs&lt;/a&gt; and &lt;a href=&quot;https://www.elastic.co/blog/using-elasticsearch-and-machine-learning-for-it-operations&quot;&gt;Using Machine Learning for IT Ops&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://yokota.blog/2017/07/12/hbase-application-archetypes-redux/&quot;&gt;Thoughts&lt;/a&gt; on how to store different types of data (entities, documents, graph, queue etc.) in &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Hbase&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, their &lt;a href=&quot;http://www.zdnet.com/article/yahoos-bullet-looks-ahead-in-querying-streaming-data/&quot;&gt;introduction&lt;/a&gt; to Bullet, Yahoo’s recently open source tool for querying streams of data&lt;/li&gt; &lt;li&gt;It looks like Basho is no more &lt;a href=&quot;https://www.theregister.co.uk/2017/07/13/will_the_last_person_at_basho_get_the_lights_oh_too_late/&quot;&gt;according to The Register&lt;/a&gt;, however there’s still hope that Riak will live on&lt;/li&gt; &lt;li&gt;There’s now &lt;a href=&quot;https://www.swiftstack.com/blog/2017/07/11/swiftstack-client-new-easy-way-interact-swiftstack-storage/&quot;&gt;a web GUI&lt;/a&gt; “that an end user can use to view, upload, download, share, and manage their data in a SwiftStack cluster”&lt;/li&gt; &lt;li&gt;Oh my word, it never ends! &lt;a href=&quot;https://www.gridgain.com/resources/blog/getting-started-apacher-ignitetm-part-6&quot;&gt;Part 6&lt;/a&gt; of GridGain’s intro to &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt; is now up.&lt;/li&gt; &lt;li&gt;An &lt;a href=&quot;https://databricks.com/blog/2017/07/12/benchmarking-big-data-sql-platforms-in-the-cloud.html&quot;&gt;article from Databricks&lt;/a&gt; on how much faster Databrinks in the cloud is that vanilla &lt;a href=&quot;/technologies/apache-spark&quot;&gt;Spark&lt;/a&gt; on AWS&lt;/li&gt; &lt;li&gt;Via &lt;a href=&quot;https://www.theregister.co.uk/2017/07/13/scality_zenko/&quot;&gt;The Register&lt;/a&gt;, Scality have released &lt;a href=&quot;http://www.zenko.io/&quot;&gt;Zenko&lt;/a&gt;, an open source S3 gateway that can federate across multiple cloud and on premise object stores, with support to come for metadata attribute search and data management, replication and workflows. Sounds like we should look into &lt;a href=&quot;/tech-categories/object-storage/&quot;&gt;object storage&lt;/a&gt; gateways at some point.&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/19/the-mid-week-news/</guid> </item> <item><title>Chronos</title><link>http://ondataengineering.net/technologies/chronos/</link><pubDate>Tue, 18 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A framework for Apache Mesos to schedule and orchestrate jobs to periodically run at fixed times, dates or intervals in a clustered environment. Leverages Mesos for resource allocation and isolation and provides a REST API and web interface for job definition and job management. Reoccurring jobs are defined using ISO8601 repeating interval notation and may also be triggered by the completion of other jobs to create dependency based jobs. Uses Zookeeper for state management and typically deployed as a service under Marathon for high-availability. Supports writing and exporting of job metrics to various systems for further analysis and notifications to various endpoints such as email and chat messaging systems. Originally created at AirBnB and written in Scala, opened sourced in March 2013 under the Apache 2.0 license, hosted under the Apache Mesos Community Projects group-owned repositories on GitHub.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Chronos&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v3.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Uses&lt;/td&gt;&lt;td&gt;Zookeeper&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://mesos.github.io/chronos/&quot;&gt;https://mesos.github.io/chronos/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mesos/chronos/&quot;&gt;https://github.com/mesos/chronos/&lt;/a&gt; - source code&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://mesos.github.io/chronos/docs/&quot;&gt;https://mesos.github.io/chronos/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/mesos/chronos/releases/&quot;&gt;https://github.com/mesos/chronos/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/chronos/</guid> </item> <item><title>Apache Aurora</title><link>http://ondataengineering.net/technologies/apache-aurora/</link><pubDate>Tue, 18 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A service scheduler for defining and managing bundled tasks as jobs across a cluster of servers using Mesos, leveraging Mesos for resource allocation and isolation at the task level. Operates as a Mesos framework, a Python based domain specific language (DSL) for job template definition, an executor for carrying out the workload described in the DSL, an associated command line interface for schedule management and a web interface providing read-only status of jobs and associated diagnostic information. Defines a fine-grained task state model to support resource allocation, rolling upgrades, health checking, priority-based scheduling and application maintenance. Handles cross-cutting concerns like observability and log collection. Supports priority-based scheduling, using pre-emption so that when resources are low, lower priority jobs can be stopped to make room for the higher priority tasks. An Apache project, originally created at Twitter, donated to the Apache Foundation in October 2013, graduating in March 2015 (0.8.0 Released). Hasn't yet reached a v1.0 milestone, however still under development from a range of contributors.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Aurora&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v0.18&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Apache Mesos&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://aurora.apache.org/&quot;&gt;http://aurora.apache.org/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://aurora.apache.org/documentation/latest/&quot;&gt;http://aurora.apache.org/documentation/latest/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://aurora.apache.org/documentation/latest/getting-started/overview/&quot;&gt;http://aurora.apache.org/documentation/latest/getting-started/overview/&lt;/a&gt; - Aurora System Overview&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=asd_h6VzaJc/&quot;&gt;https://www.youtube.com/watch?v=asd_h6VzaJc/&lt;/a&gt; - Introduction to Apache Aurora&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://aurora.apache.org/blog/&quot;&gt;http://aurora.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/apache/aurora/releases/&quot;&gt;https://github.com/apache/aurora/releases/&lt;/a&gt; - details of releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-aurora/</guid> </item> <item><title>Apache Mesos</title><link>http://ondataengineering.net/technologies/apache-mesos/</link><pubDate>Mon, 17 Jul 2017 07:45:00 +0100</pubDate> <description> &lt;p&gt;Open source cluster manager for providing efficient resource utilization across a cluster of servers through resource sharing and isolation. Allows a cluster of servers to be shared across diverse cluster computing frameworks so that different distributed workloads such as container orchestration, machine learning, analytics and stateful big data technologies can be run without interfering with each other. Has the ability to dynamically allocate resources across the servers as needed and delegates control over scheduling to the frameworks through an abstraction layer called a resource offer to support a wide array of computing frameworks. Resource isolation is implemented using a universal containeriser, supporting numerous containers including native Mesos containers and Docker containers. Fault tolerance of the Mesos instance in control of the cluster is implemented using Zookeeper. Started as a research project in the UC Berkeley RAD Lab, open sourced in 2011, with a v1.0 release in July 2016, which, included the 'unified containeriser' and GPU-based scheduling. Written in C++, uses Google Protocol Buffers for messaging and serialization to allow frameworks to be written in a variety of languages including C++, Java, Python, Go, Haskell, and Scala. Under active development, open sourced under the Apache 2.0 license, hosted on the Apache git repository and mirrored on GitHub. Software startup Mesosphere sells the Datacenter Operating System, a distributed operating system, based on Apache Mesos.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Mesos, DC/OS&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, &lt;a href=&quot;/tech-vendors/mesosphere/&quot;&gt;Mesosphere&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v1.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-aurora/&quot;&gt;Apache Aurora&lt;/a&gt;, &lt;a href=&quot;/technologies/chronos/&quot;&gt;Chronos&lt;/a&gt;, &lt;a href=&quot;/technologies/mesosphere-marathon/&quot;&gt;Mesosphere Marathon&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Uses&lt;/td&gt;&lt;td&gt;Zookeeper&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is used by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mesosphere-dcos/&quot;&gt;Mesosphere DC/OS&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://mesos.apache.org/&quot;&gt;http://mesos.apache.org/&lt;/a&gt; - product home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://mesos.apache.org/documentation/&quot;&gt;http://mesos.apache.org/documentation/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://mesos.berkeley.edu/mesos_tech_report.pdf&quot;&gt;http://mesos.berkeley.edu/mesos_tech_report.pdf&lt;/a&gt; - Mesos: A Platform for Fine-Grained Resource Sharing the the Data Centre&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://mesos.apache.org/blog/&quot;&gt;http://mesos.apache.org/blog/&lt;/a&gt; - blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-mesos/</guid> </item> <item><title>The Plan For This Week - 17/07/2017</title><link>http://ondataengineering.net/blog/2017/07/17/the-plan-for-this-week/</link><pubDate>Mon, 17 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, it’s going a quiet week for me (but not the site) this week, as we have a bunch of technology summaries on Apache Mesos and some of it’s associated technologies from Jeff Moszuti.&lt;/p&gt; &lt;p&gt;Jeff also supplied the technology summary for Apache Cassandra last week, however I very rudely forgot to credit him in the wrap up post on Friday - apologies Jeff.&lt;/p&gt; &lt;p&gt;I’ll be back on Wednesday with an update on the news, and back on Friday with some thoughts on cluster management, but until then I’ll leave you in Jeff’s capable hands.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/17/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on NoSQL Wide Column Stores</title><link>http://ondataengineering.net/blog/2017/07/14/thoughts-on-nosql-wide-column-stores/</link><pubDate>Fri, 14 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Right - it’s the end of another week and another (quick) review of a technology category is done - this time &lt;a href=&quot;/tech-categories/nosql-wide-column-stores/&quot;&gt;NoSQL Wide Column Stores&lt;/a&gt;. Let’s review what we’ve discovered. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;NoSQL Wide Column Stores are all based on the Bigtable paper from Google, and in terms of available technologies is not a huge pool, being dominated by &lt;a href=&quot;/technologies/apache-cassandra/&quot;&gt;Apache Cassandra&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt; in the open source space, and Azure Table Storage and Google Cloud Bigtable in the cloud space.&lt;/p&gt; &lt;p&gt;All the open source technologies are great technologies, firmly established, proven a huge scale, with significant backing, and with a range of commercial and managed service offerings available. ScyllaDB (&lt;a href=&quot;http://www.scylladb.com/&quot;&gt;http://www.scylladb.com/&lt;/a&gt;) is worth called out - a C++ re-write (effectively) of Apache Cassandra, giving 100% compatibility but performing a lower latencies with more consistency. Definitely one to look at if you use or are consider using Cassandra.&lt;/p&gt; &lt;p&gt;And then there are the multi-model databases - technologies that provide NoSQL wide column capabilities alongside other NoSQL capabilities (often document, graph and key-value) in the same technologies. A category we’ll come back to in the future, as well as having a proper look at the different types of NoSQL databases available.&lt;/p&gt; &lt;p&gt;In closing - why would you consider using a NoSQL Wide Column Store? The common use case is probably in the intersection of document (un-structured) and structured storage - within a column family, each record can reference a completely different set of columns and column data types, whilst retaining the ability to return structured data from queries and run (reasonably) efficient filtered scans or records by column. Add to this their massively scalability (up to thousands of nodes and petabytes of data) and high throughput low latency read/write/mutate operations, and these technologies have found themselves a useful niche.&lt;/p&gt; &lt;p&gt;In analytical terms, they’re often use to hold and serve the results of analytics (aggregations and metrics) for serving at low latencies to dashboards, but their use undoubtedly stretches way beyond that.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/14/thoughts-on-nosql-wide-column-stores/</guid> </item> <item><title>NoSQL Wide Column Stores</title><link>http://ondataengineering.net/tech-categories/nosql-wide-column-stores/</link><pubDate>Fri, 14 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;NoSQL databases based on Google Bigtable, the design of which was published in a paper in 2006. Often described as a sparse, distributed multi-dimensional sorted map (or key value store) - cells being referenced by a row and column key plus a timestamp or version (with columns arranged into column families), support for the names and formats of columns varying from row to row (within fixed column families), and architectures supporting massive horizontal scalability. Also called extensible record stores, and occasionally NoSQL column stores (although this definition is slightly inaccurate and confuses these technologies with more general purpose database columnar storage). Common functionality includes low latency high throughput reads and writes, scan/iterate operations, atomic mutations and cell level security. Common analytical use cases include the storage and serving of aggregations and metrics for real time dashboards, often as part of a wider ecosystem.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;google-bigtable&quot;&gt;Google Bigtable&lt;/h2&gt; &lt;p&gt;NoSQL Wide Column stores are all based on the original design paper for Google Bigtable that can be found at &lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf&quot;&gt;http://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf&lt;/a&gt;&lt;/p&gt; &lt;h2 id=&quot;open-source-options&quot;&gt;Open Source Options&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologis/apache-cassandra/&quot;&gt;Apache Cassandra&lt;/a&gt;&lt;/td&gt; &lt;td&gt;NoSQL wide-column datastore based on Amazon Dynamo and Google BigTable, focusing on fault tolerance, linear scalability and operational simplicity with zero downtime based on a distributed masterless node and peer-to-peer design&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt;&lt;/td&gt; &lt;td&gt;NoSQL wide-column datastore based on Google BigTable, with deep integration to the Apache Hadoop ecosystem.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt;&lt;/td&gt; &lt;td&gt;NoSQL wide-column datastore based on BigTable, supporting cell based access control (based on arbitrary boolean expressions of user security labels) and atomic mutation operators.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ScyllaDB&lt;/td&gt; &lt;td&gt;Cassandra-compatible data store re-written in C++ with the aim to provider higher throughput at lower latency, open sourced under an AGPL licence - &lt;a href=&quot;http://www.scylladb.com/&quot;&gt;http://www.scylladb.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-options&quot;&gt;Commercial Options&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;ScyllaDB Enterprise&lt;/td&gt; &lt;td&gt;Distribution of ScyllaDB (the open source product) from ScyllaDB (the company), with added enterprise features and commercial support - &lt;a href=&quot;http://www.scylladb.com/&quot;&gt;http://www.scylladb.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Commercial support for Apache HBase and Apache Accumulo is included in most commercial Hadoop distributions.&lt;/p&gt; &lt;h2 id=&quot;managed-service-options&quot;&gt;Managed Service Options&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Table Storage&lt;/td&gt; &lt;td&gt;A NoSQL wide column store service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/tables/&quot;&gt;https://azure.microsoft.com/en-us/services/storage/tables/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Bigtable&lt;/td&gt; &lt;td&gt;NoSQL wide column store service - &lt;a href=&quot;https://cloud.google.com/bigtable/&quot;&gt;https://cloud.google.com/bigtable/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Apache Cassandra is also available as a managed service from a number of vendors.&lt;/p&gt; &lt;p&gt;Apache HBase and Apache Accumulo are also available as part of most Hadoop managed services&lt;/p&gt; &lt;h2 id=&quot;multi-model-nosql-databases&quot;&gt;Multi Model NoSQL Databases&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;DataStax Enterprise&lt;/td&gt; &lt;td&gt;Commercial product built on Apache Cassandra with the addition of graph and search capabilities - &lt;a href=&quot;https://www.datastax.com/&quot;&gt;https://www.datastax.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Cosmos DB&lt;/td&gt; &lt;td&gt;Multi-model database as a service, supporting document, graph and key value use cases, including support for the Azure Table Storage API - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cosmos-db/&quot;&gt;https://azure.microsoft.com/en-us/services/cosmos-db/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-file-system/mapr-db&quot;&gt;MapR-DB&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Commercial document and wide column NoSQL database as part of the MapR stack&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;historical--legacy-options&quot;&gt;Historical / Legacy Options&lt;/h2&gt; &lt;p&gt;The following technologies were either popular options or are referenced in on-line lists of wide column NoSQL database, but are no longer sold or maintained:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Cloudata&lt;/td&gt; &lt;td&gt;Open source Bigtable clone from Gruter, started in February 2011 before being abandoned after 4 commits in March 2011 - &lt;a href=&quot;https://github.com/gruter/cloudata&quot;&gt;https://github.com/gruter/cloudata&lt;/a&gt;; &lt;a href=&quot;http://cloudata.org/&quot;&gt;http://cloudata.org/&lt;/a&gt; (dead)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hypertable&lt;/td&gt; &lt;td&gt;Open source C++ project based on Google Bigtable that ran over a distributed filesystem, started in 2008, with development ceasing in March 2016 - &lt;a href=&quot;http://hypertable.org/&quot;&gt;http://hypertable.org/&lt;/a&gt; (dead); &lt;a href=&quot;https://github.com/hypertable/hypertable&quot;&gt;https://github.com/hypertable/hypertable&lt;/a&gt;; &lt;a href=&quot;https://en.wikipedia.org/wiki/Hypertable&quot;&gt;https://en.wikipedia.org/wiki/Hypertable&lt;/a&gt;; &lt;a href=&quot;http://www.hypertable.com/blog/hypertable_inc._is_closing_its_doors&quot;&gt;http://www.hypertable.com/blog/hypertable_inc._is_closing_its_doors&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/nosql-wide-column-stores/</guid> </item> <item><title>The Mid Week News - 12/07/2017</title><link>http://ondataengineering.net/blog/2017/07/12/the-mid-week-news/</link><pubDate>Wed, 12 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;It’s a fairly light week this week, but let’s catch up on the news anyway. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt; has seen a 4.11 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt;, &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;Elastic X-Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch Hadoop&lt;/a&gt; has all seen a 5.5 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The 3.0 alpha4 release of &lt;a href=&quot;/technologies/apache-hadoop&quot;&gt;Apache Hadoop&lt;/a&gt; is out - first beta release is next!&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/07/07/do-we-need-specialized-graph-databases-benchmarking-real-time-social-networking-applications/&quot;&gt;More&lt;/a&gt; from Adrian Colyer’s “the morning paper” - how relational databases can be faster than graph databases for some types of graph operations&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/07/04/azure-data-lake-store-a-hyperscale-distributed-file-service-for-big-data-analytics/&quot;&gt;And other one&lt;/a&gt; from Adrian - this time reviewing a paper on &lt;a href=&quot;/technologies/microsoft-azure-data-lake-store/&quot;&gt;Azure Data Lake Store&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;An &lt;a href=&quot;http://flink.apache.org/features/2017/07/04/flink-rescalable-state.html&quot;&gt;article&lt;/a&gt; on Rescalable State in Apache Flink&lt;/li&gt; &lt;li&gt;And I feel like we’ve committed to this now, but here’s &lt;a href=&quot;https://www.gridgain.com/resources/blog/getting-started-apacher-ignitetm-part-5&quot;&gt;part 5&lt;/a&gt; of GridGain’s introduction to &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt;. Should be over soon.&lt;/li&gt; &lt;li&gt;And given my comments on security vulnerabilities disclosures last week, there’s a job lot this week &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5640&quot;&gt;CVE-2017-5640&lt;/a&gt; - Apache Impala (incubating) Information Disclosure&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5652&quot;&gt;CVE-2017-5652&lt;/a&gt; - Apache Impala (incubating) Information Disclosure&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.cve.mitre.org/cgi-bin/cvename.cgi?name=2017-7660&quot;&gt;CVE-2017-7660&lt;/a&gt; - Security Vulnerability in secure inter-node communication in Apache Solr&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/12/the-mid-week-news/</guid> </item> <item><title>Apache Cassandra</title><link>http://ondataengineering.net/technologies/apache-cassandra/</link><pubDate>Tue, 11 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Distributed wide-column datastore based on Amazon Dynamo and Google BigTable. Focuses on fault tolerance, linear scalability and operational simplicity with zero downtime based on a distributed masterless node and peer-to-peer design. Supports high availability using network topology aware data replication to avoid single points of failure, fast real-time and durable ingestion of data using an append-only log, strong query performance based on an in-memory index (log-structured merge-tree) that is persisted as a sorted string table (SST) for fast sequential retrieval, and tunable consistency (between strong and eventual) allowing availability (number of replicas on which a write must succeed), data accuracy (number of replicas must respond to a read request before returning data) and performance to be traded off on a global or per-operation basis. Does not support joins nor subqueries, rather, emphasises denormalisation through features like collections. Comes with a command line shell (cqlsh) for using Cassandra Query Language (resembling SQL), a wide number of drivers for many languages including Java, Python, Ruby, C++ and Go, and Nodetool, a CLI for cluster management. Metrics can be queried via JMX or pushed to external monitoring systems, SSL encryption provides secure communication, authentication and authorisation is provided based on internally controlled rolename/passwords and object permission management. An Apache project, graduating in February 2010, having been originally opened sourced in July 2008 by Facebook. Written in Java and under active development with major contributions from DataStax who distribute it as a part of their DataStax Enterprise offering. Other commercial vendors include Instaclustr and Winguzone who provide hosted and managed Apache Cassandra as a service on a number of major cloud providers.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Cassandra&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;, DataStax&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - 3.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cassandra.apache.org&quot;&gt;https://cassandra.apache.org&lt;/a&gt; - Cassandra homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cassandra.apache.org/doc/latest&quot;&gt;https://cassandra.apache.org/doc/latest&lt;/a&gt; - Cassandra documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.datastax.com/products/datastax-enterprise&quot;&gt;http://www.datastax.com/products/datastax-enterprise&lt;/a&gt; - DataStax Enterprise&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.datastax.com&quot;&gt;http://docs.datastax.com&lt;/a&gt; - DataStax Enterprise documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://academy.datastax.com/courses&quot;&gt;https://academy.datastax.com/courses&lt;/a&gt; - Free Self-Paced Courses on Apache Cassandra and DataStax Enterprise&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.datastax.com/dev/blog&quot;&gt;http://www.datastax.com/dev/blog&lt;/a&gt; - DataStax blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-cassandra/</guid> </item> <item><title>The Plan For This Week - 10/07/2017</title><link>http://ondataengineering.net/blog/2017/07/10/the-plan-for-this-week/</link><pubDate>Mon, 10 Jul 2017 08:10:00 +0100</pubDate> <description> &lt;p&gt;So we’re a little behind the curve this week, but the plan this week is to look at wide column NoSQL stores, and specifically how these can support analytical use cases.&lt;/p&gt; &lt;p&gt;Just as forewarning - it might be a slightly quieter week than usual for a number of reasons, but we’ll try and look at a couple of technologies and collect our thoughts for Friday…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/10/the-plan-for-this-week/</guid> </item> <item><title>Analytical Search</title><link>http://ondataengineering.net/tech-categories/analytical-search/</link><pubDate>Fri, 07 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Technologies for analytics over unstructured and semi-structured data based on search. Should be distributed and horizontally scaleable, support pre-defined and on-demand schemas, all standard search functionality plus analytics based on search including basic join functionality, aggregations, graph analytics and machine learning.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;primary-technologies&quot;&gt;Primary Technologies&lt;/h2&gt; &lt;p&gt;If you’re looking for search technologies that provide a wide range of analytical functions there are two primary options:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An open source distributed search server that supports a range of analytics over search results, but with some enterprise and analytics features requiring a commercial licence from Elastic who lead development&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An Apache open source distributed search server that supports a range of analytics over search results, and which is included in most Hadoop distributions.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;elasticsearch-options&quot;&gt;Elasticsearch options&lt;/h2&gt; &lt;p&gt;Although &lt;a href=&quot;/technologies/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; is an open source technology, it doesn’t include some enterprise features (such as access control, monitoring, alerting or encryption) and advanced analytical capabilities (such as graph searching or machine learning based anomaly detection), which require the &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;X-Pack&lt;/a&gt; add on from Elastic (the creators and maintainers of Elasticsearch) that’s only available under one of their commercial packages (including &lt;a href=&quot;/technologies/elastic-cloud/&quot;&gt;Elastic Cloud&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;A range of other vendors also provide Elasticsearch as a service offering (including Amazon) based on the open source version, either focusing on traditional search use cases, or event log analysis (generally based on Elasticsearch, Kibana and Logstash - the ELK stack).&lt;/p&gt; &lt;h2 id=&quot;apache-solr-options&quot;&gt;Apache Solr options&lt;/h2&gt; &lt;p&gt;All &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt; functionality is available in the open source product.&lt;/p&gt; &lt;p&gt;Cloudera and Lucidworks are currently two of the leading contributors to Apache Solr, distributing it as part of &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; and Lucidworks Fusion (&lt;a href=&quot;https://lucidworks.com/&quot;&gt;https://lucidworks.com/&lt;/a&gt;) respectively. Lucidworks also provide the version of Solr within &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;HDP&lt;/a&gt; and as an add on for the &lt;a href=&quot;/technologies/mapr-converged-data-platform&quot;&gt;MapR Data Platform&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A range of vendors also provide Apache Solr as a service offering, however these generally focus on traditional search use cases.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/analytical-search/</guid> </item> <item><title>Thoughts on Analytical Search</title><link>http://ondataengineering.net/blog/2017/07/07/thoughts-on-analytical-search/</link><pubDate>Fri, 07 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Yes, the date on this post says Friday 7th, and it’s being published well after that, but let’s pretend it’s Friday and summarise some thoughts on analytical search. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Search is search right - you index some documents and call an API with some keywords and get back a list of documents that contain those keywords. You might also get back some counts of documents matches, get some matched text snippets back as well, and get support for stemming (so that searches for fox returns documents with foxes in as well), but fundamentally it’s about turning some search terms into a list of matching documents. Right?&lt;/p&gt; &lt;p&gt;What both &lt;a href=&quot;/technologies/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt; have done is turn search into a much more general purpose analytical capability. In the same way that relational databases use indexes and full table scans as a starting point for the wide range of transformations, joins and aggregations supported by SQL, these search technologies now use their indexed lookups as the starting point for a similar range of capabilities.&lt;/p&gt; &lt;p&gt;So what can these technologies do? Aggregations were the first step, allowing results to be rolled up - great for understanding how many type X errors my system’s generated by hour over the last month. And this then lead to much more interesting aggregations, including those to support anomaly detection (are the number of errors I’m seeing now different from the usual count for this time of day) and graph analysis (what are the relationships between the terms I’m interested and the other terms in the same document).&lt;/p&gt; &lt;p&gt;And now both technologies are supporting configurable results analysis pipelines turning these into much more powerful analytical capabilities - in Solr’s case these support a range of other capabilities including MapReduce like transformations over results and the ability to execute SQL expressions over Solr indexes.&lt;/p&gt; &lt;p&gt;Which I think makes for a very interesting time to be looking at analysis of unstructured and semi-structured data, as we’re now starting to see similar analytical capabilities to those that have existed in the structured world for a long time, and they’re going to open up some extreemly interesting use cases.&lt;/p&gt; &lt;p&gt;And if &lt;a href=&quot;/technologies/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt; are blazing this trail, which one should you choose for your use case? There are plenty of websites out there that will give you their thoughts or a feature by feature breakdown (although be wary of how old some of them are, as both technologies, and specifically Solr, have seen significant changes in the last couple of years), and although both technologies have slightly different focuses (Elasticsearch has a strong pedigree in doing log analysis for example) the strong likelihood is that unless you’re pushing the boundries they’ll both support your use case.&lt;/p&gt; &lt;p&gt;So my recommendation to you would be threefold:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Do some proof of concepts with both technologies to understand how well they fit your use case and how well they work for you&lt;/li&gt; &lt;li&gt;Look at the commercial model. Although Elastic is open source, there are considerable benefits to taking on one of Elastic’s commercial offerings, both in terms of extra functionality and having their support. With Solr all the functionality is in the open source product, but there’s still value in having commercial support, and there’s a much wider range of ways of getting this and a wider range of vendors that will provide this.&lt;/li&gt; &lt;li&gt;Make sure you have access to people that understand these technologies and what they can do. They are powerful and complex pieces of technology that are relatively new, and getting access to people that understand them will ensure you get the most out of them.&lt;/li&gt; &lt;/ol&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/07/thoughts-on-analytical-search/</guid> </item> <item><title>Elasticsearch-Hadoop</title><link>http://ondataengineering.net/technologies/elasticsearch-hadoop/</link><pubDate>Thu, 06 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A suite of open source components for querying and writing documents to Elasticsearch from a range of Hadoop technologies, including MapReduce, Hive, Pig, Spark, Cascading and Storm. Specific functionality includes InputFormat and OutputFormat libraries for MapReduce, a Hive storage handler allowing external tables to be defined over Elasticsearch indexes, read and write functions for Pig, Java and Scala RDD based libraries for Spark, Spark SQL support, an Elasticsearch Tap for Cascading and a dedicated Spout and Bolt for Storm. Also includes a beta of Elasticsearch on YARN which is awaiting further developments for long running services on YARN. Used to include functionality for going snapshots of Elasticsearch indexes to HDFS which is now part of the Snapshot and Restore functionality in Elasticsearch. Certified with CDH, MapR and HDP.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;ES-Hadoop&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Elastic&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v5.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.5&lt;/td&gt; &lt;td&gt;2017-07-06&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.elastic.co/blog/es-hadoop-5-5-0-released&quot;&gt;announcement&lt;/a&gt;; &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/hadoop/current/eshadoop-5.5.0.html&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Hadoop 1.x and Elasticsearch of YARN Beta deprecated&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/products/hadoop&quot;&gt;https://www.elastic.co/products/hadoop&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/hadoop/current/index.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/hadoop/current/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/elastic/elasticsearch-hadoop&quot;&gt;https://github.com/elastic/elasticsearch-hadoop&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/elasticsearch-hadoop/</guid> </item> <item><title>Elastic Cloud</title><link>http://ondataengineering.net/technologies/elastic-cloud/</link><pubDate>Thu, 06 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Solution for provisioning, managing and monitoring Elasticsearch clusters (including Kibana and X-Pack) either on AWS as a managed service under a subscription model (Elastic Cloud) or on your own physical or cloud infrastructure (Elastic Cloud Enterprise). Includes support for scripting and plugins, high availability across multiple AWS zones, and supports automated security configuration, upgrades, scaling and backups through a management web UI (Elastic Cloud Console / Cloud UI). Elastic Cloud Enterprise supports the same capability on your own infrastructure, and includes an API in addition to the web UI for configuring and managing clusters, with Elasticsearch and Kibana provisioned using Docker containers. Elastic Cloud is available under a range of subscription licence tiers with differing levels of support and some feature differences; Elastic Cloud Enterprise is freely available but requires you to provide your own Elasticsearch licences. Elastic Cloud was launched in July 2015; Elastic Cloud Enterprise was first released as alpha in December 2016, with a 1.0 GA release in May 2017. Elastic Cloud is the only Elasticsearch service offering that includes X-Pack.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Elastic&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v1.0&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Manages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/cloud&quot;&gt;https://www.elastic.co/cloud&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/cloud/current/index.html&quot;&gt;https://www.elastic.co/guide/en/cloud/current/index.html&lt;/a&gt; - Elastic Cloud documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/cloud-enterprise/current/index.html&quot;&gt;https://www.elastic.co/guide/en/cloud-enterprise/current/index.html&lt;/a&gt; - Elastic Cloud Enterprise documentation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/elastic-cloud/</guid> </item> <item><title>The Mid Week News - 05/07/2017</title><link>http://ondataengineering.net/blog/2017/07/05/the-mid-week-news/</link><pubDate>Wed, 05 Jul 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Right - time for some updates on stuff that’s been happening over the last week. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; has seen a 0.11 release, with support for &lt;a href=&quot;https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/&quot;&gt;exactly once semantics&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Heron, the streaming technology that Twitter built to replace Storm has been donated to the Apache Foundation - see the &lt;a href=&quot;https://wiki.apache.org/incubator/HeronProposal&quot;&gt;proposal&lt;/a&gt; and &lt;a href=&quot;http://incubator.apache.org/projects/heron&quot;&gt;incubator page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A couple of further bits on Heron from Adrian Colyer’s “the morning paper” - one on the &lt;a href=&quot;https://blog.acolyer.org/2017/06/29/twitter-heron-towards-extensible-streaming-engines/&quot;&gt;architecture&lt;/a&gt; and one on &lt;a href=&quot;https://blog.acolyer.org/2017/06/30/dhalion-self-regulating-stream-processing-in-heron/&quot;&gt;Dhalion&lt;/a&gt;, their tool for dynamically managing Heron flows&lt;/li&gt; &lt;li&gt;And &lt;a href=&quot;https://blog.acolyer.org/2017/07/03/spanner-becoming-a-sql-system/&quot;&gt;one more&lt;/a&gt; from “the morning paper” on Google Spanner&lt;/li&gt; &lt;li&gt;An article on &lt;a href=&quot;https://aws.amazon.com/blogs/big-data/seven-tips-for-using-s3distcp-on-amazon-emr-to-move-data-efficiently-between-hdfs-and-amazon-s3/&quot;&gt;S3DistCp&lt;/a&gt; from Amazon - their tool for moving data between &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;S3&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hadoop/hdfs/&quot;&gt;HDFS&lt;/a&gt; that also supports a range of file manipulations.&lt;/li&gt; &lt;li&gt;And on the subject of &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;S3&lt;/a&gt;, Scality have a blog post on &lt;a href=&quot;http://www.scality.com/blog/ever-wanted-filesystem-s3-store/&quot;&gt;s3fs&lt;/a&gt;, an open source tool allowing you to mount S3 buckets as a filesystem&lt;/li&gt; &lt;li&gt;At at the risk of this becoming &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;S3&lt;/a&gt; week, a post from Hortonworks on &lt;a href=&quot;https://hortonworks.com/blog/s3guard-amazon-s3-consistency/&quot;&gt;using S3Guard&lt;/a&gt;, an extension to the Hadoop S3A FileSystem that uses Amazon DynamoDB to make access to S3 strongly consistent&lt;/li&gt; &lt;li&gt;Thoughts from Curt Monash on &lt;a href=&quot;http://www.dbms2.com/2017/06/30/analytics-on-the-edge/&quot;&gt;analytics on the edge&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.gridgain.com/resources/blog/getting-started-apacher-ignitetm-part-4&quot;&gt;Part 4&lt;/a&gt; of the getting started with &lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Apache Ignite&lt;/a&gt; series is out&lt;/li&gt; &lt;li&gt;And because it’s important that open source software pro-actively notifies users around security vulnerabilities, let’s publicise some of them here, starting with &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/www-announce/201706.mbox/%3CC6768663-E7C6-48CC-A480-400218F23486%40apache.org%3E&quot;&gt;an information disclosure&lt;/a&gt; announcement for &lt;a href=&quot;/technologies/apache-ignite&quot;&gt;Apache Ignite&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/05/the-mid-week-news/</guid> </item> <item><title>Elastic X-Pack</title><link>http://ondataengineering.net/technologies/elastic-x-pack/</link><pubDate>Wed, 05 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A set of commercial extensions to the Elastic open source products (Elasticsearch, Kibana and Logstash) including Security (formally Shield), Alerting (formally Watcher), Monitoring (formally Marvel), Reporting, Graph and Machine Learning. Security supports encryption of data and links, user authentication (via LDAP and Active Directory) and authorisation (at the cluster, index, document and field level for Elasticsearch and for access to Kibana) and full audit logging. Monitoring supports captures metrics from Elasticsearch (for clusters, nodes and indexes), Kibana and Logstash, stores these in an Elasticsearch index and exposes them through a set of Kibana dashboards for real time and historical analysis. Alerting supports the scheduling of Elasticsearch queries (e.g. over monitoring data), and configuration and extensible actions (including e-mail and a set of out of the box third party integrations) to be taken if a set of boolean or scripted conditions are met, along with a full history of alerts, all manageable through Kibana. Reporting supports the scheduled or triggered generation and distribution of reports based on Kibana visualisations or dashboards. Graph adds new APIs and Kibana visualisations for working with relationships in data in Elasticsearch, with connections between indexed terms generated on the fly using Elasticsearch aggregations and relevance scoring. Machine Learning adds automated anomaly detection on time-series data in Elasticsearch. Also includes Profiler, a tool for visualising Elasticsearch profiler results. A commercial product from Elastic, with basic monitoring and a search profiler available under a free licence.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;X-Pack&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Elastic&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v5.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add on to&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.5&lt;/td&gt; &lt;td&gt;2017-07-06&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/x-pack/current/xpack-change-list.html#xpack-5.5.0&quot;&gt;change notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Machine Learning GA&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/products/x-pack&quot;&gt;https://www.elastic.co/products/x-pack&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/x-pack/current/index.html&quot;&gt;https://www.elastic.co/guide/en/x-pack/current/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/subscriptions&quot;&gt;https://www.elastic.co/subscriptions&lt;/a&gt; - subscription offerings&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/elastic-x-pack/</guid> </item> <item><title>Elasticsearch</title><link>http://ondataengineering.net/technologies/elasticsearch/</link><pubDate>Tue, 04 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A distributed search server built on Apache Lucene that supports a number of advanced analytics over search results. Data is stored in indexes, with each index able to support multiple schemas (types), with the data itself sharded to support distributed parallel queries, with multiple replicas of each shard providing resilience and redundancy. Supports both pre-defined and schemaless types, all standard Lucene functionality (including faceting, grouping, clustering, hit highlighting, geo support, near real time indexing), the ability to update and delete documents (by id or query), upsert operations, batch operations, re-indexing (from one index into a second index), generated or calculated fields, document versioning and optimistic concurrency control, nested searches based on sub-documents or explicit parent-child document links, templated searches, a range of aggregations (include support for metrics, bucketing results, matrix calculations and custom aggregations using pipelines), custom analysers for indexing data, custom transformation pipelines prior to indexing (via an ingest node), the ability to query across clusters (cross cluster search), a plugin framework, registered queries that are executed against newly indexed data (percolation) and the ability to snapshot and restore indexes using HDFS, S3, Azure and Google Cloud. Comes with a REST API, with clients available for a range of languages including Java, C#, Python, JavaScript, PHP, Perl and Ruby. First released in February 2010, with a 1.0 release in February 2014. Development is led by Elastic, who were formed in 2012 by the creator of Elasticsearch and a lead Lucene contributor, and who provide commercial support, a number of commercial add-ons (Elastic X-Pack) and an on-site or on-AWS cloud service (Elastic Cloud).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Elastic&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;July 2017 - v5.5&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Add ons&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;Elastic X-Pack&lt;/a&gt;, &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch-Hadoop&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Manageable via&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/elastic-cloud/&quot;&gt;Elastic Cloud&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/mapr-monitoring/&quot;&gt;MapR Monitoring&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;5.5&lt;/td&gt; &lt;td&gt;2017-07-06&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.elastic.co/blog/elasticsearch-5-5-0-released&quot;&gt;announcement&lt;/a&gt;; &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/release-notes-5.5.0.html&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Windows installer&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot;&gt;https://www.elastic.co/products/elasticsearch&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/index.html&quot;&gt;https://www.elastic.co/guide/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/elastic/elasticsearch&quot;&gt;https://github.com/elastic/elasticsearch&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/blog&quot;&gt;https://www.elastic.co/blog&lt;/a&gt; - Elastic blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/elasticsearch/</guid> </item> <item><title>The Plan For This Week - 03/07/2017</title><link>http://ondataengineering.net/blog/2017/07/03/the-plan-for-this-week/</link><pubDate>Mon, 03 Jul 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;So this week I’m planning to look at search technologies.&lt;/p&gt; &lt;p&gt;One of the things I want to dig into and explore is the role of search in analytics - search to support users finding stuff on your website, or to find stuff in your enterprise document management system is one thing, but what role does it play if you want to analyse and understand data.&lt;/p&gt; &lt;p&gt;Which means we’ll probably limit our technology list to those technologies that support analytics rather than just search, but let’s see how we go.&lt;/p&gt; &lt;p&gt;See you on Friday…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/07/03/the-plan-for-this-week/</guid> </item> <item><title>Streaming Data Stores</title><link>http://ondataengineering.net/blog/2017/06/30/streaming-data-stores/</link><pubDate>Fri, 30 Jun 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;So this week we’ve been looking at &lt;a href=&quot;/technologies/streaming-data-stores&quot;&gt;streaming data stores&lt;/a&gt;, technologies for the buffering and long term storage of continuous data streams for consumption by multiple downstream consumers.&lt;/p&gt; &lt;p&gt;And as part of that look, I’ve updated our &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; pages, and we’ve taken a look at some new technologies - &lt;a href=&quot;/technologies/pravega&quot;&gt;Pravega&lt;/a&gt;, the new kid on the block, and &lt;a href=&quot;/technologies/confluent-open-source&quot;&gt;Confluent Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/confluent-enterprise&quot;&gt;Confluent Enterprise&lt;/a&gt;, Confluents offerings built around Kafka.&lt;/p&gt; &lt;p&gt;So let’s spout some thoughts on streaming data stores and the technologies we’ve looked at this week. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;I going to make a very bold statement - in a few years time, I have a sneaking suspicion that streaming data stores will be seen as the biggest shakeup of the technology space for getting data into analytical systems for thirty years. Part of this is driven by the rise of streaming analytics, where these technologies are pretty much a de-facto standard for connecting streaming data flows together, but I think they’re going to become the standard for connecting any data processing chains together (most of which I think will become more real-time continuous flows anyway). What I’m really interested about with these technologies is the way they address some of the issues in building batch pipelines - without significant engineering effort these are often extreemly tightly coupled together, causing significant issues if jobs fail or you want to change your pipeline by adding in new flows or re-generating data stores. Persistent data buffers or queues help solve a lot of these problems de-coupling jobs, and although this concept exists in a number of commercial data integration tools, it’s never been a mainstream concept until now.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Apache Kafka&lt;/a&gt; is obviously the technology that’s driven most of this change, and is now seeing significant traction, with commercial support available from Confluent and inclusion in most Hadoop distributions. However the market for these technologies is extreemly immature, and Kafka itself has a number of potential limitations depending on your use case - the primary one being that it’s probably no as elastic as it could be.&lt;/p&gt; &lt;p&gt;Which is why it’s nice to see new technologies appearing in this space, showing there’s a healthy demand for these technologies, and providing competition and diversity. &lt;a href=&quot;/technologies/mapr-streams&quot;&gt;MapR Streams&lt;/a&gt; is one, providing a Kafka compatible API over the MapR file system, and their are a range of cloud base services listed on the &lt;a href=&quot;/technologies/streaming-data-stores&quot;&gt;streaming data stores&lt;/a&gt; technology page, however the one we looked at this week was &lt;a href=&quot;/technologies/pravega&quot;&gt;Pravega&lt;/a&gt; - an open source product coming out of Dell EMC. They’re aiming to address what they see as the limitations of Kafka (summarised &lt;a href=&quot;https://www.slideshare.net/FlinkForward/flink-forward-sf-2017-srikanth-satya-tom-kaitchuck-pravega-storage-reimagined-for-streaming-world/50&quot;&gt;here&lt;/a&gt;), and I think they’re going to be an interesting technology to watch, but it’s still extreemly early days for them - they don’t have a production release yet, there is a significant capability gap to Kafka, and they’re going to need some significant commercial backing and vendor support if they’re going to be successful. What’s clear is that they’re off to a great start, and have already built a significant development community.&lt;/p&gt; &lt;p&gt;Confluent are the biggest backers of Kafka, and we looked at some of their offerings this week as well. They have what they call their Confluent Platform, which in two flavours - &lt;a href=&quot;/technologies/confluent-open-source&quot;&gt;Confluent Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/confluent-enterprise&quot;&gt;Confluent Enterprise&lt;/a&gt;. If you’re planning on using the open source version of Kafka, Confluent Open Source may well be worth a look, even if it’s just to adopt some of their open source components. Confluent Enterprise then gives you full support and extra management features, and what’s interesting here is that although the Hadoop vendors have started bundling Kafka, they don’t yet have an equivalent range of capabilities to Confluent.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/30/streaming-data-stores/</guid> </item> <item><title>Confluent Enterprise</title><link>http://ondataengineering.net/technologies/confluent-enterprise/</link><pubDate>Thu, 29 Jun 2017 08:15:00 +0100</pubDate> <description> &lt;p&gt;A package of software built around Apache Kafka and the Confluent Open Source product, with the addition of a number of commercial closed source products including a JMS client, Control Centre (for managing Kafka clusters), Multi DC Replication (active-active replication between Kafka clusters) and Auto Data Balancing. The JMS client is an implementation of the standard JMS provider interface over a Kafka topic. Control Centre is a web based UI that supports system health monitoring (broker and topic metrics and statuses based on information from the Confluent Metrics Reporter, a plugin for Kafka clusters that reports metrics to a Kafka topic), real time stream monitoring (statistics on the production and consumption of messages including the level of consumption and latency based on statistics from Confluent Monitoring Interceptors, a plugin for Kafka producers and consumers that reports statistics to a Kafka topic), the GUI based creation of Kafka connect pipelines, viewing of cluster and topic information, and e-mail alerting based on custom triggers on on topic, consumer group or broker metrics. Multi DC Replication is an optional licenced connector for Kafka connect that enables replication between two remote Kafka clusters, including active-active synchronisation. Auto Data Balancing is a tool for re-balancing topic partitions across cluster nodes, recommending moves based on information form the Confluent Metrics Reporter and rack awareness to ensure load is distributed evenly across the cluster, and easily allowing for the additional or removal of nodes. Also includes the Confluent Support Metrics features which collects broker and cluster metadata and metrics and forwards these onto Confluent for proactive support. Confluent Enterprise is the commercial version of their Confluent Platform, with an open source version also available as Confluent Open Source. Includes full commercial support for all open and closed source products. First GA release was version 1.0 of the Confluent Platform in February 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Confluent&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - v3.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;, &lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.3&lt;/td&gt; &lt;td&gt;2017-08-01&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.confluent.io/blog/we-will-say-exactly-confluent-platform-3-3-available-now/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/confluent-enterprise/&quot;&gt;https://www.confluent.io/product/confluent-enterprise/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.confluent.io/current/&quot;&gt;http://docs.confluent.io/current/&lt;/a&gt; - Confluent Platform documentation&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/&quot;&gt;https://www.confluent.io/blog/&lt;/a&gt; - Confluent blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/confluent-enterprise/</guid> </item> <item><title>Confluent Open Source</title><link>http://ondataengineering.net/technologies/confluent-open-source/</link><pubDate>Thu, 29 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A package of open source projects built around Apache Kafka with the addition of the Confluent Schema Registry, Kafka REST Proxy, a number of connectors for Kafka Connect and a number of Kafka clients (language SDKs). The Schema Registry allows Kafka message schemas to be defined and versioned centrally, with schemas stored in a Kafka topic, a REST interface for managing schemas, support for schema evolution (with support for backwards, forwards and full compatibility between versions), plugins for Kafka clients to serialise / deserialise messages using the schemas, and support for running as a distributed service. The REST Proxy provides a REST interface onto a Kafka cluster, with support for viewing cluster metadata (covering brokers, topics, partitions and configuration) and both submitting and consuming messages, with support for JSON, JSON-encoded Avro and base64 messages, and integration to the Schema Registry for Avro messages. Bundled connectors for Kafka Connect include HDFS, JDBC, Elasticsearch and S3. Bundled client libraries (all open source) include those for C/C++, Go, .NET and Python. Also includes a Version Collector that reports version information to Confluent. Used to include Camus, a tool for unloading Kafka topics to HDFS, but this has now been deprecated in favour of Kafka Connect. Development of the open source projects is led by Confluent, who then bundle and distribute them for free as the Confluent Open Source version of their Confluent Platform, with the Confluent Enterprise version adding a number of closed source features and commercial support for all open and closed source products. Available as a zip, tar, deb or rpm package from Confluent, with all source code hosted on GitHub. First GA release was version 1.0 of the Confluent Platform in February 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;Confluent&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;August 2017 - v3.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/confluent-enterprise/&quot;&gt;Confluent Enterprise&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.3&lt;/td&gt; &lt;td&gt;2017-08-01&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.confluent.io/blog/we-will-say-exactly-confluent-platform-3-3-available-now/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/confluent-open-source/&quot;&gt;https://www.confluent.io/product/confluent-open-source/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://docs.confluent.io/current/&quot;&gt;http://docs.confluent.io/current/&lt;/a&gt; - Confluent Platform documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/confluentinc&quot;&gt;https://github.com/confluentinc&lt;/a&gt; - Confluent GitHub home&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/&quot;&gt;https://www.confluent.io/blog/&lt;/a&gt; - Confluent blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/confluent-open-source/</guid> </item> <item><title>The Mid Week News - 28/06/2017</title><link>http://ondataengineering.net/blog/2017/06/28/the-mid-week-news/</link><pubDate>Wed, 28 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;News time, and it’s looking dangerously like this is becoming a weekly thing - it won’t last long. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-atlas&quot;&gt;Apache Atlas&lt;/a&gt; has graduated from the Apache incubator&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-calcite&quot;&gt;Apache Calcite&lt;/a&gt; has seen a 1.13 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/building-real-time-streaming-etl-pipeline-20-minutes/&quot;&gt;More thoughts&lt;/a&gt; from Confluent on building ETL pipelines using &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt; and streaming technologies&lt;/li&gt; &lt;li&gt;An excellent &lt;a href=&quot;https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb&quot;&gt;article&lt;/a&gt; from Ozan Onay at Bradfield School of Computer Science on why technologies built for the biggest companies in the world (Google, Amazon, LinkedIn) may not be right for you&lt;/li&gt; &lt;li&gt;From Cloudera - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/06/offset-management-for-apache-kafka-with-apache-spark-streaming/&quot;&gt;how to manage your read position&lt;/a&gt; when reading from &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Two new updates from Cloudera on &lt;a href=&quot;/technologies/cloudera-altus&quot;&gt;Altus&lt;/a&gt; - one on &lt;a href=&quot;http://vision.cloudera.com/announcing-workload-analytics-for-cloudera-altus/&quot;&gt;workload analytics&lt;/a&gt; and the other on &lt;a href=&quot;http://blog.cloudera.com/blog/2017/06/announcing-support-for-spot-instances-in-cloudera-altus/&quot;&gt;support for AWS spot instances&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A post from Sematext on the &lt;a href=&quot;https://sematext.com/blog/2017/06/19/solr-vs-elasticsearch-differences/&quot;&gt;differences&lt;/a&gt; between &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Solr&lt;/a&gt; and &lt;a href=&quot;/technologies/elastic-search&quot;&gt;Elastic Search&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A &lt;a href=&quot;https://cloud.google.com/blog/big-data/2017/06/how-qubit-deduplicates-streaming-data-at-scale-with-google-cloud-platform&quot;&gt;reference case&lt;/a&gt; from Google on how Qubit use Google Cloud Bigtable to identify (and drop) duplicate records&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/28/the-mid-week-news/</guid> </item> <item><title>Pravega</title><link>http://ondataengineering.net/technologies/pravega/</link><pubDate>Tue, 27 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Technology for the buffering and long term storage of streaming data, designed for low latency and high throughput, with support for exactly once semantics, durable writes, strict ordering, dynamic scaling, transactions and long term storage backed by HDFS. Data is stored in named streams (continuous streams of bytes with serialisation and de-serialisation done in clients), with streams partitioned by a Routing Key into stream segments. Data is stored in two tiers, the first using Apache BookKeeper for recent data, the second using HDFS for long term storage, with automatic ageing of data and seamless reads across tiers. Operates on a publish/subscribe model, with subscribers able to select any point in history to read from. Supports automatic scaling of streams (dynamically increasing or decreasing the number of stream segments based on the operations per second on the stream), exactly once semantics (ensuring records are read once and once only even after failure), durable writes (data is persisted before write operations are acknowledged), transactions (multiple events can be committed in a single operation), ordered streams (events will always be read in the same order they're written), ReaderGroups (allows multiple subscribers to co-ordinate reads from a single stream) and a state synchroniser API (allowing multiple clients to synchronise arbitrary state through Pravega). Supports a Java SDK and out of the box integration with Flink, along with support for deployment using docker swarm, dc/os and AWS (all currently in development). Open sourced under an Apache 2.0 licence, started in July 2016 within Dell EMC, and does not yet have a first formal release, but is under active development by a wider range of contributors. Stated plans for future functionality include automatic deletion of data based on a retention period, support for other tier 2 storage technologies, access control, runtime metrics and Spark support.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;June 2017&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://pravega.io/&quot;&gt;http://pravega.io/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://pravega.io/docs/&quot;&gt;http://pravega.io/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://pravega.io/docs/pravega-concepts/&quot;&gt;http://pravega.io/docs/pravega-concepts/&lt;/a&gt; - key concepts&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/pravega/pravega&quot;&gt;https://github.com/pravega/pravega&lt;/a&gt; - GitHub repo&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://blog.pravega.io/&quot;&gt;http://blog.pravega.io/&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/pravega/pravega/releases&quot;&gt;https://github.com/pravega/pravega/releases&lt;/a&gt; - release history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/pravega/</guid> </item> <item><title>Streaming Data Stores</title><link>http://ondataengineering.net/tech-categories/streaming-data-stores/</link><pubDate>Mon, 26 Jun 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Technologies for the persistent storage of continuous streams of data, with data access based on a publish/subscribe model. Should support multiple independant publishers and subscribers, the ability to add new subscribers and replay the history of a stream, horizontal scalability and load balancing, durable writes, ordered streams (data is always read in the order it was written), high throughput and low latency characteristics, handling of updates and deletes to source records, and the ability to secure the data.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;open-source-technologies&quot;&gt;Open Source Technologies&lt;/h2&gt; &lt;p&gt;The following are open source Streaming Data Store technologies:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for buffering and storing real-time streams of data between publishers to subscribers, with a focus on high throughput at low latency.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A package of open source projects built around &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; with the addition of the Confluent Schema Registry, Kafka REST Proxy, a number of connectors for Kafka Connect and a number of Kafka clients (language SDKs).&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/pravega/&quot;&gt;Pravega&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Technology for the buffering and long term storage of streaming data, designed for low latency and high throughput, with support for exactly once semantics, durable writes, strict ordering, dynamic scaling, transactions and long term storage backed by HDFS.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;commercial-technologies&quot;&gt;Commercial Technologies&lt;/h2&gt; &lt;p&gt;The following are commercial Streaming Data Store technologies:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/confluent-enterprise/&quot;&gt;Confluent Enterprise&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A commercial version of the Confluent Open Source product, with the addition of a number of commercial closed source products including a JMS client, Control Centre (for managing Kafka clusters), Multi DC Replication (active-active replication between Kafka clusters) and Auto Data Balancing.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-streams&quot;&gt;MapR Streams&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Extension to the MapR FileSystem to provide streaming data storage capabilities and a Kafka compatible API&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;technologies-available-as-a-service&quot;&gt;Technologies Available as a Service&lt;/h2&gt; &lt;p&gt;The following are Streaming Data Store technologies available as a managed service in the cloud:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Confluent Cloud&lt;/td&gt; &lt;td&gt;Confluent Enterprise as a service - &lt;a href=&quot;https://www.confluent.io/confluent-cloud/&quot;&gt;https://www.confluent.io/confluent-cloud/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Amazon Kinesis Streams&lt;/td&gt; &lt;td&gt;Streaming data storage and publish service - &lt;a href=&quot;https://aws.amazon.com/kinesis/streams/&quot;&gt;https://aws.amazon.com/kinesis/streams/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Event Hubs&lt;/td&gt; &lt;td&gt;Elastic service for the buffering and publishing of streaming event data - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/event-hubs/&quot;&gt;https://azure.microsoft.com/en-us/services/event-hubs/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Pub/Sub&lt;/td&gt; &lt;td&gt;Real time message and streaming data service with “at least once” delivery - &lt;a href=&quot;https://cloud.google.com/pubsub/&quot;&gt;https://cloud.google.com/pubsub/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;hadoop-distributions&quot;&gt;Hadoop Distributions&lt;/h2&gt; &lt;p&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; is also bundled with a number of Hadoop distributions:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Cloudera’s distribution of Hadoop, available in free and commercial versions and in the cloud&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks Data Flow&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distribution of a set of Apache open source technologies (primarily NiFi, Kafka and Storm) for processing streaming data, available for free with commercial support also available&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An Apache open source distribution of Hadoop&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/streaming-data-stores/</guid> </item> <item><title>The Plan For This Week - 26/06/2017</title><link>http://ondataengineering.net/blog/2017/06/26/the-plan-for-this-week/</link><pubDate>Mon, 26 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;So the plan for this week is to look at streaming data stores - Kafka, Pravega and maybe some of the cloud based services.&lt;/p&gt; &lt;p&gt;Message Ends.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/26/the-plan-for-this-week/</guid> </item> <item><title>Hadoop Distributions</title><link>http://ondataengineering.net/tech-categories/hadoop-distributions/</link><pubDate>Fri, 23 Jun 2017 17:30:00 +0100</pubDate> <description> &lt;p&gt;Products or services built around Hadoop (or an Hadoop compatible core) combined with a number of Hadoop compatible products. Hadoop compatibility covers the use of YARN (for resource management of multiple jobs running on the same infrastructure) and HDFS (for local storage of data with support for co-locating processing with the data).&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;h2 id=&quot;further-information&quot;&gt;Further Information&lt;/h2&gt; &lt;p&gt;See also our Hadoop (HDFS and YARN) &lt;a href=&quot;/tech-categories/hadoop-distributions/ecosystem/&quot;&gt;ecosystem diagrams&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We also have a summary of the &lt;a href=&quot;/tech-vendors/odpi/&quot;&gt;ODPi&lt;/a&gt; organisation that’s trying to drive compatibility between Hadoop distributions.&lt;/p&gt; &lt;h2 id=&quot;commercial-distributions&quot;&gt;Commercial Distributions&lt;/h2&gt; &lt;p&gt;The following are distributions from commercial vendors for installation on pre-provisioned infrastructure, with many also including tooling for programmatically provisioning infrastructure when installing in cloud environments.&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distribution of Hadoop based on the addition of a number of closed source products, including Cloudera Manager (for installing and managing clusters), Cloudera Director (for installing in cloud environments) and Cloudera Navigator (for managing metadata and the encryption of data). Available in free and commercial editions.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;Hortonworks Data Platform&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A distribution of Hadoop based on a commitment to the Apache open source ecosystem, utilising only open source products with minimal extra patching. Uses Ambari for installing and managing clusters, and Cloudbreak for installing in cloud environments. Free to use with commercial support available.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;&lt;/td&gt; &lt;td&gt;A data platform built around MapR-FS (along with MapR-DB and MapR-Streams) that provides Hadoop compatibility (via YARN and the MapR-FS HDFS compatible API) and is bundled with a package of Hadoop projects via the MapR Ecosystem Pack. Available in free and commercial editions.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Syncfusion Big Data Platform&lt;/td&gt; &lt;td&gt;Distribution for Windows - &lt;a href=&quot;https://www.syncfusion.com/products/big-data&quot;&gt;https://www.syncfusion.com/products/big-data&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;See also our &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;comparison&lt;/a&gt; of the major commercial Hadoop distributions.&lt;/p&gt; &lt;h2 id=&quot;hadoop-cloud-offerings&quot;&gt;Hadoop Cloud Offerings&lt;/h2&gt; &lt;p&gt;The following are cloud based Hadoop service offerings, supporting the programmatic provisioning and management of Hadoop clusters. Many also provide higher level APIs that allow for submission and management of individual Hadoop jobs, with some services allowing clusters to be automatically provisioned to execute a job and then terminated afterwards.&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Amazon EMR&lt;/td&gt; &lt;td&gt;Hadoop as a service, with support for a wide range of Hadoop technologies and the ability to programmatically execute Hadoop jobs and dynamically provision clusters to execute these - &lt;a href=&quot;https://aws.amazon.com/emr/&quot;&gt;https://aws.amazon.com/emr/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Microsoft Azure HD Insight&lt;/td&gt; &lt;td&gt;Hadoop service based on &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;HDP&lt;/a&gt; - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/hdinsight/&quot;&gt;https://azure.microsoft.com/en-us/services/hdinsight/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Dataproc&lt;/td&gt; &lt;td&gt;Hadoop service, with support for MapReduce, Spark, Pig and Hive, and the ability to programatically submit and manage jobs - &lt;a href=&quot;https://cloud.google.com/dataproc/&quot;&gt;https://cloud.google.com/dataproc/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Platform for accessing individual CDH capabilities as services, with the first capabilities supported being the execution of Spark, MapReduce or Hive (over MapReduce or Spark) jobs using managed CDH clusters on AWS cloud infrastructure over data in Amazon S3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SAP Cloud Platform Big Data Services (previously Altiscale)&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://cloudplatform.sap.com/capabilities/data-storage/big-data.html&quot;&gt;https://cloudplatform.sap.com/capabilities/data-storage/big-data.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Rackspace&lt;/td&gt; &lt;td&gt;Based on Hortonworks HDP - &lt;a href=&quot;https://www.rackspace.com/big-data&quot;&gt;https://www.rackspace.com/big-data&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Qubole Data Service&lt;/td&gt; &lt;td&gt;Runs on the major clouds - &lt;a href=&quot;https://www.qubole.com/&quot;&gt;https://www.qubole.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;hadoop-hardware-appliances&quot;&gt;Hadoop Hardware Appliances&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Teradata Appliance for Hadoop&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;http://www.teradata.com/products-and-services/appliance-for-hadoop&quot;&gt;http://www.teradata.com/products-and-services/appliance-for-hadoop&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Oracle Big Data Appliance&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://www.oracle.com/engineered-systems/big-data-appliance/index.html&quot;&gt;https://www.oracle.com/engineered-systems/big-data-appliance/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;non-commercial-options&quot;&gt;Non Commercial Options&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-bigtop/&quot;&gt;Apache Bigtop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;An Apache open source distribution of Hadoop. Packages up a number of Apache Hadoop components, certifies their interoperability using an automated integration test suite, and packages them up as RPMs/DEBs packages for most flavours of Linux.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;OpenStack Sahara&lt;/td&gt; &lt;td&gt;Allows provisioning of Hadoop on OpenStack - &lt;a href=&quot;https://docs.openstack.org/developer/sahara/&quot;&gt;https://docs.openstack.org/developer/sahara/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Hops&lt;/td&gt; &lt;td&gt;A distribution based on Hops HDFS and Hops YARN which use a distributed MySQL database for metadata to increase performance and scalability, available as a cloud or on premises offering - &lt;a href=&quot;http://www.hops.io&quot;&gt;http://www.hops.io&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;historical--legacy-options&quot;&gt;Historical / Legacy Options&lt;/h2&gt; &lt;p&gt;The following are either no longer available, or are now simply re-badged versions of other distributions:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Intel Distribution for Apache Hadoop&lt;/td&gt; &lt;td&gt;Focused on optimisations for Intel processors, SSD disks and networking kit; ceased when Intel invested into Cloudera - see &lt;a href=&quot;https://newsroom.intel.com/news-releases/cloudera-intel-commit-to-accelerate-and-transform-how-enterprises-use-big-data-intel-makes-significant-equity-investment-in-cloudera/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Pivotal HD&lt;/td&gt; &lt;td&gt;Pivotal has now partnered with Hortonworks - see &lt;a href=&quot;https://hortonworks.com/press-releases/hortonworks-pivotal-expand-relationship-deliver-enterprise-ready-modern-data-platforms-data-management-analytics/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM InfoSphere BigInsights&lt;/td&gt; &lt;td&gt;IBM has now partnered with Hortonworks - see &lt;a href=&quot;https://hortonworks.com/blog/data-met-science-anything-became-possible/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/hadoop-distributions/</guid> </item> <item><title>Hadoop in the Cloud</title><link>http://ondataengineering.net/blog/2017/06/23/hadoop-in-the-cloud/</link><pubDate>Fri, 23 Jun 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;So this week has been a bit of a scattergun - one technology (&lt;a href=&quot;/technologies/cloudera-altus&quot;&gt;Cloudera Altus&lt;/a&gt;), three vendors (&lt;a href=&quot;/tech-vendors/amazon-web-services&quot;&gt;Amazon Web Services&lt;/a&gt;, &lt;a href=&quot;/tech-vendors/microsoft-azure&quot;&gt;Microsoft Azure&lt;/a&gt; and &lt;a href=&quot;/tech-vendors/google-cloud-platform&quot;&gt;Google Cloud Platform&lt;/a&gt; - and yes, I know they’re not technically vendors) and one (refreshed) technology category (&lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distributions&lt;/a&gt;) - with the overriding theme of thinking about Hadoop in the cloud. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Every Hadoop distribution that you can install on your own physical hardware can also be installed on virtual infrastructure in a cloud in exactly the same way, however this is a spectacular way to avoid the benefits a cloud brings, and unless you’re going to be using your cluster all the time, probably an expensive way to do it given you’ll pay for your infrastructure by the hour.&lt;/p&gt; &lt;p&gt;So what every Hadoop vendor has done (with technologies like &lt;a href=&quot;/technologies/cloudera-director&quot;&gt;Cloudera Director&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt;), and what all the cloud providers now offer, is a way to automatically provision the infrastructure you need as part of deploying your Hadoop cluster, allowing you to spin up entire Hadoop clusters in minutes, and enabling the use of transient clusters which only exist for the period of time required to run a specific job or workload (although you’ll obviously need to persist your output into a persistent store). And we’ve now moved to Hadoop as a service, and we don’t care about the infrastructure anymore.&lt;/p&gt; &lt;p&gt;What Cloudera have done with &lt;a href=&quot;/technologies/cloudera-altus&quot;&gt;Cloudera Altus&lt;/a&gt;, and what Amazon did with Elastic Map Reduce a long time ago, is to elevate the stack one level higher to the Hadoop job - you can submit an Hadoop job (Hive, Spark, MapReduce) to Altus, and it will provision some infrastructure, create a cluster, run the job and then tear everything down. And we’ve now moved to Hadoop jobs as a service, and we don’t care about the clusters anymore.&lt;/p&gt; &lt;p&gt;If you’re working in the cloud this feels like the natural evolution of the cloud story, and to be blunt, even if you’re working on premises, having an on premises cloud that allows you to do this seems like an natural evolution (and in which case OpenStack Sahara might well be worth a look). And this feels like an area of differentiation between the various Hadoop cloud offerings at the moment - a lot of them allow you to programmatically run jobs via their API, but few allow the execution of jobs to automatically provision and tear down clusters, although you can obviously orchestrate this yourself.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/23/hadoop-in-the-cloud/</guid> </item> <item><title>Google Cloud Platform</title><link>http://ondataengineering.net/tech-vendors/google-cloud-platform/</link><pubDate>Thu, 22 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A cloud computing service operated by Google, with support for infrastructure, storage, databases and analytics services. First services were available in preview in April 2008.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Vendor Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Google&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;infrastructure-services&quot;&gt;Infrastructure Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Compute Engine&lt;/td&gt; &lt;td&gt;Virtual servers - &lt;a href=&quot;https://cloud.google.com/compute/&quot;&gt;https://cloud.google.com/compute/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Container Engine&lt;/td&gt; &lt;td&gt;Kubernetes cluster service - &lt;a href=&quot;https://cloud.google.com/container-engine/&quot;&gt;https://cloud.google.com/container-engine/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Persistent Disk&lt;/td&gt; &lt;td&gt;Block storage for virtual machines - &lt;a href=&quot;https://cloud.google.com/persistent-disk/&quot;&gt;https://cloud.google.com/persistent-disk/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;storage-services&quot;&gt;Storage Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/google-cloud-storage/&quot;&gt;Google Cloud Storage&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Object store service with strong consistency, multiple storage tiers and deep integration to the Google Cloud ecosystem.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;compute-services&quot;&gt;Compute Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Functions&lt;/td&gt; &lt;td&gt;Serverless code execution service - &lt;a href=&quot;https://cloud.google.com/functions/&quot;&gt;https://cloud.google.com/functions/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;database-services&quot;&gt;Database Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Dataproc&lt;/td&gt; &lt;td&gt;Hadoop service, with support for MapReduce, Spark, Pig and Hive - &lt;a href=&quot;https://cloud.google.com/dataproc/&quot;&gt;https://cloud.google.com/dataproc/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Spanner&lt;/td&gt; &lt;td&gt;Horizontally scalable relational database for transaction processing - &lt;a href=&quot;https://cloud.google.com/spanner/&quot;&gt;https://cloud.google.com/spanner/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud SQL&lt;/td&gt; &lt;td&gt;Managed database service, with support for MySQL and PostgreSQL - &lt;a href=&quot;https://cloud.google.com/sql/&quot;&gt;https://cloud.google.com/sql/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Big Query&lt;/td&gt; &lt;td&gt;Analytical SQL database service - &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;https://cloud.google.com/bigquery/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Bigtable&lt;/td&gt; &lt;td&gt;NoSQL wide column store service - &lt;a href=&quot;https://cloud.google.com/bigtable/&quot;&gt;https://cloud.google.com/bigtable/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Datastore&lt;/td&gt; &lt;td&gt;NoSQL document store service - &lt;a href=&quot;https://cloud.google.com/datastore/&quot;&gt;https://cloud.google.com/datastore/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;analytics-services&quot;&gt;Analytics Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Datalab&lt;/td&gt; &lt;td&gt;Web based data exploration and analysis tool based on Jupyter - &lt;a href=&quot;https://cloud.google.com/datalab/&quot;&gt;https://cloud.google.com/datalab/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Data Studio&lt;/td&gt; &lt;td&gt;Drag and drop reporting and dashboarding tool - &lt;a href=&quot;https://cloud.google.com/data-studio/&quot;&gt;https://cloud.google.com/data-studio/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-data-services&quot;&gt;Streaming Data Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Pub/Sub&lt;/td&gt; &lt;td&gt;Real time message and streaming data service with “at least once” delivery - &lt;a href=&quot;https://cloud.google.com/pubsub/&quot;&gt;https://cloud.google.com/pubsub/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Dataflow&lt;/td&gt; &lt;td&gt;Batch and streaming data flow service based on Apache Beam - &lt;a href=&quot;https://cloud.google.com/dataflow/&quot;&gt;https://cloud.google.com/dataflow/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-integration-services&quot;&gt;Data Integration Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Dataprep&lt;/td&gt; &lt;td&gt;Data preparation service (in private beta) for “visually exploring, cleaning, and preparing structured and unstructured data for analysis” - &lt;a href=&quot;https://cloud.google.com/dataprep/&quot;&gt;https://cloud.google.com/dataprep/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;machine-learning-services&quot;&gt;Machine Learning Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Google Cloud Machine Learning Engine&lt;/td&gt; &lt;td&gt;Machine learning service based on TensorFlow - &lt;a href=&quot;https://cloud.google.com/ml-engine/&quot;&gt;https://cloud.google.com/ml-engine/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Google Machine Learning Services&lt;/td&gt; &lt;td&gt;Suite of machine learning services including video, image, speech and text analysis - &lt;a href=&quot;https://cloud.google.com/products/machine-learning/&quot;&gt;https://cloud.google.com/products/machine-learning/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/&quot;&gt;https://cloud.google.com/&lt;/a&gt; - Google Cloud Platform homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/products/&quot;&gt;https://cloud.google.com/products/&lt;/a&gt; - products homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cloudplatform.googleblog.com/&quot;&gt;https://cloudplatform.googleblog.com/&lt;/a&gt; - Google Cloud Platform blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/blog/big-data/&quot;&gt;https://cloud.google.com/blog/big-data/&lt;/a&gt; - Google Cloud Platform Big Data and Machine Learning blog&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/google-cloud-platform/</guid> </item> <item><title>The Mid Week News - 21/06/2017</title><link>http://ondataengineering.net/blog/2017/06/21/the-mid-week-news/</link><pubDate>Wed, 21 Jun 2017 08:00:00 +0100</pubDate> <description> &lt;p&gt;Time for some news, and only a week since we last did it! &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-pig&quot;&gt;Apache Pig&lt;/a&gt; has seen a 0.17 release, with support for using Spark as an execution engine introduced to complement the existing support for Tez and MapReduce&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kudu&quot;&gt;Apache Kudu&lt;/a&gt; has seen a 1.4 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudbreak&quot;&gt;Cloudbreak&lt;/a&gt; has seen a 1.16 release, adding support for Hortonworks Flex Support Subscription&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala&quot;&gt;Apache Impala&lt;/a&gt; has seen a 2.9 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hortonworks-data-cloud-for-aws&quot;&gt;Hortonworks Data Cloud for AWS&lt;/a&gt; has a tech preview of it’s 2.0 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://www.zdnet.com/article/kafka-the-story-so-far/&quot;&gt;Interesting post&lt;/a&gt; on the history of &lt;a href=&quot;/technologies/apache-kafka&quot;&gt;Kafka&lt;/a&gt; from ZDNet&lt;/li&gt; &lt;li&gt;Yahoo have &lt;a href=&quot;https://yahooeng.tumblr.com/post/161855616651/open-sourcing-bullet-yahoos-forward-looking&quot;&gt;open sourced Bullet&lt;/a&gt;, a “forward looking query engine” for streaming data&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.datanami.com/2017/06/14/hortonworks-shifts-focus-streaming-analytics/&quot;&gt;A view&lt;/a&gt; from Datanami on the latest &lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;HDF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/part-4-sams-stream-builder-building-complex-stream-analytics-apps-without-code/&quot;&gt;Part 4&lt;/a&gt; of Hortonworks intro to &lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;HDF&lt;/a&gt; 3.0 looking at stream builder (the GUI for building streaming flows)&lt;/li&gt; &lt;li&gt;A little old, but a still useful &lt;a href=&quot;http://www.dbms2.com/2016/08/21/introduction-to-data-artisans-and-flink/&quot;&gt;view&lt;/a&gt; on Data Artisans and &lt;a href=&quot;/technologies/apache-flink&quot;&gt;Flink&lt;/a&gt; from Curt Monash&lt;/li&gt; &lt;li&gt;A more recent post from Curt, with &lt;a href=&quot;http://www.dbms2.com/2017/06/14/cloudera-altus/&quot;&gt;his views&lt;/a&gt; on &lt;a href=&quot;/technologies/cloudera-altus&quot;&gt;Cloudera Altus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://blog.knoldus.com/2017/06/13/spark-streaming-vs-kafka-stream/&quot;&gt;A view&lt;/a&gt; on &lt;a href=&quot;/technologies/apache-spark/spark-streaming&quot;&gt;Spark Streaming&lt;/a&gt; vs &lt;a href=&quot;/technologies/apache-kafka/kafka-streams&quot;&gt;Kafka Streams&lt;/a&gt;&lt;/li&gt; &lt;li&gt;More views on the IBM-Hortonworks &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;HDP&lt;/a&gt; deal from &lt;a href=&quot;https://www.theregister.co.uk/2017/06/15/ibm_adopts_hortonworks_for_hadoop_distribution/&quot;&gt;The Register&lt;/a&gt; and &lt;a href=&quot;http://blogs.gartner.com/merv-adrian/2017/06/21/ibm-ends-hadoop-distribution-hortonworks-expands-hybrid-open-source/&quot;&gt;Gartner&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks are &lt;a href=&quot;https://hortonworks.com/blog/hortonworks-when-youre-hot-youre-really-hot/&quot;&gt;blowing their trumpet&lt;/a&gt; (no pun intended) on their &lt;a href=&quot;/technologies/hortonworks-data-flow&quot;&gt;HDF&lt;/a&gt; 3.0 release and their IBM &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;HDP&lt;/a&gt; deal&lt;/li&gt; &lt;li&gt;Cloudera have published &lt;a href=&quot;http://blog.cloudera.com/blog/2017/06/solr-memory-tuning-for-production-part-2/&quot;&gt;part 2&lt;/a&gt; of their Solr memory tuning guide&lt;/li&gt; &lt;li&gt;And finally, Databricks’ &lt;a href=&quot;https://databricks.com/blog/2017/05/31/top-5-reasons-for-choosing-s3-over-hdfs.html&quot;&gt;view&lt;/a&gt; on &lt;a href=&quot;/tech-categories/object-stores&quot;&gt;object storage&lt;/a&gt; (specifically S3) vs &lt;a href=&quot;/tech-categories/hadoop-compatible-filesystems&quot;&gt;HDFS&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/06/21/the-mid-week-news/</guid> </item> <item><title>Microsoft Azure</title><link>http://ondataengineering.net/tech-vendors/microsoft-azure/</link><pubDate>Wed, 21 Jun 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;A cloud computing service operated by Microsoft, with support for infrastructure, storage, databases and analytics services, available in 34 geographical regions. Announced in Otober 2008, with first services available in February 2010. Previously known as Windows Azure.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Vendor Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Azure&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;!-- Technology metadata --&gt; &lt;h2 id=&quot;infrastructure-services&quot;&gt;Infrastructure Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Virtual Machines&lt;/td&gt; &lt;td&gt;Virtual servers with support for a range of operating systems and pre-build images, and for management at scale (Virtual Machine Scale Sets) - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/virtual-machines/&quot;&gt;https://azure.microsoft.com/en-us/services/virtual-machines/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Container Service&lt;/td&gt; &lt;td&gt;Container service using DC/OS, Docker Swarm or Kubernetes - &lt;a href=&quot;https://azure.microsoft.com/en-gb/services/container-service/&quot;&gt;https://azure.microsoft.com/en-gb/services/container-service/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Disk Storage&lt;/td&gt; &lt;td&gt;Persistent disk storage to support virtual machines - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/unmanaged-disks/&quot;&gt;https://azure.microsoft.com/en-us/services/storage/unmanaged-disks/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;storage-services&quot;&gt;Storage Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure File Storage&lt;/td&gt; &lt;td&gt;Network storage, mountable on multiple machines over REST and SMB - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/files/&quot;&gt;https://azure.microsoft.com/en-us/services/storage/files/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/microsoft-azure-blob-storage/&quot;&gt;Azure Blob Storage&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Highly scalable and resilient object storage&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/microsoft-azure-data-lake-store/&quot;&gt;Azure Data Lake Store&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Massively scalable HDFS compatible filesystem as a service, based on Microsoft’s Cosmos technology&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;compute-services&quot;&gt;Compute Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Functions&lt;/td&gt; &lt;td&gt;Service for executing arbitrary code in response to a trigger or timer - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/functions/&quot;&gt;https://azure.microsoft.com/en-us/services/functions/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Batch&lt;/td&gt; &lt;td&gt;Service for executing batch jobs across a pool of compute servers - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/batch/&quot;&gt;https://azure.microsoft.com/en-us/services/batch/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;database-services&quot;&gt;Database Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure HDInsight&lt;/td&gt; &lt;td&gt;Hadoop service based on &lt;a href=&quot;/technologies/hortonworks-data-platform&quot;&gt;HDP&lt;/a&gt;, with support a range of Hadoop technologies including Spark, Hive, MapReduce, HBase, Storm, Kafka, and Microsoft R Server - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/hdinsight/&quot;&gt;https://azure.microsoft.com/en-us/services/hdinsight/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure SQL Database&lt;/td&gt; &lt;td&gt;Scalable relational database - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/sql-database/&quot;&gt;https://azure.microsoft.com/en-us/services/sql-database/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Database for MySQL&lt;/td&gt; &lt;td&gt;MySQL as a service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/mysql/&quot;&gt;https://azure.microsoft.com/en-us/services/mysql/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Database for PostgreSQL&lt;/td&gt; &lt;td&gt;PostgreSQL as a service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/postgresql/&quot;&gt;https://azure.microsoft.com/en-us/services/postgresql/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure SQL Data Warehouse&lt;/td&gt; &lt;td&gt;Scalable analytical database - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/sql-data-warehouse/&quot;&gt;https://azure.microsoft.com/en-us/services/sql-data-warehouse/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Redis Cache&lt;/td&gt; &lt;td&gt;Redis as a service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cache/&quot;&gt;https://azure.microsoft.com/en-us/services/cache/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Table Storage&lt;/td&gt; &lt;td&gt;A NoSQL wide column store service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/tables/&quot;&gt;https://azure.microsoft.com/en-us/services/storage/tables/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Cosmos DB&lt;/td&gt; &lt;td&gt;Massively scalable, low latency multi-model (key-value, graph and document) NoSQL database, previously known as Azure DocumentDB - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cosmos-db/&quot;&gt;https://azure.microsoft.com/en-us/services/cosmos-db/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Search&lt;/td&gt; &lt;td&gt;Search service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/search/&quot;&gt;https://azure.microsoft.com/en-us/services/search/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;analytics-services&quot;&gt;Analytics Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Data Lake Analytics&lt;/td&gt; &lt;td&gt;Massively parallel analytics job service, with support for U-SQL, R, Python, and .NET - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/data-lake-analytics/&quot;&gt;https://azure.microsoft.com/en-us/services/data-lake-analytics/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Data Catalog&lt;/td&gt; &lt;td&gt;A metadata catalog service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/data-catalog/&quot;&gt;https://azure.microsoft.com/en-us/services/data-catalog/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Time Series Insights&lt;/td&gt; &lt;td&gt;Storage, analytics and visualisation service for time series data, currently in preview - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/time-series-insights/&quot;&gt;https://azure.microsoft.com/en-us/services/time-series-insights/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-data-services&quot;&gt;Streaming Data Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Event Hubs&lt;/td&gt; &lt;td&gt;Elastic service for the buffering and publishing of streaming event data - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/event-hubs/&quot;&gt;https://azure.microsoft.com/en-us/services/event-hubs/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Stream Analytics&lt;/td&gt; &lt;td&gt;Service for querying streams of data using a SQL like language - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/stream-analytics/&quot;&gt;https://azure.microsoft.com/en-us/services/stream-analytics/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;data-integration-services&quot;&gt;Data Integration Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Data Factory&lt;/td&gt; &lt;td&gt;Data transformation workflow management - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/data-factory/&quot;&gt;https://azure.microsoft.com/en-us/services/data-factory/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Scheduler&lt;/td&gt; &lt;td&gt;Scheduling as a service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/scheduler/&quot;&gt;https://azure.microsoft.com/en-us/services/scheduler/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;machine-learning-services&quot;&gt;Machine Learning Services&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Azure Machine Learning&lt;/td&gt; &lt;td&gt;Machine learning service - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/machine-learning/&quot;&gt;https://azure.microsoft.com/en-us/services/machine-learning/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Azure Cognitive Services&lt;/td&gt; &lt;td&gt;Suite of services including vision, speech and text analysis - &lt;a href=&quot;https://azure.microsoft.com/en-us/services/cognitive-services/&quot;&gt;https://azure.microsoft.com/en-us/services/cognitive-services/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/&quot;&gt;https://azure.microsoft.com/&lt;/a&gt; - Amazon Web Services homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/services/&quot;&gt;https://azure.microsoft.com/en-us/services/&lt;/a&gt; - products homepage&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/&quot;&gt;https://azure.microsoft.com/en-us/blog/&lt;/a&gt; - Azure Blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/topics/announcements/&quot;&gt;https://azure.microsoft.com/en-us/blog/topics/announcements/&lt;/a&gt; - Azure Blog (announcements)&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-vendors/microsoft-azure/</guid> </item> </channel> </rss>
