<?xml version="1.0" encoding="UTF-8"?> <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"> <channel><title>OnDataEngineering</title><description>A collaborative site for independent, critical and technical thinking on the use cases, architectural patterns and technologies relating to the transformation and preparation of data for exploitation.</description><link>http://ondataengineering.net/</link><atom:link href="http://ondataengineering.net/feed.xml" rel="self" type="application/rss+xml" /> <item><title>The Week That Was - 08/06/2018</title><link>http://ondataengineering.net/blog/2018/06/08/the-week-that-was/</link><pubDate>Fri, 08 Jun 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;There are more major site updates coming, hopefully next week, but in the meantime there’s been some minor updates this week… &lt;!--more--&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Added Azure Time Series Insights to the &lt;a href=&quot;/tech-categories/time-series-databases/&quot;&gt;Time Series Databases&lt;/a&gt; tech category from which it was missing&lt;/li&gt; &lt;li&gt;Added Kafka Streams to the Streaming Analytics section of the &lt;a href=&quot;/tech-vendors/apache/&quot;&gt;Apache&lt;/a&gt; tech vendor page from which it was missing&lt;/li&gt; &lt;li&gt;Finally updated the &lt;a href=&quot;/technologies/apache-hadoop/hdfs/&quot;&gt;HDFS&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt; pages for Hadoop 3.0 and 3.1, although both these summaries could do with more work&lt;/li&gt; &lt;li&gt;Finally updated the &lt;a href=&quot;/technologies/apache-druid/&quot;&gt;Druid&lt;/a&gt; page to rename this to Apache Druid following it’s donation to the Apache Foundation&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/06/08/the-week-that-was/</guid> </item> <item><title>The Mid Week News 06/06/2018</title><link>http://ondataengineering.net/blog/2018/06/06/the-mid-week-news/</link><pubDate>Wed, 06 Jun 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s a bumper week this week as there was no news last week ‘cos I was on holiday! Lucky me. So here we go… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt; has hit 1.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-carbondata/&quot;&gt;Apache CarbonData&lt;/a&gt; has hit 1.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; has hit 1.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt; has hit 2.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-slider/&quot;&gt;Apache Slider&lt;/a&gt; has been retired from the Apache Incubator&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/scality-ring/&quot;&gt;Scality RING&lt;/a&gt; has hit 7.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/streamsets-data-collector/&quot;&gt;StreamSets Data Collector&lt;/a&gt; has hit 3.3&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;ZDNet have a good summary of the upcoming &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Spark&lt;/a&gt; Summit - &lt;a href=&quot;https://www.zdnet.com/article/spark-summit-2018-preview-putting-ai-up-front-and-giving-r-and-python-programmers-more-respect/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Cloudera have published their latest post on deploying &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;, this time looking at the cloud - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/05/deploy-cloudera-edh-clusters-like-a-boss-revamped-part-3-cloud-considerations/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks have published their lastest post on &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; 3 looking at running &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Spark&lt;/a&gt; in Docker containers on Hadoop - &lt;a href=&quot;https://hortonworks.com/blog/containerized-apache-spark-yarn-apache-hadoop-3-1/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And also from Hortonworks - their latest view on Data Steward Studio, part of the &lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;DataPlane Service&lt;/a&gt; - &lt;a href=&quot;https://hortonworks.com/blog/discover-data-steward-studio-dss-understand-hybrid-data-lakes-exploit-business-value/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Amazon Neptune is now generally available - &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-neptune-generally-available/&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;https://www.zdnet.com/article/aws-neptune-going-ga-the-good-the-bad-and-the-ugly-for-graph-database-users-and-vendors/&quot;&gt;ZDNet view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;TheRegister have a thought provoking piece on the rise of open source databases and what this means for Oracle - &lt;a href=&quot;https://www.theregister.co.uk/2018/05/31/rise_of_the_open_source_data_strategies/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;InfoQ have an interesting article on columnar databases, vectorisation and &lt;a href=&quot;/technologies/apache-arrow/&quot;&gt;Apache Arrow&lt;/a&gt; - &lt;a href=&quot;https://www.infoq.com/articles/columnar-databases-and-vectorization?utm_campaign=infoq_content&amp;amp;utm_source=infoq&amp;amp;utm_medium=feed&amp;amp;utm_term=global&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet - how different data and analytics vendors are supporting GDPR - &lt;a href=&quot;https://www.zdnet.com/article/gdpr-what-the-data-companies-are-offering/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Databricks have announced Databricks Runtime 4.1 - &lt;a href=&quot;https://databricks.com/blog/2018/05/23/announcing-databricks-runtime-4-1.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;It looks like Google have just acquired Cask - &lt;a href=&quot;https://www.datanami.com/2018/05/22/google-cloud-adds-cask-data/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Confluent Cloud is now available on Google Cloud as well as AWS - &lt;a href=&quot;https://cloud.google.com/blog/big-data/2018/05/google-cloud-platform-and-confluent-partner-to-deliver-a-managed-apache-kafka-service&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And rounding us out, a munch of vulnerability announcements this week &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0114&quot;&gt;CVE-2014-0114&lt;/a&gt; - execution of arbitrary code with Apache Commons BeanUtils now impacts &lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1309&quot;&gt;CVE-2018-1309&lt;/a&gt; - &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; External XML Entity issue in SplitXML processor&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1310&quot;&gt;CVE-2018-1310&lt;/a&gt; - &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; Apache NiFi JMS Deserialization issue&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-8028&quot;&gt;CVE-2017-8028&lt;/a&gt; - Spring Security LDPA issue impacts &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1324&quot;&gt;CVE-2018-1324&lt;/a&gt; - Apache Commons Compress issue impacts &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/06/06/the-mid-week-news/</guid> </item> <item><title>The Mid Week News 23/05/2018</title><link>http://ondataengineering.net/blog/2018/05/23/the-mid-week-news/</link><pubDate>Wed, 23 May 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s time for the news again - let’s go… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; 1.4 has been announced - due out in June&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt; 6.0 has been announced, out now in beta&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt; Data Engineering is now GA and Analytics DB is now beta on Azure&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt; 3.0 is out&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;Hortonworks DataPlane Services&lt;/a&gt; is up to 1.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/streamsets-data-collector&quot;&gt;StreamSets Data Collector&lt;/a&gt; is up to 3.2&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Datanami and ZDNet have published their views on CDH 6.0 - &lt;a href=&quot;https://www.datanami.com/2018/05/22/cloudera-gives-data-scientists-more-options-for-ml/&quot;&gt;Datanami&lt;/a&gt;; &lt;a href=&quot;https://www.zdnet.com/article/cloudera-enterprise-6-hits-the-streets/&quot;&gt;ZDNet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks has published it’s latest blog entry on using Docker on &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt; - &lt;a href=&quot;https://hortonworks.com/blog/trying-containerized-applications-apache-hadoop-yarn-3-1/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Nexla has published a whitepaper on Hadoop &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;Data Storage Formats&lt;/a&gt; - &lt;a href=&quot;https://www.nexla.com/new-whitepaper-understanding-avro-parquet-orc/&quot;&gt;link&lt;/a&gt; (via &lt;a href=&quot;https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/&quot;&gt;Datanami&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;Couple of security announcements this week &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-8012&quot;&gt;CVE-2018-8012&lt;/a&gt; - no authentication/authorization is enforced when a server attempts to join a quorum in &lt;a href=&quot;/technologies/apache-zookeeper/&quot;&gt;Apache ZooKeeper&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=2018-8010&quot;&gt;CVE-2018-8010&lt;/a&gt; - XML external entity expansion (XXE) in &lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; config files&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;And we like these - Data Engineers are more in demand than Data Scientists - &lt;a href=&quot;https://www.infoworks.io/2018/04/23/data-engineers-greater-demand-data-scientists/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/05/23/the-mid-week-news/</guid> </item> <item><title>The Mid Week News 16/05/2018</title><link>http://ondataengineering.net/blog/2018/05/16/the-mid-week-news/</link><pubDate>Wed, 16 May 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s Wednesday, it’s the news (and it’s very quiet again).. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt; has seen a high priority security patch release (1.9.1)&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt; is up to 3.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-orc/&quot;&gt;Apache ORC&lt;/a&gt; is up to 1.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; continues it’s relentless release march with 5.8&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Google have announced Google Cloud Memorystore for &lt;a href=&quot;/tech-vendors/google-cloud-platform/&quot;&gt;Google Cloud Platform&lt;/a&gt; - a NoSQL key value store with Redis compatibilitiy - &lt;a href=&quot;https://cloudplatform.googleblog.com/2018/05/Introducing-Cloud-Memorystore-A-fully-managed-in-memory-data-store-service-for-Redis.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Microsoft have announced Kafka compatibility for Azure Event Hub - &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/azure-event-hubs-for-kafka-ecosystems-in-public-preview/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Although it’s an advert for Snowflake, it’s also a passable summary of the evolution of data warehouse data platforms - &lt;a href=&quot;https://www.linkedin.com/pulse/data-warehousing-evolution-frank-bell/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/05/16/the-mid-week-news/</guid> </item> <item><title>The Mid Week News 09/05/2018</title><link>http://ondataengineering.net/blog/2018/05/09/the-mid-week-news/</link><pubDate>Wed, 09 May 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s time for the news again. One one tech release this week, but we have some reading for you… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt; Core is up to 3.7&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Google Cloud Composer, and orchestration service based on Apache Airflow is now available on the &lt;a href=&quot;/tech-vendors/google-cloud-platform/&quot;&gt;Google Cloud Platform&lt;/a&gt; - &lt;a href=&quot;https://cloud.google.com/blog/big-data/2018/05/cloud-composer-is-now-in-beta-build-and-run-practical-workflows-with-minimal-effort&quot;&gt;link&lt;/a&gt;; [Datanami view]9https://www.datanami.com/2018/05/01/apache-airflow-to-power-googles-new-workflow-service/)&lt;/li&gt; &lt;li&gt;Confluent now support running their &lt;a href=&quot;/technologies/confluent-enterprise/&quot;&gt;Confluent Platform&lt;/a&gt; (bsaed on &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; on Kubernetes, although it’s only available in their commercial version - &lt;a href=&quot;https://www.confluent.io/blog/introducing-the-confluent-operator-apache-kafka-on-kubernetes/&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2018/05/03/want-kafka-on-kubernetes-confluent-has-it-made/&quot;&gt;Datanami view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;I’d like to talk about how to test data pipelines in more detail at some point, but this is right up my ally - a new framework called Great Expectations for defining tests or checks that run as part of the pipeline - &lt;a href=&quot;https://medium.com/@expectgreatdata/down-with-pipeline-debt-introducing-great-expectations-862ddc46782a&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Cloudera, how to backup and recover data in &lt;a href=&quot;/technologies/apache-solr&quot;&gt;Apache Solr&lt;/a&gt; - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/05/backup-and-disaster-recovery-for-cloudera-search/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Datanami - DataTorrent, the company behind &lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt; and their commercial version of it (DataTorrent RTS) has gone under - &lt;a href=&quot;https://www.datanami.com/2018/05/08/datatorrent-stream-processing-startup-folds/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Again from Datanami - looks like Netflix has moved its Keystone data pipeline from Samza to &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update from Microsoft on CosmosDB - &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/azure-cosmosdb-build-2018-the-catalyst-for-next-generation-apps/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/05/09/the-mid-week-news/</guid> </item> <item><title>The Mid Week News 02/05/2018</title><link>http://ondataengineering.net/blog/2018/05/02/the-mid-week-news/</link><pubDate>Wed, 02 May 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;Wednesday is news day… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; has seen it’s 2.0 GA release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt; is up to 2.12&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Azure SQL Data Warehouse is seen a major Generation 2 upgrade, it still uses Azure Blob Storage (decoupling compute from storage), but can now cache to local SSD disks, meaning performance is now on par with RedShift - &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/blazing-fast-data-warehousing-with-sql-data-warehouse-gen2/&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;https://www.zdnet.com/article/azure-sql-data-warehouse-gen-2-microsofts-shot-across-amazons-bow/&quot;&gt;ZDNet view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And while we’re talking about Cloud Analytical Databases - Datanami have an article on the growth of Google BigQuery - &lt;a href=&quot;https://www.datanami.com/2018/04/24/googles-bigquery-gaining-steam-as-cloud-warehouse-wars-heat-up/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Thoughts from ZDNet on the maturity of Hadoop, including new features in Hadoop 3.x, &lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;Hortonworks DataPlane&lt;/a&gt;, IBM and Hortonworks pushing &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Atlas&lt;/a&gt; as a standard Enterprise metadata repository, and their new plans for &lt;a href=&quot;/tech-vendors/odpi/&quot;&gt;ODPi&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Dremio has a 2.0 version out - I’d not heard of this before but it’s worth a look if you want to be able to exploit data from multiple sources and create (and automatically materialise) derived tables - &lt;a href=&quot;https://www.zdnet.com/article/dremio-2-0-adds-data-reflections-improvements-support-for-looker-and-connectivity-to-azure-data-lake/&quot;&gt;ZDNet link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Couple of interesting paper reviews from The Morning Papers this week &lt;ul&gt; &lt;li&gt;Firstly - Skyway, which allows objects to be moved directly between JVM heaps on different machines avoiding the need for serialisation and de-serialization in distributed systems, apparently delivering a 16% performance increase over Spark using Kyro - &lt;a href=&quot;https://blog.acolyer.org/2018/04/26/skyway-connecting-managed-heaps-in-distributed-big-data-systems/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And secondly, and I love this sort of stuff - using the ASICs on network switches to deliver a co-ordination service (ala ZooKeeper) at ridiculous throughput and latency - &lt;a href=&quot;https://blog.acolyer.org/2018/04/30/netchain-scale-free-sub-rtt-coordination/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;There are a bunch of CVE vulnerabilities announced for Apache Tika - &lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1338&quot;&gt;CVE-2018-1338&lt;/a&gt;; &lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1339&quot;&gt;CVE-2018-1339&lt;/a&gt;; &lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1335&quot;&gt;CVE-2018-1335&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/05/02/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 25/04/2018</title><link>http://ondataengineering.net/blog/2018/04/25/the-mid-week-news/</link><pubDate>Wed, 25 Apr 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s another slow news week - is everyone on holiday of something? Read on for what we have… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt; has hit 5.0 - it’s first release for over a year&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Apache Accumulo&lt;/a&gt; is up to 1.9&lt;/li&gt; &lt;li&gt;Confluent &lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/confluent-enterprise&quot;&gt;Enterprise&lt;/a&gt; have hit 4.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/zenko/cloudserver/&quot;&gt;Zenko Cloudserver&lt;/a&gt; is up to 7.4&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Hortonworks has formally announced Data Steward Studio for &lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;Hortonworks DataPlane&lt;/a&gt;, although it’s been in tech preview for a while - &lt;a href=&quot;https://www.datanami.com/2018/04/17/hortonworks-upgrades-data-plane-service/&quot;&gt;Datanami&lt;/a&gt;; &lt;a href=&quot;https://www.theregister.co.uk/2018/04/18/hortonworks_data_steward_studio_release/&quot;&gt;The Register&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The Register also has a longer look at &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt; and where it’s going - &lt;a href=&quot;https://www.theregister.co.uk/2018/04/18/hortonworks_data_steward_studio_release/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And again from The Register, thoughts on Scality, it’s new funding round for doing multi-cloud storage via &lt;a href=&quot;/technologies/zenko/&quot;&gt;Zenko&lt;/a&gt; - &lt;a href=&quot;https://www.theregister.co.uk/2018/04/18/scality_zenko_60m_funding/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Datanami - Presto looks like it’s catching on - &lt;a href=&quot;https://www.datanami.com/2018/04/18/presto-use-surges-qubole-finds/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Again from Datanami - apparently a Teradata survey says that cloud analytics engines are falling short - &lt;a href=&quot;https://www.datanami.com/2018/04/24/cloud-analytics-engines-falling-short-survey-finds/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, is PostgreSQL about to have it’s day - &lt;a href=&quot;https://www.zdnet.com/article/has-the-time-finally-come-for-postgresql/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/04/25/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 18/04/2018</title><link>http://ondataengineering.net/blog/2018/04/18/the-mid-week-news/</link><pubDate>Wed, 18 Apr 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It’s a very slow news week this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/druid/&quot;&gt;Druid&lt;/a&gt; is up to 0.12&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Spark 2.3 is now available for &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;Cloudera CDH&lt;/a&gt; - &lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/ANNOUNCE-CDS-2-3-Release-2-Powered-by-Apache-Spark-Released/td-p/66412&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Hortonworks, a summary of running IBM Big SQL on HDP - &lt;a href=&quot;https://hortonworks.com/blog/access-data-anywhere-using-db2-big-sqls-federation/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From The Register, Actian has been sold - &lt;a href=&quot;http://www.theregister.co.uk/2018/04/13/actian_acquired/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A good summary of &lt;a href=&quot;/technologies/mesosphere-dcos/&quot;&gt;DC/OS&lt;/a&gt; - &lt;a href=&quot;https://blog.knoldus.com/2018/04/14/dc-os-the-architecture-1/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/04/18/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 11/04/2018</title><link>http://ondataengineering.net/blog/2018/04/11/the-mid-week-news/</link><pubDate>Wed, 11 Apr 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;It was half term holiday week last week (sorry - forgot to say) which meant no news, but we’re back this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt; has hit 3.1, with what looks like some significant new functionality&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; has hit 7.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt; has a 2.5 tech preview release with support for HDF&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt; has hit a 1.10 release of it’s Map Reduce implementation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; has hit 1.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; has hit 1.6&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/mapr-expansion-pack/&quot;&gt;MapR Expansion Pack&lt;/a&gt; has hit 5.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt; has hit 4.2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit 5.7&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Amazon have announced a new cheaper One Zone-IA Storage Class for &lt;a href=&quot;/technologies/amazon-s3/&quot;&gt;S3&lt;/a&gt; that doesn’t support geo redundancy, and the general availability of S3 select - &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-s3-update-new-storage-class-general-availability-of-s3-select/&quot;&gt;summary&lt;/a&gt;; &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2018/04/announcing-s3-one-zone-infrequent-access-a-new-amazon-s3-storage-class/&quot;&gt;One Zone-IA&lt;/a&gt;; &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2018/04/amazon-s3-select-is-now-generally-available/&quot;&gt;S3 Select&lt;/a&gt;; &lt;a href=&quot;https://www.theregister.co.uk/2018/04/05/aws_drops_s3_storage_costs/&quot;&gt;TheRegister view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Hortonworks, a view on the performance of &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; over local disk vs S3 cloud storage - &lt;a href=&quot;https://hortonworks.com/blog/cloud-architectures-interactive-analytics-apache-hive/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hardly surprise, but from Datanami - Excel remains the go to Data Prep tool - &lt;a href=&quot;https://www.datanami.com/2018/04/02/survey-excel-remains-go-to-data-prep-tool/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update on Oracle’s new “automated” database / data warehouse strategy - &lt;a href=&quot;https://www.enterprisetech.com/2018/03/28/oracle-ellison-seek-path-around-aws/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Microsoft have announced a public preview of soft deletes for &lt;a href=&quot;/technologies/microsoft-azure-blob-storage/&quot;&gt;Azure Storage Blobs&lt;/a&gt; - &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/soft-delete-for-azure-storage-blobs-now-in-public-preview/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;MapR are now also talking about “Streams of Record” with &lt;a href=&quot;/technologies/mapr-es/&quot;&gt;MapR-ES&lt;/a&gt; - &lt;a href=&quot;https://mapr.com/blog/extending-your-stream-of-record-mapr-6-0-1-mep-5-0/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;We have a bunch of security announcements this week: &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1308&quot;&gt;CVE-2018-1308&lt;/a&gt; - XXE attack through Apache Solr’s DIH’s dataConfig request parameter&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1284&quot;&gt;CVE-2018-1284&lt;/a&gt; - Hive UDF series UDFXPathXXXX allow users to pass carefully crafted XML to access local files&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1315&quot;&gt;CVE-2018-1315&lt;/a&gt; - Hive ‘COPY FROM FTP’ statement in HPL/SQL can write to arbitrary location if the FTP server is compromised&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1282&quot;&gt;CVE-2018-1282&lt;/a&gt; - Hive JDBC driver is susceptible to SQL injection attack if the input parameters are not properly cleaned&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/04/11/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 28/03/2018</title><link>http://ondataengineering.net/blog/2018/03/28/the-mid-week-news/</link><pubDate>Wed, 28 Mar 2018 07:30:00 +0100</pubDate> <description> &lt;p&gt;Wednesday’s come round again, so let’s catch up on the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-arrow/&quot;&gt;Apache Arrow&lt;/a&gt; has hit 0.9&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; is up to 2.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt; has hit a symbolic 1.4 after graduating&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hawq/&quot;&gt;Apache HAWQ&lt;/a&gt; has hit 2.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; has hit 1.7&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit 5.6&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;There’s a summary on the &lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Accumulo&lt;/a&gt; blog on how to export metrics to Grafana (and other metrics tools) - &lt;a href=&quot;http://accumulo.apache.org/blog/2018/03/22/view-metrics-in-grafana.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update from Datanami on Presto and Starburst (the commercial company that now backs it) - &lt;a href=&quot;https://www.datanami.com/2018/03/21/building-presto-business-no-magic-trick-for-starburst/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;More from Databricks and Microsoft on Azure Databricks - &lt;a href=&quot;https://databricks.com/blog/2018/03/22/azure-databricks-industry-leading-analytics-platform-powered-by-apache-spark.html&quot;&gt;Databricks&lt;/a&gt;; &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/implementation-patterns-for-big-data-and-data-warehouse-on-azure/&quot;&gt;Azure&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Cloudera, deploying &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; using &lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; and Ansible - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/03/automated-provisioning-of-cdh-in-the-cloud-with-cloudera-director-and-ansible/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;It looks like &lt;a href=&quot;/technologies/apache-arrow/&quot;&gt;Apache Arrow&lt;/a&gt; has a new native Go implementation in the works, donated by InfluxDB - &lt;a href=&quot;https://arrow.apache.org/blog/2018/03/22/go-code-donation/&quot;&gt;Arrow blog&lt;/a&gt;; &lt;a href=&quot;https://www.influxdata.com/blog/influxdata-apache-arrow-go-implementation/&quot;&gt;Influx blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Datanami, ZEPL have moved their analytics tool based on &lt;a href=&quot;/technologies/apache-zeppelin/&quot;&gt;Apache Zeppelin&lt;/a&gt; out of beta - &lt;a href=&quot;https://www.datanami.com/2018/03/23/apache-zeppelin-launches-latest-data-science-notebook/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, thoughts on GPU accelerated databases - &lt;a href=&quot;http://www.zdnet.com/article/gpu-databases-are-coming-of-age/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/28/the-mid-week-news/</guid> </item> <item><title>The Week That Was - 23/03/2018</title><link>http://ondataengineering.net/blog/2018/03/23/the-week-that-was/</link><pubDate>Fri, 23 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;There have been a few minor updates to the site this week… &lt;!--more--&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;There’s a new information on &lt;a href=&quot;/technologies/openlink-virtuoso-universal-server/&quot;&gt;OpenLink Virtuoso Universal Server&lt;/a&gt; and updates to the &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt; tech category page for this and OpenLink Software Universal Data Access Suite courtesy of TallTed&lt;/li&gt; &lt;li&gt;I’ve added SQData CDC and Debezium to the &lt;a href=&quot;/tech-categories/data-ingestion/&quot;&gt;Data Ingestion&lt;/a&gt; page. Debezium looks interesting - an open source package of Kafka and Kafka Connect for streaming data out of databases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/23/the-week-that-was/</guid> </item> <item><title>OpenLink Virtuoso Universal Server</title><link>http://ondataengineering.net/technologies/openlink-virtuoso-universal-server/</link><pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate> <description> &lt;p&gt;Multi-model database (RDBMS, VDBMS) supporting tabular relational (SQL), graph relational (SPARQL), hybrid (SPARQL-in-SQL a/k/a SPASQL), XML (XPath, XQuery, XSLT), filesystem/objects, and other forms of data; First shipped in 1999, available as Open Source or Enterprise Edition; various add-ons available for Enterprise Edition; virtualizes local and/or remote tabular relational databases and/or other data sources as RDF semantic web data sources.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;OpenLink&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2018&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://virtuoso.openlinksw.com/&quot;&gt;https://virtuoso.openlinksw.com/&lt;/a&gt; - product home page&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/openlink-virtuoso-universal-server/</guid> </item> <item><title>The Mid Week News - 21/03/2018</title><link>http://ondataengineering.net/blog/2018/03/21/the-mid-week-news/</link><pubDate>Wed, 21 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s time for the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ranger/&quot;&gt;Apache Ranger&lt;/a&gt; has hit the big 1.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt; has hit 0.16&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt; has hit 1.13&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt; has hit 2.4&lt;/li&gt; &lt;li&gt;Databricks have published some more blog posts on 2.3 features for &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Influx have published some more blog posts on 1.5 features for &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Datanami have a summary of the new features in &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Spark&lt;/a&gt; 2.3 - &lt;a href=&quot;https://www.datanami.com/2018/03/14/top-3-new-features-in-apache-spark-2-3/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Confluent have a post of how to continuously extract data from your database using &lt;a href=&quot;/technologies/apache-kafka/kafka-connect/&quot;&gt;Kafka Connect&lt;/a&gt; - &lt;a href=&quot;https://www.confluent.io/no-more-silos-how-to-integrate-your-databases-with-apache-kafka-and-cdc&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt; have announced Hortonworks Operational Services - their new on site or in the cloud managed service for HDP or HDF - &lt;a href=&quot;https://hortonworks.com/blog/operational-services-embark-big-data-journey-confidence/&quot;&gt;blog&lt;/a&gt;; &lt;a href=&quot;https://hortonworks.com/services/support/operational-services/&quot;&gt;homepage&lt;/a&gt;&lt;/li&gt; &lt;li&gt;ZDNet have their view on Hortonworks Operational Services, KSQL and Waterline - &lt;a href=&quot;http://www.zdnet.com/article/hortonworks-confluent-and-waterline-make-big-data-easier/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/21/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 14/03/2018</title><link>http://ondataengineering.net/blog/2018/03/14/the-mid-week-news/</link><pubDate>Wed, 14 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s Wednesday, and it’s time for the weekly news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-falcon/&quot;&gt;Apache Falcon&lt;/a&gt;, which I thought was dead, has just hit 0.11&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; has seen it’s second 2.0 beta release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-parquet/&quot;&gt;Apache Parquet&lt;/a&gt; has seen a 1.4 release of it’s C++ library&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; has hit 1.5&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Datanami have the lowdown on StreamSets’ new Data Protection product out that supports automatic identification of personally identifiable information and a range of options for obfuscating or encrypting it - &lt;a href=&quot;https://www.datanami.com/2018/03/07/streamsets-balances-streaming-data-demands-for-security-access/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Databricks have blogged about two key new features in Spark 2.3 - &lt;a href=&quot;https://databricks.com/blog/2018/03/06/apache-spark-2-3-with-native-kubernetes-support.html&quot;&gt;Kubernetes support&lt;/a&gt; and &lt;a href=&quot;https://databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html&quot;&gt;stream to stream joins&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ODBMS Industry Watch, and interesting interview with John Ryan, Data Warehouse Solution Architect (Director) at UBS, on database technologies (RDBMS, NoSQL and NewSQL) with some thoughts on the Lambda architecture thrown in at the end - &lt;a href=&quot;http://www.odbms.org/blog/2018/03/on-rdbms-nosql-and-newsql-databases-interview-with-john-ryan/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Again from Datanami, some interesting thoughts on Elastic and where they’re going - &lt;a href=&quot;https://www.datanami.com/2018/03/12/elastic-plots-its-own-course-to-big-data-success/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/14/the-mid-week-news/</guid> </item> <item><title>NiFi Registry</title><link>http://ondataengineering.net/technologies/apache-nifi/registry/</link><pubDate>Fri, 09 Mar 2018 08:30:00 +0000</pubDate> <description> &lt;p&gt;A solution for the configuration management of NiFi flows. Integrates with NiFi to allow users to store, retrieve and upgrade flows, keeping a full history of all changes to a flow committed to the registry, with flows stored and organised by buckets. Supports local users and groups, or authentication via certificates, LDAP or Kerberos, with access control policies allowing read, write and delete permissions to be specified for buckets, users and groups. Has a Web based UI and a REST interface for managing buckets, local users and groups, viewing flow history and for managing access control. First released in January 2018.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;March 2018 - v0.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Is packaged by&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks DataFlow&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.1&lt;/td&gt; &lt;td&gt;2018-01-01&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://cwiki.apache.org/confluence/display/NIFI/Release+Notes#ReleaseNotes-NiFiRegistry0.1.0&quot;&gt;summary&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://nifi.apache.org/registry.html&quot;&gt;https://nifi.apache.org/registry.html&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://nifi.apache.org/docs/nifi-registry-docs/index.html&quot;&gt;https://nifi.apache.org/docs/nifi-registry-docs/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/HDF3/HDF-3.1.0/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/HDF3/HDF-3.1.0/index.html&lt;/a&gt; - Hortonworks documentation (as part of HDF 3.1)&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-nifi/registry/</guid> </item> <item><title>Cloudera Altus Data Engineering</title><link>http://ondataengineering.net/technologies/cloudera-altus/data-engineering/</link><pubDate>Fri, 09 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;Managed service for the execution of Spark, MapReduce or Hive (over MapReduce or Spark) jobs using managed CDH clusters on AWS and Azure cloud infrastructure over data in Amazon S3 or Azure Data Lake Storage (ADLS). Jobs run on clusters within a defined AWS or Azure environment, which can be transient (created and terminated on demand) or persistent, with each cluster supporting one service type (Hive, Spark, MapReduce) with a fixed node count. Jobs can then be queued individually or in batch for execution against an existing cluster or against a dynamically created cluster, with jobs specified either by uploading a JAR to S3 (for Spark or MapReduce) or via a Hive script (either directly uploaded or uploaded to S3), and the ability to either halt or continue the queue on job failure. Supports access to clusters via SSH, read only access to Cloudera Manager, a SOCKS proxy to cluster web UIs (including the CM admin console, YARN history server and Spark history server), and access to server and workload logs (including the ability to write these to S3 for access after clusters have been terminated). All nodes managed by Altus are tagged with the cluster name and node role (master, worker or Cloudera Manager) and bootstrap scripts can be specified for execution on nodes after cluster startup.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2018&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-hadoop/map-reduce/&quot;&gt;MapReduce&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt;, &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/altus/altus-data-engineering.html&quot;&gt;https://www.cloudera.com/products/altus/altus-data-engineering.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/documentation/altus.html&quot;&gt;https://www.cloudera.com/documentation/altus.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2017/05/data-engineering-with-cloudera-altus/&quot;&gt;http://blog.cloudera.com/blog/2017/05/data-engineering-with-cloudera-altus/&lt;/a&gt; - intro blog post&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-altus/data-engineering/</guid> </item> <item><title>Cloudera Altus Analytical DB (Beta)</title><link>http://ondataengineering.net/technologies/cloudera-altus/analytical-db/</link><pubDate>Fri, 09 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;Impala as a managed service, supporting the dynamic provisionng of Impala clusters on AWS and Azure cloud infrastructure over data in Amazon S3 or Azure Data Lake Storage (ADLS). Currently in Beta, with limited documentation available.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Cloudera Altus Analytical DB&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Sub-Project&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Parent Project&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2018&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Related Technologies&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Packages&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://www.cloudera.com/products/altus/altus-analytic-db.html&quot;&gt;https://www.cloudera.com/products/altus/altus-analytic-db.html&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://vision.cloudera.com/introducing-cloudera-altus-analytic-db-beta-for-cloud-based-data-warehousing/&quot;&gt;http://vision.cloudera.com/introducing-cloudera-altus-analytic-db-beta-for-cloud-based-data-warehousing/&lt;/a&gt; - intro blog post&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2018/02/a-technical-overview-of-cloudera-altus-analytic-db/&quot;&gt;http://blog.cloudera.com/blog/2018/02/a-technical-overview-of-cloudera-altus-analytic-db/&lt;/a&gt; - technical overview&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/cloudera-altus/analytical-db/</guid> </item> <item><title>The Mid Week News - 07/03/2018</title><link>http://ondataengineering.net/blog/2018/03/07/the-mid-weeks-news/</link><pubDate>Wed, 07 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s time for the news again… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt; has hit 2.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; has also hit 2.3&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/druid/&quot;&gt;Druid&lt;/a&gt; has been donated to the Apache Incubator - &lt;a href=&quot;https://wiki.apache.org/incubator/DruidProposal&quot;&gt;proposal&lt;/a&gt;; &lt;a href=&quot;http://incubator.apache.org/projects/druid&quot;&gt;incubator page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Elastic have announced that they’ll be open sourcing their &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;Elastic X-Pack&lt;/a&gt; as of Elastic 6.3. The code will be moved into the public repos for their other products (but under the Elastic EULA), and the free elements will be pre-bundled with those products rather than requiring a separate download - &lt;a href=&quot;https://www.elastic.co/blog/doubling-down-on-open&quot;&gt;accouncement&lt;/a&gt;; &lt;a href=&quot;https://www.elastic.co/products/x-pack/open&quot;&gt;details&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2018/02/28/elastic-make-entire-stack-open-source/&quot;&gt;Datanami view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An excellent article on Data Warehouse Automation - we’ll get to talking more about this soon - &lt;a href=&quot;http://www.sspaeti.com/blog/why-data-warehouse-automation-is-not-more-popular/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;MapR have announced “MapR Data Fabric for Kubernetes” - persistent storage for containers running on Kubernetes - &lt;a href=&quot;https://community.mapr.com/community/products/blog/2018/03/06/announcing-mapr-data-fabric-for-kubernetes&quot;&gt;announcement&lt;/a&gt;; &lt;a href=&quot;https://mapr.com/solutions/data-fabric/kubernetes/&quot;&gt;homepage&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2018/03/06/inside-maprs-support-kubernetes/&quot;&gt;Datanami view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks have blogged about what’s new in Cloudbreak 2.4 - &lt;a href=&quot;https://hortonworks.com/blog/announcing-cloudbreak-2-4/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The latest Hortonworks blog post on HDF 3.1 is up, this time on the &lt;a href=&quot;/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt; C++ agent - &lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-hdf-3-1-blog-series-part-6-introducing-apache-minifi-c-agent/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;AWS have published their best practice for running &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; on AWS - &lt;a href=&quot;https://aws.amazon.com/blogs/big-data/best-practices-for-running-apache-kafka-on-aws/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Datanami have covered Cloudera’s announcement of &lt;a href=&quot;//technologies/cloudera-altus/&quot;&gt;Altus&lt;/a&gt; Data Science (R and Python-based machine learning workloads based on their &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Data Science Workbench&lt;/a&gt;) coming to beta soon, with an operational database build on HBase coming as the fourth package in the future - &lt;a href=&quot;https://www.datanami.com/2018/03/06/clouderas-vision-cloud-coming-focus/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Again from Datanami, a report that Streamlio is claiming up to 150% performance advantage of Apache Pulsar vs Apacke Kafka as a &lt;a href=&quot;/tech-categories/streaming-data-stores/&quot;&gt;Streaming Data Store&lt;/a&gt; - &lt;a href=&quot;https://www.datanami.com/2018/03/06/streamlio-claims-pulsar-performance-advantages-kafka/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, this is a well worth a read if you have an interest in &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;Graph Databases&lt;/a&gt; or &lt;a href=&quot;/tech-categories/rdf-databases/&quot;&gt;RDF Databases&lt;/a&gt; that’s dense with information - &lt;a href=&quot;http://www.zdnet.com/article/back-to-the-future-does-graph-database-success-hang-on-query-language/&quot;&gt;link&lt;/a&gt; &lt;ul&gt; &lt;li&gt;Cypher (the open source Graph query language from Neo4J) now has adapters to allow Cypher jobs to be run over Spark and TinkerPop Gremlin compatible databases&lt;/li&gt; &lt;li&gt;There’s a SPARQL Gremlin bridge, allowing you to run SPARQL queries over TinkerPop Gremlin compatible databases&lt;/li&gt; &lt;li&gt;Amazone Neptune (which supports both Gremlin and SPARQL), is apparently built on BlazeGraph&lt;/li&gt; &lt;li&gt;There’s a new massively parallel distributed graph database from Cambridge Semantics (CS) called AnzoGraph, which they compare to TigerGraph&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Looks like I missed the donation of this to the Apache Foundation, but Apache Hivemall is a scalable machine learning library implemented as Hive UDFs/UDAFs/UDTFs - &lt;a href=&quot;http://hivemall.incubator.apache.org/&quot;&gt;home page&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;LinkedIn have proposed DrElephant to the Apache Foundation -&lt;/td&gt; &lt;td&gt;their performance monitoring and tuning service for jobs and workflows that run on Apache Hadoop and Apache Spark - &lt;a href=&quot;https://wiki.apache.org/incubator/DrElephantProposal&quot;&gt;proposal&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/07/the-mid-weeks-news/</guid> </item> <item><title>The Week That Was - 02/03/2018</title><link>http://ondataengineering.net/blog/2018/03/02/the-week-that-was/</link><pubDate>Fri, 02 Mar 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;Ok, it’s been a while, but there’s been a bunch of (small) updates to the site, and it’s time to summarise. I’ve got a few more random updates next week, and then we’ll get back into a groove of new content.&lt;/p&gt; &lt;p&gt;Back to those updates, and they are, in no particular order… &lt;!--more--&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Updated the &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt; and associated technology pages for MapR 6.0 and MEP 4.0 and 4.1, including: &lt;ul&gt; &lt;li&gt;Renamed MapR-Streams to &lt;a href=&quot;/technologies/mapr-es/&quot;&gt;MapR-ES&lt;/a&gt; and MapR File System to &lt;a href=&quot;/technologies/mapr-fs/&quot;&gt;MapR-FS&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Moved &lt;a href=&quot;/technologies/mapr-es/&quot;&gt;MapR-ES&lt;/a&gt; and &lt;a href=&quot;/technologies/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; to top level projects&lt;/li&gt; &lt;li&gt;Renamed MapR Ecosystem Pack to &lt;a href=&quot;/technologies/mapr-expansion-pack/&quot;&gt;MapR Expansion Pack&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Added references to Apache Fluo, Omid and Tephra to the &lt;a href=&quot;/tech-categories/nosql-wide-column-stores/&quot;&gt;NoSQL Wide Column Stores&lt;/a&gt; technology category page - these are projects that add functionality on top of other NoSQL Wide Column Store databases.&lt;/li&gt; &lt;li&gt;Added a bunch of related technologies to the &lt;a href=&quot;/tech-categories/compute-cluster-managers/&quot;&gt;Compute Cluster Manager&lt;/a&gt; page&lt;/li&gt; &lt;li&gt;Added tech category links to &lt;a href=&quot;/tech-categories/hadoop-distributions/distribution-comparison/&quot;&gt;Hadoop Distributions comparison&lt;/a&gt; page&lt;/li&gt; &lt;li&gt;Refreshed the technology pages for &lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; and it’s sub-projects&lt;/li&gt; &lt;li&gt;Updates to reflect the rename of Apache Coral to Apache Nemo, including the &lt;a href=&quot;/tech-vendors/apache/&quot;&gt;Apache&lt;/a&gt; vendor page&lt;/li&gt; &lt;li&gt;Added references to Uno and Muchos to the &lt;a href=&quot;/technologies/apache-accumulo/&quot;&gt;Accumulo&lt;/a&gt; page&lt;/li&gt; &lt;li&gt;Added a list of Kafka management tools to the &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; page&lt;/li&gt; &lt;li&gt;Added links to the Cloudera and Hortonworks documentation and product pages to a bunch of open source Hadoop related technology pages&lt;/li&gt; &lt;li&gt;Added Mnemonic to the &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;data storage formats&lt;/a&gt; page&lt;/li&gt; &lt;li&gt;Refreshed the &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;object stores&lt;/a&gt; page, and added Wasabi&lt;/li&gt; &lt;li&gt;Refreshed the add-on information on the &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Updated the &lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; page with a link to blog entry from Sematext listing alternative add-ons to the Elastic X-Pack&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/03/02/the-week-that-was/</guid> </item> <item><title>The Mid Week News - 28/02/2018</title><link>http://ondataengineering.net/blog/2018/02/28/the-mid-week-news/</link><pubDate>Wed, 28 Feb 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;News time again, and it’s a bit quieter than the monster last week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-datafu/&quot;&gt;Apache DataFu&lt;/a&gt; has graduated from the Apache Incubator&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Hortonworks Cloudbreak&lt;/a&gt; has seen it’s first 2.x GA release - 2.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit 5.5&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;DataTorrent (the authors of &lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt;) have released version 3.1 of their DataTorrent DTS product, that looks like they’re expanding their product a bit - &lt;a href=&quot;https://www.datatorrent.com/blog/technical-details-for-datatorrent-rts-3-10-release/&quot;&gt;post1&lt;/a&gt;; &lt;a href=&quot;https://www.datatorrent.com/blog/datatorrent-online-analytics-service/&quot;&gt;post2&lt;/a&gt;; &lt;a href=&quot;http://www.zdnet.com/article/datatorrents-hard-code-around-streaming-data-philosophy-in-90-days/&quot;&gt;ZDNet view&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2018/02/22/datatorrent-glues-open-source-componentry-apoxi/&quot;&gt;Datanami view&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Atlus&lt;/a&gt; has a new Java SDK - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/02/altus-sdk-for-java-blog/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/google-cloud-storage/&quot;&gt;Google Cloud Storage&lt;/a&gt; now offers strongly consistent object operations through the use of Spanner - I’ve got some updates to the site around object storage consistency I’ll put live shortly - &lt;a href=&quot;https://cloudplatform.googleblog.com/2018/02/how-Google-Cloud-Storage-offers-strongly-consistent-object-listing-thanks-to-Spanner.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A write up from Bloor on Snowflake DB - &lt;a href=&quot;https://www.bloorresearch.com/2018/02/cloud-data-warehousing-snowflake-old-ideas-shot-ribbons/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Thoughts on open source software and it’s impact on Big Data from Datanami - &lt;a href=&quot;https://www.datanami.com/2018/02/26/weighing-open-sources-worth-future-big-data/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Looks like TigerGraph - the hybrid OLTP/OLAP massively scalable graph database - has launched it’s 2.0 platform. Thoughts from &lt;a href=&quot;https://www.theregister.co.uk/2018/02/27/tigergraph_launches_realtime_graph_analytics_collaboration/&quot;&gt;The Register&lt;/a&gt; and &lt;a href=&quot;https://www.datanami.com/2018/02/27/tigergraph-serves-collaboration-security-multi-graph/&quot;&gt;Datanami&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/02/28/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 21/02/2018</title><link>http://ondataengineering.net/blog/2018/02/21/the-mid-week-news/</link><pubDate>Wed, 21 Feb 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;Right, following our week off (the snow was lovely thank you), we’re back with a bumper edition of the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt; has hit 1.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; has hit 2.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt; has hit 1.2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt; has released a 5.0 alpha&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; has hit 6.2, along with &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;X-Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch Hadoop&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-oozie/&quot;&gt;Apache Oozie&lt;/a&gt; has security vulnerablity - &lt;a href=&quot;https://cve.mitre.org/cgi-bin/cvename.cgi?name=2017-15712&quot;&gt;CVE-2017-15712&lt;/a&gt; - a user can expose private files on the Oozie server process by constructing a workflow that references sensitive files&lt;/li&gt; &lt;li&gt;Trifacta have just announced a new funding round, including funding from Google that resell their software as Google Cloud Dataprep - &lt;a href=&quot;https://www.datanami.com/2018/02/06/trifacta-cashing-cloud-analytics/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A couple of updates on the benefits of &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; 3 - &lt;a href=&quot;https://hortonworks.com/blog/hadoop-3-adds-value-hadoop-2/&quot;&gt;Hortonworks link&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2018/02/07/erasure-coding-changes-hadoop-storage-economics/&quot;&gt;erasure coding thoughts from Datanami&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Data Artisans, a view on end to end exactly once processing in &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; - &lt;a href=&quot;https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A bit batch of updates from Hortonworks on new features in &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;HDF&lt;/a&gt; following on from last weeks GA announcement &lt;ul&gt; &lt;li&gt;NiFi Registry - &lt;a href=&quot;https://hortonworks.com/blog/hdf-3-1-blog-series-part-2-introducing-nifi-registry/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; 1.0 support - &lt;a href=&quot;https://hortonworks.com/blog/hdf-3-1-blog-series-part-3-kafka-1-0-support-powerful-hdf-integrations/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Unit testing and continuous integration in &lt;a href=&quot;/technologies/streaming-analytics-manager/&quot;&gt;Hortonworks Streaming Analytics Manager&lt;/a&gt; - &lt;a href=&quot;https://hortonworks.com/blog/hortonworks-dataflow-hdf-3-1-blog-series-part-4-unit-testing-continuous-integration-delivery-streaming-analytics-apps/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;NiFi&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Atlas&lt;/a&gt; integration - &lt;a href=&quot;https://hortonworks.com/blog/hdf-3-1-blog-series-part-6-introducing-nifi-atlas-integration/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Couple of big updates from InfluxData (creators of &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt;) - &lt;a href=&quot;https://www.influxdata.com/blog/adventures-in-building-a-modern-time-series-platform/&quot;&gt;new funding round&lt;/a&gt; and &lt;a href=&quot;https://www.influxdata.com/blog/ifql-and-the-future-of-influxdata/&quot;&gt;IFQL as their new standard query language&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An article from Datanami on Scylla, the C++ re-write of &lt;a href=&quot;/technologies/apache-cassandra/&quot;&gt;Cassandra&lt;/a&gt; - &lt;a href=&quot;https://www.datanami.com/2018/02/13/scylla-eyes-cassandras-nosql-workloads/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update from Cloudera on new features in &lt;a href=&quot;/technologies/hue/&quot;&gt;Hue&lt;/a&gt; in CDH 5.14 - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/02/new-in-cloudera-5-14-query-assistance-improvements-and-adls-integration-for-the-self-service-analytic-database/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From InfoQ - implementing a resilient &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; cluster at Goldman Sachs - &lt;a href=&quot;https://www.infoq.com/articles/resilient-kafka-goldman-sachs&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A technical overview of &lt;a href=&quot;/technologies/cloudera-altus/analytical-db/&quot;&gt;Cloudera Altus Analytic DB&lt;/a&gt; from Cloudera - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/02/a-technical-overview-of-cloudera-altus-analytic-db/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;This is always interesting - LinkedIn’s experiences of Hadoop failures at extreme scale and how they test for them at smaller scale - &lt;a href=&quot;https://engineering.linkedin.com/blog/2018/02/dynamometer--scale-testing-hdfs-on-minimal-hardware-with-maximum&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Should you migrate all your batch ETL jobs to streaming jobs - probably not, but here is Netflix’s experiences courtesy of InfoQ - &lt;a href=&quot;https://www.infoq.com/articles/netflix-migrating-stream-processing&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/02/21/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 07/02/2018</title><link>http://ondataengineering.net/blog/2018/02/07/the-mid-week-news/</link><pubDate>Wed, 07 Feb 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;No news next week, but back the week after, hopefully with a resumption of updates.&lt;/p&gt; &lt;p&gt;In the meantime, let’s have this weeks news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks Data Flow (HDF)&lt;/a&gt; has seen a 3.1 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-carbondata/&quot;&gt;Apache CarbonData&lt;/a&gt; has seen a 1.3 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Nemo has entered the Apache Incubator - it’s a runtime for data processing languages (currently supporting &lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; with &lt;a href=&quot;/technologies/apache-spark/&quot;&gt;Apache Spark&lt;/a&gt; support coming) that dynamically adjusts to the runtime environment and uses Apache REEF to run over &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt; or &lt;a href=&quot;/technologies/apache-mesos/&quot;&gt;Mesos&lt;/a&gt; - &lt;a href=&quot;https://snuspl.github.io/nemo/&quot;&gt;homepage&lt;/a&gt;; &lt;a href=&quot;https://wiki.apache.org/incubator/NemoProposal&quot;&gt;Apache proposal&lt;/a&gt;. &lt;em&gt;NOTE: this was originally called and submitted as Coral, but was subsequently renamed&lt;/em&gt;&lt;/li&gt; &lt;li&gt;From MapR on &lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt;, part 1 of 4 on why their technologies are the best - &lt;a href=&quot;https://mapr.com/blog/mapr-data-technologies-gloves-off-series-1-4-storage/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Datanami - 2018 will be the year of the Data Engineer - &lt;a href=&quot;https://www.datanami.com/2018/02/05/2018-will-year-data-engineer/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An intro to NiFi Registry (that enables configuration management of flows) from Hortonworks - &lt;a href=&quot;https://hortonworks.com/blog/hdf-3-1-blog-series-part-2-introducing-nifi-registry/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;There’s a new Gartner Critical Capabilities for Object Storage report out, and The Register have a summary - &lt;a href=&quot;https://www.theregister.co.uk/2018/02/02/gartner_object_storage_report/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Pivotal, graph processing on Greenplum using MADLib - &lt;a href=&quot;https://content.pivotal.io/blog/graph-processing-on-greenplum-database-using-apache-madlib&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/02/07/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 31/01/2018</title><link>http://ondataengineering.net/blog/2018/01/31/the-mid-week-news/</link><pubDate>Wed, 31 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s Wednesday, which means it’s news time… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; has seen a 5.14 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-manager/&quot;&gt;Cloudera Manager&lt;/a&gt; is up to 5.14&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-navigator/&quot;&gt;Cloudera Navigator&lt;/a&gt; is up to 2.13&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-director/&quot;&gt;Cloudera Director&lt;/a&gt; is up to 2.7&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; has hit 1.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/minifi/&quot;&gt;Apache NiFi MiNiFi&lt;/a&gt; has seen 0.4 releases of it’s C++ and Java versions&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-atlas/&quot;&gt;Apache Atlas&lt;/a&gt; has a 1.0 alpha release out&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Hortonworks have an update on &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt; support for long running applications coming in Hadoop 3.1 - &lt;a href=&quot;https://hortonworks.com/blog/first-class-support-long-running-services-apache-hadoop-yarn/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Something interesting from Gartner - some thoughts on the Data Warehouse, the Data Lake, and what roles each of them play in a larger logical data warehouse - &lt;a href=&quot;https://blogs.gartner.com/henry-cook/2018/01/28/the-logical-data-warehouse-and-its-jobs-to-be-done/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An introduction to Apache Pulsar, the latest Kafka competitor - &lt;a href=&quot;http://furkankamaci.com/apache-pulsar-distributed-pub-sub-messaging-system/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Neo4J - a comparison of &lt;a href=&quot;/tech-categories/rdf-databases/&quot;&gt;RDF Triple Stores&lt;/a&gt; and &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;Labeled Property Graphs&lt;/a&gt; - &lt;a href=&quot;https://neo4j.com/blog/rdf-triple-store-vs-labeled-property-graph-difference/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Thoughts on Informatica’s entry to the cloud from Bloor - &lt;a href=&quot;https://www.bloorresearch.com/2018/01/informatica-pale-pink-maybe-orange/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Grab yourself a free copy of the &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; For Beginners book from Hortonworks - &lt;a href=&quot;https://hortonworks.com/blog/introduction-apache-nifi/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/31/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 24/01/2018</title><link>http://ondataengineering.net/blog/2018/01/24/the-mid-week-news/</link><pubDate>Wed, 24 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;And it’s time for the news again… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt; has hit 2.11&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; continues it’s relentless development march to 5.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/alluxio/&quot;&gt;Alluxio&lt;/a&gt; is up to 1.7&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; has it’s first 2.0 beta out&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;There’s an update from LinkedIn on the latest with &lt;a href=&quot;/technologies/apache-gobblin/&quot;&gt;Apache Gobblin&lt;/a&gt; including new features added since 0.11 - &lt;a href=&quot;https://engineering.linkedin.com/blog/2018/01/gobblin-enters-apache-incubation&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2 of Cloudera’s &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; deployment blog posts is up, focusing on “where Cloudera services and roles should be placed across the various nodes in your clusters” - &lt;a href=&quot;http://blog.cloudera.com/blog/2018/01/deploy-cloudera-edh-clusters-like-a-boss-revamped-part-2/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Data Artisans - information on checkpointing in &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; - &lt;a href=&quot;https://data-artisans.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet - an interview with Marko A. Rodriguez - the creator of the Titan graph database (now JanusGraph), DSE Graph and TinkerPop - &lt;a href=&quot;http://www.zdnet.com/article/from-graph-to-the-world-pioneering-a-database-virtual-machine/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Bloor have issued a Market Report Paper on SQL Engines on Hadoop - covering Hadoop &lt;a href=&quot;/tech-categories/query-engines/&quot;&gt;query engines&lt;/a&gt; capabilities, transactional (operational) capabilities and some &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical database&lt;/a&gt; - &lt;a href=&quot;https://www.bloorresearch.com/research/sql-engines-hadoop/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/24/the-mid-week-news/</guid> </item> <item><title>An Update</title><link>http://ondataengineering.net/blog/2018/01/19/an-update/</link><pubDate>Fri, 19 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;So if you’ve been following this site, it’s probably become clear that the pace of updates has slowed quite considerably - unfortunately at this moment I don’t have the same time available on a regular basis that I did a few months ago.&lt;/p&gt; &lt;p&gt;So for the next few months until things quieten down I’m going to change my strategy a little. There will still be (semi-regular) updates, however these will appear as and when they’re ready, and they’ll be no posts on a Monday with any sort of commitment for what will happen that week. We will keep up with the weekly news updates however, to make sure we’re staying on top of the technologies we’ve looked at to date.&lt;/p&gt; &lt;p&gt;And we’ll try and get a few more contributors involved - if you’re interested in contributing of helping in any way then please do get in touch.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/19/an-update/</guid> </item> <item><title>The Mid Week News - 17/01/2018</title><link>http://ondataengineering.net/blog/2018/01/17/the-mid-week-news/</link><pubDate>Wed, 17 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;After last weeks bumper edition, we’re back to normal this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache NiFi&lt;/a&gt; has hit 1.5&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Teradata have spun off the support and development of Presto (originally developed at Facebook) into a new company called Starburst data - &lt;a href=&quot;https://www.bloorresearch.com/2017/12/teradata-spins-off-starburst/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;It looks like Lucene 7.1 (and therefore &lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;ElasticSearch&lt;/a&gt; and presumably at some point &lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Solr&lt;/a&gt;) can now support Attibute Based Access Control - &lt;a href=&quot;https://www.elastic.co/blog/attribute-based-access-control-with-xpack&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update from ZDNet on &lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt; - &lt;a href=&quot;http://www.zdnet.com/article/mapr-midcourse-correction-puts-original-ceo-back-in-the-drivers-seat/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/17/the-mid-week-news/</guid> </item> <item><title>The Mid Week News - 10/01/2018</title><link>http://ondataengineering.net/blog/2018/01/10/the-mid-week-news/</link><pubDate>Wed, 10 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s the first news back after the Christmas break, so brace yourself - it’s a massive bumper jam packed edition… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The big one this week is &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Apache Hadoop&lt;/a&gt; 3.0 - there’s links to the release note on our &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; page and some links below to some commentry&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; has hit 6.1, along with &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;X-Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch Hadoop&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-solr/&quot;&gt;Apache Solr&lt;/a&gt; 7.2 is out&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;Apache HBase&lt;/a&gt; 1.4 is out&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt; is up to 1.12 - Kafka support is interesting&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-knox/&quot;&gt;Apache Knox&lt;/a&gt; has hit 0.14&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-arrow/&quot;&gt;Apache Arrow&lt;/a&gt; has hit 0.8&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/pravega/&quot;&gt;Pravega&lt;/a&gt; - the Kafka challenger - has hit 0.2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-nifi/minifi&quot;&gt;MiNiFi&lt;/a&gt; has seen 0.3 releases of it’s Java version&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt; has seen it’s second 2.x technology preview release - 2.2&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Both ZDNet and Datanami have posts on &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; 3.0 and what the roadmap past this looks like - &lt;a href=&quot;http://www.zdnet.com/article/hadoop-3-confronts-the-realities-of-storage-growth/&quot;&gt;ZDNet&lt;/a&gt;; &lt;a href=&quot;https://www.datanami.com/2017/12/15/hadoop-3-0-ships-roadmap-reveal/&quot;&gt;Datanami&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Blog posts have appeared for &lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Kudu&lt;/a&gt; 1.6 and &lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; 5.3 that have been added to their technology pages. Greenplum is looking to move to a fully containerised deployment model - which is interesting.&lt;/li&gt; &lt;li&gt;Azure HDInsight has seen a big price reduction and a bunch of new announcements - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/azure-hdinsight-announcements-significant-price-reduction-and-amazing-new-capabilities/&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;http://www.zdnet.com/article/microsofts-cloud-big-data-service-cuts-prices-up-to-52/&quot;&gt;ZDNet commentary&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An excellent article from Ehud Kaldor and SwiftStack on the differences between NFS and &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;Object Storage&lt;/a&gt; - &lt;a href=&quot;https://www.swiftstack.com/blog/2018/01/04/nasing-object-storage/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks have published a set of pre-canned streaming analytics projects using &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;HDP&lt;/a&gt; and &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;HDF&lt;/a&gt;, including Ad Serving, Clickstream Analysis and Predictive Maintenance - &lt;a href=&quot;https://hortonworks.com/blog/applying-big-data-streaming-analytics-in-real-world/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A couple of old Databricks announcements we didn’t cover at the time for some reason &lt;ul&gt; &lt;li&gt;Databricks Unified Analytics Platform - Databricks runtime + interactive collaborative notebooks and dashboards + production job / notebook scheduling + enterprise security - &lt;a href=&quot;https://databricks.com/product/unified-analytics-platform&quot;&gt;homepage&lt;/a&gt;; &lt;a href=&quot;https://databricks.com/blog/2017/10/05/build-complex-data-pipelines-with-unified-analytics-platform.html&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Databricks Delta - a service over cloud blog stores like S3 that adds ACID transactions and support for automatic data indexing - &lt;a href=&quot;https://databricks.com/product/databricks-delta&quot;&gt;homepage&lt;/a&gt;; &lt;a href=&quot;https://databricks.com/blog/2017/10/25/databricks-delta-a-unified-management-system-for-real-time-big-data.html&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And some thoughts from ZDNet - &lt;a href=&quot;http://www.zdnet.com/article/the-future-of-the-future-spark-big-data-insights-streaming-and-deep-learning-in-the-cloud/&quot;&gt;Spark in the cloud&lt;/a&gt;; &lt;a href=&quot;http://www.zdnet.com/article/databricks-is-no-longer-playing-david-and-goliath/&quot;&gt;Databricks strategy&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Merv Adrian’s latest Hadoop tracker is up detailing the component versions used by the major &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; vendors - &lt;a href=&quot;https://blogs.gartner.com/merv-adrian/2018/01/03/january-2018-hadoop-tracker/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;If you’ve got some time for reading, AtScale have a list of their top 10 posts and articles from 2017 - &lt;a href=&quot;http://blog.atscale.com/what-youve-missed-in-2017&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, their thoughts on big data in 2018 and the move to the cloud - &lt;a href=&quot;http://www.zdnet.com/article/big-data-2018-cloud-storage-becomes-the-de-facto-data-lake/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The excellent db-engines site have announced their database of the year - &lt;a href=&quot;https://db-engines.com/en/blog_post/76&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;DZone have published a Refcard for &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; covering a whole pile of useful getting started information - &lt;a href=&quot;https://dzone.com/refcardz/apache-kafka&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A good write up of the features in &lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; 6.0 from Logz.io - &lt;a href=&quot;https://logz.io/blog/elastic-stack-6-new/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Are you running &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Kafka&lt;/a&gt; - we have a couple of posts this week from NewRelic and Confluent on monitoring it - &lt;a href=&quot;https://blog.newrelic.com/2017/12/12/new-relic-kafkapocalypse/&quot;&gt;NewRelic&lt;/a&gt;; &lt;a href=&quot;https://www.confluent.io/blog/blog-post-on-monitoring-an-apache-kafka-deployment-to-end-most-blog-posts&quot;&gt;Confluent&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/microsoft-azure-blob-storage/&quot;&gt;Azure Blob Storage&lt;/a&gt; now supports an archive level tier - &lt;a href=&quot;https://azure.microsoft.com/en-au/blog/cloud-storage-now-more-affordable-announcing-general-availability-of-azure-archive-storage/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A deep drive into the &lt;a href=&quot;/technologies/apache-hadoop/yarn/&quot;&gt;YARN&lt;/a&gt; capacity scheduler from Hortonworks - &lt;a href=&quot;https://hortonworks.com/blog/yarn-capacity-scheduler/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Apache &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Flink&lt;/a&gt; - 2017 in review and plans for 2018 - &lt;a href=&quot;http://flink.apache.org/news/2017/12/21/2017-year-in-review.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;dataArtisans have responded to the Databricks Spark Streaming vs Flink benchmark - &lt;a href=&quot;https://data-artisans.com/blog/curious-case-broken-benchmark-revisiting-apache-flink-vs-databricks-runtime&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Apache Mnemonic and Trafodion have graduated from the Apache Incubator - &lt;a href=&quot;https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces25&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;http://incubator.apache.org/projects/trafodion&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache Nifi&lt;/a&gt; project has released the first (0.1) version of the NiFi registry for the configuration management of flows - &lt;a href=&quot;https://nifi.apache.org/registry.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A write-up from ZDNet on &lt;a href=&quot;/technologies/streamsets-data-collector/&quot;&gt;Streamsets&lt;/a&gt; - &lt;a href=&quot;http://www.zdnet.com/article/streamsets-updates-etl-to-the-cloud-data-pipeline/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;It’s an old article, but still interesting - ZDNet looked at &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;graph&lt;/a&gt; vs &lt;a href=&quot;/tech-categories/rdf-databases/&quot;&gt;rdf&lt;/a&gt; databases - &lt;a href=&quot;http://www.zdnet.com/article/graph-databases-and-rdf-its-a-family-affair/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;By comparison this is ancient (from 2015), but looks like a really good intro the the &lt;a href=&quot;/technologies/apache-hbase/&quot;&gt;HBase&lt;/a&gt; architecture from MapR - &lt;a href=&quot;https://mapr.com/blog/in-depth-look-hbase-architecture/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;At the risk of this becoming a ZDNet fest - their views on big data in 2017 and 2018 - &lt;a href=&quot;http://www.zdnet.com/article/big-data-crystal-balls-and-looking-glasses-reviewing-2017-predicting-2018/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update from the &lt;a href=&quot;/technologies/pravega/&quot;&gt;Pravega&lt;/a&gt; blog on their architecture and design principles - &lt;a href=&quot;http://blog.pravega.io/2017/12/14/i-have-a-stream/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;For the deeply technical - how to build a distributed log (&lt;a href=&quot;/tech-categories/streaming-data-stores/&quot;&gt;streaming data store&lt;/a&gt;) - &lt;a href=&quot;https://bravenewgeek.com/building-a-distributed-log-from-scratch-part-1-storage-mechanics/?0&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And last but not least, from Sonra - dimensional modelling on Hadoop - &lt;a href=&quot;https://sonra.io/2017/05/15/dimensional-modeling-and-kimball-data-marts-in-the-age-of-big-data-and-hadoop/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/10/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 08/01/2018</title><link>http://ondataengineering.net/blog/2018/01/08/the-plan-for-this-week/</link><pubDate>Mon, 08 Jan 2018 07:30:00 +0000</pubDate> <description> &lt;p&gt;Welcome back - I hope you’ve had some time off and a relaxing break, I certainly have.&lt;/p&gt; &lt;p&gt;It’s time to get back into it, however before we push on I’m going to take this week just to catch up with a bunch of minor updates to existing technology and technology category pages based on stuff that’s happened over the last few months that I’ve not had time to fold into the site.&lt;/p&gt; &lt;p&gt;Expend a bumper news update on Wednesday, and a post on Friday with some details of the changes.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2018/01/08/the-plan-for-this-week/</guid> </item> <item><title>The Week That Was</title><link>http://ondataengineering.net/blog/2017/12/15/the-week-that-was/</link><pubDate>Fri, 15 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So I’ve been looking at self service data preparation tools this week, and it’s fair to say that once again the topic at hand has turned out to be far much more that I expected… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Last week we looked at data ingest - getting data to your analytical platform from which point you could then conform, standardise, integrate and otherwise prepare it for analytics. This is difficult - the complexity of this preparation, the variety and volume of input data, the potentially widely varying levels of data quality, and the range of analytics you might want to do make this extreemly challenging - just look at every failed or massively overrun BI or analytics project.&lt;/p&gt; &lt;p&gt;This is going to be a really important area for us to look at one this site - perhaps the most important one. And these week I’ve stumbled into it by accident before I was ready.&lt;/p&gt; &lt;p&gt;Self service data preparation tools - I’ve seen some of these before I thought - they’re basically tools that allow you to do basic ingestion and transformation of ad-hoc data sources, often targeting power users or analysts rather than data engineers.&lt;/p&gt; &lt;p&gt;And that may have been true a few years ago, but it’s clear this is an area that’s seen massive change over the last few years, to the point where there are now a huge range of tools covering a range of capabilities including data cataloging (crawling your data sources and constructing models of how it all fits together, often supported by machine learning), data profiling, test data management, data preparation (targeting both analysts and power users with user friendly and powerful graphical user interfaces and data engineers via extensions to existing and established data integration and transformation tools) as well as all the follow up stuff including workflow management, data quality management, metadata management and data governance.&lt;/p&gt; &lt;p&gt;And these tools all cover different capabilities - although there are some stand alone tools there’s a huge range that cover multiple capabilities, from traditional data integration tools that have added new functionality, data lake management tools, analytics tools that including data ingest/preparation functionality, semantic web technologies, data warehouse automation tools, and all in one end to end analytical tools.&lt;/p&gt; &lt;p&gt;So it’s going to take me a while to get to the bottom of these, and I feel like I have a lot of reading to do.&lt;/p&gt; &lt;p&gt;For now, we’re going to take a three week break for Christmas, back on the 8th of January. When we come back we might take a quick look at streaming analytics, maybe a bit of a review of commercial analyst reporting, and then we’ll dive headlong into this.&lt;/p&gt; &lt;p&gt;Have a good holiday everyone, and we’ll see you soon…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/15/the-week-that-was/</guid> </item> <item><title>The Mid Week News - 13/12/2017</title><link>http://ondataengineering.net/blog/2017/12/13/the-mid-week-news/</link><pubDate>Wed, 13 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s time for your weekly dose of the news, but don’t worry, it’s a fairly light one this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-calcite/&quot;&gt;Apache Calcite&lt;/a&gt; has hit 1.5&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; has hit 1.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kudu/&quot;&gt;Apache Kudu&lt;/a&gt; has hit 1.6&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; has hit 5.3&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;From Cloudera, a deep dive into &lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; security and delegation tokens - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/12/hadoop-delegation-tokens-explained/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From The Register, thoughts on &lt;a href=&quot;/tech-categories/object-stores/&quot;&gt;object storage&lt;/a&gt; and the increasing challenge of scale out file systems - &lt;a href=&quot;https://www.theregister.co.uk/2017/12/11/the_failure_of_object_storage/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Thoughts on choosing an &lt;a href=&quot;/tech-categories/hadoop-distributions/&quot;&gt;Hadoop Distribution&lt;/a&gt; from Kognitio - &lt;a href=&quot;https://kognitio.com/blog/which-hadoop-distribution-is-right-for-you/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From the SmartCat blog (via DZone), problems with &lt;a href=&quot;/technologies/apache-kafka/kafka-streams/&quot;&gt;Kafka Stream&lt;/a&gt; - &lt;a href=&quot;https://www.smartcat.io/blog/2017/problem-with-kafka-streams&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From InfoQ - thoughts on Amazon Nepture, their new cloud graph database - &lt;a href=&quot;https://www.infoq.com/news/2017/12/amazon-neptune?utm_campaign=infoq_content&amp;amp;utm_source=infoq&amp;amp;utm_medium=feed&amp;amp;utm_term=Database&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/13/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 11/12/2017</title><link>http://ondataengineering.net/blog/2017/12/11/the-plan-for-this-week/</link><pubDate>Mon, 11 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So we looked at data ingestion tools last week, however there was once type that we didn’t include that I want to look at this week, and that’s data wrangling tools - tools designed for the one off manual ingestion of data, focusing on quickly and easily cleaning and standardising data from whatever form it’s in into a standard form for onwards processing.&lt;/p&gt; &lt;p&gt;See you at the end of the week…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/11/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Data Ingestion Technologies</title><link>http://ondataengineering.net/blog/2017/12/08/thoughts-on-data-ingestion-technologies/</link><pubDate>Fri, 08 Dec 2017 07:45:00 +0000</pubDate> <description> &lt;p&gt;So we’ve been looking at &lt;a href=&quot;/tech-categories/data-ingestion/&quot;&gt;data ingestion&lt;/a&gt; technologies - let’s talk about it… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Before you can exploit data, you need to get it into a position where you can exploit it. In some limited cases that might be where it currently sites, but in most cases that means moving it to somewhere you can run more expansive and expensive analytics.&lt;/p&gt; &lt;p&gt;The challenge here is the potential range of different sources you might want to acquire data from - event logs, relational databases, NoSQL databases, mainframes, application APIs, cloud platforms, file based feeds etc. And although any good data integration or transformation tool will include adapters to read data from a wide range of sources, reliably getting data in is always a challenge, and you’ll quickly end up either building a framework for ingesting data or with huge amounts of copied and pasted code.&lt;/p&gt; &lt;p&gt;So what are these challenges? Let’s brain dump:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Supporting both batch and continuous ingestion of data&lt;/li&gt; &lt;li&gt;If you’re pulling data, working out what data needs acquiring (that hasn’t been acquired before), and if it’s being pushed to you, making sure that you’re not missing anything&lt;/li&gt; &lt;li&gt;Support for acquiring full snapshots, new data and CDC feeds (containing new, changed and deleted records)&lt;/li&gt; &lt;li&gt;Capturing data continuously for systems that aren’t designed for it (mainframes, databases, applications)&lt;/li&gt; &lt;li&gt;Distributed collection - do you need to run agents on remote machines to capture data, and maybe pre-do some processing nearer the edge before forwarding it on&lt;/li&gt; &lt;li&gt;For file based feeds, file based checks, including headers and footers, completeness and format&lt;/li&gt; &lt;li&gt;Resilience and reliability - if you’re receiving a million records a minute what happens when you’re down&lt;/li&gt; &lt;li&gt;Tracking what data you’ve received and when you received it&lt;/li&gt; &lt;li&gt;Checking that there are things changing in your source that’s going to impact your analytics - has it introduced new fields, new values for fields you’re not expecting, changed data types; do the fields still contain what they contained when you originally wrote your analytics?&lt;/li&gt; &lt;li&gt;Tracking metrics of the data you’re receiving - do you have stats (and graphs) or how much data you’re receiving, what the profile of the data looks like so you can spot trends and deviations?&lt;/li&gt; &lt;li&gt;Acquiring new data without spending weeks writing, debugging and testing lots of code&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;TLDR - it’s easy to acquire data, it’s really difficult to do this in a reliable and robust way that doesn’t include huge amounts of development and maintenance.&lt;/p&gt; &lt;p&gt;And this is where specialist data ingestion tools come in. They don’t do anything a general purpose data transformation / ingestion tool can’t do - they just come with a huge amount of the functionality you need for ingesting data out of the box that you’d otherwise have to build yourself, and focusing on making this as simple, quick and robust as possible.&lt;/p&gt; &lt;p&gt;If I need to spell this out any more clearly - if you’re not using a data ingestion tool to capture your data, then it’ll be well worth your time looking at one.&lt;/p&gt; &lt;p&gt;And there’s a really interesting range to choose from now. If you’re looking for a generally purpose tool, there’s a range of open source and commercial offers available, from &lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache Nifi&lt;/a&gt; which we’ve looked at both, to &lt;a href=&quot;/technologies/streamsets-data-collector/&quot;&gt;StreamSets Data Collector&lt;/a&gt; and &lt;a href=&quot;/technologies/apache-gobblin/&quot;&gt;Apache Gobblin (Incubating)&lt;/a&gt; that we looked at this week.&lt;/p&gt; &lt;p&gt;And then there’s a range of capabilities that have different focuses, from continuous event ingestion (or log shipping), to database unloads and continuous ingestion from databases.&lt;/p&gt; &lt;p&gt;And please remember - this is about the aquisition of data and not transformation or aggregation for analytics. You’re trying to get it to your analytics platform in a state where it’s ready for onward processing, but without doing so much work that the chance of a failure means you’ve got lots of data lying on the floor. We’ll look at tools for doing the analytics soon…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/08/thoughts-on-data-ingestion-technologies/</guid> </item> <item><title>Data Ingestion</title><link>http://ondataengineering.net/tech-categories/data-ingestion/</link><pubDate>Fri, 08 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Our list of and information on commercial, open source and cloud based data ingestion tools, including NiFi, StreamSets, Gobblin, Logstash, Flume, FluentD, Sqoop, GoldenGate and alternatives to these.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Category Definition&lt;/h2&gt; &lt;!-- Tech Vendor metadata --&gt; &lt;p&gt;Specialist tools designed to acquire and ingest data into an analytical platform ready for analysis or for further transformation to support analysis. And although more general purpose data integration/transformation tools can fulfil this function, specialist data ingestion tools provide capabilities designed to make this faster and more reliable. Key features include support for remote agents to acquire and forward data, GUIs for configuring ingestion pipelines, support for data quality checks to monitor and/or reject incoming data, and basic file and record level transformations on top of the standard functionality to acquire data from a wide range of sources out of the box. &lt;!--more--&gt;&lt;/p&gt; &lt;h2 id=&quot;general-purpose-ingestion-tools&quot;&gt;General Purpose Ingestion Tools&lt;/h2&gt; &lt;p&gt;These tools support both batch and streaming ingestion from a wide range of data sources:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-nifi/&quot;&gt;Apache Nifi&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Open source, with commercial support available from Hortonworks through &lt;a href=&quot;/technologies/hortonworks-data-flow/&quot;&gt;Hortonworks Data Flow&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/streamsets-data-collector/&quot;&gt;StreamSets Data Collector&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Open source, with commercial support available from StreamSets&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-gobblin/&quot;&gt;Apache Gobblin (Incubating)&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Open Source Java framework for managing big data ingestion, including replication, organisation and lifecycle management&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Skool&lt;/td&gt; &lt;td&gt;Open source tool from BT for bring database and file data into Hadoop through generation of Sqoop, Hive, Pig and Oozie code from configuration; open sourced in September 2016 but has seen limited development since - &lt;a href=&quot;https://github.com/BT-OpenSource/Skool&quot;&gt;https://github.com/BT-OpenSource/Skool&lt;/a&gt;; &lt;a href=&quot;https://blog.cloudera.com/blog/2016/09/skool-an-open-source-data-integration-tool-for-apache-hadoop-from-british-telecom/&quot;&gt;https://blog.cloudera.com/blog/2016/09/skool-an-open-source-data-integration-tool-for-apache-hadoop-from-british-telecom/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-ingestion-tools&quot;&gt;Streaming Ingestion Tools&lt;/h2&gt; &lt;p&gt;Tools specialising in the ingestion of log files or events, with support for distributed collection and forwarding of data, sometimes called log shipping tools. There’s a write up of some of the tools available from Sematext: &lt;a href=&quot;https://sematext.com/blog/logstash-alternatives/&quot;&gt;https://sematext.com/blog/logstash-alternatives/&lt;/a&gt;&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Logstash&lt;/td&gt; &lt;td&gt;Heavily integrated with ElasticSearch but also supports a number of other targets; open source with commercial support from Elastic as part of their ELK stack - &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;https://www.elastic.co/products/logstash&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Beats&lt;/td&gt; &lt;td&gt;Lightweight technology written in Go to forward events to Logstash; open source with commercial support from Elastic as part of their ELK stack - &lt;a href=&quot;https://www.elastic.co/products/beats&quot;&gt;https://www.elastic.co/products/beats&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-flume/&quot;&gt;Apache Flume&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Runs on Hadoop and supports the continuous ingestion of data using a set of independent agents connected together into pipelines&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Fluentd&lt;/td&gt; &lt;td&gt;Ruby based tool, part of the Cloud Native Computing Foundation; open source, with commercial support available from TreasureData - &lt;a href=&quot;http://www.fluentd.org/&quot;&gt;http://www.fluentd.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Logagent-js&lt;/td&gt; &lt;td&gt;JavaScript based tool; open source, with commercial support available from Sematext - &lt;a href=&quot;https://github.com/sematext/logagent-js&quot;&gt;https://github.com/sematext/logagent-js&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;rsyslog&lt;/td&gt; &lt;td&gt;Focused on log processing, with lineage back to UNIX syslogd; written in C; open source, with commercial support available from Adiscon - &lt;a href=&quot;http://www.rsyslog.com/&quot;&gt;http://www.rsyslog.com/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Syslog-ng&lt;/td&gt; &lt;td&gt;Focused on log processing, with lineage back to UNIX syslogd; written in C; open source, with commercial support available from BalaBit - &lt;a href=&quot;https://syslog-ng.org/&quot;&gt;https://syslog-ng.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Gollum&lt;/td&gt; &lt;td&gt;Open source project from Trivago; written in Go, quiet, but with new releases still being produced - &lt;a href=&quot;https://github.com/trivago/gollum/&quot;&gt;https://github.com/trivago/gollum/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;LogZoom&lt;/td&gt; &lt;td&gt;Open source tool from PacketZoom for processing data from processing data from Beats, written in Go, however inactive since November 2016 - &lt;a href=&quot;https://github.com/packetzoom/logzoom&quot;&gt;https://github.com/packetzoom/logzoom&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Heka&lt;/td&gt; &lt;td&gt;Open source tool from Mozilla, however inactive since August 2016 - &lt;a href=&quot;https://github.com/mozilla-services/heka&quot;&gt;https://github.com/mozilla-services/heka&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Suro&lt;/td&gt; &lt;td&gt;Open source tool from Netflix, however inactive since December 2015 - &lt;a href=&quot;https://github.com/Netflix/suro&quot;&gt;https://github.com/Netflix/suro&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Scribe&lt;/td&gt; &lt;td&gt;Open source tool from Facebook, however inactive since May 2014 - &lt;a href=&quot;https://github.com/facebookarchive/scribe&quot;&gt;https://github.com/facebookarchive/scribe&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;database-unload-tools&quot;&gt;Database Unload Tools&lt;/h2&gt; &lt;p&gt;The following are specialist tools for unloading data form databases. Most data transformation tools and processing tools will also be able to unload data from databases, and are therefore an alternative to using a specialist tool:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-sqoop/&quot;&gt;Apache Sqoop&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Specialist technology for moving bulk data between Hadoop and structured (relational) databases.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;database-change-capture-tools&quot;&gt;Database Change Capture Tools&lt;/h2&gt; &lt;p&gt;The following technologies support the continuous capture and ingestion of record change events from databases, and are sometimes known as change data capture tools:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Oracle GoldenGate for Big Data 12c&lt;/td&gt; &lt;td&gt;Commercial product for the continuous replication of data from a wide range of relational databases into a wide range of “Big Data” targets - &lt;a href=&quot;https://www.oracle.com/middleware/data-integration/goldengate/big-data/index.html&quot;&gt;https://www.oracle.com/middleware/data-integration/goldengate/big-data/index.html&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;IBM Infosphere Data Replication&lt;/td&gt; &lt;td&gt;Commercial product for the continuous replication from relational databases, including IBM systems on mainframes to a range of systems including kafka and Hadoop - &lt;a href=&quot;https://www.ibm.com/us-en/marketplace/infosphere-data-replication&quot;&gt;https://www.ibm.com/us-en/marketplace/infosphere-data-replication&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SyncSort DMX Change Data Capture&lt;/td&gt; &lt;td&gt;Commercial tool for continually capturing data from mainframe databases - &lt;a href=&quot;https://www.syncsort.com/en/Products/BigData/DMX-Change-Data-Capture&quot;&gt;https://www.syncsort.com/en/Products/BigData/DMX-Change-Data-Capture&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Quest Shareplex&lt;/td&gt; &lt;td&gt;Commercial product for the continuous replication of data from Oracle or SQL Server to a range of targets including Kafka, Hadoop and flat files; previously known as Dell Shareplex, SharePlex for Oracle and Quest Data Connector for Oracle and Hadoop - &lt;a href=&quot;https://www.quest.com/products/shareplex/&quot;&gt;https://www.quest.com/products/shareplex/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Attunity Replicate&lt;/td&gt; &lt;td&gt;Commercial technology for the continuous replication of data between a wide variety of sources including Kafka, relational and analytical databases, mainframes, Hadoop and the cloud; with a free limited Express edition - &lt;a href=&quot;https://www.attunity.com/products/replicate/&quot;&gt;https://www.attunity.com/products/replicate/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Continuent Tungsten Replicator&lt;/td&gt; &lt;td&gt;Continuous replication of Oracle, MySQL and Amazon RDS databases to Hadoop, Vertica, RedShift and others, with an open source version available - &lt;a href=&quot;https://www.continuent.com/solutions/#bigdata&quot;&gt;https://www.continuent.com/solutions/#bigdata&lt;/a&gt;; &lt;a href=&quot;https://github.com/continuent/tungsten-replicator&quot;&gt;https://github.com/continuent/tungsten-replicator&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Dbvisit Replicate&lt;/td&gt; &lt;td&gt;Commercial product for the continuous replication of data from Oracle to a number of targets including Hadoop and Kafka - &lt;a href=&quot;http://www.dbvisit.com/products/dbvisit_replicate_real_time_oracle_database_replication/&quot;&gt;http://www.dbvisit.com/products/dbvisit_replicate_real_time_oracle_database_replication/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;SQData CDC&lt;/td&gt; &lt;td&gt;Commercial tool for continuous replication with a wide range of sources and targets - &lt;a href=&quot;https://www.sqdata.com/changed-data-capture/&quot;&gt;https://www.sqdata.com/changed-data-capture/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;streaming-data-store-ingestion&quot;&gt;Streaming Data Store Ingestion&lt;/h2&gt; &lt;p&gt;A number of &lt;a href=&quot;/tech-categories/streaming-data-stores/&quot;&gt;streaming data stores&lt;/a&gt; have integrated tools for the aquisition of data:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;a href=&quot;/technologies/apache-kafka/kafka-connect/&quot;&gt;Kafka Connect&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Framework for building scalable and reliable integrations between Kafka and other technologies, including the ingestion of data, that’s part of the core Apache Kafka technology&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Debezium&lt;/td&gt; &lt;td&gt;Open Source tool for continuous replication from a number of databases based on Kafka and Kafka Connect - &lt;a href=&quot;http://debezium.io/&quot;&gt;http://debezium.io/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Amazon Kinesis Streams&lt;/td&gt; &lt;td&gt;Includes an Amazon Kinesis Agent for capture and ingestion of data - &lt;a href=&quot;https://aws.amazon.com/kinesis/streams/&quot;&gt;https://aws.amazon.com/kinesis/streams/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;cloud-based-ingestion-tools&quot;&gt;Cloud Based Ingestion Tools&lt;/h2&gt; &lt;p&gt;The following are cloud based ingestion as a service tools, primarily for ingesting data into cloud based analytical platforms:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Amazon Kinesis Firehose&lt;/td&gt; &lt;td&gt;Streaming data movement, with support for basic transformation including routing, splitting and batching - &lt;a href=&quot;https://aws.amazon.com/kinesis/firehose/&quot;&gt;https://aws.amazon.com/kinesis/firehose/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;other-tools&quot;&gt;Other Tools&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Apache Chukwa&lt;/td&gt; &lt;td&gt;Specialist technology for the ingestion of continuous data flows into an Hadoop cluster, and the subsequent management and analysis of the data; donated by Yahoo in 2010 but now largely abandoned - &lt;a href=&quot;https://chukwa.apache.org/&quot;&gt;https://chukwa.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Apache ManifoldCF&lt;/td&gt; &lt;td&gt;Framework for replicating data from content repositories to analytical search technologies - &lt;a href=&quot;http://manifoldcf.apache.org/&quot;&gt;http://manifoldcf.apache.org/&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/tech-categories/data-ingestion/</guid> </item> <item><title>Apache Gobblin (Incubating)</title><link>http://ondataengineering.net/technologies/apache-gobblin/</link><pubDate>Wed, 06 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Java based framework for ingesting data into Hadoop. Ingestion jobs are defined through job configuration files, and are made up of a number of stages - a Source identifies work to be done and generates Work Units which are then processed by Tasks, with Tasks consisting of an Extractor (reads the records to be processed), one or more Converters (a 1:N transformation of records), a Quality Checker (covers both record and file checks), a Fork Operator (allows data to be written to multiple targets) and a Writer (writes out completed records), with the output of a completed task being committed by a Publisher. Gobblin ships with a number of standard components, including support for a range of sources and targets, as well as supporting custom implementations of any stage. Jobs can be run using a number of frameworks, including MapReduce (with all tasks running as mapper only jobs), YARN, and as Java threads within a single JVM, with some modes also supporting an internal scheduler and job management engine. Supports job locks (to ensure multiple instances of the same job don't run at the same time), job history metadata (via a job execution history store that supports a REST API that can be used to monitor jobs), exactly-once processing support (via Publisher commits), failure handling (retrying both within and across jobs), capture and forwarding of execution and data quality metrics, post processing of data (e.g. to remove duplicates or generate aggregations), partitioned writers, job configuration file templates, Hive table registration, high availability, data retention management (automatically deleting old data according to a number of retention rules), and data purging (Gobblin Compliance). Developed at LinkedIn from late 2013, first announced in November 2014 and open sourced shortly afterwards, before being donated to the Apache Foundation in February 2017, and with stated deployments at a number of large organisations.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Other Names&lt;/td&gt;&lt;td&gt;Apache Gobblin, Gobblin&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/apache/&quot;&gt;The Apache Software Foundation&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Open Source - Active&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;December 2017 - v0.11&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.5&lt;/td&gt; &lt;td&gt;2015-09-28&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://engineering.linkedin.com/big-data/bridging-batch-and-streaming-data-ingestion-gobblin&quot;&gt;Annoucement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.6&lt;/td&gt; &lt;td&gt;2015-12-21&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.6.0&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;2016-05-18&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.7.0&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://engineering.linkedin.com/blog/2016/06/announcing-gobblin-0-7-0--going-beyond-ingestion&quot;&gt;Announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Dataset lifecycle features&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.8&lt;/td&gt; &lt;td&gt;2016-09-03&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.8.0&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.9&lt;/td&gt; &lt;td&gt;2016-12-19&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.9.0&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.10&lt;/td&gt; &lt;td&gt;2017-05-05&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.10.0&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;First Apache release&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0.11&lt;/td&gt; &lt;td&gt;2017-07-20&lt;/td&gt; &lt;td&gt;https://github.com/apache/incubator-gobblin/releases/tag/gobblin_0.11.0&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;http://gobblin.apache.org/&quot;&gt;http://gobblin.apache.org/&lt;/a&gt; - home page&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://gobblin.readthedocs.io/en/latest/l&quot;&gt;http://gobblin.readthedocs.io/en/latest/l&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://engineering.linkedin.com/data-ingestion/gobblin-big-data-ease&quot;&gt;https://engineering.linkedin.com/data-ingestion/gobblin-big-data-ease&lt;/a&gt; - announcement&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/ShirshankaDas/apache-gobblin-bridging-batch-and-streaming-data-integration-big-data-meetup-2017&quot;&gt;https://www.slideshare.net/ShirshankaDas/apache-gobblin-bridging-batch-and-streaming-data-integration-big-data-meetup-2017&lt;/a&gt; - presentation from May 2017&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/apache/incubator-gobblin/releases&quot;&gt;https://github.com/apache/incubator-gobblin/releases&lt;/a&gt; - release announcements / history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/apache-gobblin/</guid> </item> <item><title>The Mid Week News - 06/12/2017</title><link>http://ondataengineering.net/blog/2017/12/06/the-mid-week-news/</link><pubDate>Wed, 06 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Right - time for your weekly updates on new software releases and interesting new information and posts, with a big dump from AWS re:Invent this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-beam/&quot;&gt;Apache Beam&lt;/a&gt; has hit 2.2&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/druid/&quot;&gt;Druid&lt;/a&gt; has hit 0.11&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;After the Azure product dump a few weeks ago, it’s Amazon’s turn via AWS re:Invent: &lt;ul&gt; &lt;li&gt;Amazon Neptune - a graph/RDF database as a service with support for TinkerPop Gremlin and RDF SPARQL - &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-neptune-fast-reliable-graph-database-built-for-the-cloud/&quot;&gt;announcement&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-neptune-a-fully-managed-graph-database-service/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Amazon SageMaker - service for building, training and deploying machine learning at scale - &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-amazon-sagemaker/&quot;&gt;announcement&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/blogs/aws/sagemaker/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;AWS Fargate - provisioning of containers on AWS without managing servers or clusters - &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-aws-fargate-a-technology-to-run-containers-without-managing-infrastructure/&quot;&gt;announcement&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/blogs/aws/aws-fargate/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Elastic Kubernetes Service (EKS) - Kubernetes as a service - &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-amazon-elastic-container-service-for-kubernetes/&quot;&gt;announcement&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-elastic-container-service-for-kubernetes/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;S3 Select and Glacier Select - retrieve subsets of stored objects by running select queries server side - &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-s3-select-is-now-available-in-limited-preview/&quot;&gt;S3 announcement&lt;/a&gt;, &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-glacier-select-makes-big-data-analytics-of-archive-data-possible/&quot;&gt;Glacier announcement&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/blogs/aws/s3-glacier-select/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;See also summaries from &lt;a href=&quot;https://www.theregister.co.uk/2017/11/29/amazon_aws_kubernetes/&quot;&gt;The Register&lt;/a&gt;, from &lt;a href=&quot;https://www.infoq.com/news/2017/12/aws-reinvent-day-one&quot;&gt;InfoQ&lt;/a&gt;, and the &lt;a href=&quot;https://aws.amazon.com/blogs/aws/category/events/reinvent/&quot;&gt;motherlist of blog posts&lt;/a&gt; relating to re:Invent from Amazon&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;From Cloudera, infrastructure considerations for deploying &lt;a href=&quot;/technologies/cloudera-cdh/&quot;&gt;CDH&lt;/a&gt; - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/11/deploy-cloudera-edh-clusters-like-a-boss-revamped-part-1/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;MapR have posted their thoughts on &lt;a href=&quot;/technologies/apache-drill/&quot;&gt;Apache Drill&lt;/a&gt; as part of the &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt;, and their view of it as “a unified SQL access layer across files, tables and streams”, along (of course) with some new benchmarks - &lt;a href=&quot;https://community.mapr.com/community/products/blog/2017/11/29/apache-drill-version-111-on-mapr-release-overview&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An interesting post of MariaDB AX, the data warehouse solution from MariaDB that’s built on MariaDB ColumnStore, on bulk and streaming ingestion of data - &lt;a href=&quot;https://mariadb.com/resources/blog/real-time-data-streaming-mariadb-ax&quot;&gt;link&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;AtScale now runs over Amazon RedShift - &lt;a href=&quot;http://blog.atscale.com/atscale_aws_redshift&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Confluent have a new blog post on Confluent Platform 4.0 (&lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/confluent-enterprise/&quot;&gt;Confluent Enterprise&lt;/a&gt;) - &lt;a href=&quot;https://www.confluent.io/blog/introducing-confluent-platform-4-0/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From ZDNet, an interview on &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; and thoughts on the wider ecosystem - &lt;a href=&quot;http://www.zdnet.com/article/real-time-applications-are-going-places/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Google, another post on the separation of storage and compute with BigQuery - &lt;a href=&quot;https://cloud.google.com/blog/big-data/2017/11/separation-of-storage-and-compute-in-bigquery&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;http://www.crail.io/&quot;&gt;Crail&lt;/a&gt; has been accepted to the Apache Incubator - we last saw this in October when it was submitted, so that’s a pretty quick turn around. As a recap, this looks like a high performance distributed and tiered (in memory, flash and disk) storage layer for temporary data that provides memory, storage and network access that bypasses the JVM and OS, and with integration to Spark (as a custom Spark Suffler that improves sort performance by a factor of five) and Hadoop (via an HDFS adaptor).&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/06/the-mid-week-news/</guid> </item> <item><title>StreamSets Data Collector</title><link>http://ondataengineering.net/technologies/streamsets-data-collector/</link><pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate> <description> &lt;p&gt;General purpose technology for the movement of data between systems, including the ingestion of batch and streaming data into an analytical platform. Pipelines are configured in a graphical user interface, and consist of a single origin, one or more processor stages and then one or more destinations, with support for a wide range of source/destination technologies and processor transformations. Supports a wide range of data formats, executors (tasks that can be triggered based on events from pipelines, e.g. to send e-mails or run a shell script), handling of erroroneous records, support for CDC CRUD records, previewing of data within the editor UI, real-time reporting and alerting on a range of execution and data quality metrics, the ability to dynamically handle changes to schemas and the semantic meaning of data and a full Python SDK. Can run in standalone mode (as a single process, with the option to run single or multi-threaded), as a Spark Straming or MapReduce job on a cluster, or in an ultralight agent (StreamSets Data Collector Edge). Java based, Open Source under the Apache 2.0 licence, hosted on GitHub, with development led by StreamSets who also provide commercial support and a number of commercial add-ons, including Control Hub (cloud service for developing and managing pipelines), Dataflow Performance Manager (for managing data metrics) and Data Protector (for managing senstive data). Started in October 2014, with a v1.0 release in September 2015.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;StreamSets&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial Open Source&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;June 2018 - v3.3&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.0&lt;/td&gt; &lt;td&gt;2017-12-15&lt;/td&gt; &lt;td&gt;See 3.0 notes on &lt;a href=&quot;https://streamsets.com/documentation-page/&quot;&gt;documentation and release page&lt;/a&gt;; &lt;a href=&quot;https://streamsets.com/blog/announcing-streamsets-data-collector-version-3-0/&quot;&gt;blog post&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.1&lt;/td&gt; &lt;td&gt;2017-03-30&lt;/td&gt; &lt;td&gt;See 3.1 notes on &lt;a href=&quot;https://streamsets.com/documentation-page/&quot;&gt;documentation and release page&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.2&lt;/td&gt; &lt;td&gt;2018-05-11&lt;/td&gt; &lt;td&gt;See 3.2 notes on &lt;a href=&quot;https://streamsets.com/documentation-page/&quot;&gt;documentation and release page&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3.3&lt;/td&gt; &lt;td&gt;2018-05-24&lt;/td&gt; &lt;td&gt;See 3.3 notes on &lt;a href=&quot;https://streamsets.com/documentation-page/&quot;&gt;documentation and release page&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://streamsets.com/product/&quot;&gt;https://streamsets.com/product/&lt;/a&gt; - product homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://streamsets.com/docs/&quot;&gt;https://streamsets.com/docs/&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://github.com/streamsets/datacollector&quot;&gt;https://github.com/streamsets/datacollector&lt;/a&gt; - source code&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://streamsets.com/blog&quot;&gt;https://streamsets.com/blog&lt;/a&gt; - blog&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://streamsets.com/documentation-page/&quot;&gt;https://streamsets.com/documentation-page/&lt;/a&gt; - Documentation and release history&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/streamsets-data-collector/</guid> </item> <item><title>The Plan For This Week - 04/12/2017</title><link>http://ondataengineering.net/blog/2017/12/04/the-plan-for-this-week/</link><pubDate>Mon, 04 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;Right, time to push on with more technology categories and actually add some meaningful content to this site, and we’re going to focus on data movement, ingestion and transformation tools for a little while.&lt;/p&gt; &lt;p&gt;First up this week, technologies for the continuous ingestion of event data.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/04/the-plan-for-this-week/</guid> </item> <item><title>Technology Categories</title><link>http://ondataengineering.net/blog/2017/12/01/technology-categories/</link><pubDate>Fri, 01 Dec 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So this has taken far too long, and some proper updates to this site are long overdue, but let’s summarise what I’ve been looking at for the last three weeks. And yes, I said they’d be new content last week, but in the end the stuff I had (which was old from when I was planning the site) just wasn’t up to scratch, so it’s been binned rather than published. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;So the big update has been some (minor) structural changes. Firstly, the &lt;a href=&quot;/technologies/&quot;&gt;technology&lt;/a&gt;, &lt;a href=&quot;/tech-categories/&quot;&gt;technology category&lt;/a&gt; and &lt;a href=&quot;/tech-vendors/&quot;&gt;technology vendor&lt;/a&gt; index pages are now part of the open source content repository for this site, meaning that they’re editable just like any of the technology, vendor or category pages. And secondly, the technology category pages now have a meta description under the header, with the summary of the technology category now moved into the body of the content.&lt;/p&gt; &lt;p&gt;And with the new index pages has come a completely redesigned &lt;a href=&quot;/tech-categories/&quot;&gt;technology category index page&lt;/a&gt;, with all the technology categories now organised into sections (categories!), with a bit more description and structure. And as part of doing this I’ve taken the opportunity to review the technology categories we have and make some tweaks and adjustments - I’m still not entirely happy, but I’ve spent far too much time thinking about it, and it’s time to move on.&lt;/p&gt; &lt;p&gt;But I have made some updates to the technology categories as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;I’ve moved/copied a bunch of commercial and open source Hadoop based technologies from the &lt;a href=&quot;/tech-categories/query-engines/&quot;&gt;query engines&lt;/a&gt; page to the &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt; page. I’ve debated for far to long what the different between these categories are, but I think I’ve got to somewhere I’m comfortable with, and hopefully the technology category descriptions now reflect this.&lt;/li&gt; &lt;li&gt;I’ve added RecordService and the Hive Metastore to the Data Storage Services section of the &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;data storage formats&lt;/a&gt; page. I’m thinking about splitting this section out into it’s own category at some point, as the storage of structured data that can then be exploited by multiple tools is an area that requires more consideration.&lt;/li&gt; &lt;li&gt;I’ve moved the analytical graph databases from the &lt;a href=&quot;/tech-categories/graph-analytics/&quot;&gt;graph analytics&lt;/a&gt; page into the &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt; page, leaving the graph analytics page to focus on graph analytics run over external data. I’ve also broken out the &lt;a href=&quot;/tech-categories/graph-databases/&quot;&gt;graph databases&lt;/a&gt; that also support analytics into their own section.&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;/tech-categories/in-memory-databases/&quot;&gt;in memory databases&lt;/a&gt; page is no longer included on the index page, as all the information is now replicated to other pages with the exception of some operational relational database stuff. Once this has a new home, we’ll drop this category.&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/12/01/technology-categories/</guid> </item> <item><title>The Mid Week News - 29/11/2017</title><link>http://ondataengineering.net/blog/2017/11/29/the-mid-week-news/</link><pubDate>Wed, 29 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;To tide you over whilst the content I promised never arrives, let’s look at the news, and it feels like a interesting crop this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The Confluent platform - &lt;a href=&quot;/technologies/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt; and &lt;a href=&quot;/technologies/confluent-enterprise/&quot;&gt;Confluent Enterprise&lt;/a&gt; - has hit 4.0 based on the Apache Kafka 1.0 release&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Cloudera have announced &lt;a href=&quot;/technologies/cloudera-altus/analytical-db/&quot;&gt;Altus Analytical DB&lt;/a&gt; - their cloud based SQL analytics service. We’ll take a deeper look at this in a few week. &lt;a href=&quot;http://vision.cloudera.com/introducing-cloudera-altus-analytic-db-beta-for-cloud-based-data-warehousing/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Zenko Orbit has been announced - a web based portal for managing object storage data across multiple clouds, for example when used behind &lt;a href=&quot;/technologies/zenko/cloudserver/&quot;&gt;Zenko CloudServer&lt;/a&gt; - &lt;a href=&quot;https://www.zenko.io/blog/introducing-zenko-orbit/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Confluent Cloud is now generally available on AWS - &lt;a href=&quot;https://www.confluent.io/blog/confluent-cloud-enterprise-ready-hosted-apache-kafka/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;If you’ve upgraded to Elastic Cloud 1.1 and Kibana’s not available - Elastic have a workaround for you! &lt;a href=&quot;https://www.elastic.co/blog/elastic-cloud-enterprise-1-1-0-upgrade-issues&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;This is pretty neat - from “the morning paper”, a in-memory key value store implemented directly on NIC FPGAs that can do 1.22 billion KV operations per second when running on 10 NICs - &lt;a href=&quot;https://blog.acolyer.org/2017/11/23/kv-direct-high-performance-in-memory-key-value-store-with-programmable-nic/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Confluent, an update on transactions in &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; - &lt;a href=&quot;https://www.confluent.io/blog/transactions-apache-kafka/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An update on the upcoming features in &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; 1.4 and 1.5 - &lt;a href=&quot;http://flink.apache.org/news/2017/11/22/release-1.4-and-1.5-timeline.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Apache Impala&lt;/a&gt; has graduated from the Apache Incubator - &lt;a href=&quot;https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces24&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/29/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 27/11/2017</title><link>http://ondataengineering.net/blog/2017/11/27/the-plan-for-this-week/</link><pubDate>Mon, 27 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So having (pretty much) finished my extended and rather more painful tidy up of what we’ve done so far, I’ve got a bunch of content to put live this week, before we move on to a brand new technology category next week. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;For the record, the &lt;a href=&quot;/technologies/&quot;&gt;technology&lt;/a&gt;, &lt;a href=&quot;/tech-vendors/&quot;&gt;technology vendor&lt;/a&gt; and &lt;a href=&quot;/tech-categories/&quot;&gt;technology category&lt;/a&gt; index pages are now part of the content site, meaning that these are now editable as per any other content page. They’ll be a bunch of changes to these going live this week.&lt;/p&gt; &lt;p&gt;I’ve also slightly changed the structure of technology category pages (and will do a similar thing for technology and technology vendor pages in due course). The description of these pages is now a meta description of the page rather than a summary of the technology category, with this moved down to be the initial text in the content.&lt;/p&gt; &lt;p&gt;Oh, add the draft banner has now moved to the left hand sidebar.&lt;/p&gt; &lt;p&gt;The content this week is coming from me digging through my old notes I made when planning the site, which includes a few technology summaries I did whilst planning what I wanted to do. We’ll stick these live this week, along with a bunch of updates to the technology category pages, and a new re-designed technology category index page.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/27/the-plan-for-this-week/</guid> </item> <item><title>The Mid Week News - 22/11/2017</title><link>http://ondataengineering.net/blog/2017/11/22/the-mid-week-news/</link><pubDate>Wed, 22 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s Wednesday, which means it’s time for the news, and there’s big MapR and Microsoft Azure announcements this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; version 2.9 is out&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/apache-nifi/minifi/&quot;&gt;MiNiFi&lt;/a&gt; C++ version has seen a 0.3 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/greenplum/&quot;&gt;Greenplum&lt;/a&gt; continues it’s regular release schedule with a 5.2 release&lt;/li&gt; &lt;li&gt;Hortonworks &lt;a href=&quot;/technologies/cloudbreak/&quot;&gt;Cloudbreak&lt;/a&gt; has a 2.1 technical preview out with all new documentation&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; 6.0 details have been updated with a link to their blog post on the removal of mapping types&lt;/li&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; 1.2 details have been updated with a link to the latest Cloudera blog post&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt; v6.0 is out - we’ll wait for the dust to settle a bit before updating the site - &lt;a href=&quot;https://mapr.com/products/whats-new/6-0/&quot;&gt;what’s new&lt;/a&gt;; &lt;a href=&quot;http://www.zdnet.com/article/mapr-6-0-converges-control-of-data-at-rest-and-in-motion-on-the-same-pane-of-glass/&quot;&gt;ZDNet write-up&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Microsoft’s big Connect event has thrown out a bunch of announcements: &lt;ul&gt; &lt;li&gt;Azure Databricks is a new service jointly developed with Databricks that brings Spark as a service as a first class citizen into Azure - we’ll look more at this in the coming weeks I think - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/a-technical-overview-of-azure-databricks/&quot;&gt;link&lt;/a&gt;; &lt;a href=&quot;https://databricks.com/blog/2017/11/15/introducing-azure-databricks.html&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Azure Cosmos DB (their NoSQL database) now supports an Apache Cassandra compatible API to join the existing SQL, Gemlin (Neo4j), MongoDB and Azure Table Store APIs - making it a true multi model database supporting wide column storage, graph, relational, document and key value store use cases - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/azure-cosmosdb-microsoft-connect-2017/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Azure Time Series Insights (TSI) - their time series databases has hit general availability - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/microsoft-announces-the-general-availability-of-azure-time-series-insights/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Azure Database for MariaDB has been announced in preview - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/mariadb-postgresql-and-mysql-more-choices-on-microsoft-azure/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;ZDNet have a good write up - &lt;a href=&quot;http://www.zdnet.com/article/microsoft-gets-data-fabulous-at-nyc-event/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;There’s also a summary from Microsoft themselves - &lt;a href=&quot;https://azure.microsoft.com/en-gb/blog/connect-2017-gettopannouncementslist-cloud-data-ai/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;From DZone - an introduction to Pulsar - &lt;a href=&quot;https://dzone.com/articles/a-developers-introduction-to-the-pulsar-streaming&quot;&gt;link&lt;/a&gt;, the Kafka alternative from Yahoo&lt;/li&gt; &lt;li&gt;A view from Kognitio on why it’s not open source (although it can be used over Hadoop for free), and what their differentiators are - &lt;a href=&quot;https://kognitio.com/blog/why-isnt-kognitio-open-source/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A good write up from the Knoldus blog (which is always good value for money) on the architecture of &lt;a href=&quot;/technologies/apache-storm/&quot;&gt;Apache Storm&lt;/a&gt; - &lt;a href=&quot;https://blog.knoldus.com/2017/11/14/apache-storm-architecture/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Influx have announced IFQL - a new query language for &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; - &lt;a href=&quot;https://www.influxdata.com/blog/announcing-ifql-a-new-query-language-and-engine-for-influxdb/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An introduction from Cloudera to &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Cloudera Data Science Workbench&lt;/a&gt; and &lt;a href=&quot;/technologies/cloudera-altus/&quot;&gt;Cloudera Altus&lt;/a&gt; - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/11/cloud-scale-modeling-with-cloudera-altus/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/22/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 20/11/2017</title><link>http://ondataengineering.net/blog/2017/11/20/the-plan-for-this-week/</link><pubDate>Mon, 20 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So I said last week was going to be the last catch up week, but (as is becoming a depressingly predictable pattern recently) I’m going to overrun.&lt;/p&gt; &lt;p&gt;However, I’ve been taking the time to do some well needed structural updates to the site - hopefully sorting my SEO problem, and allowing me to publish new custom technology, vendor and category index pages this week.&lt;/p&gt; &lt;p&gt;So, bear with me please. Some final updates this week and then next we’ll start on our final set of technology categories before we move onto Chapter 3.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/20/the-plan-for-this-week/</guid> </item> <item><title>The Mid Week News - 15/11/2017</title><link>http://ondataengineering.net/blog/2017/11/15/the-mid-week-news/</link><pubDate>Wed, 15 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;News time again, let’s catch up on what’s new… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/elasticsearch/&quot;&gt;Elasticsearch&lt;/a&gt; has hit the big 6.0, along with &lt;a href=&quot;/technologies/elastic-x-pack/&quot;&gt;X-Pack&lt;/a&gt; and &lt;a href=&quot;/technologies/elasticsearch-hadoop/&quot;&gt;Elasticsearch Hadoop&lt;/a&gt;, with &lt;a href=&quot;/technologies/elastic-cloud/&quot;&gt;Elastic Cloud&lt;/a&gt; up to 1.1&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-apex/&quot;&gt;Apache Apex&lt;/a&gt; has seen a 3.8 release of it’s Malhar library&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-phoenix/&quot;&gt;Apache Phoenix&lt;/a&gt; has seen a 4.13 release&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; is up to 1.4&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/zenko/cloudserver/&quot;&gt;Zenko CloudServer&lt;/a&gt; is up to 7.1&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;ZDNet have an interview with the CEO of Elastic - &lt;a href=&quot;http://www.zdnet.com/article/elasticsearch-6-0-not-that-new-but-quite-improved/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;IBM Data Science Experience (DSX) is now certified on &lt;a href=&quot;/technologies/hortonworks-data-platform/&quot;&gt;HDP&lt;/a&gt; - &lt;a href=&quot;https://hortonworks.com/blog/certification-ibm-data-science-experience-dsx-hdp-win-win-customers/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;An interview from ODBMS Industry Watch with Head of Data Technical Field for Pivotal and the founder and CEO Datometry. There’s some significant product plugs in there, but it’s worth a read - &lt;a href=&quot;http://www.odbms.org/blog/2017/11/on-the-future-of-data-warehousing-interview-with-jacque-istok-and-mike-waas/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From DataArtisans - an updated on CEP with &lt;a href=&quot;/technologies/apache-flink/&quot;&gt;Apache Flink&lt;/a&gt; - &lt;a href=&quot;https://data-artisans.com/blog/complex-event-processing-flink-cep-update&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;More from Confluent for using &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; and KSQL in micro services architectures - &lt;a href=&quot;https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/15/the-mid-week-news/</guid> </item> <item><title>Thoughts on MapR</title><link>http://ondataengineering.net/blog/2017/11/10/thoughts-on-mapr/</link><pubDate>Fri, 10 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;I’ve somehow spent (pretty much) all of these week taking another look at MapR - the time taken being a combination of me getting sucked down some rabbit holes, and the contradictory and confusing nature of MapR’s public material. But I think we’ve got somewhere, so let’s renew what we already thought about MapR and what might have changed recently… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, let’s review what I said in &lt;a href=&quot;/blog/2017/04/28/the-week-that-was/&quot;&gt;The Week That Was - 28/04/2017&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;I have to admit to being surprised by MapR’s offerings. I’d always assumed they were a knock-off Hadoop distribution that was trying to find leverage by embedding a bunch of commercial components, however what’s become clear is that what they’re selling is not an Hadoop distribution but an enterprise data platform (based on MapR-FS) that just happens to have Hadoop compatibility. In short, &lt;a href=&quot;/technologies/mapr-file-system&quot;&gt;MapR-FS&lt;/a&gt; is a highly resilient, scalable and performant, with support for full random read/write access, multi-tenancy, block level replication, snapshots, quotas, extensive and flexible access control, which supports a fully POSIX compliant filesystem with HDFS, NFS and FUSE APIs, a document and wide column datastore with OJAI and HBase APIs, a streaming data stores with Kafka compatible APIs, master-slave and master-master replication of database and streaming data stores, plus YARN support, meaning you can run any Hadoop compatible tool over the top. That’s a lot of capability in a single platform, which feels like it’s going to drive a strong TCO story.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;And in &lt;a href=&quot;/blog/2017/05/05/the-week-that-was/&quot;&gt;The Week That Was - 05/05/2017&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;What I’ve really liked about MapR is their strategy around their common data platform to underpin a bunch of different data storage capabilities. I talked a little bit about their data platform &lt;a href=&quot;/blog/2017/04/28/the-week-that-was/&quot;&gt;last time&lt;/a&gt;, but this week as part of looking at &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; and &lt;a href=&quot;/technologies/mapr-file-system/mapr-streams/&quot;&gt;MapR-Streams&lt;/a&gt; I’ve been thinking about how this compares and contrasts to Hadoop. Firstly, they’re both aiming to provide a common data platform that provides the ability to have a single cluster than can provide flexibility and value for money by allowing you to exploit the same infrastructure for multiple use cases. MapR appears to have fully embraced this, ensuring they support the ability to scale, partition and manage the platform in ways that Hadoop can’t yet, and by providing capabilities that Hadoop (and more specifically HDFS) doesn’t that actually make it work as a general purpose data platform - full random read and write access for starters. I’m also taken by MapR’s ability to provide access to the common data platform at different layers - rather than just build capabilities on top of their file system API, they’ve integrated (for example) MapR-DB at a much lower level, providing a range of benefits over HBase running over HDFS. It’s clear that Hadoop still has a long way to go to fulfil it’s potential, and without addressing some of it’s limitations we’re going to continue to see new technologies opting to implement their own storage systems from scratch (Kudu being a great example), leading to Hadoop clusters running multiple independent storage stacks on the same data nodes, which feels like it’s defeating the point.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Looking back, that feels like it all still holds true. So what’s changed recently?&lt;/p&gt; &lt;p&gt;Well, the answer is fundamentally nothing (and yet I’ve spent almost an entire week looking at this!). In the time since we last looked at MapR there hasn’t been even a minor release (5.2 came out in August 2016) so there’s no major new functionality or product changes - my guess is they’re gearing up for a big 6.0 release given they’ve started to talk about some elements of this.&lt;/p&gt; &lt;p&gt;However, it looks like they’re having a push around widening the use cases for their &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;Converged Data Platform&lt;/a&gt; and the number of ways they bundle and market this. When we last looked this was already also available as MapR Edge (a version designed to run on low power devices at the edge of the network) and MapR Converged Data Platform for Docker (a version designed to provide persistent storage for docker containers), however they’ve now introduce a new version - MapR-XD - a version built around MapR-FS bundled with their monitoring and management software (and one would assume the new Orbit Cloud Suite - details below), that’s being positioned as a cloud scale data store / fabric which will provide a single layer over on-premises and cloud storage, with support for automatic tiering, mirroring and replication.&lt;/p&gt; &lt;p&gt;(NOTE: MapR’s material is inconsistent in whether MapR-XD is a re-branding of MapR-FS or a new product that includes MapR-FS, however I’m going with &lt;a href=&quot;https://community.mapr.com/message/59688-what-is-the-difference-between-mapr-fs-and-mapr-xd&quot;&gt;this&lt;/a&gt; and the fact that MapR-XD has it’s own installation page separate from MapR under &lt;a href=&quot;https://maprdocs.mapr.com/home/install.html&quot;&gt;here&lt;/a&gt; and say that it’s a new product.)&lt;/p&gt; &lt;p&gt;This has then been supplemented via a couple of new add-ons.&lt;/p&gt; &lt;p&gt;Firstly the MapR Orbit Cloud Suite, which adds full cloud support to the MapR Converged Data Platform (and appears to provide a bunch of the functionality of MapR-XD), including support for deployment of cloud infrastructure along with MapR, integration with cloud object stores, plus mirroring and replication, with support for multi-tenancy, object tiering and with OpenStack integration announced.&lt;/p&gt; &lt;p&gt;The second is the MapR Data Science Refinery, a docker based analytics notebook powered by Apache Zeppelin that fully integrates with the MapR Converged Data Platform. MapR have been pushing the use of the Converged Data Platform as a data science and machine learning platform for a while now, and this feels like it supports that.&lt;/p&gt; &lt;p&gt;Oh, and they’ve renamed MapR Streams to MapR-ES (Event Streams), as &lt;a href=&quot;https://community.mapr.com/thread/21827-what-is-mapr-es-event-data-streams&quot;&gt;apparently&lt;/a&gt; people were often wrongly assuming it was a streaming engine like Storm or Flink.&lt;/p&gt; &lt;p&gt;So that’s that. If you haven’t already, I strongly suggest you have a read through the information we have on MapR on this site, starting with our &lt;a href=&quot;/tech-vendors/mapr/&quot;&gt;MapR&lt;/a&gt; vendor page and following the links through to the &lt;a href=&quot;/technologies/mapr-converged-data-platform/&quot;&gt;MapR Converged Data Platform&lt;/a&gt; and onwards to the products it packages and is managed by. It’ll only take you 10 minutes I promise!&lt;/p&gt; &lt;p&gt;We’ll be back next week with our final catch up week before we launch into some new technology categories. See you then.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/10/thoughts-on-mapr/</guid> </item> <item><title>The Mid Week News - 08/11/2017</title><link>http://ondataengineering.net/blog/2017/11/08/the-mid-week-news/</link><pubDate>Wed, 08 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s time to take my head out of MapR (updates and post hopefully coming tomorrow if I can push on though) and break for the news, although it’s a bit light this week… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The big one this week is that &lt;a href=&quot;/technologies/apache-kafka/&quot;&gt;Apache Kafka&lt;/a&gt; has hit 1.0&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ignite/&quot;&gt;Apache Ignite&lt;/a&gt; has hit 2.3&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-kylin/&quot;&gt;Apache Kylin&lt;/a&gt; has hit 2.2&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Another benchmark to take with a pinch of salt - &lt;a href=&quot;/technologies/mapr-file-system/mapr-db/&quot;&gt;MapR-DB&lt;/a&gt; is faster than both Cassandra and HBase - &lt;a href=&quot;https://mapr.com/whitepapers/mike-leone-esg-lab-nosql-benchmark/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Hortonworks on extensibility in &lt;a href=&quot;/technologies/streaming-analytics-manager/&quot;&gt;Streaming Analytics Manager&lt;/a&gt; - &lt;a href=&quot;https://hortonworks.com/blog/streaming-analytics-manager-extensibility/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From The Register - it looks like the IBM Cloud is undergoing another name change - &lt;a href=&quot;https://www.theregister.co.uk/2017/11/02/ibm_renames_bluemix_ibm_cloud/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/08/the-mid-week-news/</guid> </item> <item><title>Thoughts on Hortonworks DataPlane and Cloudera SDX</title><link>http://ondataengineering.net/blog/2017/11/03/thoughts-on-hortonworks-dataplane-and-cloudera-sdx/</link><pubDate>Fri, 03 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So I’ve spent most of this week reviewing and making some minor refreshes to our &lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt; and &lt;a href=&quot;/tech-vendors/cloudera/&quot;&gt;Cloudera&lt;/a&gt; information, and taking a further look at &lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;Hortonworks DataPlane Service&lt;/a&gt; and Cloudera SDX. &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Firstly, let’s review what I said in &lt;a href=&quot;/blog/2017/09/27/the-mid-week-news/&quot;&gt;The Mid Week News - 27/09/2017&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;The big news this week is the simultaneous big product announcements from Hortonworks and Cloudera that look like they might be similar capabilities, but I think are probably trying to solve subtly different problems - we’ll revisit these in a few weeks once there’s more information available and do some technology summaries.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://www.cloudera.com/products/sdx.html&quot;&gt;Cloudera SDX&lt;/a&gt; (Shared Data Experience, coming in CDH 5.13) appears to be trying to enable the “one” data platform experience that you get with an on premesis CDH cluster in the cloud, specifically a persistent shared storage layer with shared metadata, security and governance and a range of workloads on top. That looks different in the cloud - you probably don’t want a persistent Cloudera cluster that you’re paying for by the hour even if you’re not using it - so SDX gives you a shared storage layer using cloud object storage, a shared metadata and management layer, and then the ability to run compute workloads in isolated transient workload clusters managed through Cloudera Altus. The original sales pitch of a single shared Hadoop data platform re-imagined for the cloud. More details via a &lt;a href=&quot;http://vision.cloudera.com/introducing-cloudera-sdx-a-shared-data-experience-for-the-hybrid-cloud/&quot;&gt;Cloudera VISION blog post&lt;/a&gt; and a &lt;a href=&quot;http://blog.cloudera.com/blog/2017/09/cloudera-sdx-under-the-hood/&quot;&gt;Cloudera Engineering blog post&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://hortonworks.com/products/data-management/dataplane-service/&quot;&gt;Hortonworks Data Plane&lt;/a&gt; is again all about shared metadata, security and data management, but this time across a range of different data platforms - Hadoop, relational databases and your EDW, either on-premesis or in the cloud, and for data in motion or at rest. It’s open source, extensible for adding new services, with data lifecycle management being first up, allowing you to replicate, backup &amp;amp; restore and tier your data across your data platforms. It’s another cloud service (because obviously), and they talk about it as a Global Data Management Platform. More details via a &lt;a href=&quot;https://hortonworks.com/blog/category-emerges-introducing-hortonworks-dataplane-service/&quot;&gt;Hortonworks blog post&lt;/a&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;With Cloudera SDX, CDH 5.13 has come and gone, and there’s almost no new information about SDX. The 5.13 &lt;a href=&quot;http://community.cloudera.com/t5/Community-News-Release/ANNOUNCE-Cloudera-Enterprise-5-13-is-Now-Available/m-p/60879#M200&quot;&gt;announcement&lt;/a&gt; name checks SDX as the “SDX Cloud Reference Architecture”, which I think probably sums up what it is as much as anything, especially given there’s absolutely no reference to SDX in the Cloudera documentation, and there’s nothing on their site beyond the product page and two blog posts linked above. It feels like this is Cloudera pushing the traditional Hadoop one platform, lots of different workloads message, but now applying it to the cloud as well.&lt;/p&gt; &lt;p&gt;Hortonworks on the other hand seem to be heading in a slightly different direction with the new &lt;a href=&quot;/technologies/hortonworks-dataplane-service/&quot;&gt;Hortonworks DataPlane Service&lt;/a&gt;. The premise for this is that it becomes a single place to understand, manage and govern all the data your enterprise holds, wherever it may be - it’s a big ask, but it feels like there’s value there. Saying that it’s early days for this product is an understatement - it’s now had it’s first generally available release (see &lt;a href=&quot;https://hortonworks.com/blog/hdp-2-6-3-dataplane-service/&quot;&gt;this post&lt;/a&gt;) and there’s a big pile of documentation on the Hortonworks site, but the functionality at the moment is pretty limited, and there’s no visibility yet of plugin services coming from any of the Hortonworks partners. And this is an interesting change for Hortonworks, in that this is a commercial managed service offering and not open source software (although there’s no public sign up process yet and the documentation talks about how to install it), and it only works with Ambari managed clusters and you have to have a SmartSense ID. Which makes you wonder whether this a response to challenges in generating revenue from support and consultancy from fully open source software. It will also be interesting to see how this will impact Atlas and Ranger - you could easily see a world where a lot of the end user functionality in these products migrates into the DataPlane service. One to watch I think - it’ll be interesting to see where this goes.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/03/thoughts-on-hortonworks-dataplane-and-cloudera-sdx/</guid> </item> <item><title>Hortonworks DataPlane Service</title><link>http://ondataengineering.net/technologies/hortonworks-dataplane-service/</link><pubDate>Thu, 02 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;An extensible platform for managing, governing and securing data, with capabilities delivered through plugable services. Includes three core capabiliies - the Data Services Catalog (allows plugable services to be registered and managed), Security Control (manages role based access control to information within the platform and integration with LDAP for users and groups), and Data Source Integration (allows registration of data sources, with support currently limited to Ambari managed Hadoop clusters). Currently supports two services - Data Lifecycle Manager (DLM) (a production ready service for replicating data between clusters, with initial support for Hive tables and HDFS snapshottable directories, but with future plans to support point in time backup and restore and automatic tiering of data) and Data Steward Studio (DSS) (a technical preview service for creating data asset collections and for viewing information on data assets, including poperties, tags, schemas, lineage, security, access audit events and statistics, with statistics provided via a background data profiler, and with supported data assets currently limited to Hive tables). Future services referenced include Cloudbreak, Data Analytics Studio (execute, track and optimize queries for Apache Hive) and IBM DSX. Stated plan is for this to be a cloud service, however this is not currently generally available, and the documentation currently details installation steps for a local machine. Has dependancies on Atlas (for Hive metadata), Ranger (for access audit logs) and Spark (for data profile computation). First released in November 2017.&lt;/p&gt; &lt;!-- Tech Category metadata --&gt; &lt;h2&gt;Technology Information&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td&gt;Vendors&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;/tech-vendors/hortonworks/&quot;&gt;Hortonworks&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Commercial&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;Last Updated&lt;/td&gt;&lt;td&gt;May 2018 - 1.1&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;release-history&quot;&gt;Release History&lt;/h2&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;version&lt;/td&gt; &lt;td&gt;release date&lt;/td&gt; &lt;td&gt;release links&lt;/td&gt; &lt;td&gt;release comment&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;2017-11-01&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://hortonworks.com/blog/hdp-2-6-3-dataplane-service/&quot;&gt;announcement&lt;/a&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1.1&lt;/td&gt; &lt;td&gt;2018-05-21&lt;/td&gt; &lt;td&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/DPS1/DPS-1.1.0/release-notes/content/dps_whats_new_in_this_release.html&quot;&gt;release notes&lt;/a&gt;&lt;/td&gt; &lt;td&gt;Significantly expanded docs&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/products/data-management/dataplane-service/&quot;&gt;https://hortonworks.com/products/data-management/dataplane-service/&lt;/a&gt; - homepage&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://docs.hortonworks.com/HDPDocuments/DPS1/DPS-1.0.0/index.html&quot;&gt;https://docs.hortonworks.com/HDPDocuments/DPS1/DPS-1.0.0/index.html&lt;/a&gt; - documentation&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;https://hortonworks.com/blog/category-emerges-introducing-hortonworks-dataplane-service/&quot;&gt;https://hortonworks.com/blog/category-emerges-introducing-hortonworks-dataplane-service/&lt;/a&gt; - intro blog post&lt;/li&gt; &lt;/ul&gt; &lt;h2 id=&quot;news&quot;&gt;News&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;See HDP updates - HDP Search tracks HDP releases&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/technologies/hortonworks-dataplane-service/</guid> </item> <item><title>The Mid Week News - 01/11/2017</title><link>http://ondataengineering.net/blog/2017/11/01/the-mid-week-news/</link><pubDate>Wed, 01 Nov 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;It’s Wednesday, which means it’s time for the news… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Technology updates (details are on the relevant technology pages):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-ambari/&quot;&gt;Ambari&lt;/a&gt; has hit 2.6&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;/technologies/apache-hadoop/&quot;&gt;Hadoop&lt;/a&gt; has hit 2.8.2, the first 2.8 GA release for production use&lt;/li&gt; &lt;li&gt;Cloudera have finally published their blog post on &lt;a href=&quot;/technologies/cloudera-data-science-workbench/&quot;&gt;Data Science Workbench&lt;/a&gt; version 1.2 - &lt;a href=&quot;http://blog.cloudera.com/blog/2017/10/new-in-cloudera-data-science-workbench-1-2-usage-monitoring-for-administrators/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Other technology news:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Hortonworks have announced the general availability of their first plugin for their new DataPlane Service - Data Lifecycle Manager (DLM) - &lt;a href=&quot;https://hortonworks.com/blog/disasters-can-instant-takes-village-build-hybrid-cloud-based-recovery-solution/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Influx have a blog post on the internals of &lt;a href=&quot;/technologies/influxdb/&quot;&gt;InfluxDB&lt;/a&gt; - &lt;a href=&quot;https://www.influxdata.com/blog/influxdb-internals-101-part-one/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Following up on the Linux Foundation open data licence last week, some expert views from The Register - &lt;a href=&quot;https://www.theregister.co.uk/2017/10/25/linux_foundation_data_licence_analysis/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;From Amazon - how to build a Data Lake on &lt;a href=&quot;/tech-vendors/amazon-web-services/&quot;&gt;AWS&lt;/a&gt; with AWS Glue and S3 - &lt;a href=&quot;https://aws.amazon.com/blogs/big-data/build-a-data-lake-foundation-with-aws-glue-and-amazon-s3/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Thoughts from O’Reilly (via the Cloudera Vision Blog) on (Hadoop) data marts in the cloud - &lt;a href=&quot;https://www.oreilly.com/ideas/rethinking-data-marts-in-the-cloud&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Following up on our look at analytical databases, an interview from ODBMS Industry Watch with Colin Mahony from Vertica - &lt;a href=&quot;http://www.odbms.org/blog/2017/10/on-vertica-and-the-new-combined-micro-focus-company-interview-with-colin-mahony/&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;There’s a new vulnerability in Apache Tika - CVE-2016-6809 - allows Java code execution for serialized objects embedded in MATLAB files - &lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-6809&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;li&gt;And one in &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Apache Hive&lt;/a&gt; - CVE-2017-12625 - issues with column masking over views - &lt;a href=&quot;http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-12625&quot;&gt;link&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/11/01/the-mid-week-news/</guid> </item> <item><title>The Plan For This Week - 30/10/2017</title><link>http://ondataengineering.net/blog/2017/10/30/the-plan-for-this-week/</link><pubDate>Mon, 30 Oct 2017 07:30:00 +0000</pubDate> <description> &lt;p&gt;So, I think we’re probably done with looking at data storage and databases, however before we move on to data acquisition, processing and transformation tools, and the interesting set of supporting capabilities that live within a data ecosystem, there’s a bit of housekeeping to do.&lt;/p&gt; &lt;p&gt;So over this week (and maybe next), expect some random updates. I want to update and rework the technology categories home page to provide a bit more structure, and there are a few technologies I’ve been meaning to double back on now there should be some more documentation around beyond a press release (Hortonworks Data Plane, Cloudera SDX, MapR-XD/ES for starters). Plus I need to work out what technology categories might be coming up.&lt;/p&gt; &lt;p&gt;So hang in there - new content coming, but what and when might be a little random for the next few weeks…&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/30/the-plan-for-this-week/</guid> </item> <item><title>Thoughts on Query Engines and Analytical Databases</title><link>http://ondataengineering.net/blog/2017/10/27/thoughts-on-query-engines-and-analytical-databases/</link><pubDate>Fri, 27 Oct 2017 07:30:00 +0100</pubDate> <description> &lt;p&gt;Right, we’ve finally completed our look at &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt;, with a short stop to look at &lt;a href=&quot;/tech-categories/query-engines&quot;&gt;query engines&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So let’s summarise and spew some thoughts… &lt;!--more--&gt;&lt;/p&gt; &lt;p&gt;Let’s start with &lt;a href=&quot;/tech-categories/analytical-databases/&quot;&gt;analytical databases&lt;/a&gt;, with a bit of noddy pseudo-history tale telling. Once upon a time the relational database was invented, but these initially focused on transactional use creates - creating, finding, updating and deleting records - what’s now sometimes referred to as OLTP (online transaction processing). However SQL was a great and so people started using it to try and generate reports on the data in their relational databases - queries that focused on aggregating and joining significant portions of their data. And that was generally fine, until data volumes increased to the point where databases designed for transactional workloads struggled to handle the loads generated from these reports or analytics - fetching lots of data off disk and aggregating it was expensive.&lt;/p&gt; &lt;p&gt;And so the analytical OLAP (online analytical processing) databases were born - designed to primarily support the large full table scan aggregation queries, while still retaining the core relational database support for transactions. These were marketed as data warehouse or analytical databases, and with them came a bunch of new technologies - parallelism and the invention of the MPP (massively parallel processing) database, as full table scans and aggregations lend themselves well to partitioning and parallelisation (even if joins do not); columnar compression, which enables faster and more efficient table scans of columns from database tables; pre-aggregation of data, through materialized views and pre-generated cubes; and a range of new functionality designed to complement SQL as an analytical tool, such as support for machine learning, geographical analytics, map reduce and custom analytical functions. Today, these are often sold as appliances, bundling clusters of compute and storage servers with huge bandwidth interconnects between them, however many have now also started embracing the cloud, being available as a cloud service but also to a lesser extents as cloud native software. Open source projects in this space however are scarce.&lt;/p&gt; &lt;p&gt;Instead, the the charge of open source software into the space ended up being spearheaded by Hadoop. Whilst analytical databases have long separated storage and compute (with some interesting abilities to push some parts of the query down to the storage layer), it was Hadoop that’s formalised this by separating them into completely separate and interchangeable components. This can be seen from the very first versions of Hadoop, in that it was made up of two products - HDFS and MapReduce - storage and compute, and over time there’s been evolution on both sides. In storage, HDFS has remained a constant, but there’s been huge innovation in the storage formats of data (see our &lt;a href=&quot;/tech-categories/data-storage-formats/&quot;&gt;Data Storage Formats&lt;/a&gt; page). On the compute side, there’s been a veritable explosion of &lt;a href=&quot;/tech-categories/query-engines&quot;&gt;query engines&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;These started out as batch query engines - every query starting up a new job (initial MapReduce) to go and read all the data and execute the query. However there’s been significant push into low latency high concurrency query engines, led by the big Hadoop vendors - Cloudera with &lt;a href=&quot;/technologies/apache-impala/&quot;&gt;Impala&lt;/a&gt; and Hortonworks with &lt;a href=&quot;/technologies/apache-hive/&quot;&gt;Hive&lt;/a&gt; - both trying to make Hadoop a realistic competitor in the analytical database market. Compared to analytical databases Hadoop query engines are new technologies - their query optimisers and SQL compliance generally lag the mature analytical databases, however they’re seeing significant investment, and they’re not at the point where they’ll probably support most of your use cases.&lt;/p&gt; &lt;p&gt;And this split of storage and compute has brought some interesting benefits. This first is support for the whole “schema-on-read” shtick - the idea that you can query your raw data without having to do any preparation first. It’s slow, and painful, but for an initial exploratory analysis it’s a valuable tool. And of course if there’s value in the data, you’re still feel to do some work that makes it quicker, easier and more efficient to query. The second is that these tools have naturally evolved some level of query federation - if I want to exploit raw un prepared data I have to accept that this data may be in multiple places in a range of formats, and if I have a query engine that’s separated from the underlying storage, why not make that storage pluggable, and support multiple storage platforms. And so many of these tools support querying over a range of data sources, from HDFS, to S3, to HBase, to relational and NoSQL database, and (interestingly) some emerging support for Kafka . They don’t have the level of sophistication around semantic layers and caching and materialisation of data the &lt;a href=&quot;/tech-categories/data-virtualization/&quot;&gt;Data Virtualization&lt;/a&gt; technologies do, but it can still be a hugely valuable capability.&lt;/p&gt; &lt;p&gt;And now we’re starting to see commercial vendors get involved, both large established vendors (Teradata, IBM, Oracle) who are updating their products to run over HDFS and external data stores, but also new vendors in this space who’ve seen an opportunity to sell commercial products in this space that offer a level of functionality and maturity that maybe some of the open source products can’t match. If you’re running open source Hadoop, some of these may well be worth a look.&lt;/p&gt; &lt;p&gt;Finally - a couple of footnotes…&lt;/p&gt; &lt;p&gt;Although many of these tools support SQL, there are many that have their own query languages - Pig has Pig Latin, MRQL has it’s own language - and of course you could probably count most of the graph and machine learning projects as query languages, which suggests I’ve probably not named this category particularly well. SQL is always going to be the dominant language in this space however, and anything with it’s own query language is unlikely to make an impact.&lt;/p&gt; &lt;p&gt;It’s also worth commenting on the role of the Hive metadata in the Hadoop query engine ecosystem. If you’re separating compute and storage, you need some way of telling the compute what data’s available for query and what format it’s in. Within Hive, this was the Hive Metastore, and this is now gradually being adopted as the standard in this space, giving some interesting interoperability options, in that if you define a table in the Hive Metastore, you can query that with either Hive or Impala (or any other technology that uses the Metastore). And now there’s a proposal to break the Metastore out of the Hive project into it’s own top level Apache project, to reflect the wider role it has in the Hadoop ecosystem.&lt;/p&gt; &lt;p&gt;Right - that will do, and hopefully brings the protracted birth of our analytical databases content to and end. Have a good weekend everyone, and we’ll see you on Monday for a week or two of random catch up and clean up.&lt;/p&gt; </description> <guid isPermaLink="true">http://ondataengineering.net/blog/2017/10/27/thoughts-on-query-engines-and-analytical-databases/</guid> </item> </channel> </rss>
