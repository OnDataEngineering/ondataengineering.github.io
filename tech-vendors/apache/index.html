<!doctype html><html class="no-js" lang="en"><head><meta charset="utf-8" /><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="stylesheet" type="text/css" href="/assets/css/app.css" /> <script src="/assets/js/modernizr.min.js"></script> <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script> <script> WebFont.load({ google: { families: [ 'Lato:400,700,400italic:latin', 'Volkhov::latin' ] } }); </script> <noscript><link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic|Volkhov' rel='stylesheet' type='text/css' /> </noscript><title>The Apache Software Foundation - OnDataEngineering</title><meta property="og:title" content="The Apache Software Foundation" /><meta name="description" content="The Apache Software Foundation is a non-profit organisation that supports a wide range of open source projects, including providing and mandating a standard governance model (including the use of the Apache license), holding all trademarks for project names and logos, and providing legal protection to developers. It was founded in 1999 and now oversees nearly 200 projects." /><meta property="og:description" content="The Apache Software Foundation is a non-profit organisation that supports a wide range of open source projects, including providing and mandating a standard governance model (including the use of the Apache license), holding all trademarks for project names and logos, and providing legal protection to developers. It was founded in 1999 and now oversees nearly 200 projects." /><link rel="canonical" href="http://ondataengineering.net/tech-vendors/apache/" /><meta property="og:url" content="http://ondataengineering.net/tech-vendors/apache/" /><meta property="og:site_name" content="OnDataEngineering" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2016-12-16T00:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@OnDataEng" /><meta name="twitter:creator" content="@OnDataEng" /> <script type="application/ld+json"> { "@context": "http://schema.org", "@type": "BlogPosting", "headline": "The Apache Software Foundation", "datePublished": "2016-12-16T00:00:00+00:00", "description": "The Apache Software Foundation is a non-profit organisation that supports a wide range of open source projects, including providing and mandating a standard governance model (including the use of the Apache license), holding all trademarks for project names and logos, and providing legal protection to developers. It was founded in 1999 and now oversees nearly 200 projects.", "logo": "http://ondataengineering.net/assets/img/logo.png", "url": "http://ondataengineering.net/tech-vendors/apache/" } </script><link type="text/plain" rel="author" href="http://ondataengineering.net/humans.txt" /><link rel="icon" sizes="32x32" href="http://ondataengineering.net/assets/img/favicon-32x32.png" /><link rel="icon" sizes="192x192" href="http://ondataengineering.net/assets/img/touch-icon-192x192.png" /><link rel="apple-touch-icon-precomposed" sizes="180x180" href="http://ondataengineering.net/assets/img/apple-touch-icon-180x180-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="152x152" href="http://ondataengineering.net/assets/img/apple-touch-icon-152x152-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://ondataengineering.net/assets/img/apple-touch-icon-144x144-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="120x120" href="http://ondataengineering.net/assets/img/apple-touch-icon-120x120-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://ondataengineering.net/assets/img/apple-touch-icon-114x114-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="76x76" href="http://ondataengineering.net/assets/img/apple-touch-icon-76x76-precomposed.png" /><link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://ondataengineering.net/assets/img/apple-touch-icon-72x72-precomposed.png" /><link rel="apple-touch-icon-precomposed" href="http://ondataengineering.net/assets/img/apple-touch-icon-precomposed.png" /><meta name="msapplication-TileImage" content="http://ondataengineering.net/assets/img/msapplication_tileimage.png" /><meta name="msapplication-TileColor" content="#fabb00" /><body id="top-of-page" class="two-heading-page"><div id="navigation" class="contain-to-grid sticky"><nav class="top-bar" role="navigation" data-topbar><ul class="title-area"><li class="name"> <a href="/" title="OnDataEngineering/"> <span class="show-for-small-only">OnDataEngineering</span> <img class="show-for-medium-up" id="site-logo" src="http://ondataengineering.net/assets/img/logo.png" alt="OnDataEngineering"> </a><li class="toggle-topbar menu-icon"><a href="#"><span>Navigation</span></a></ul><section class="top-bar-section"><ul class="nav-menu-align"><li class="divider"><li class="divider"><li><a href="http://ondataengineering.net/technologies/">Technologies</a><li class="divider"><li><a href="http://ondataengineering.net/tech-categories/">Tech Categories</a><li class="divider"><li><a href="http://ondataengineering.net/tech-vendors/">Tech Vendors</a><li class="divider"><li><a href="http://ondataengineering.net/blog/">Blog</a><li class="divider"><li><a href="http://discourse.ondataengineering.net">Forums</a><li class="divider"><li class="has-dropdown"> <a href="http://ondataengineering.net/site/">Site</a><ul class="dropdown"><li><a href="http://ondataengineering.net/site/">Site Info</a><li><a href="http://ondataengineering.net/site/search/">Search</a><li><a href="http://ondataengineering.net/site/content-license/">Content License</a><li><a href="http://ondataengineering.net/site/subscribe/">Subscribe</a><li><a href="http://ondataengineering.net/site/contributing/">Contributing</a></ul><li class="divider"><li class="divider"><li class="divider"></ul></section></nav></div><div class="row t20"><div class="columns medium-12"><nav class="breadcrumbs" role="menubar" aria-label="breadcrumbs"> <a href="http://ondataengineering.net">Home</a> <a href="http://ondataengineering.net/tech-vendors/">tech vendors</a> <a class="current">apache</a></nav></div></div><div class="row t30"><div class="medium-9 columns medium-push-3"><article itemscope itemtype="http://schema.org/Article"><header><h1> <span itemprop="name">The Apache Software Foundation</span> <a class="button tiny radius" href="https://github.com/OnDataEngineering/OnDataEngineeringContent/edit/master/_tech-vendors/apache.md" title="Spotted a typo or error on this page, or have content to add to it? Click here to edit it and send us your proposed changes">edit &nbsp; <img style="height: 13px;" src="/assets/fonts/info-with-circle.svg"></a> <a class="button tiny radius" href="http://discourse.ondataengineering.net/t/the-apache-software-foundation" title="Have questions to ask on, or changes to propose to the contents of this page? Click here to discuss them on its Discourse topic">discuss &nbsp; <img style="height: 13px;" src="/assets/fonts/info-with-circle.svg"></a></h1></header><p itemprop="description"> The Apache Software Foundation is a non-profit organisation that supports a wide range of open source projects, including providing and mandating a standard governance model (including the use of the Apache license), holding all trademarks for project names and logos, and providing legal protection to developers. It was founded in 1999 and now oversees nearly 200 projects. <span itemprop="articleSection"><h2>Vendor Information</h2><table><tbody><tr><td>Other Names<td>Apache</table><h2>Vendor Technologies</h2><table><tbody><tr><td> <a href="http://ondataengineering.net/technologies/apache-accumulo/">Apache Accumulo</a><td>NoSQL wide-column datastore based on BigTable. Supports horizontal scalability, cell based access control (based on arbitrary boolean expressions of user security labels), high availability, atomic read-modify-write operations, map reduce support (both as a source and sink), table constraints, LDAP and Kerberos integration, and replication between instances. Comes with a web based monitoring interface (Accumulo Monitor) and a CLI. Written in Java, with thrift based API allowing access from other languages including C++, Python, Ruby. Originally developed at the NSA, donated to the Apache Foundation in September 2011, before graduating in March 2012, and is still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-ambari/">Apache Ambari</a><td>Platform for installing, managing and monitoring Apache Hadoop clusters. Supports the installation of different versions of different distributions of Hadoop through Stack definitions (with support for HDP out of the box, and further stacks and add ons available through management packs), and the specification of Blueprints (cluster layouts and configuration for a given Stack) that can be used to programmatically create multiple clusters (e.g. dev, test and production). Also supports both rolling (no downtime) and express (faster but with downtime) upgrades; cluster administration (including adding and removing nodes/services, viewing the status of nodes/services, and configuring services with the versioning of configuration and the ability to rollback changes); the automated Kerberization of clusters; the collection, storage (in HBase) and visualisation (via Grafana or through dashboards in Ambari) of system and Hadoop component metrics via the Ambari Metrics System (AMS); alerting on statuses and metrics; the collection, storage (in Solr) and searching/viewing of log entries from across the Hadoop cluster (currently in technical preview); and a framework for UI components within Ambari (Ambari Views, treated here as a sub-project). Web based, with a REST API, and backed by a backend database (Oracle, MySQL or Postgres). Donated to the Apache Foundation by Hortonworks, IBM and Yahoo in August 2011 as the Hadoop Management System (HMS), graduating in December 2013 after changing it's name to Ambari. Still under active development with a large number of contributors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-apex/">Apache Apex</a><td>Data transformation engine based on Directed Acyclic Graph (DAG) flows configured through a Java API or via JSON, with a stated focus on performance, code re-use, testability and ease of operations. Runs over YARN and HDFS with native support for both micro-batch streaming and batch uses cases, and includes a range of standard operators and connectors (called Apex Malhar). An Apache project, graduating in April 2016, having been originally donated in August 2015 by DataTorrent from their DataTorrent RTS product which launched in June 2014. Java based, with development lead by DataTorrent who distribute it as DataTorrent RTS in two editions - a Community Edition (which also includes a basic management GUI and a tool for configuring Apex for data ingestion), and an Enterprise Edition (which further includes a graphical transformation editor, a self service dashboard, security integration and commercial support, and is also available as a cloud offering).<tr><td> <a href="http://ondataengineering.net/technologies/apache-atlas/">Apache Atlas</a><td>A metadata and data governance solution for Hadoop. Supports an extensible metadata model with out of the box support for Hive datasets and data lineage from Hive queries and Sqoop imports, with limited support for Falcon, Storm and Kafka. Allows datasets and data items to be tagged (and for these tags to be used for access control by Apache Ranger), and includes support for business taxonomies as a technical preview. Implemented as a graph based database using Titan (which by default uses HBase and Solr), with a web based user interface and a REST API for searching and visualising/retrieving metadata, and Kafka topics for the ingest of metadata (primarily from hooks in metadata sources such as Hive or Sqoop) and the publishing of metadata change events. An incubating Apache project, donated to the Apache Foundation in May 2015 by the Hortonworks Data Governance Initiative in partnership with Aetna, Merck, Target, Schlumberger and SAS. Has not yet reached a v1.0 milestone or graduated as a top level Apache project, but is still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-avro/">Apache Avro</a><td>Data serialisation framework that supports both messaging and data storage. Primarily uses a compact binary format but also supports a JSON format. Supports a range of data structures (including records, enumerations, arrays and maps) with APIs for a wide range of both static and dynamically typed languages. Schema based, with schemas primarily specified in JSON, and support for both code generation from schema definitions as well as dynamic runtime usage. Schemas are serialised alongside data, with support for automatic schema resolution if the schema used to read the data differs from that used to write it. Started as an Hadoop sub-project by Cloudera in April 2009, with an initial v1.0 release in July 2009, before becoming a top level Apache project in May 2010. Has seen significant adoption in the Hadoop ecosystem.<tr><td> <a href="http://ondataengineering.net/technologies/apache-bigtop/">Apache Bigtop</a><td>An Apache open source distribution of Hadoop. Packages up a number of Apache Hadoop components, certifies their interoperability using an automated integration test suite, and packages them up as RPMs/DEBs packages for most flavours of Linux. Also includes virtual machine images and vagrant, docker and puppet recipes for deploying and working with Hadoop. Does not patch projects for distribution, but requires any fixes to be made upstream. An Apache Open Source project, started by Cloudera, donated to the Apache foundation in June 2011, graduating in September 2012, with a 1.0 release in August 2015 based on Hadoop 2.6. Since donating the project, Cloudera have backed away from it, with the project lead moving to Pivotal in December 2013. Now has a broad range of contributors, however usage by the major distributors is not clear.<tr><td> <a href="http://ondataengineering.net/technologies/apache-calcite/">Apache Calcite</a><td>A framework for building SQL based data access capabilities. Supports a SQL parser and validator, tools for the transformation and (cost based) optimisation of SQL expression trees, and an adapter framework for accessing metadata and executing queries (including out of the box adapters for a number of database technologies as well as CSV files and POJO objects), along with specific support for streaming SQL queries and optimising data cube queries to use materialised views. Also includes (as a sub-project named Avatica), a framework for building database drivers with support for a standard JDBC driver, server and wire protocols, plus a local embeddable JDBC driver. Used in a range of other projects including Drill, Flink, Hive, Kylin, Phoenix, Samza, Storm and Cascading. An Apache project, originally created by Julian Hyde in May 2012 as Optiq, donated to the Apache Foundation in May 2014, graduating in October 2015 following a v1.0 release in January 2015. Under active development with a range of contributors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-crunch/">Apache Crunch</a><td>An abstraction layer over MapReduce (and now Spark) that provides a high level Java API for creating data transformation pipelines, originally designed to make working with MapReduce easier based on the Google FlumeJava paper. Also includes connectors for HBase, Hive and Kafka, Java 8 lambda support, an experimental Scala wrapper for the API (Scrunch), and support for in memory pipelines and helper classes to support testing. Open sourced by Cloudera in October 2011, donated to the Apache Foundation in May 2012, before graduating in February 2013. Support for Spark was added as part of v0.10 in June 2014. Still being maintained, and appears to have had been adopted at a number of large companies, but with limited new development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-datafu/">Apache DataFu</a><td>A set of libraries for working with data in Hadoop. Consists of two sub-projects - DataFu Pig (a set of Pig User Defined Functions) and DataFu Hourglass (a framework for incremental processing using MapReduce). Originally created at LinkedIn, with the Pig UDFs being open sourced in January 2012 as DataFu, with a v1.0 release in September 2013. Split into sub-projects in October 2013 when LinkedIn open sourced DataFu Hourglass and added it to the project. Donated to the Apache Foundation in January 2014, however is still incubating and has not yet graduated. Last release was v1.3 in November 2015 (albeit with a very minor v1.3.1 release in August 2016), with little development activity since this time.<tr><td> <a href="http://ondataengineering.net/technologies/apache-drill/">Apache Drill</a><td>An MPP query engine that supports queries over one or more underlying databases or datasets without first defining a schema and with the ability to join data from multiple datastores together. Supports a range of underlying technologies including HDFS, NAS, HBase, MongoDB, MapR-DB, MapR-FS, Amazon S3, Azure Blob Storage, Google Cloud Storage, JDBC, Avro, JSON and Parquet. Pushes queries down to underlying datastores where possible, and supports an in-memory columnar datastore based on a schema free JSON document model for performing cross datastore query operations. Supports dynamic schema discovery, with support for complex and nested types, including a number of SQL extensions. Supports standard SQL, UDFs (including Hive UDFs) and comes with JDBC and ODBC drivers, a REST API, plus a shell, web console and C++ API. Designed to be horizontally scalable and to support high throughput and low latency use cases. Supports Kerberos and username/password authentication, plus a full authorisation model. Created by MapR Based on Google's Dremel paper, donated to the Apache Foundation in September 2012, graduating in November 2014, with a 1.0 release in May 2015, and is still under active development<tr><td> <a href="http://ondataengineering.net/technologies/apache-falcon/">Apache Falcon</a><td>Data feed management system for Hadoop. Supports the definition, scheduling and orchestration (including support for late data and retry policies) of data processing pipelines (referred to as processes, with support for Ozzie, Spark, Hive and Pig jobs), the management of the data produced and consumed by these pipelines (referred to as feeds, with support for data in HDFS and Hive) and the generation and visualisation of pipeline lineage information, all across multiple Hadoop clusters. Also includes the ability to mirror or replicate HDFS and Hive data between clusters, to failover processing between clusters and to import and export data using Sqoop. Supports both a web and command line interface and a REST API. An Apache project, graduating in December 2014, having been originally donated by inMobi in April 2013. Hasn't yet reached a v1.0 milestone, however still under development led by inMobi and Hortonworks with a range of other contributors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-flink/">Apache Flink</a><td>Specialised stream processing technology inspired by the Google Data Flow model. Based on a single record (not micro batch) model, with exactly once processing semantics (for supported sources and sinks) via light weight checkpointing, and focusing on high throughput, low latency use cases. Supports both a Java and Scala API, with a fluent DataStream API for working with continuous data flows (including a flexible windowing API that supports both event time and processing time windows and support for out of order or late data), and a DataSet API for working with batch data sets (that uses the same streaming execution engine). Also supports a number of connectors and extra libraries, including experimental support for SQL expressions, a CEP library (FlinkCEP) that can be used to detect complex event patterns, a beta package for running Storm apps on Flink, a graph processing library (Gelly) and a machine learning library (FlinkML). Clustered, with support for YARN and Mesos as well as standalone clusters. Open sourced by Data Artisans in April 2013, donated to the Apache Foundation in April 2014 before graduating in August 2014. Under active development with a large number of contributors and a range of user case studies. Sold as a hosted managed service (dA Platform) by Data Artisans who also supply training.<tr><td> <a href="http://ondataengineering.net/technologies/apache-flume/">Apache Flume</a><td>Specialist technology for the continuous movement of data using a set of independent agents connected together into pipelines. Supports a wide range of sources, targets and buffers (channels), along with the ability to chain agents together and to modify and drop events in-flight. Designed to be highly reliable, and to support reconfiguration without the need for a restart. Heavily integrated with the Hadoop ecosystem. An Apache project, donated by Cloudera in June 2011, graduating in June 2012, with a v1.2 release (the first considered ready for production use) in July 2012. Java based, with commercial support available as part of most Hadoop distributions.<tr><td> <a href="http://ondataengineering.net/technologies/apache-giraph/">Apache Giraph</a><td>An iterative, highly scalable graph processing system built on top of MapReduce and based on Pregel, with a number of features added including a framework for creating re-usable code (called blocks). An Apache project, graduating in May 2012, having been originally donated by Yahoo in August 2011. Java based, no commercial support available, but is mature and has been adopted by a number of companies (including LinkedIn and most famously Facebook who scaled it to process a trillion edges), and has a number of active developers.<tr><td> <a href="http://ondataengineering.net/technologies/apache-hadoop/">Apache Hadoop</a><td>A distributed storage and compute platform consisting of a distributed filesystem (HDFS) and a cluster workload and resource management layer (YARN), along with MapReduce, a solution built on HDFS and YARN for massive scale parallel processing of data. Has an extensive ecosystem of compatible technologies. An Apache Open Source project, started in January 2006 as a Lucene sub-project, becoming a top level project in January 2008, with a 1.0 release in December 2011 (containing HDFS and MapReduce), and a 2.2 release (the first 2.x GA release) in October 2013 (adding YARN). Very active, with a deep and broad range of contributors, and backing from multiple commercial vendors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-hama/">Apache Hama</a><td>A general purpose BSP (Bulk Synchronous Parallel) processing engine inspired by Pregel and DistBelief that runs over Mesos or YARN. Supports BSP, graph computing and machine learning programming models, as well as Apache MRQL. An Apache project, donated in 2008, and graduated in 2012. Java based, with no commercial support available, limited case studies for it's use and limited active developers, with the last release being in June 2015.<tr><td> <a href="http://ondataengineering.net/technologies/apache-hawq/">Apache Hawq</a><td>A port of the Greenplum MPP database (which itself is based on PostgreSQL) to run over YARN and HDFS. Supports all the features of Greenplum (ACID transactions, broad SQL support and in database language and analytics support, including support for Apache MADLib), integrated with Apache Ambari, an Input Format for MapReduce to read Hawq tables, and both row and Parquet (column) based storage of data managed by Hawq. Also supports queries over data not managed by Hawq via external tables, with a Java based framework (PXF) for accessing external data, and out of the box support for accessing data in HDFS (text, Avro, JSON), Hive and HBase, with a number of open source connectors also available. Fault tolerant and horizontally scalable, with the ability to scale up or down on the fly. Originally created as Pivotal Hawq based on a fork of Greenplum in 2011, with an initial 1.0 release as part of Pivotal HD in July 2013. Open sourced and donated to the Apache Foundation in September 2015, becoming Apache Hawq, with the first open source release (2.0) in October 2016. Development led by Pivotal, who also distribute binaries as Pivotal HDB and provide training, consultancy and support. Pivotal HDB is also available as Hortonworks HDB.<tr><td> <a href="http://ondataengineering.net/technologies/apache-hbase/">Apache HBase</a><td>NoSQL wide-column datastore based on Google BigTable. Focuses on random real-time access to data, and supports horizontal scalability, consistent reads and writes, versioning and fine grained security controls. Runs on Hadoop and HDFS, and is heavily integrated with the Hadoop ecosystem. An Apache project, first released as part of Hadoop 0.15 in October 2007 before graduating as a top level project in May 2010. Java based, with commercial support available as part of most Hadoop distributions.<tr><td> <a href="http://ondataengineering.net/technologies/apache-hive/">Apache Hive</a><td>Technology that supports the exposure of data in Hadoop as structured tables and the execution of analytical SQL queries over these. Consists of a number of distinct components (that we treat as sub-projects) including Hive Metastore (stores the definitions of the structured tables), Hive Server (supports the execution of analytical SQL queries as MapReduce, Spark or Tez jobs) and HCatalog (allows MapReduce and Pig jobs to read and write Hive tables). First released by Facebook as an Hadoop contrib module in September 2008, becoming an Hadoop sub-project in November 2008, and a top level Apache project in September 2010, following a first official stable release (0.3) in April 2009. Java based, under active development from a number of large commercial sponsors, with commercial support available as part of most Hadoop distributions.<tr><td> <a href="http://ondataengineering.net/technologies/apache-ignite/">Apache Ignite</a><td>A distributed in-memory data fabric/grid, supporting a number of use cases including a key value store (with SQL support), real time stream/event processing engine, arbitrary compute, long running service management, an in-memory HDFS compatible file system for acceleration of Hadoop jobs, an in-memory machine learning grid and in-memory shared Spark RDDs. An Apache project, graduating in September 2015, having been originally donated by GridGain from their In-Memory Data Fabric product launched in 2007. Java based, with development lead by GridGain who also supply commercial support (as GridGain Professional with ongoing Q&A and bug fixes before they're included in Ignite) along with GridGain Enterprise (which includes extra features such as a management GUI, enterprise security and rolling upgrades).<tr><td> <a href="http://ondataengineering.net/technologies/apache-impala/">Apache Impala</a><td>An MPP query engine that supports the execution of SQL queries over in HDFS, HBase, Kudu and S3 based on tables defined in the Hive Metastore. Focus is on analytical (OLAP) use cases, and more specifically on low latency interactive queries (rather than long running batch queries), with some support for batch inserts of data. Supports DDL statements for updating the Hive Metastore, uses (broadly) the same SQL syntax as Hive (including UDFs and a range of aggregate and analytical functions), as well as the same JDBC / ODBC drivers, and is therefore compatible with any Hive query tool (such as Beeline). Supports querying over data in Parquet, Text, Avro, RCFile and SequenceFile formats, with the ability to write Parquet and Text data. Support Kerberos and LDAP authentication, and integration with Apache Sentry for authorisation. Includes a shell (Impala Shell) that supports some shell only commands for tuning performance and diagnosing problems. Created by Cloudera, started in May 2011 and first announced in October 2012, with a 1.0 GA release in May 2013. Donated to the Apache Foundation in December 2015, is still incubating, and is still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-kafka/">Apache Kafka</a><td>Technology for buffering and storing real-time streams of data between publishers to subscribers, with a focus on high throughput at low latency. Based on a distributed, horizontally scalable architecture, with messages organised into topics which are partitioned and replicated across nodes to provide resilience and written to disk to provide persistence. Topics may have multiple publishers and subscribers, with ability to do fault tolerant reads and to load balance across subscribers. Records consist of a key, value and timestamp, with the ability to compact topics to remove updates and deletes by key. Supports a full security model, and the ability to set quotas. Comes with a Java client, but clients for a wide range of languages are also available. Has two sub-projects (Kafka Connect and Kafka Streams) that are bundled with the main product. Originally developed at LinkedIn, being open sourced in January 2011, before being donated to the Apache Foundation in July 2011. Graduated in October 2012, and although it has not had a v1.0 release is considered production quality and stable. Development is primarily led by Confluent (which was founded by the team that built Kafka at LinkedIn), who distribute a Confluent Open Source product (which includes further clients and connectors) and a subscription based Confluent Enterprise product (which includes management, replication and data balancing features and commercial support under a subscription licence). Commercial support is also available from most Hadoop vendors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-knox/">Apache Knox</a><td>A stateless gateway for the Apache Hadoop ecosystem that provides perimeter security. Includes support for user authentication (via LDAP, Active Directory and a number of single sign on solutions), access authorisation on a per service basis, transitions to Kerberos authentication, reverse proxying and auditing, extension points for supporting new services, audit capabilities, and out of the box support for a number of Hadoop technology end points. An Apache project, started by Hortonworks in February 2013, donated to the Apache Foundation two months later in April, before graduating in February 2014. Hasn't yet reached a v1.0 milestone, however still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-kudu/">Apache Kudu</a><td>Columnar storage technology for tables of structured data, supporting low latency reads, updates and deletes by primary key, as well as analytical column/table scans. Provides Java, C++ and Python APIs, is queryable via Impala and Spark SQL, and provides Spark, Flume and MapReduce connectors. Supports cluster deployments (including co-existence with Hadoop), with tables partitioned into tablets (configurable on a per table basis), with tablets then replicated and distributed across the cluster, using the Raft Consensus Algorithm for consistency. Also supports variable column encoding (including bit shuffle, run length, dictionary and prefix encoding) and compression. Includes a web UI for reporting operational information, and metrics available from the command line, via HTTP or via a log file. Started in November 2012, with a initial beta release in September 2015. Donated to the Apache Foundation in December 2015, graduating in July 2016, with a 1.0 release in September 2016. Implemented in C++.<tr><td> <a href="http://ondataengineering.net/technologies/apache-mahout/">Apache Mahout</a><td>Machine learning technology comprising of a Scala based linear algebra engine (codenamed Samsara) with an R-like DSL/API that runs over Spark (with experimental support for H2O and Flink), an optimiser, a wide variety of pre-made algorithms, and a Scala REPL (based on Spark Shell) for interactive execution. Can be embedded and integrated within larger applications, for example MLlib when running over Spark. Also includes some original, now deprecated, algorithms implemented over MapReduce. Created in January 2008 as a Lucene sub-project, becoming a top level Apache project in April 2010. The original MapReduce algorithms were deprecated and Samsara introduced as part of v0.10 in April 2015. Supported by most major Hadoop distributions, and still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-myriad/">Apache Myriad</a><td>Tool that allows YARN applications to run over Apache Mesos, allowing them to co-exist and share cluster resources. Consists of Myriad Executor, a Mesos managed task that in turns manages a YARN Node Manager, and Myriad Scheduler, a plugin for the YARN Resource Manager that delegates resource negotiation to Mesos (and launches Myriad Executor processes on required nodes via Mesos). Supports fixed resource allocation to YARN Node Managers, as well as fine-grained scaling where resources are dynamically requested from Mesos. Includes a web based user interface and REST API that includes support for scaling YARN resources when using fixed resource allocation. Originally created by eBay, MapR and Mesosphere and dondated to the Apache Foundation in March 2015. Has not yet graduated or reached a 1.0 release, with development activity seeming very quiet since October 2016.<tr><td> <a href="http://ondataengineering.net/technologies/apache-nifi/">Apache NiFi</a><td>General purpose technology for the movement of data between systems, including the ingestion of data into an analytical platform. Based on directed acyclic graph of Processors and Connections, with the unit of work being a FlowFile (a blob of data plus a set of key/value pair attributes). Supports guaranteed delivery of FlowFiles, with NiFi resiliently storing state (by default to a local write ahead log) and data blobs (by default a set of local partitions on disk), with all transformation logic executed via a thread pool within the NiFi instance (with the option to deploy multiple NiFi instances as a cluster). All flows are configured in a graphical user interface, which is also used for management and operations (starting/stopping individual Processors and viewing real time statuses, statistics and other information). Also supports data provenance (reporting on the processing events and lineage of individual FlowFiles), scheduling of Processor execution (based on periodic execution timers or cron specifications), multi-threaded Processor execution, configuration of Processor batch sizes (to enable low latency or high throughput), prioritised queues within Connections (allowing FlowFiles to be processed based on their age or a priority attribute as an alternative to FIFO), back pressure (based on counts or data volume against individual Connections) and pressure release (automatic discarding of FlowFiles based on their age), the ability to stream data to and from other NiFi instances and other streaming technologies, the ability to import and export flows as XML (flow templates), an expression language for setting Processor configuration and populating FlowFile attributes, Controller Services to provide shared services to processors (e.g. access to credentials, shared state), Reporting Tasks to output status and statistics information and a user security model. Extensible through the addition of custom Processors, Controller Services, Reporting Tasks and Prioritizers, and integrates with Apache Ranger and Apache Ambari. Originally developed at the NSA as "Niagara Files", before being donated to the Apache Foundation in November 2014, graduating in July 2015. Java based, with development lead by Hortonworks after their aquisition of Onyara (which was set up by original NiFi developers to provide commercial support and services).<tr><td> <a href="http://ondataengineering.net/technologies/apache-oozie/">Apache Oozie</a><td>Technology for managing workflows of jobs on Hadoop clusters. Primary concepts include workflows (a sequence of jobs modelled as a directed acyclic graph), coordinators (schedule the execution of workflows based on the time or the presence of data) and bundles (collections of coordinators), with all configuration specified in XML. Supports a range of technologies, including MapReduce, Pig, Hive, Sqoop, Spark, Java executables and shell scripts. Includes a server component, a metadata database for holding definitions and state (with support for a range of database technologies), a command line interface and a read only web interface for viewing the status of jobs. Also supports the parameterisation of workflows, the modelling of datasets (and the use of these to manage dependencies between workflows within coordinators), automatic retry and failure handling, and the ability to send job status notifications via HTTP or JMS. Open sourced by Yahoo in June 2010. Donated to the Apache Foundation in July 2011, graduating in August 2012. Commercial support available as part of most Hadoop distributions<tr><td> <a href="http://ondataengineering.net/technologies/apache-parquet/">Apache Parquet</a><td>Data serialisation framework that supports a columnar storage format to enable efficient querying of data. Built using Apache Thrift, and supports complex nested data structures, using techniques from the Google Dremel paper. Consists of three sub-projects, the specification and Thrift definitions (Parquet Format), the Java and Hadoop libraries (Parquet MR) and the C++ implementation (Parquet CPP). Created as a joint effort between Twitter and Cloudera based on work started as part of Avro Trevni, with an initial v1.0 release in July 2013. Donated to the Apache Foundation in May 2014, graduating in April 2015. Has seen significant adoption in the Hadoop ecosystem.<tr><td> <a href="http://ondataengineering.net/technologies/apache-phoenix/">Apache Phoenix</a><td>A SQL query engine over Apache HBase tables that supports a subset of SQL 92 (including joins), and comes with a JDBC driver. Supports a range of features including ACID transactions (via Apache Tephra), user defined functions, secondary indexes, atomic upserts, views, multi tenancy tables (where each user or tenant can only see their data) and dynamic columns (which are only specified at query time). Supports a range of SQL DDL commands, creating and modifying underlying HBase tables as required, or can run over existing HBase tables in a read only mode. Comes with connectors to allow Spark, Hive, Pig, Flume and MapReduce to read and write Phoenix tables, and a number of utilities, including a bulk loader and a command line SQL tool. Open sourced by SalesForce in January 2013 at v1.0, donated to the Apache foundation in December 2013, before graduating in May 2014. Commercial support available through Hortonworks as part of HDP, with Cloudera making it available via Cloudera Labs without support. Active project with a range of contributors, including many from SalesForce and Hortonworks.<tr><td> <a href="http://ondataengineering.net/technologies/apache-pig/">Apache Pig</a><td>Technology for running analytical and data processing jobs against data in Hadoop. Jobs are written in Pig Latin (a custom procedural language that can be extended using user defined functions in a range of languages), which is then translated into Map Reduce or Tez (with Spark in development) for execution. Supports both a batch mode for running pre-defined scripts and an interactive mode, and connectors for reading and writing to HBase and Accumulo as well as HDFS. Originally developed at Yahoo in 2006 before being donated to the Apache Foundation in October 2007. Graduated as an Hadoop sub-project in October 2008, before becoming a top level project in September 2010. Although has not had a v1.0 release, has been production quality for many years. Commercial support available as part of most Hadoop distributions<tr><td> <a href="http://ondataengineering.net/technologies/apache-ranger/">Apache Ranger</a><td>A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store (with a web based administration interface and REST API), and plugins for Hadoop components (including HDFS, Hive, HBase, Storm, Knox, Solr, Kafka, YARN, Atlas and NiFi) to manage authorisation of user access to data. Supports data masking and row level access policies (currently only supported by Hive), the ability to define policies against tags as well as directly against resources (with tags assigned to resources externally, e.g. in Apache Atlas), and the ability to use more complex conditions (e.g. denying access after an expiration date or based on a users location). Extendable with the ability to add support for new services (Ranger Stacks) and to add custom decision rules (via content enrichers and condition evaluators). Also supports a full audit capability of access requests and decisions, and a key management service for HDFS encryption keys. An Apache project, donated in July 2014 as Argus by the Hortonworks following their acquisition of XA Secure, graaduating in February 2017. Has not yet reached a v1.0 milestone, but is still under active development with a range of contributors.<tr><td> <a href="http://ondataengineering.net/technologies/apache-sentry/">Apache Sentry</a><td>A centralised security framework for managing access to data in Hadoop. Supports integration with LDAP and Active Directory for user authentication, a central policy server/store, and plugins for Hadoop components (including Hive, Solr, Impala and HDFS, with support for Kafka and Sqoop2 in preview) to manage authorisation of user access to data, although HDFS support is limited to Hive data only. Also supports row level filtering policies for Solr, and historical support for defining policies in files per service (Sentry Policy Files). Integrates with the Hue security app (to manage permissions) and with Cloudera Navigator (for authorisation audit events). Started in 2012 as Cloudera Access, with an initial 1.0 release in 2013 as Sentry. Donated to the Apache Foundation in August 2013, graduating in March 2016.<tr><td> <a href="http://ondataengineering.net/technologies/apache-slider/">Apache Slider</a><td>Framework for hosting long running distributed applications on YARN, allowing YARN to manage the resources these applications use. Can handle any application that supports a base set of requirements (including being able to install and run from a tarball), with experimental support for docker packaged applications. Operates as a YARN application master (the Slider AM), an associated command line interface and lightweight agents to manage running components. Supports manual scaling, automatic recovery, rolling upgrades and component placement controls, and includes out of the box configuration for a number of applications including Accumulo, HBase, Kafka, Memcached, Solr, Storm and Tomcat. An incubating Apache project, originally donated in April 2014. Hasn't yet reached a v1.0 milestone, however still under development led by Hortonworks.<tr><td> <a href="http://ondataengineering.net/technologies/apache-solr/">Apache Solr</a><td>A search server built on Apache Lucene with a REST-like API for loading and searching data. Supports a distributed deployment (SolrCloud) that can run over HDFS on an Hadoop cluster. Includes an administration web interface, an extensible plugin architecture, support for schemaless indexing, faceted, grouped and clustered results, hit highlighting, geo-spacial and graph searches, near real time indexing and searching, (experimental) streaming expressions for parallel compute (including support for MapReduce and SQL) and broad authentication and security capabilities. A sub-project of the Apache Lucene project, originally donated to the Apache foundation by CNET Networks in January 2006, graduating as a top level project in January 2007, before merging with the Lucene project in March 2010. Java based, with commercial support available as part of most Hadoop distributions (although this is bundled as Cloudera Search with CDH and HDP Search with HDP), as well as from Lucidworks.<tr><td> <a href="http://ondataengineering.net/technologies/apache-spark/">Apache Spark</a><td>A high performance general purpose distributed data processing engine based on directed acyclic graphs that primarily runs in memory, but can spill to disk if required, and which supports processing applications written in Java, Scala, Python and R. Includes a number of sub-projects that support more specialised analytics including Spark SQL, Spark Streaming, MLlib (machine learning) and GraphX (graph analytics). Requires a cluster manager (YARN, EC2 and Mesos are supported as well as standalone clusters) and can access data in a wide range of technologies (including HDFS, other Hadoop data sources, relational databases and NoSQL databases). An Apache project, originally started at UC Berkley in 2009, open sourced in 2010, and donated to the Apache foundation in June 2013, graduating in February 2014. v1.0 was released in May 2014, with a v2.0 release in July 2016. Java based, with development led by Databricks (who sell a Spark hosted service), and with commercial support available as part of most Hadoop distributions.<tr><td> <a href="http://ondataengineering.net/technologies/apache-sqoop/">Apache Sqoop</a><td>Specialist technology for moving bulk data between Hadoop and structured (relational) databases. Command line based, with the ability to import and export data between a range of databases (including mainframe partitioned datasets) and HDFS, Hive, HBase and Accumulo. Supports parallel partitioned unloads, writing to Avro, Sequence File, Parquet and text files, incremental imports and saved jobs that can be shared via a simple metadata store. An Apache project, started in May 2009 as an Hadoop contrib module, migrating to a Cloudera GitHub project in April 2010 (with a v1.0 release shortly after), before being donated to the Apache foundation in June 2011, graduating in March 2012. The last major release (v1.4) was in November 2011, with only minor releases since then. However in January 2012 a significant re-write was announced as part of a proposed v2.0 release to address a number of usability, security and architectural issues. This will introduce a new Sqoop Server and Metadata Repository, supporting both a CLI and web UI, centralising job definitions, database connections and credentials, as well as enabling support for a wider range of connectors including NoSQL databases, Kafka and (S)FTP folders. Java based, with commercial support available as part of most Hadoop distributions.<tr><td> <a href="http://ondataengineering.net/technologies/apache-storm/">Apache Storm</a><td>Specialised distributed stream processing technology based on a single record (not micro batch) model with at least once processing semantics. Processing flows are called topologies based on a directed acyclic graph of spouts (which produce unbounded streams of tuples) and bolts (which process streams and optionally produce output streams). Supports high throughput and low latency use cases, horizontal scalability, fault tolerance (failed workers are automatically restarted and failed over to new nodes if required), back pressure, windowing (with support for sliding and tumbling windows based on time or event counts), stateful bolts and a shared bolt storage cache (that's updatable from the command line). Also includes a higher level micro batch API (Trident) that supports exactly-once processing semantics, fault-tolerant state management and higher level operations including joins, aggregations and groupings, support for SQL (StormSQL) and frameworks and utilities to make defining and deploying topologies easier (Flux). Has both a graphical web based and command line interface, plus a REST API. Primarily written in Clojure, JVM based, but supports multiple languages through the use of Thrift for defining and submitting topologies, and the use of spouts that can interface to other languages using JSON over stdin/stdout. Originally created at BackType, before being open sourced in September 2011 after the acquisition of BackType by Twitter. Donated to the Apache Foundation in September 2013, graduating in September 2014, with a 1.0 release in April 2016. Has multiple reference cases for being deployed at scale, including Twitter, and is still under active development.<tr><td> <a href="http://ondataengineering.net/technologies/apache-tajo/">Apache Tajo</a><td>Distributed analytical database engine. Supports HDFS, Amazon S3, Google Cloud Storage, OpenStack Swift and local storage, and querying over Postgres, HBase and Hive tables. Provides a standard SQL interface, JDBC driver, and supports partitioning, compression and indexing (currently experimental). An Apache project, donated by Gruter in March 2013, and graduated in April 2014. Java based, with development lead by Gruter who also supply commercial support, a Tajo managed service, a data analytics hub (Qrytica) built on Tajo, and a Tajo Data Warehouse appliance.<tr><td> <a href="http://ondataengineering.net/technologies/apache-tez/">Apache Tez</a><td>Data processing framework based on Directed Acyclic Graphs (DAGs), that runs natively on YARN and was designed to be a replacement for the use of MapReduce within Hadoop analytical tools (primarily Hive and Pig), and therefore offer better performance with similar scalability. Targeted more at application developers rather than data engineers, includes a number of performance optimisations (including dynamic DAG re-configuration during execution and re-use of sessions and containers), and comes with a UI for viewing live and historic Tez job executions based on information in the YARN Application Timeline Server. Created by Hortonworks and donated to the Apache Foundation in February 2013 before graduating in July 2014. Still under active development, and now used by Cascading and Flink in addition to Hive and Pig.<tr><td> <a href="http://ondataengineering.net/technologies/apache-whirr/">Apache Whirr</a><td>A set of libraries (now moved to the Apache Attic and no longer maintained) for deploying and managing a supported set of services in a cloud environment. Written in Java, with explicit support for a set of standard services (including Hadoop, Cassandra, HBase, Elasticsearch and Solr) configured through property files. Uses jclouds to provision and manage cloud infrastructure, and provides both a CLI and Java API. Originally a set of python scripts maintained as an Hadoop contrib project. Donated to the Apache Foundation in May 2010, graduating in August 2011. Development ceased in September 2012, with the project being moved to the Apache Attic in March 2015.<tr><td> <a href="http://ondataengineering.net/technologies/apache-zeppelin/">Apache Zeppelin</a><td>A web based notebook for interactive data analytics. Supports a wide range of interpreters (including Spark, JDBC SQL, Pig, Elasticsearch, Beam, Flink, Shell, Python amongst many others), a range of output formats (plain text, HTML, mathematical expressions using MathJax and tabular data), a range of visualisations for tabular data (including the ability to add more via a JavaScript NPM based plugin system called Helium), forms for user entry of parameters, and an Angular API to enable dynamic and interactive functionality within notebooks. Has a plugable storage for notebooks (with out of the box support for git, S3, Azure and ZeppelinHub), support for multi-user environments and a security model. Open sourced by NFLabs (now called ZEPL) in 2013 before being donated to the Apache Foundation in December 2014, graduating in May 2016. Under active development with a wide range of contributors, led by ZEPL, who sell Zeppelin as a managed service (ZepplinHub).<tr><td> <a href="http://ondataengineering.net/technologies/apache-zookeeper/">Apache ZooKeeper</a><td>Service for managing coordination (e.g. configuration information and synchronisation) of distributed and clustered systems. Based on a hierarchical key-value store, with support for things such as sequential nodes (whose names are automatically assigned a sequence number suffix), ephemeral nodes (which only exist whilst their owners session exists) and the ability to watch nodes. Guarantees that all writes are serial and ordered (i.e. all clients will see them in the same order), meaning it's more appropriate for low write high read scenarios. Can run in a high available cluster called an ensemble. Originally an Hadoop sub-project, but graduated to a top level Apache project in January 2011. Java based, still under active development, and used by a range of technologies including Hadoop, Mesos, HBase, Kafka and Solr.</table><h2 id="links">Links</h2><ul><li><a href="https://www.apache.org/">https://www.apache.org/</a> - homepage<li><a href="https://www.apache.org/foundation/how-it-works.html">https://www.apache.org/foundation/how-it-works.html</a> - information on the foundation</ul><h2 id="news">News</h2><ul><li><a href="http://apache.org/foundation/mailinglists.html#foundation-announce">http://apache.org/foundation/mailinglists.html#foundation-announce</a> - the Apache Foundation announcements mailing list<li><a href="https://blogs.apache.org/">https://blogs.apache.org/</a>; <a href="https://blogs.apache.org/planet/feed/entries/rss">https://blogs.apache.org/planet/feed/entries/rss</a> - The set of Apache Foundation blogs</ul><ul></ul><h2>Blog Posts</h2><ul class="side-nav"><li> <a href="http://ondataengineering.net/blog/2017/01/20/core-hadoop-technologies-pt3/"> <span class="font-size-h5 pr20">Core Hadoop Technologies (pt3)</span> <span id="page-meta" class="font-size-small"> <span class="pr10 icon-calendar"> 2017-01-20</span> <span class="pr10 icon-archive"> Technologies</span> <span class="pr10 icon-price-tag"> Apache</span> <span class="pr10 icon-price-tag"> Avro</span> <span class="pr10 icon-price-tag"> Parquet</span> <span class="pr10 icon-price-tag"> Kafka</span> <span class="pr10 icon-price-tag"> Pig</span> <span class="pr10 icon-price-tag"> Oozie</span> <span class="pr10 icon-price-tag"> Kafka Connect</span> <span class="pr10 icon-price-tag"> Kafka Streams</span> <span class="pr10 icon-edit"> Peter</span> </span> </a><li> <a href="http://ondataengineering.net/blog/2017/01/13/core-hadoop-technologies-pt2/"> <span class="font-size-h5 pr20">Core Hadoop Technologies (pt2)</span> <span id="page-meta" class="font-size-small"> <span class="pr10 icon-calendar"> 2017-01-13</span> <span class="pr10 icon-archive"> Technologies</span> <span class="pr10 icon-price-tag"> Apache</span> <span class="pr10 icon-price-tag"> Solr</span> <span class="pr10 icon-price-tag"> Sqoop</span> <span class="pr10 icon-price-tag"> Spark</span> <span class="pr10 icon-price-tag"> GraphX</span> <span class="pr10 icon-price-tag"> MLlib</span> <span class="pr10 icon-price-tag"> Spark SQL</span> <span class="pr10 icon-price-tag"> Spark Streaming</span> <span class="pr10 icon-edit"> Peter</span> </span> </a><li> <a href="http://ondataengineering.net/blog/2017/01/06/core-hadoop-technologies/"> <span class="font-size-h5 pr20">Core Hadoop Technologies (pt1)</span> <span id="page-meta" class="font-size-small"> <span class="pr10 icon-calendar"> 2017-01-06</span> <span class="pr10 icon-archive"> Technologies</span> <span class="pr10 icon-price-tag"> Flume</span> <span class="pr10 icon-price-tag"> HBase</span> <span class="pr10 icon-price-tag"> Hive</span> <span class="pr10 icon-price-tag"> Apache</span> <span class="pr10 icon-price-tag"> HCatalog</span> <span class="pr10 icon-price-tag"> Hive Metastore</span> <span class="pr10 icon-price-tag"> Hive Server</span> <span class="pr10 icon-edit"> Peter</span> </span> </a><li> <a href="http://ondataengineering.net/blog/2016/12/16/apache-hadoop/"> <span class="font-size-h5 pr20">Apache Hadoop</span> <span id="page-meta" class="font-size-small"> <span class="pr10 icon-calendar"> 2016-12-16</span> <span class="pr10 icon-archive"> Technologies</span> <span class="pr10 icon-price-tag"> Hadoop</span> <span class="pr10 icon-price-tag"> HDFS</span> <span class="pr10 icon-price-tag"> YARN</span> <span class="pr10 icon-price-tag"> MapReduce</span> <span class="pr10 icon-price-tag"> Apache</span> <span class="pr10 icon-edit"> Peter</span> </span> </a><li></ul></span></article><div class="row b30"></div></div><div class="medium-3 columns medium-pull-9"><aside><div class="panel sidebar radius"><p>OnDataEngineering is a collaboratively authored site on the transformation and preparation of data for analytics, licensed under a Creative Commons Licence. Read more <a href="/site/">here</a><p>For details on how to contribute to this site see <a href="/site/contributing/">here</a></div><div class="panel sidebar radius b0"><p>Spotted a typo or error on this page, or have content to add to it? <a href="https://github.com/OnDataEngineering/OnDataEngineeringContent/edit/master/_tech-vendors/apache.md">Edit</a> it and send us your proposed changes<p>Have questions to ask on, or changes to propose to the contents of this page? <a href="http://discourse.ondataengineering.net/t/the-apache-software-foundation">Discuss</a> them on its Discourse topic<p>Want to discuss this or other technologies? See the <a href="http://discourse.ondataengineering.net/c/technologies">Technologies</a> category of our Discourse forums<p><p> See the <a href="https://github.com/OnDataEngineering/OnDataEngineeringContent/commits/master/_tech-vendors/apache.md">history</a> of this page, or <a href="https://github.com/OnDataEngineering/OnDataEngineeringContent/blob/master/_tech-vendors/apache.md">view</a> this page in GitHub.</div></aside></div></div></div><div id="up-to-top" class="row"><div class="small-12 columns text-right"> <a class="iconfont" href="#top-of-page">&#xf108;</a></div></div><footer><div class="row"><div class="columns"><div id="footer" class="row panel radius" style="margin: 0px"><div class="medium-6 large-5 columns"><h5>Licencing</h5><p> <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a> <br /> The contents of <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type">OnDataEngineering.net</span> is licensed under the <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. For full details see <a xmlns:cc="http://creativecommons.org/ns#" href="http://ondataengineering.net/site/content-license/" rel="cc:morePermissions">here</a>.</div><div class="small-6 medium-3 large-3 large-offset-1 columns"><h5>Subscribe by</h5><ul class="no-bullet"><li > <a href="" title=""></a><li > <a href="https://twitter.com/OnDataEng" target="_blank" title="Follow us on twitter">Twitter</a><li > <a href="http://eepurl.com/cyQSqv" target="_blank" title="Subscribe to updates by e-mail">E-Mail</a><li > <a href="/atom.xml" title="Subscribe to Atom Feed">Atom</a><li > <a href="/feed.xml" title="Subscribe to RSS Feed">RSS</a></ul></div><div class="small-6 medium-3 large-3 columns"><h5>Credits</h5><ul class="no-bullet"><li > <a href="" title=""></a><li > <a href="http://jekyllrb.com/" target="_blank" title="Jekyll">Jekyll</a><li > <a href="http://phlow.github.io/feeling-responsive/" target="_blank" title="Feeling Responsive">Feeling Responsive</a><li > <a href="http://foundation.zurb.com/" target="_blank" title="Foundation">Foundation</a><li > <a href="http://entypo.com/" target="_blank" title="Icons by Daniel Bruce">Icons by Daniel Bruce</a><li > <a href="http://jch.penibelst.de/" target="_blank" title="Jekyll Compress HTML">Jekyll Compress HTML</a></ul></div></div></div></div></footer><script src="/assets/js/app.min.js"></script> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-88912556-1', 'auto'); ga('set', 'anonymizeIp', true); ga('send', 'pageview'); </script>
